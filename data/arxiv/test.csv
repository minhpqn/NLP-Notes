"id","title","abstract","category"
"2004.12573","Bayesian Learning of Probabilistic Dipole Inversion for Quantitative   Susceptibility Mapping","  A learning-based posterior distribution estimation method, Probabilistic Dipole Inversion (PDI), is proposed to solve quantitative susceptibility mapping (QSM) inverse problem in MRI with uncertainty estimation. A deep convolutional neural network (CNN) is used to represent the multivariate Gaussian distribution as the approximated posterior distribution of susceptibility given the input measured field. In PDI, such CNN is firstly trained on healthy subjects dataset with labels by maximizing the posterior Gaussian distribution loss function as used in Bayesian deep learning. When tested on new dataset without any label, PDI updates the pre-trained network in an unsupervised fashion by minimizing the KL divergence between the approximated posterior distribution represented by CNN and the true posterior distribution given the likelihood distribution from known physical model and prior distribution. Based on our experiments, PDI provides additional uncertainty estimation compared to the conventional MAP approach, meanwhile addressing the potential discrepancy issue of CNN when test data deviates from training dataset. ","eess"
"1908.01621","Extending parton branching TMDs to small $x$","  We explore the possibility to include small-$x$ dynamics effects in the parton branching (PB) approach to transverse momentum dependent (TMD) parton distribution functions. To this end, we first revisit the PB method at leading order, presenting a new fit to inclusive-DIS precision data, and performing a numerical study of the dynamic soft-gluon resolution scale. Next we investigate the effects of modified CCFM kernels, including both Sudakov and non-Sudakov form factors. ","hep-ph"
"1906.10356","Millimeter-Wave Path Loss at 73 GHz in Indoor and Outdoor Airport   Environments","  In this paper, two large-scale fading path loss models are presented based on indoor and outdoor channel measurements at 73 GHz. The line-of-sight millimeter-wave propagation measurement campaigns were uniquely conducted within the indoor and outdoor environments at an airport setting, i.e., the Boise Airport. The channel measurements were made with directional transmit and receive antennas with a 24 dBi gain at different receive antenna heights. From the measured data, we obtained the parameters of two path loss models, i.e., the close-in reference distance model (CIM) and the floating-intercept model (FIM). Results show that the path loss exponents estimated from the CIM are very close to that of the free-space path loss model, while the FIM provides a better fit to the measurement data. ","eess"
"1905.10272","Exploring Evolving Plants as Interacting Particles in a Randomly   Generated Heterogeneous Environment","  We model evolution of plants in a world, made up of different locations, with multiple environments (mutually exclusive and collectively exhaustive subsets of locations). Each environment (landmass) has temperature, rainfall, and other attributes that directly affect plant growth and reproduction. Each plant has preferences for environment attributes. Depending on how suitable the environment is to the plants, seeds are released or death occurs. With every reproductive cycle, genetic mutations occur. To model competition, plants in compete for survival, and success is stochastically dependent on environmental fitness. Our model determines whether and how evolution occurs, and how the attributes of plants change and possibly converge over time in relation to the attributes of the environment. ","q-bio"
"1910.01033","Dynamic emergence of fragmenting, exploding cages of irradiated   single-walled carbon nanotubes and C60","  Experimental results from irradiated-carbon nanostructures can be partially explained by selective applications of classical damage theories and ad-hoc thermal models by treating the binary atomic collision cascades and multi-atomic thermal spikes as energy-dissipating mechanisms. An information-theoretic model is developed by treating the irradiated single-walled carbon nanotubes and C60 as entropy-generating dissipative structures. The model is based on evaluating the experimental probability distribution functions of the sputtered constituents and components from the irradiated carbon nanostructures that yield their Shannon entropy or information. Three information-based functions of fractal dimension, relative entropy and dynamic emergence are defined and employed to characterize the profiles of self-organizing, information-generating dissipative structures. Fractal dimension determines the space-filling character, relative entropy establishes the distance between any two of the dissipative structures. Dynamic emergence function provides the profile of the emerging sequences. Results derived from the existing theories and thermal models are compared with the information-theoretic dynamic emergence model to comprehensively describe the nature of the dissipative structures in irradiated carbon nanostructures without making apriori assumptions about the energy-dissipating mechanisms. ","cond-mat"
"1901.11248","Triplet superconductivity in ferromagnets due to magnon exchange","  We consider the superconducting pairing induced by spin waves exchange in a ferromagnet with both conduction and localized electrons, the latter being described as spins. We use the microscopic Eliashberg theory to describe the pairing of conducting electrons and the RPA approach to treat the localized spins assuming an exchange coupling between the conducting electrons and spins. In the framework of non relativistic Hamiltonian twe found that he spin wave exchange results in equal spin electron pairing described by the two components of the order parameter, $\Delta^{\uparrow}$ (both spins up) and $\Delta^{\downarrow}$ (both spins down). Due to the conservation of total spin projection on the axis of the spontaneous ferromagnetic moment, the spin wave exchange at low temperatures includes an emission of magnons and an absorption of thermal magnons by the conduction electrons. The absorption and emission processes depend differently on the temperature, with the absorption being progressively suppressed as the temperature drops. As a result, the superconducting pairing exists only if the electron-spin wave exchange parameter $g$ exceeds some critical value $g_c$. At $g>g_c$ pairing vanishes if the temperature drops below the lowest point $T_{cl}$ or increases above the upper critical point $T_{ch} \approx T_m$ (the Curie temperature) where the spin waves cease to exist. This behavior inherent to the spin carrying glue is in an obvious disagreement with the results of conventional BCS approach which assumes that the effective electron-electron attraction is simply proportional to the static magnetic susceptibility. ","cond-mat"
"1704.03005","Functional Regression on Manifold with Contamination","  We propose a new method for functional nonparametric regression with a predictor that resides on a finite-dimensional manifold but is only observable in an infinite-dimensional space. Contamination of the predictor due to discrete/noisy measurements is also accounted for. By using functional local linear manifold smoothing, the proposed estimator enjoys a polynomial rate of convergence that adapts to the intrinsic manifold dimension and the contamination level. This is in contrast to the logarithmic convergence rate in the literature of functional nonparametric regression. We also observe a phase transition phenomenon regarding the interplay of the manifold dimension and the contamination level. We demonstrate that the proposed method has favorable numerical performance relative to commonly used methods via simulated and real data examples. ","stat"
"2008.09726","Variational approach to time-dependent fluorescence of a driven qubit","  We employ the Dirac-Frenkel variational principle and multiple Davydov ansatz to study time-dependent fluorescence spectra of a driven qubit in the weak- to strong qubit-reservoir coupling regimes, where both the Rabi frequency and spontaneous decay rate are comparable to the transition frequency of the qubit. Our method agrees well with the time-local master-equation approach in the weak-coupling regime, and offers a flexible way to compute the spectra from the bosonic dynamics instead of two-time correlation functions. While the perturbative master equation breaks down in the strong-coupling regime, our method actually becomes more accurate due to the use of bosonic coherent states under certain conditions. We show that the counter-rotating coupling between the qubit and the reservoir has considerable contributions to the photon number dynamics and the spectra under strong driving conditions even though the coupling is moderately weak. The time-dependent spectra are found to be generally asymmetric, a feature that is derived from photon number dynamics. In addition, it is shown that the spectral profiles can be dramatically different from the Mollow triplet due to strong dissipation and/or multiphoton processes associated with the strong driving. Our formalism provides a unique perspective to interpret time-dependent spectra. ","quant-ph"
"1911.01127","Generalized Stueckelberg-Higgs gauge theories","  The aim of this work is to discuss and explorer some generalized aspects of generation of photon mass respecting gauge symmetry. So with this intention we introduce the generalized Stueckelberg and Higgs gauge theories and present the classical and quantum conceptual aspects. We construct the quantum theory by writing the transition amplitude in the Fadeev-Senjanovic formalism and put it in a covariant form by the Fadeev-Popov method. Posteriorly we analyze the independence of physics by gauge choices via BRST symmetry. As we will see, the Stueckelberg structure has influence in the quantization process of the Higgs theory in the Gerardus 't Hooft shape, in which we see an intimate relationship between the Stueckelberg compensating field and the Goldstone boson. The degrees of freedom are explored not only in the quantization process, due to the constraints in gauge theories, but also in the Goldstone theorem, wherein we understand how the generalized gauge field eat the Goldstone boson and acquire mass. ","hep-th"
"1906.02822","The Political Significance of Social Penumbras","  To explain the political clout of different social groups, traditional accounts typically focus on the group's size, resources, or commonality and intensity of its members' interests. We contend that a group's ""penumbra""-the set of individuals who are personally familiar with people in that group--is another important explanatory factor that merits systematic analysis. To this end, we designed a panel study that allows us to learn about the characteristics of the penumbras of politically relevant groups such as gay people, the unemployed or recent immigrants. Our study reveals major and systematic differences in the penumbras of various social groups, even ones of similar size. Moreover, we find evidence that entering a group's penumbra is associated with a change in attitude on related political questions. Taken together, our findings suggest that penumbras help account for variation in the political standing of different groups in society. ","stat"
"1912.03914","Prospects for detecting $SU(2)_L$ hidden sector bosons at ILC","  We investigate the possibility of detecting hidden vector gauge bosons at ILC linear collider. The study is performed in the framework of hidden sector extension of Standard Model with 3 degenerate dark gauge bosons. By studying the cross section of pair dark gauge boson with photon at initial state radiation we found that at the energy $\sqrt{s} \approx$ 1300 GeV the cross section can be as large as $48fb$, the same order ($\mathcal{O}(fb)$) with the irreducible background of the Standard Model. Hence more methods needed to be done to eliminate the background for this model. ","hep-ph"
"2001.10005","Constraints on the density distribution of type Ia supernovae ejecta   inferred from late-time light-curve flattening","  The finite time, $\tau_{\rm dep}$, over which positrons from $\beta^{+}$ decays of $^{56}$Co deposit energy in type Ia supernovae ejecta lead, in case the positrons are trapped, to a slower decay of the bolometric luminosity compared to an exponential decline. Significant light-curve flattening is obtained when the ejecta density drops below the value for which $\tau_{\rm dep}$ equals the $^{56}$Co life-time. We provide a simple method to accurately describe this ""delayed deposition"" effect, which is straightforward to use for analysis of observed light curves. We find that the ejecta heating is dominated by delayed deposition typically from 600 to 1200~day, and only later by longer lived isotopes $^{57}$Co and $^{55}$Fe decay (assuming solar abundance). For the relatively narrow $^{56}$Ni velocity distributions of commonly studied explosion models, the modification of the light curve depends mainly on the $^{56}$Ni mass-weighted average density, $\langle \rho \rangle t^{3}$. Accurate late-time bolometric light curves, which may be obtained with JWST far-infrared (far-IR) measurements, will thus enable to discriminate between explosion models by determining $\langle \rho \rangle t^3$ (and the $^{57}$Co and $^{55}$Fe abundances). The flattening of light curves inferred from recent observations, which is uncertain due to the lack of far-IR data, is readily explained by delayed deposition in models with $\langle \rho\rangle t^{3} \approx 0.2\,M_{\odot}\,(10^{4}\, \textrm{km}\,\textrm{s}^{-1})^{-3}$, and does not imply supersolar $^{57}$Co and $^{55}$Fe abundances. ","astro-ph"
"1901.08948","Gamma-ray burst localisation strategies for the SPHiNX hard X-ray   polarimeter","  SPHiNX is a proposed gamma-ray burst (GRB) polarimeter mission operating in the energy range 50-600 keV with the aim of studying the prompt emission phase. The polarisation sensitivity of SPHiNX reduces as the uncertainty on the GRB sky position increases. The stand-alone ability of the SPHiNX design to localise GRB positions is explored via Geant4 simulations. Localisation at the level of a few degrees is possible using three different routines. This results in a large fraction (> 80%) of observed GRBs having a negligible (< 5%) reduction in polarisation sensitivity due to the uncertainty in localisation. ","astro-ph"
"1910.06299","Placement and Allocation of Virtual Network Functions: Multi-dimensional   Case","  Network function virtualization (NFV) is an emerging design paradigm that replaces physical middlebox devices with software modules running on general purpose commodity servers. While gradually transitioning to NFV, Internet service providers face the problem of where to introduce NFV in order to make the most benefit of that; here, we measure the benefit by the amount of traffic that can be served in an NFV-enabled network. This problem is non-trivial as it is composed of two challenging subproblems: 1) placement of nodes to support virtual network functions (referred to as VNF-nodes); 2) allocation of the VNF-nodes' resources to network flows. This problem has been studied for the one-dimensional setting, where all network flows require one network function, which requires a unit of resource to process a unit of flow. In this work, we consider the multi-dimensional setting, where flows can require multiple network functions, which can also require a different amount of each resource to process a unit of flow. The multi-dimensional setting introduces new challenges in addition to those of the one-dimensional setting (e.g., NP-hardness and non-submodularity) and also makes the resource allocation subproblem a multi-dimensional generalization of the generalized assignment problem with assignment restrictions. To address these difficulties, we propose a novel two-level relaxation method that allows us to draw a connection to the sequence submodular theory and utilize the property of sequence submodularity along with the primal-dual technique to design two approximation algorithms. We further prove that the proposed algorithms have a non-trivial approximation ratio that depends on the number of VNF-nodes, resources, and a measure of the available resource compared to flow demand. Finally, we perform extensive trace-driven simulations to show the effectiveness of the proposed algorithms. ","cs"
"1910.00986","Visibility and Line-Of-Sight Extinction Estimates in Gale Crater during   the 2018/MY34 Global Dust Storm","  Northern line-of-sight extinction within Gale Crater during the 2018 global dust storm was monitored daily using MSL's Navcam. Additional observations with Mastcam (north) and Navcam (all directions) were obtained at a lower cadence. Using feature identification and geo-referencing, extinction was estimated in all possible directions. Peak extinction of $>1.1$ km$^{-1}$ was measured between sols 2086 and 2090, an order of magnitude higher than previous maxima. Northern and western directions show an initial decrease, followed by a secondary peak in extinction, not seen in column opacity measurements. Due to foreground topography, eastern direction results are provided only as limits, and southern results were indeterminable. Mastcam red and green filter results agree well, but blue filter results show higher extinctions, likely due to low signal-to-noise. Morning results are systematically higher than afternoon results, potentially indicative of atmospheric mixing. ","astro-ph"
"1909.05751","Controlled-phase Gate using Dynamically Coupled Cavities and Optical   Nonlinearities","  We propose an architecture for a high-fidelity deterministic controlled-phase gate between two photonic qubits using bulk optical nonlinearities in near-term feasible photonic integrated circuits. The gate is enabled by converting travelling continuous-mode photons into stationary cavity modes using strong classical control fields that dynamically change the cavity-waveguide coupling rate. This process limits the fidelity degrading noise pointed out by Shapiro [J. Shapiro, Phys. Rev. A, 73, 2006] and Gea-Banacloche [J. Gea-Banacloche, Phys. Rev. A, 81, 2010]. We show that high-fidelity gates can be achieved with self-phase modulation in $\chi^{\scriptscriptstyle(3)}$ materials as well as second-harmonic generation in $\chi^{\scriptscriptstyle(2)}$ materials. The gate fidelity asymptotically approaches unity with increasing storage time for a fixed duration of the incident photon wave packet. Further, dynamically coupled cavities enable a trade-off between errors due to loss and wave packet distortions since loss does not affect the ability to emit wave packets with the same shape as the incoming photons. Our numerical results show that gates with $99\%$ fidelity are feasible with near-term improvements in cavity loss using LiNbO$_3$ or GaAs. ","quant-ph"
"2002.12883","The ARF-AID system: Methods that preserve endogenous protein levels and   facilitate rapidly inducible protein degradation","  The ARF-AID (Auxin Response Factor-Auxin Inducible Degron) system is a re-engineered auxin-inducible protein degradation system. Inducible degron systems are widely used to specifically and rapidly deplete proteins of interest in cell lines and organisms. An advantage of inducible degradation is that the biological system under study remains intact and functional until perturbation. This feature necessitates that the endogenous levels of the protein are maintained. However, endogenous tagging of genes with AID can result in chronic, auxin-independent proteasome-mediated degradation. The additional expression of the ARF-PB1 domain in the re-engineered ARF-AID system prevents chronic degradation of AID-tagged proteins while preserving rapid degradation of tagged proteins. Here we describe the protocol for engineering human cell lines to implement the ARF-AID system for specific and inducible protein degradation. These methods are adaptable and can be extended from cell lines to organisms. ","q-bio"
"1902.04701","Efficient Bayesian shape-restricted function estimation with constrained   Gaussian process priors","  This article revisits the problem of Bayesian shape-restricted inference in the light of a recently developed approximate Gaussian process that admits an equivalent formulation of the shape constraints in terms of the basis coefficients. We propose a strategy to efficiently sample from the resulting constrained posterior by absorbing a smooth relaxation of the constraint in the likelihood and using circulant embedding techniques to sample from the unconstrained modified prior. We additionally pay careful attention to mitigate the computational complexity arising from updating hyperparameters within the covariance kernel of the Gaussian process. The developed algorithm is shown to be accurate and highly efficient in simulated and real data examples. ","stat"
"1909.13109","The quaternionic Monge-Amp\`{e}re operator and plurisubharmonic   functions on the Heisenberg group","  Many fundamental results of pluripotential theory on the quaternionic space $\mathbb{H}^n$ are extended to the Heisenberg group. We introduce notions of a plurisubharmonic function, the quaternionic Monge-Amp\`{e}re operator, differential operators $d_0$ and $d_1$ and a closed positive current on the Heisenberg group. The quaternionic Monge-Amp\`{e}re operator is the coefficient of $ (d_0d_1u)^n$. We establish the Chern-Levine-Nirenberg type estimate, the existence of quaternionic Monge-Amp\`{e}re measure for a continuous quaternionic plurisubharmonic function and the minimum principle for the quaternionic Monge-Amp\`{e}re operator. Unlike the tangential Cauchy-Riemann operator $ \overline{\partial}_b $ on the Heisenberg group which behaves badly as $ \partial_b\overline{\partial}_b\neq -\overline{\partial}_b\partial_b $, the quaternionic counterpart $d_0$ and $d_1$ satisfy $ d_0d_1=-d_1d_0 $. This is the main reason that we have a better theory for the quaternionic Monge-Amp\`{e}re operator than $ (\partial_b\overline{\partial}_b)^n$. ","math"
"1907.08231","Dark matter in Inert Doublet Model with one scalar singlet and $U(1)_X$   gauge symmetry","  We study Dark Matter (DM) abundance in the framework of the extension of the Standard Model (SM) with an additional $U(1)_X$ gauge symmetry. One complex singlet is included to break the $U(1)_X$ gauge symmetry, meanwhile one of the doublets is considered inert to introduce a DM candidate. The stability of the DM candidate is analyzed with a continuous $U(1)_X$ gauge symmetry as well as discrete $Z_2$ symmetry. We find allowed regions for the free model parameters which are in agreement with the most up-to-date experimental results reported by CMS and ATLAS collaborations, the upper limit on WIMP-nucleon cross section imposed by XENON1T collaboration and the upper limit on the production cross-section of a $Z^{\prime}$ gauge boson times the branching ratio of the $Z^{\prime}$ boson decaying into $\ell^-\ell^+$. We also obtain allowed regions for the DM candidate mass from the relic density reported by the PLANCK collaboration including light, intermediate and heavy masses; depending mainly on two parameters of the scalar potential, $\lambda_{2x}$ and $\lambda_{345}=\lambda_3+\lambda_4+2\lambda_5$. We find that trough $pp\rightarrow \chi\chi \gamma$ production, it may only be possible for a future hadron-hadron Circular Collider (FCC-hh) to be able to detect a DM candidate within the range of masses 10-60 GeV. ","hep-ph"
"1906.12242","Bidirectional Type Class Instances (Extended Version)","  GADTs were introduced in Haskell's eco-system more than a decade ago, but their interaction with several mainstream features such as type classes and functional dependencies has a lot of room for improvement. More specifically, for some GADTs it can be surprisingly difficult to provide an instance for even the simplest of type classes.   In this paper we identify the source of this shortcoming and address it by introducing a conservative extension to Haskell's type classes: Bidirectional Type Class Instances. In essence, under our interpretation class instances correspond to logical bi-implications, in contrast to their traditional unidirectional interpretation.   We present a fully-fledged design of bidirectional instances, covering the specification of typing and elaboration into System FC, as well as an algorithm for type inference and elaboration. We provide a proof-of-concept implementation of our algorithm, and revisit the meta-theory of type classes in the presence of our extension. ","cs"
"2006.00239","Normalized solutions for the fractional NLS with mass supercritical   nonlinearity","  We investigate the existence of solutions to the fractional nonlinear Schr\""{o}dinger equation $(-\Delta)^s u = f(u)$ with prescribed $L^2$-norm $\int_{\mathbb{R}^N} |u|^2 \, dx =m$ in the Sobolev space $H^s(\mathbb{R}^N)$. Under fairly general assumptions on the nonlinearity $f$, we prove the existence of a ground state solution and a multiplicity result in the radially symmetric case. ","math"
"2005.09001","Non-Relativistic Supersymmetry on Curved Three-Manifolds","  We construct explicit examples of non-relativistic supersymmetric field theories on curved Newton-Cartan three-manifolds. These results are obtained by performing a null reduction of four-dimensional supersymmetric field theories on Lorentzian manifolds and the Killing spinor equations that their supersymmetry parameters obey. This gives rise to a set of algebraic and differential Killing spinor equations that are obeyed by the supersymmetry parameters of the resulting three-dimensional non-relativistic field theories. We derive necessary and sufficient conditions that determine whether a Newton-Cartan background admits non-trivial solutions of these Killing spinor equations. Two classes of examples of Newton-Cartan backgrounds that obey these conditions are discussed. The first class is characterised by an integrable foliation, corresponding to so-called twistless torsional geometries, and includes manifolds whose spatial slices are isomorphic to the Poincar\'e disc. The second class of examples has a non-integrable foliation structure and corresponds to contact manifolds. ","hep-th"
"1905.13610","Arithmetic Chern-Simons theory with real places","  The goal of this paper is two folds: we generalize the arithmetic Chern-Simons theory over totally imaginary number fields to arbitrary number fields (with real places) and provide new examples of non-trivial arithmetic Chern-Simons invariant with coefficient $\mathbb{Z}/n\mathbb{Z}$ $ (n \geq 2)$ associated to a non-abelian gauge group. The main idea for the generalization is to use cohomology with compact support to deal with real places. So far, the non-trivial examples are limited to some non-abelian gauge group with coefficient $\mathbb{Z}/2\mathbb{Z}$ and the abelian cyclic gauge group with coefficient $\mathbb{Z}/n\mathbb{Z}$. Our non-trivial examples with non-abelian gauge group and general coefficient $\mathbb{Z}/n\mathbb{Z}$ will be given by a simple twisting argument. In the appendix, we explain alternative method of generalization based on the work of Zink and Conrad-Masullo. ","math"
"1901.02235","Pressure-induced densification of vitreous silica: insight from elastic   properties","  \textit{In situ} high-pressure Brillouin light scattering experiments along loading-unloading paths are used to investigate the compressibility of vitreous silica. An accurate equation of state is obtained below \SI{9}{GPa} using sound velocities corrected for dispersion. Conversely, huge inelastic effects are observed in the range \SIrange{10}{60}{GPa}, unveiling the reversible transformation from the fourfold-coordinated structure to the sixfold one. We find that the associated density changes fully correlate with the average Si coordination number. Decompression curves from above \SI{20}{GPa} reveal abrupt backward coordination changes around \SIrange{10}{15}{GPa} and significant hysteresis. Further, contrary to common wisdom, the residual densification of recovered silica samples can be figured out from the pressure cycles. ","cond-mat"
"1612.01343","Phonon scattering limited mobility in the representative cubic   perovskite semiconductors SrGeO$_3$, BaSnO$_3$ and SrTiO$_3$","  Cubic perovskite oxides are emerging high-mobility transparent conducting oxides (TCOs), but Ge-based TCOs had not been known until the discovery of metastable cubic SrGeO$_3$. $0.5 \times 0.4 \times 0.2$-mm$^3$ large single crystals of the cubic SrGeO$_3$ perovskite were successfully synthesized employing the high-pressure flux method. The phonon spectrum is determined from the IR optical reflectance and Raman-scattering analysis to evaluate the electron transport governed by optical phonon scattering. A calculated room-temperature mobility on the order of $3.9 \times 10^2$ cm$^2$V$^{-1}$s$^{-1}$ is obtained, identifying cubic SrGeO$_3$ as one of the most promising TCOs. Employing classical phonon theory and a combined experimental-theoretical approach, a comprehensive analysis of the intrinsic electron mobility in the cubic perovskite semiconductors SrGeO$_3$, BaSnO$_3$, and SrTiO$_3$ is provided based on the magnitude of polarization and eigenfrequency of optically active phonons. ","cond-mat"
"1705.09707","Krieger's finite generator theorem for actions of countable groups III","  We continue the study of Rokhlin entropy, an isomorphism invariant for probability-measure-preserving actions of countable groups introduced in Part I. In this paper we prove a non-ergodic finite generator theorem and use it to establish sub-additivity and semi-continuity properties of Rokhlin entropy. We also obtain formulas for Rokhlin entropy in terms of ergodic decompositions and inverse limits. Finally, we clarify the relationship between Rokhlin entropy, sofic entropy, and classical Kolmogorov--Sinai entropy. In particular, using Rokhlin entropy we give a new proof of the fact that ergodic actions with positive sofic entropy have finite stabilizers. ","math"
"2002.08077","The role of disc torques in forming resonant planetary systems","  The most accurate method for modelling planetary migration and hence the formation of resonant systems is using hydrodynamical simulations. Usually, the force (torque) acting on a planet is calculated using the forces from the gas disc and the star, while the gas accelerations are computed using the pressure gradient, the star, and the planet's gravity, ignoring its own gravity. For the non-migrating the neglect of the disc gravity results in a consistent torque calculation while for the migrating case it is inconsistent. We aim to study how much this inconsistent torque calculation can affect the final configuration of a two-planet system. Our focus will be on low-mass planets because most of the multi-planetary systems, discovered by the Kepler survey, have masses around 10 Earth masses. Performing hydrodynamical simulations of planet-disc interaction, we measure the torques on non-migrating and migrating planets for various disc masses as well as density and temperature slopes with and without considering the disc self-gravity. Using this data, we find a relation that quantifies the inconsistency, use it in an N-body code, and perform an extended parameter study modelling the migration of a planetary system with different planet mass ratios and disc surface densities, in order to investigate the impact of the torque inconsistency on the architecture of the planetary system. Not considering disc self-gravity produces an artificially larger torque on the migrating planet that can result in tighter planetary systems. The deviation of this torque from the correct value is larger in discs with steeper surface density profiles. In hydrodynamical modelling of multi-planetary systems, it is crucial to account for the torque correction, otherwise the results favour more packed systems. ","astro-ph"
"2008.00856","Multiport based teleportation -- protocol and its performance","  We propose a novel multi-port teleportation scheme performing transmission of a number of unknown quantum states or one composite system in one go. Teleported states arrive on several ports on the receiver's side. Using equivalence between the teleportation process and state discrimination task we derive a lower bound on the performance of the protocol, measured in the entanglement fidelity. Obtained bound is effective, in the sense it depends only on the global parameters like the number of teleported states, the number of ports, and the dimension of the underlying Hilbert space. The lower bound outperform the explicit values of the entanglement fidelity calculated for the non- and optimal port-based teleportation with the minimal possible dimension of the port. We show that the number of teleported systems can grow when the number $N$ of ports increases. We further obtain that maximal number of faithfully teleported systems differs qualitatively in deterministic and probabilistic scheme: it scales as $o(N)$ and $o(\sqrt{N})$ respectively. In the end, we deliver closed-form expressions for the entanglement fidelity as well as for the probability of success in the qubit case in the picture of the spin angular momentum. ","quant-ph"
"1904.00119","A Space-based Decametric Wavelength Radio Telescope Concept","  This paper reports a design study for a space-based decametric wavelength telescope. While not a new concept, this design study focused on many of the operational aspects that would be required for an actual mission. This design optimized the number of spacecraft to insure good visibility of approx. 80% of the radio galaxies -- the primary science target for the mission. A 5,000 km lunar orbit was selected to guarantee minimal gravitational perturbations from Earth and lower radio interference. Optimal schemes for data downlink, spacecraft ranging, and power consumption were identified. An optimal mission duration of 1 year was chosen based on science goals, payload complexity, and other factors. Finally, preliminary simulations showing image reconstruction were conducted to confirm viability of the mission. This work is intended to show the viability and science benefits of conducting multi-spacecraft networked radio astronomy missions in the next few years. ","astro-ph"
"2005.12396","Generalised Schwarzschild metric from double copy of point-like charge   solution in Born-Infeld theory","  We discuss possible application of classical double copy procedure to construction of a generalisation of the Schwarzschild metric starting from an $\alpha'$-corrected open string analogue of Coulomb solution. The latter is approximated by a point-like charge solution of the Born-Infeld action, which represents the open string effective action for an abelian vector field in the limit when derivatives of the field strength are small. The Born-Infeld solution has a regular electric field which is constant near the origin, suggesting that corrections from derivative terms in the open string effective action may be small there. The generalization of the Schwarschild metric obtained by the double copy construction from the Born-Infeld solution looks non-singular but the corresponding curvature invariants still blow up at $r=0$. We discuss the origin of this singularity and comment on possible generalisations. ","hep-th"
"1906.03213","Tuning the exchange bias on a single atom from 1 mT to 10 T","  Shrinking spintronic devices to the nanoscale ultimately requires localized control of individual atomic magnetic moments. At these length scales, the exchange interaction plays important roles, such as in the stabilization of spin-quantization axes, the production of spin frustration, and creation of magnetic ordering. Here, we demonstrate the precise control of the exchange bias experienced by a single atom on a surface, covering an energy range of four orders of magnitude. The exchange interaction is continuously tunable from milli-eV to micro-eV by adjusting the separation between a spin-1/2 atom on a surface and the magnetic tip of a scanning tunneling microscope (STM). We seamlessly combine inelastic electron tunneling spectroscopy (IETS) and electron spin resonance (ESR) to map out the different energy scales. This control of exchange bias over a wide span of energies provides versatile control of spin states, with applications ranging from precise tuning of quantum state properties, to strong exchange bias for local spin doping. In addition we show that a time-varying exchange interaction generates a localized AC magnetic field that resonantly drives the surface spin. The static and dynamic control of the exchange interaction at the atomic-scale provides a new tool to tune the quantum states of coupled-spin systems. ","cond-mat"
"1912.08346","A consistency-test for determining whether ultra-compact dwarf galaxies   could be the remnant nuclei of threshed galaxies","  It has been suggested that ultra-compact dwarf (UCD) galaxies are the ""threshed'"" remains of larger galaxies. Simulations have revealed that extensive tidal-stripping may pare a galaxy back to its tightly-bound, compact nuclear star cluster. It has therefore been proposed that the two-component nature of UCD galaxies may reflect the original nuclear star cluster surrounded by the paltry remnants of its host galaxy. A simple quantitative test of this theory is devised and applied here. If the mass of the central black hole in UCD galaxies, relative to the mass of the UCD galaxies' inner stellar component, i.e. the suspected nuclear star cluster, matches with the (black hole mass)-(nuclear star cluster mass) relation observed in other galaxies, then it would provide quantitative support for the stripped galaxy scenario. Such consistency is found for four of the five UCD galaxies reported to have a massive black hole. The (black hole mass)-(nuclear star cluster mass) relation is then used to predict the central black hole mass in two additional UCD galaxies, and to reveal that NGC 205 and possibly NGC 404 (which only has an upper limit to its black hole mass) also follow this scaling relation. ","astro-ph"
"1904.08260","A silicon quantum-dot-coupled nuclear spin qubit","  Single nuclear spins in the solid state have long been envisaged as a platform for quantum computing, due to their long coherence times and excellent controllability. Measurements can be performed via localised electrons, for example those in single atom dopants or crystal defects. However, establishing long-range interactions between multiple dopants or defects is challenging. Conversely, in lithographically-defined quantum dots, tuneable interdot electron tunnelling allows direct coupling of electron spin-based qubits in neighbouring dots. Moreover, compatibility with semiconductor fabrication techniques provides a compelling route to scaling to large numbers of qubits. Unfortunately, hyperfine interactions are typically too weak to address single nuclei. Here we show that for electrons in silicon metal-oxide-semiconductor quantum dots the hyperfine interaction is sufficient to initialise, read-out and control single silicon-29 nuclear spins, yielding a combination of the long coherence times of nuclear spins with the flexibility and scalability of quantum dot systems. We demonstrate high-fidelity projective readout and control of the nuclear spin qubit, as well as entanglement between the nuclear and electron spins. Crucially, we find that both the nuclear spin and electron spin retain their coherence while moving the electron between quantum dots, paving the way to long range nuclear-nuclear entanglement via electron shuttling. Our results establish nuclear spins in quantum dots as a powerful new resource for quantum processing. ","quant-ph"
"2006.07431","Nano-photocurrent mapping of local electronic structure in twisted   bilayer graphene","  We report a combined nano-photocurrent and infrared nanoscopy study of twisted bilayer graphene (TBG) enabling access to the local electronic phenomena at length scales as short as 20 nm. We show that the photocurrent changes sign at carrier densities tracking the local superlattice density of states of TBG. We use this property to identify domains of varying local twist angle by local photo-thermoelectric effect. Consistent with the photocurrent study, infrared nano-imaging experiments reveal optical conductivity features dominated by twist-angle dependent interband transitions. Our results provide a fast and robust method for mapping the electronic structure of TBG and suggest that similar methods can be broadly applied to probe electronic inhomogeneities of moir\'e superlattices in other van der Waals heterostructures. ","cond-mat"
"1903.03330","Master Majorana neutrino mass parametrization","  After showing that the neutrino mass matrix in all Majorana models can be described by a general master formula, we will present a master parametrization for the Yukawa matrices, also valid for all Majorana models, that automatically ensures agreement with neutrino oscillation data. The application of the master parametrization will be illustrated in an example model. ","hep-ph"
"1903.12208","Magnetic susceptibility of topological semimetals","  We give a review of theoretical and experimental results concerning the magnetic susceptibility of the Weyl, Dirac, and nodal-line semimetals. In particular, dependences of the susceptibility on the chemical potential, temperature, and magnitude of the magnetic field are discussed. The presented results show that the specific features of the magnetic susceptibility can serve as a hallmark of the topological semimetals, and hence magnetic measurements can be useful in investigating these materials. ","cond-mat"
"1901.01729","Abnormal anti-crossing effect in photon-magnon coupling","  We report the experimental demonstration of an abnormal, opposite anti-crossing effect in a photon-magnon-coupled system that consists of an Yttrium Iron Garnet film and an inverted pattern of split-ring resonator structure (noted as ISRR) in a planar geometry. It is found that the normal shape of anti-crossing dispersion typically observed in photon-magnon coupling is changed to its opposite anti-crossing shape just by changing the position/orientation of the ISRR's split gap with respect to the microstrip line axis along which ac microwave currents are applied. Characteristic features of the opposite anti-crossing dispersion and its linewidth evolution are analyzed with the help of analytical derivations based on electromagnetic interactions. The observed opposite anti-crossing dispersion is ascribed to the compensation of both intrinsic damping and coupling-induced damping in the magnon modes. This compensation is achievable by controlling the relative strength and phase of oscillating magnetic fields generated from the ISRR's split gap and the microstrip feeding line. The position/orientation of an ISRR's split gap provides a robust means of controlling the dispersion shape of anti-crossing and its damping in a photon-magnon coupling, thereby offering more opportunity for advanced designs of microwave devices. ","cond-mat"
"1902.02875","Dynamical learning of dynamics","  The ability of humans and animals to quickly adapt to novel tasks is difficult to reconcile with the standard paradigm of learning by slow synaptic weight modification. Here we show that fixed-weight neural networks can learn to generate required dynamics by imitation. After appropriate weight pretraining, the networks quickly and dynamically adapt to learn new tasks and thereafter continue to achieve them without further teacher feedback. We explain this ability and illustrate it with a variety of target dynamics, ranging from oscillatory trajectories to driven and chaotic dynamical systems. ","q-bio"
"1811.10336","Kinematic strangeness production in cluster hadronization","  We present a modification to the non-perturbative strangeness production mechanisms in the Monte-Carlo event generator Herwig in order to make the processes more dynamic and collective. We compare the model to a series of observables for soft physics at both LEP and LHC. ","hep-ph"
"2008.07686","The Massive and Distant Clusters of WISE Survey. VIII. Radio Activity in   Massive Galaxy Clusters","  We present a study of the central radio activity of galaxy clusters at high redshift. Using a large sample of galaxy clusters at $0.7<z<1.5$ from the Massive and Distant Clusters of {\it WISE} Survey and the Faint Images of the Radio Sky at Twenty-Centimeters $1.4$~GHz catalog, we measure the fraction of clusters containing a radio source within the central $500$~kpc, which we term the cluster radio-active fraction, and the fraction of cluster galaxies within the central $500$~kpc exhibiting radio emission. We find tentative ($2.25\sigma$) evidence that the cluster radio-active fraction increases with cluster richness, while the fraction of cluster galaxies that are radio-luminous ($L_{1.4~\mathrm{GHz}}\geq10^{25}$~W~Hz$^{-1}$) does not correlate with richness at a statistically significant level. Compared to that calculated at $0 < z < 0.6$, the cluster radio-active fraction at $0 < z < 1.5$ increases by a factor of $10$. This fraction is also dependent on the radio luminosity. Clusters at higher redshift are much more likely to host a radio source of luminosity $L_{1.4~\mathrm{GHz}}\gtrsim10^{26}$~W~Hz$^{-1}$ than are lower redshift clusters. We compare the fraction of radio-luminous cluster galaxies to the fraction measured in a field environment. For $0.7<z<1.5$, we find that both the cluster and field radio-luminous galaxy fraction increases with stellar mass, regardless of environment, though at fixed stellar mass, cluster galaxies are roughly $2$ times more likely to be radio-luminous than field galaxies. ","astro-ph"
"2002.02464","Cosmology with quasars: predictions for eROSITA from a quasar Hubble   diagram","  Our group has developed a technique that makes use of the observed non-linear relation between the ultraviolet and the X-ray luminosity in quasars to provide an independent measurement of their distances, thus turning quasars into standardizable candles. This technique, at present, it is mostly based upon quasar samples with data from public catalogues both in the X-rays and in the optical/ultraviolet and extends the Hubble diagram of supernovae to a redshift range still poorly explored (z>2). From the X-ray perspective, we are now on the eve of a major change, as the upcoming mission eROSITA is going to provide us with up to ~3 millions of active galactic nuclei across the entire sky. Here we present predictions for constraining cosmological parameters such as the amount of dark matter ($\Omega_{\rm m}$), dark energy ($\Omega_\Lambda$) and the evolution of the equation of state of dark energy ($w$) through the Hubble diagram of quasars, based on the 4-year eROSITA all-sky survey. Our simulations show that the eROSITA quasars, complemented by redshift and broad-band photometric information, will supply the largest quasar sample at z<2, but with very few objects available for cosmology at higher redshifts that survives the cut for the Malmquist bias, as eROSITA will sample the brighter end of the X-ray luminosity function. The power of the quasar Hubble diagram for precision cosmology lies in the high-redshift regime, where quasars can be observed up to redshift ~7.5, essential to discriminate amongst different model extrapolations. Therefore, to be competitive for cosmology, the eROSITA quasar Hubble diagram must be complemented with the already available quasar samples and dedicated (deep) large programmes at redshift z>3. ","astro-ph"
"1903.09133","Loop Corrected Soft Photon Theorem as a Ward Identity","  Recently Sahoo and Sen obtained a series of remarkable results concerning sub-leading soft photon and graviton theorems in four dimensions. Even though the S- matrix is infrared divergent, they have shown that the sub-leading soft theorems are well defined and exact statements in QED and perturbative Quantum Gravity. However unlike the well studied Cachazo-Strominger soft theorems in tree-level amplitudes, the new sub-leading soft expansion is at the order ln {\omega} (where {\omega} is the soft frequency) and the corresponding soft factors structurally show completely different properties then their tree-level counterparts. Whence it is natural to ask if these theorems are associated to asymptotic symmetries of the S-matrix. We consider this question in the context of sub-leading soft photon theorem in scalar QED and show that there are indeed an infinity of conservation laws whose Ward identities are equivalent to the loop-corrected soft photon theorem. This shows that in the case of four dimensional QED, the leading and sub-leading soft photon theorems are equivalent to Ward identities of (asymptotic) charges. ","hep-th"
"1903.04530","Orthology: definitions, inference, and impact on species phylogeny   inference","  Orthology is a central concept in evolutionary and comparative genomics, used to relate corresponding genes in different species. In particular, orthologs are needed to infer species trees. In this chapter, we introduce the fundamental concepts of orthology relationships and orthologous groups, including some non-trivial (and thus commonly misunderstood) implications. Next, we review some of the main methods and resources used to identify orthologs. The final part of the chapter discusses the impact of orthology methods on species phylogeny inference, drawing lessons from several recent comparative studies. ","q-bio"
"1909.04366","Structured Modeling of Joint Deep Feature and Prediction Refinement for   Salient Object Detection","  Recent saliency models extensively explore to incorporate multi-scale contextual information from Convolutional Neural Networks (CNNs). Besides direct fusion strategies, many approaches introduce message-passing to enhance CNN features or predictions. However, the messages are mainly transmitted in two ways, by feature-to-feature passing, and by prediction-to-prediction passing. In this paper, we add message-passing between features and predictions and propose a deep unified CRF saliency model . We design a novel cascade CRFs architecture with CNN to jointly refine deep features and predictions at each scale and progressively compute a final refined saliency map. We formulate the CRF graphical model that involves message-passing of feature-feature, feature-prediction, and prediction-prediction, from the coarse scale to the finer scale, to update the features and the corresponding predictions. Also, we formulate the mean-field updates for joint end-to-end model training with CNN through back propagation. The proposed deep unified CRF saliency model is evaluated over six datasets and shows highly competitive performance among the state of the arts. ","cs"
"1910.08651","Hypergeometric Series Representations of Feynman Integrals by GKZ   Hypergeometric Systems","  We show that almost all Feynman integrals as well as their coefficients in a Laurent series in dimensional regularization can be written in terms of Horn hypergeometric functions. By applying the results of Gelfand-Kapranov-Zelevinsky (GKZ) we derive a formula for a class of hypergeometric series representations of Feynman integrals, which can be obtained by triangulations of the Newton polytope $\Delta_G$ corresponding to the Lee-Pomeransky polynomial $G$. Those series can be of higher dimension, but converge fast for convenient kinematics, which also allows numerical applications. Further, we discuss possible difficulties which can arise in a practical usage of this approach and give strategies to solve them. ","hep-th"
"1806.11320","On the Potential of Multi-Mode Antennas for Direction-of-Arrival   Estimation","  In this paper, we show that a multi-mode antenna (MMA) is an interesting alternative to a conventional phased antenna array for direction-of-arrival (DoA) estimation. By MMA we mean a single physical radiator with multiple ports, which excite different characteristic modes. In contrast to phased arrays, a closed-form mathematical model of the antenna response, like a steering vector, is not straightforward to define for MMAs. Instead one has to rely on calibration measurement or electromagnetic field (EMF) simulation data, which is discrete. To perform DoA estimation, array interpolation technique (AIT) and wavefield modeling (WM) are suggested as methods with inherent interpolation capabilities, fully taking antenna nonidealities like mutual coupling into account. We present a non-coherent DoA estimator for low-cost receivers and show how coherent DoA estimation and joint DoA and polarization estimation can be performed with MMAs. Utilizing these methods, we assess the DoA estimation performance of an MMA prototype in simulations for both 2D and 3D cases. The results show that WM outperforms AIT for high SNR. Coherent estimation is superior to non-coherent, especially in 3D, because non-coherent suffers from estimation ambiguities. In conclusion, DoA estimation with a single MMA is feasible and accurate. ","eess"
"2004.08036","IoT Smart City Architectures an Analytical Evaluation","  While several IoT architectures have been proposed for enabling smart city visions, not much work has been done to assess and compare these architectures. By applying our proposed evaluation framework that incorporates a variety of 33 criteria, this paper presents a comparative analysis of nine existing well-known IoT architectures. The results of the analysis highlight the strengths and weaknesses of these architectures and give insight to city leaders, architects, and developers aiming at selecting the most appropriate architecture or their combination that may fit their own specific smart city development scenario.   Keywords. Internet of things, IoT, smart city architecture, evaluation framework ","cs"
"2004.14492","Rethinking Class-Discrimination Based CNN Channel Pruning","  Channel pruning has received ever-increasing focus on network compression. In particular, class-discrimination based channel pruning has made major headway, as it fits seamlessly with the classification objective of CNNs and provides good explainability. Prior works singly propose and evaluate their discriminant functions, while further study on the effectiveness of the adopted metrics is absent. To this end, we initiate the first study on the effectiveness of a broad range of discriminant functions on channel pruning. Conventional single-variate binary-class statistics like Student's T-Test are also included in our study via an intuitive generalization. The winning metric of our study has a greater ability to select informative channels over other state-of-the-art methods, which is substantiated by our qualitative and quantitative analysis. Moreover, we develop a FLOP-normalized sensitivity analysis scheme to automate the structural pruning procedure. On CIFAR-10, CIFAR-100, and ILSVRC-2012 datasets, our pruned models achieve higher accuracy with less inference cost compared to state-of-the-art results. For example, on ILSVRC-2012, our 44.3% FLOPs-pruned ResNet-50 has only a 0.3% top-1 accuracy drop, which significantly outperforms the state of the art. ","cs"
"1907.03005","One-Way Coupled Tumor Response Model for   Combined-Hyperthermia-Radiotherapy Treatment with Anisotropic Scattering","  Therapies such as combined-hyperthermia-radiotherapy (CHR) take advantage of excellent radiosensitization properties of hyperthermia and treat of tumors with both radiation and heat. To appropriately model a CHR treatment, features like tumor heating (heat transfer), dosimetry (radiation transport), and tumor dynamics (cell population dynamics) must be considered together. Our first paper on modeling such treatments introduced a one-way coupled model that could only account for isotropic scattering of radiation. In the present work, we extend our transport model to incorporate anisotropic scattering. ","q-bio"
"1812.09223","Quark-Gluon Tagging: Machine Learning vs Detector","  Distinguishing quarks from gluons based on low-level detector output is one of the most challenging applications of multi-variate and machine learning techniques at the LHC. We first show the performance of our 4-vector-based LoLa tagger without and after considering detector effects. We then discuss two benchmark applications, mono-jet searches with a gluon-rich signal and di-jet resonances with a quark-rich signal. In both cases an immediate benefit compared to the standard event-level analysis exists. ","hep-ph"
"2004.00845","Occlusion-Aware Depth Estimation with Adaptive Normal Constraints","  We present a new learning-based method for multi-frame depth estimation from a color video, which is a fundamental problem in scene understanding, robot navigation or handheld 3D reconstruction. While recent learning-based methods estimate depth at high accuracy, 3D point clouds exported from their depth maps often fail to preserve important geometric feature (e.g., corners, edges, planes) of man-made scenes. Widely-used pixel-wise depth errors do not specifically penalize inconsistency on these features. These inaccuracies are particularly severe when subsequent depth reconstructions are accumulated in an attempt to scan a full environment with man-made objects with this kind of features. Our depth estimation algorithm therefore introduces a Combined Normal Map (CNM) constraint, which is designed to better preserve high-curvature features and global planar regions. In order to further improve the depth estimation accuracy, we introduce a new occlusion-aware strategy that aggregates initial depth predictions from multiple adjacent views into one final depth map and one occlusion probability map for the current reference view. Our method outperforms the state-of-the-art in terms of depth estimation accuracy, and preserves essential geometric features of man-made indoor scenes much better than other algorithms. ","cs"
"2006.10958","A Blind Beam Tracking Scheme for Millimeter Wave Systems","  Millimeter-wave is one of the technologies powering the new generation of wireless communication systems. To compensate the high path-loss, millimeter-wave devices need to use highly directional antennas. Consequently, beam misalignment causes strong performance degradation reducing the link throughput or even provoking a complete outage. Conventional solutions, e.g. IEEE 802.11ad, propose the usage of additional training sequences to track beam misalignment. These methods however introduce significant overhead especially in dynamic scenarios. In this paper we propose a beamforming scheme that can reduce this overhead. First, we propose an algorithm to design a codebook suitable for mobile scenarios. Secondly, we propose a blind beam tracking algorithm based on particle filter, which describes the angular position of the devices with a posterior density function constructed by particles. The proposed scheme reduces by more than 80% the overhead caused by additional training sequences. ","eess"
"2007.12171","On regular separable countably compact $\mathbb{R}$-rigid spaces","  We call a regular topological space $X$ to be $\mathbb R$-rigid if any continuous real-valued function on $X$ is constant. In this paper we construct a number of consistent examples of countably compact $\mathbb R$-rigid spaces with additional properties like separability and first countability. This way we answer several questions of Tzannes, Banakh, Ravsky, and the first author, as well as get a consistent $\mathbb R$-rigid counterexample to a classical problem of Nyikos. ","math"
"1904.10739","Cognitive Radar Using Reinforcement Learning in Automotive Applications","  The concept of cognitive radar (CR) enables radar systems to achieve intelligent adaption to a changeable environment with feedback facility from receiver to transmitter. However, the implementation of CR in a fast-changing environment usually requires a well-known environmental model. In our work, we stress the learning ability of CR in an unknown environment using a combination of CR and reinforcement learning (RL), called RL-CR. Less or no model of the environment is required. We also apply the general RL-CR to a specific problem of automotive radar spectrum allocation to mitigate mutual interference. Using RL-CR, each vehicle can autonomously choose a frequency subband according to its own observation of the environment. Since radar's single observation is quite limited compared to the overall information of the environment, a long short-term memory (LSTM) network is utilized so that radar can decide the next transmitted subband by aggregating its observations over time. Compared with centralized spectrum allocation approaches, our approach has the advantage of reducing communication between vehicles and the control center. It also outperforms some other distributive frequency subband selecting policies in reducing interference under certain circumstances. ","eess"
"2006.07463","Phase-type approximations perturbed by a heavy-tailed component for the   Gerber-Shiu function of risk processes with two-sided jumps","  We consider in this paper a risk reserve process where the claims and gains arrive according to two independent Poisson processes. While the gain sizes are phase-type distributed, we assume instead that the claim sizes are phase-type perturbed by a heavy-tailed component; that is, the claim size distribution is formally chosen to be phase-type with large probability $1-\epsilon$ and heavy-tailed with small probability $\epsilon$. We analyze the seminal Gerber-Shiu function coding the joint distribution of the time to ruin, the surplus immediately before ruin, and the deficit at ruin. We derive its value as an expansion with respect to powers of $\epsilon$ with known coefficients and we construct approximations from the first two terms of the aforementioned series. The main idea is based on the so-called fluid embedding that allows to put the considered risk process into the framework of spectrally negative Markov-additive processes and use its fluctuation theory developed in Ivanovs and Palmowski (2012). ","math"
"1909.00667","Brane Webs and Magnetic Quivers for SQCD","  It is widely considered that the classical Higgs branch of 4d $\mathcal{N}=2$ SQCD is a well understood object. However there is no satisfactory understanding of its structure. There are two complications: (1) the Higgs branch chiral ring contains nilpotent elements, as can easily be checked in the case of $\mathrm{SU}(N)$ with 1 flavour. (2) the Higgs branch as a geometric space can in general be decomposed into two cones with nontrivial intersection, the baryonic and mesonic branches. To study the second point in detail we use the recently developed tool of magnetic quivers for five-brane webs, using the fact that the classical Higgs branch for theories with 8 supercharges does not change through dimensional reduction. We compare this approach with the computation of the hyper-K\""ahler quotient using Hilbert series techniques, finding perfect agreement if nilpotent operators are eliminated by the computation of a so called radical. We study the nature of the nilpotent operators and give conjectures for the Hilbert series of the full Higgs branch, giving new insights into the vacuum structure of 4d $\mathcal{N}=2$ SQCD. In addition we demonstrate the power of the magnetic quiver technique, as it allows us to identify the decomposition into cones, and provides us with the global symmetries of the theory, as a simple alternative to the techniques that were used to date. ","hep-th"
"2001.09237","Exfoliation of Two-Dimensional Nanosheets of Metal Diborides","  The metal diborides are a class of ceramic materials with crystal structures consisting of hexagonal sheets of boron atoms alternating with planes of metal atoms held together with mixed character ionic/covalent bonds. Many of the metal diborides are ultrahigh temperature ceramics like HfB$_2$, TaB$_2$, and ZrB$_2$, which have melting points above 3000$^\circ$C, high mechanical hardness and strength at high temperatures, and high chemical resistance, while MgB$_2$ is a superconductor with a transition temperature of 39 K. Here we demonstrate that this diverse family of non-van der Waals materials can be processed into stable dispersions of two-dimensional (2D) nanosheets using ultrasonication-assisted exfoliation. We generate 2D nanosheets of the metal diborides AlB$_2$, CrB$_2$, HfB$_2$, MgB$_2$, NbB$_2$, TaB$_2$, TiB$_2$, and ZrB$_2$, and use electron and scanning probe microscopies to characterize their structures, morphologies, and compositions. The exfoliated layers span up to micrometers in lateral dimension and reach thicknesses down to 2-3 nm, while retaining their hexagonal atomic structure and chemical composition. We exploit the convenient solution-phase dispersions of exfoliated CrB$_2$ nanosheets to incorporate them directly into polymer composites. In contrast to the hard and brittle bulk CrB$_2$, we find that CrB$_2$ nanocomposites remain very flexible and simultaneously provide increases in the elastic modulus and the ultimate tensile strength of the polymer. The successful liquid-phase production of 2D metal diborides enables their processing using scalable low-temperature solution-phase methods, extending their use to previously unexplored applications, and reveals a new family of non-van der Waals materials that can be efficiently exfoliated into 2D forms. ","cond-mat"
"1907.08030","Scrambling in Hyperbolic Black Holes: shock waves and pole-skipping","  We study the scrambling properties of $(d+1)$-dimensional hyperbolic black holes. Using the eikonal approximation, we calculate out-of-time-order correlators (OTOCs) for a Rindler-AdS geometry with AdS radius $\ell$, which is dual to a $d-$dimensional conformal field theory (CFT) in hyperbolic space with temperature $T = 1/(2 \pi \ell)$. We find agreement between our results for OTOCs and previously reported CFT calculations. For more generic hyperbolic black holes, we compute the butterfly velocity in two different ways, namely: from shock waves and from a pole-skipping analysis, finding perfect agreement between the two methods. The butterfly velocity $v_B(T)$ nicely interpolates between the Rindler-AdS result $v_B(T=\frac{1}{2\pi \ell})=\frac{1}{d-1}$ and the planar result $v_B(T \gg \frac{1}{\ell})=\sqrt{\frac{d}{2(d-1)}}$. ","hep-th"
"1908.05274","Measuring dynamical masses from gas kinematics in simulated   high-redshift galaxies","  Advances in instrumentation have recently extended detailed measurements of gas kinematics to large samples of high-redshift galaxies. Relative to most nearby, thin disk galaxies, in which gas rotation accurately traces the gravitational potential, the interstellar medium (ISM) of z>1 galaxies is typically more dynamic and exhibits elevated turbulence. If not properly modeled, these effects can strongly bias dynamical mass measurements. We use high-resolution FIRE-2 cosmological zoom-in simulations to analyze the physical effects that must be considered to correctly infer dynamical masses from gas kinematics. Our analysis covers a range of galaxy properties from low-redshift Milky-Way-mass galaxies to massive high-redshift galaxies (M_* > 10^11 M_sun at z=1). Selecting only snapshots where a disk is present, we calculate the rotational profile v_phi(r) of the cool (10^3.5 K < T < 10^4.5 K) gas and compare it to the circular velocity v_c=sqrt(GM/r). In the simulated galaxies, the gas rotation traces the circular velocity at intermediate radii, but the two quantities diverge significantly in the center and in the outer disk. Our simulations appear to over-predict observed rotational velocities in the centers of massive galaxies (likely from a lack of black hole feedback), so we focus on larger radii. Gradients in the turbulent pressure at these radii can provide additional radial support and bias dynamical mass measurements low by up to 40%. In both the interior and exterior, the gas' motion can be significantly non-circular due to e.g. bars, satellites, and inflows/outflows. We discuss the accuracy of commonly-used analytic models for pressure gradients (or ""asymmetric drift"") in the ISM of high-redshift galaxies. ","astro-ph"
"1902.01145","Quantum thermodynamics in adiabatic open systems and its trapped-ion   experimental realization","  Quantum thermodynamics aims at investigating both the emergence and the limits of the laws of thermodynamics from a quantum mechanical microscopic approach. In this scenario, thermodynamic processes with no heat exchange, namely, adiabatic transformations, can be implemented through quantum evolutions in closed systems, even though the notion of a closed system is always an idealization and approximation. Here, we begin by theoretically discussing thermodynamic adiabatic processes in open quantum systems, which evolve non-unitarily under decoherence due to its interaction with its surrounding environment. From a general approach for adiabatic non-unitary evolution, we establish heat and work in terms of the underlying Liouville superoperator governing the quantum dynamics. As a consequence, we derive the conditions that an adiabatic open-system quantum dynamics implies in the absence of heat exchange, providing a connection between quantum and thermal adiabaticity. Moreover, we determine families of decohering systems exhibiting the same maximal heat exchange, which imply in classes of thermodynamic adiabaticity in open systems. We then approach the problem experimentally using a hyperfine energy-level quantum bit of an Ytterbium $^{171}$Yb$^+$ trapped ion, which provides a work substance for thermodynamic processes, allowing for the analysis of heat and internal energy throughout a controllable engineered dynamics. ","quant-ph"
"1909.11796","Bayesian Pseudo Posterior Mechanism under Differential Privacy","  We propose a Bayesian pseudo posterior mechanism to generate record-level synthetic datasets equipped with a differential privacy (DP) guarantee from any proposed synthesis model. The pseudo posterior mechanism employs a data record-indexed, risk-based weight vector with weights $\in [0, 1]$ to surgically downweight high-risk records for the generation and release of record-level synthetic data. The differentially private pseudo posterior synthesizer constructs weights using Lipschitz bounds for a log-likelihood utility for each data record, which provides a practical, general formulation for using weights based on record-level sensitivities that we show achieves dramatic improvements in the DP expenditure as compared to the unweighted synthesizer. By selecting weights to remove likelihood contributions with non-finite log-likelihood values, we achieve a local privacy guarantee at every sample size. We compute a local sensitivity specific to our Consumer Expenditure Surveys dataset for family income, published by the U.S. Bureau of Labor Statistics, and reveal mild conditions that guarantee its contraction to a global sensitivity result over the space of databases. We further employ a censoring mechanism to lock-in a local result with desirable risk and utility performances to achieve a global privacy result as an alternative to relying on asymptotics. We show that utility is better preserved for our pseudo posterior mechanism as compared to the exponential mechanism (EM) estimated on the same non-private synthesizer due to the use of targeted downweighting. Our results may be applied to any synthesizing model envisioned by the data disseminator in a computationally tractable way that only involves estimation of a pseudo posterior distribution for parameter(s) $\theta$, unlike recent approaches that use naturally-bounded utility functions under application of the EM. ","stat"
"1912.11793","Attention-based ASR with Lightweight and Dynamic Convolutions","  End-to-end (E2E) automatic speech recognition (ASR) with sequence-to-sequence models has gained attention because of its simple model training compared with conventional hidden Markov model based ASR. Recently, several studies report the state-of-the-art E2E ASR results obtained by Transformer. Compared to recurrent neural network (RNN) based E2E models, training of Transformer is more efficient and also achieves better performance on various tasks. However, self-attention used in Transformer requires computation quadratic in its input length. In this paper, we propose to apply lightweight and dynamic convolution to E2E ASR as an alternative architecture to the self-attention to make the computational order linear. We also propose joint training with connectionist temporal classification, convolution on the frequency axis, and combination with self-attention. With these techniques, the proposed architectures achieve better performance than RNN-based E2E model and performance competitive to state-of-the-art Transformer on various ASR benchmarks including noisy/reverberant tasks. ","eess"
"1909.07831","Neutral competition in a deterministically changing environment:   revisiting continuum approaches","  Environmental variation can play an important role in ecological competition by influencing the relative advantage between competing species. Here, we consider such effects by extending a classical, competitive Moran model to incorporate an environment that fluctuates periodically in time. We adapt methods from work on these classical models to investigate the effects of the magnitude and frequency of environmental fluctuations on two important population statistics: the probability of fixation and the mean time to fixation. In particular, we find that for small frequencies, the system behaves similar to a system with a constant fitness difference between the two species, and for large frequencies, the system behaves similar to a neutrally competitive model. Most interestingly, the system exhibits nontrivial behavior for intermediate frequencies. We conclude by showing that our results agree quite well with recent theoretical work on competitive models with a stochastically changing environment, and discuss how the methods we develop ease the mathematical analysis required to study such models. ","q-bio"
"2002.07734","Artificial Intelligent Ethics in the Digital Era: an Engineering Ethical   Framework Proposal","  Nowadays technology is being adopted on every aspect of our lives and it is one of most important transformation driver in industry. Moreover, many of the systems and digital services that we use daily rely on artificial intelligent technology capable of modeling social or individual behaviors that in turns also modify personal decisions and actions. In this paper, we briefly discuss, from a technological perspective, a number of critical issues including the purpose of promoting trust and ensure social benefit by the proper use of Artificial Intelligent Systems. To achieve this goal we propose a generic ethical technological framework as a first attempt to define a common context towards developing real engineering ethical by design. We hope that this initial proposal to be useful for early adopters and especially for standardization teams. ","cs"
"2003.03552","Cycles of given lengths in unicyclic components in sparse random graphs","  Let $L$ be subset of $\{3,4,\dots\}$ and let $X_{n,M}^{(L)}$ be the number of cycles belonging to unicyclic components whose length is in $L$ in the random graph $G(n,M)$. We find the limiting distribution of $X_{n,M}^{(L)}$ in the subcritical regime $M=cn$ with $c<1/2$ and the critical regime $M=\frac{n}{2}\left(1+\mu n^{-1/3}\right)$ with $\mu=O(1)$. Depending on the regime and a condition involving the series $\sum_{l \in L} \frac{z^l}{2l}$, we obtain in the limit either a Poisson or a normal distribution as $n\to\infty$. ","math"
"1901.01610","Iterated Feature Screening based on Distance Correlation for   Ultrahigh-Dimensional Censored Data with Covariates Measurement Error","  Feature screening is an important method to reduce the dimension and capture informative variables in ultrahigh-dimensional data analysis. Many methods have been developed for feature screening. These methods, however, are challenged by complex features pertinent to the data collection as well as the nature of the data themselves. Typically, incomplete response caused by right-censoring and covariates measurement error are often accompanying with survival analysis. Even though there are many methods have been proposed for censored data, little work has been available when both incomplete response and measurement error occur simultaneously. In addition, the conventional feature screening methods may fail to detect the truly important covariates which are marginally independent of the response variable due to correlations among covariates. In this paper, we explore this important problem and propose the valid feature screening method in the presence of survival data with measurement error. In addition, we also develop the iteration method to improve the accuracy of selecting all important covariates. Numerical studies are reported to assess the performance of the proposed method. Finally, we implement the proposed method to two different real datasets. ","stat"
"2002.04708","Radial expansion preserves hyperbolic convexity and radial contraction   preserves spherical convexity","  On a flat plane, convexity of a set is preserved by both radial expansion and contraction of the set about any point inside it. Using the Poincar\'e disk model of hyperbolic geometry, we prove that radial expansion of a hyperbolic convex set about a point inside it always preserves hyperbolic convexity. Using stereographic projection of a sphere, we prove that radial contraction of a spherical convex set about a point inside it, such that the initial set is contained in the closed hemisphere centred at that point, always preserves spherical convexity. ","math"
"1808.07730","Adaptive Tuning Of Hamiltonian Monte Carlo Within Sequential Monte Carlo","  Sequential Monte Carlo (SMC) samplers form an attractive alternative to MCMC for Bayesian computation. However, their performance depends strongly on the Markov kernels used to rejuvenate particles. We discuss how to calibrate automatically (using the current particles) Hamiltonian Monte Carlo kernels within SMC. To do so, we build upon the adaptive SMC approach of Fearnhead and Taylor (2013), and we also suggest alternative methods. We illustrate the advantages of using HMC kernels within an SMC sampler via an extensive numerical study. ","stat"
"1604.02441","An introduction to varieties in weighted projective space","  Weighted projective space arises when we consider the usual geometric definition for projective space and allow for non-trivial weights. On its own, this extra freedom gives rise to more than enough interesting phenomena, but it is the fact that weighted projective space arises naturally in the context of classical algebraic geometry that can be surprising. Using the Riemann-Roch theorem to calculate l(E,nD) where E is a non-singular cubic curve inside projective 2-space and D=p is a point in E we obtain a non-negatively graded ring R(E) by taking the direct sum of the L(E,nD) for n greater than or equal to 0. This gives rise to an embedding of E inside the weighted projective space P(1,2,3).   To understand a space it is always a good idea to look at the things inside it. The main content of this paper is the introduction and explanation of many basic concepts of weighted projective space and its varieties. There are already many brilliant texts on the topic but none of them are aimed at an audience with only an undergraduate's knowledge of mathematics. This paper hopes to partially fill this gap whilst maintaining a good balance between 'interesting' and 'simple'.   The main result of this paper is a reasonably simple degree-genus formula for non-singular 'sufficiently general' plane curves, proved using not much more than the Riemann-Hurwitz formula. ","math"
"2004.13111","Emergent Geometries from the BMN Matrix Model","  We review recent results of emergent geometries in the BMN matrix model, a one-dimensional gauge theory considered as a non-perturbative formulation of M-theory on the plane-wave geometry. A key to understand the emergent geometries is the eigenvalue distribution of a BPS operator. Gauge-theory calculation shows that the BPS operator reproduces the corresponding supergravity solutions in the gauge/gravity duality and also brane geometries in the M-brane picture. At finite temperatures, these geometries should be realised in a non-trivial way. Monte Carlo simulations of this gauge theory revealed two types of phase transitions: the confinement/deconfinement transition and the Myers transition, which provide insights into the emergence of the geometries. Especially, the numerical results qualitatively agree with the critical temperature of the confinement/deconfinement transition predicted on the gravity side. ","hep-th"
"1807.03285","A gauged horizontal $SU(2)$ symmetry and $R_{K^{(\ast)}}$","  One of the greatest challenges for models of $b \to s$ anomalies is the necessity to produce a large contribution to a quark times a lepton current, $J_q \times J_\ell$, and to avoid accordingly large contributions to flavour-changing $J_q \times J_q$ and $J_\ell \times J_\ell$ amplitudes, which are severely constrained by data. We consider a gauged horizontal symmetry involving the two heaviest generations of all left-handed fermions. In the limit of degenerate masses for the horizontal bosons, and in the absence of mixing between the two heavier generations and the lighter one, such symmetry would make $J_q \times J_q$ and $J_\ell \times J_\ell$ amplitudes exactly flavour-diagonal. Mixing with the first generation is however inescapable due to the CKM matrix, and the above mechanism turns out to be challenged by constraints such as $D^0 -\bar D^0$ mixing. Nonetheless, we show that a simultaneous description of all data can be accomplished by simply allowing for non-degenerate masses for the horizontal bosons. Such scenario predicts modifications in several processes that can be tested at present and upcoming facilities. In particular, it implies a lower and upper bound for $\mathcal B (B \to K \mu^\pm \tau^\mp)$, an asymmetry between its two charge conjugated modes, and well-defined correlations with LFV in $\tau$ decays. ","hep-ph"
"1904.12238","Ergodic Mutual Information for Generalized Fadings","  In this paper, novel expressions are derived to evaluate the ergodic mutual information (EMI) under BPSK modulation of single-input single-output (SISO) systems operating in generalized fading channels, including $\eta$-$\mu$ fading and $\kappa$-$\mu$ fading. To verify our derivation, we first investigate the specific fading types, namely Rayleigh, Nakagami-$m$ and Rician, and then turn to generalized fading scenarios. It is shown that all the expressions concluded from the generalized cases can be specialized into those derived from the specific ones. Different from the conventional results of the EMI, our developed expressions contain only the simplest numerical calculations, without any Meijer's G-functions which must be implemented in the particular computing software. Additionally, it should be noted that our work provides a complete analysis of the EMI in wireless channel under discrete inputs. ","eess"
"2007.15229","Hydrogen recombination near-infrared line mapping of Centaurus A with   IRSF/SIRIUS","  Centaurus A (Cen A) is one of the most famous galaxies hosting an active galactic nucleus (AGN), where the interaction between AGN activities and surrounding interstellar and intergalactic media has been investigated. Recent studies reported detections of the H{\alpha} emission from clouds in the galactic halo toward the northeast and southwest of the nucleus of Cen A, suggesting that AGN jets may have triggered star formation there. We performed near-infrared line mapping of Cen A with the IRSF 1.4-m telescope, using the narrow-band filter tuned for Pa{\beta}, from which we find that the Pa{\beta} emission is not detected significantly from either northeast or southwest regions. The upper limit of the Pa{\beta}/H{\alpha} ratio in the northeast region is compatible with that expected for a typical HII region, in line with the scenario that AGNs have triggered star formation there. On the other hand, the upper limit of Pa{\beta}/H{\alpha} in the southwest region is significantly lower than that expected for a typical HII region. A possibility to explain the low Pa{\beta}/H{\alpha} ratio in the southwest region is the scattering of H{\alpha} and Pa{\beta} photons from the center of Cen A by dust grains in the halo clouds. From the upper limit of Pa{\beta}/H{\alpha} in the southwest region, we obtain constraints on the dust size distribution, which is found to be compatible with those seen in the interstellar medium of our Galaxy. ","astro-ph"
"1904.04273","Bulk thermal transport coefficients in a quantum Hall system and the   fundamental difference between thermal and charge response","  We derive and calculate thermal transport coefficient for a quantum Hall system in the linear response regime, and show that they are exponentially small in the bulk, in contrast to the quantized value of the charge Hall coefficient, thus violating Wiedemann-Franz law. This corroborates earlier reports about the essential difference between the charge and thermal quantum Hall effect, that originates from the different behavior of the corresponding $U(1)$ and gravitational anomalies. We explicitly calculate the bulk currents when a temperature profile is applied within the bulk, and show that they are proportional to the second derivative of the respective gravitational potential (tidal force), and nonuniversal, in contrast to the charge current which is proportional to the first derivative of the electrochemical potential. ","cond-mat"
"2001.07456","Dynamical transitions in a driven diffusive model with interactions","  We study the dynamics of an asymmetric simple exclusion process with open boundaries and local interactions using a pair approximation which generalizes the 2-node cluster mean field theory and the Markov chain approach to kinetics and shares with these approaches the property of reproducing exact results for the bulk current-density relation and the steady state phase diagrams. We find that the relaxation rate exhibits a dynamical transition, with no static counterpart, analogous to that found without interactions. Remarkably, for some values of the model's parameters, we find 2 dynamical transitions in the same low density phase. We study the dynamics of relaxation to the steady state on both sides of these transitions and make an attempt at providing a physical interpretation for this phenomenon. Results from numerical approaches and a modified Domain Wall Theory confirm the picture provided by the pair approximation. ","cond-mat"
"2006.08471","Probability of symptoms and critical disease after SARS-CoV-2 infection","  We quantified the probability of developing symptoms (respiratory or fever \geq 37.5 {\deg}C) and critical disease (requiring intensive care or resulting in death) of SARS-CoV-2 positive subjects. 5,484 contacts of SARS-CoV-2 index cases detected in Lombardy, Italy were analyzed, and positive subjects were ascertained via nasal swabs and serological assays. 73.9% of all infected individuals aged less than 60 years did not develop symptoms (95% confidence interval: 71.8-75.9%). The risk of symptoms increased with age. 6.6% of infected subjects older than 60 years had critical disease, with males at significantly higher risk. ","q-bio"
"1912.08935","Exploring the Landscape of effective field theories","  In this thesis we provide new tools to determine and explore the Landscape of four-dimensional effective field theories originating from string and M-theory. The main aim is to introduce, within four-dimensional effective descriptions, elements that are predicted from string theory. To this end, a hierarchy of forms is introduced within the four-dimensional $\mathcal{N}=1$ supergravity theories. The inclusion of gauge three-forms delivers a dynamical way to generate flux-induced superpotentials. Instead, gauge two-forms, dual descriptions of axions, may be eventually gauged by three-forms to generate a superpotential coupling between the different chiral multiplet sectors of the theory. The mutual constraints among the background fluxes, such as tadpole cancellations, are imposed by gauge four-forms. A hierarchy of objects, to which the gauge forms couple, is then introduced: four-dimensional BPS-strings, membranes and 3-branes enlarge the Landscape, allowing the background fluxes to consistently change transversing different spacetime regions. The Freed-Witten anomaly cancellations and the changing of tadpole cancellation conditions due to background sources are neatly expressed by BPS-junctions of membranes ending on strings and 3-branes ending on membranes. Membrane-mediated domain wall transitions are studied, which determine how the scalar fields flow connecting a vacuum to another of the Landscape. According to the perturbative regime that is scanned only some transitions are allowed, with a dramatic influence on the spectrum of objects that can be consistently incorporated in the four-dimensional description. ","hep-th"
"2006.13824","Spatial Pattern Recognition with Adjacency-Clustering: Improved   Diagnostics for Semiconductor Wafer Bin Maps","  In semiconductor manufacturing, statistical quality control hinges on an effective analysis of wafer bin maps, wherein a key challenge is to detect how defective chips tend to spatially cluster on a wafer--a problem known as spatial pattern recognition. Detecting defect patterns on a wafer can deliver key diagnostics about the root causes of defects and assist production engineers in mitigating future failures. Recently, there has been a growing interest in mixed-type spatial pattern recognition--when multiple defect patterns, of different shapes, co-exist on the same wafer. Mixed-type spatial pattern recognition entails two central tasks: (1) spatial filtering, to distinguish systematic patterns from random noises; and (2) spatial clustering, to group the filtered patterns into distinct defect types. Observing that spatial filtering is instrumental to high-quality pattern recognition, we propose to use a graph-theoretic method called adjacency-clustering, which leverages spatial dependence among adjacent defective chips to effectively filter the raw wafer bin maps. Tested on real-world data and compared against a state-of-the-art approach, our proposed method achieves at least 49% gain in terms of internal cluster validation quality (i.e., validation without external class labels), and about 6% gain in terms of Normalized Mutual Information--an external cluster validation metric based on external class labels. Interestingly, the margin of improvement appears to be a function of the defect pattern complexity, with larger gains achieved for more complex-shaped patterns. This superior performance is a testament to the method's promising impact to semiconductor manufacturing, as well as other contexts where mixed-type spatial patterns are prevalent. ","stat"
"2002.00164","Separability criteria based on Heisenberg-Weyl representation of density   matrices","  Separability is an important problem in theory of quantum entanglement. By using the Bloch representation of quantum states in terms of the Heisenberg-Weyl observable basis, we present a new separability criterion for bipartite quantum systems. It is shown that this criterion can be better than the previous ones in detecting entanglement. The results are generalized to multipartite quantum states. ","quant-ph"
"1901.09182","Chiral excitation of spin waves in ferromagnetic films","  We theoretically investigate the interlayer dipolar and exchange couplings for an array of metallic magnetic nanowires grown on top of an extended ultrathin yttrium iron garnet film. The calculated interlayer dipolar coupling agrees with observed anticrossings [Chen \emph{et al.}, Phys. Rev. Lett. \textbf{120}, 217202 (2018)], concluding that the interlayer exchange coupling is suppressed by a spacer layer between the nanowires and film. The Kittel mode in the nanowire array couples chirally to spin waves in the film, even though Damon-Eshbach surface modes do not exist. The chirality is suppressed when the interlayer exchange coupling becomes strong. ","cond-mat"
"1901.00170","Sums of certain fractional parts","  In this note, an upper bound for the sum of fractional parts of certain smooth functions is established. Such sums arise naturally in numerous problems of analytic number theory. The main feature is here an improvement of the main term due to the use of Weyl's bound for exponential sums and a device used by Popov. ","math"
"1908.11683","Identities and Properties of Multi-Dimensional Generalized Bessel   Functions","  The Generalized Bessel Function (GBF) extends the single variable Bessel function to several dimensions in a nontrivial manner. Two-dimensional GBFs have been studied extensively in the literature and have found application in laser physics, crystallography, and electromagnetics. In this article, we document several properties of $m$-dimensional GBFs including an underlying partial differential equation structure, asymptotics for simulatneously large order and argument, and analysis of generalized Neumann, Kapteyn, and Schl\""{o}milch series. We extend these results to mixed-type GBFs where appropriate. ","math"
"1909.08523","Keck/OSIRIS IFU Detection of a z $\sim$ 3 Damped Lyman Alpha Host Galaxy","  We present Keck/OSIRIS infrared IFU observations of the $z = $ 3.153 sub-DLA DLA2233+131, previously detected in absorption to a background quasar and studied with single slit spectroscopy and PMAS integral field spectroscopy (IFU). We used the Laser Guide Star Adaptive Optics (LGSAO) and OSIRIS IFU to reduce the point-spread function of the background quasar to FWHM$\sim$0.15 arcseconds and marginally resolve extended, foreground DLA emission. We detect [OIII]$\lambda$5007 emission with a flux F$^{[OIII]\lambda5007}$ = $(2.4\pm0.5)\times10^{-17}$ erg s$^{-1}$ cm$^{-2}$, as well as unresolved [OIII]$\lambda$4959 and H$\beta\lambda$4861 emission. Using a composite spectrum over the emission region, we measure dynamical mass $\sim$ $3.1\times10^9$ M$_{\odot}$. We make several estimates of star formation rate using [OIII]$\lambda$5007 and H$\beta\lambda$4861 emission, and measure a star formation rate of $\sim$ $7.1- 13.6$ M$_{\odot}$ yr$^{-1}$. We map [OIII]$\lambda$5007 and H$\beta\lambda$4861 emission and the corresponding velocity fields to search for signs of kinematic structure. These maps allow for a more detailed kinematic analysis than previously possible for this galaxy. While some regions show slightly red and blue-shifted emission indicative of potential edge-on disk rotation, the data are insufficient to support this interpretation. ","astro-ph"
"1807.09288","Global consensus Monte Carlo","  To conduct Bayesian inference with large data sets, it is often convenient or necessary to distribute the data across multiple machines. We consider a likelihood function expressed as a product of terms, each associated with a subset of the data. Inspired by global variable consensus optimisation, we introduce an instrumental hierarchical model associating auxiliary statistical parameters with each term, which are conditionally independent given the top-level parameters. One of these top-level parameters controls the unconditional strength of association between the auxiliary parameters. This model leads to a distributed MCMC algorithm on an extended state space yielding approximations of posterior expectations. A trade-off between computational tractability and fidelity to the original model can be controlled by changing the association strength in the instrumental model. We further propose the use of a SMC sampler with a sequence of association strengths, allowing both the automatic determination of appropriate strengths and for a bias correction technique to be applied. In contrast to similar distributed Monte Carlo algorithms, this approach requires few distributional assumptions. The performance of the algorithms is illustrated with a number of simulated examples. ","stat"
"2005.03021","S-duality and correlation functions at large R-charge","  We study the ratio of pairs of adjacent correlators of Coulomb-branch operators in $SU(2)$ $\mathcal{N}=2$ SQCD with four flavors within the framework of the Large Quantum Number Expansion. Capitalizing on the order-by-order S-duality invariance of the large-R-charge expansion we compute ab initio the dependence of the leading large-$\mathcal{J}$ behavior on the marginal coupling $\tau$ and we find excellent agreement with numerical estimates from localization. ","hep-th"
"1905.09125","New Fayet-Iliopoulos terms in ${\mathcal N}=2$ supergravity","  We present a new type of Fayet-Iliopoulos (FI) terms in ${\mathcal N}=2$ supergravity that do not require the gauging of the $R$-symmetry. We elaborate on the impact of such terms on the vacuum structure of the ${\mathcal N}=2$ theory and compare their properties with the standard Fayet-Iliopoulos terms that arise from gaugings. In particular, we show that, with the use of the new FI terms, models with a single physical ${\mathcal N}=2$ vector multiplet can be constructed that give stable de Sitter vacua. ","hep-th"
"1811.09288","Common nonlinear features and spin-orbit coupling effects in the Zeeman   splitting of novel wurtzite materials","  The response of semiconductor materials to external magnetic fields is a reliable approach to probe intrinsic electronic and spin-dependent properties. In this study, we investigate the common Zeeman splitting features of novel wurtzite materials, namely InP, InAs, and GaAs. We present values for the effective g-factors of different energy bands and show that spin-orbit coupling effects, responsible for the spin splittings, also have noticeable contributions to the g-factors. Within the Landau level picture, we show that the nonlinear Zeeman splitting recently explained in magneto photoluminescence experiments for InP nanowires by Tedeschi et al. [Phys. Rev. B 99, 161204 (2019)] are also present in InAs, GaAs and even in the conventional GaN. Such nonlinear features stem from the peculiar coupling of the A and B valence bands, as a consequence of the interplay between the wurtzite crystal symmetry and the breaking of time-reversal symmetry by the external magnetic field. Moreover, we develop an analytical model to describe the experimental nonlinear Zeeman splitting and apply it to InP and GaAs data. Extrapolating our fitted results, we found that the Zeeman splitting of InP reaches a maximum value, which is a prediction that could be probed at higher magnetic fields. ","cond-mat"
"1804.09467","Stochastic Coherence Theory for Qubits","  The resource theory of coherence studies the operational value of superpositions in quantum technologies. A key question in this theory concerns the efficiency of manipulation and interconversion of this resource. Here we solve this question completely for mixed states of qubits by determining the optimal probabilities for mixed state conversions via stochastic incoherent operations. This implies new lower bounds on the asymptotic state conversion rate between mixed single-qubit states which in some cases is proven to be tight. Furthermore, we obtain the minimal distillable coherence for given coherence cost among all single-qubit states, which sheds new light on the irreversibility of coherence theory. ","quant-ph"
"1909.04731","Higgs Mechanism and Debye Screening in the Generalized Electrodynamics","  In this work we study the Higgs mechanism and the Debye shielding for the Bopp-Podolsky theory of electrodynamics. We find that not only the massless sector of the Podolsky theory acquires a mass in both these phenomena, but also that its massive sector has its mass changed. Furthermore, we find a mathematical analogy in the way these masses change between these two mechanisms. Besides exploring the behaviour of the screened potentials, we find a temperature for which the presence of the generalized gauge field may be experimentally detected. ","hep-th"
"1901.10741","Axialvector tetraquark candidates for the $Z_c(3900)$, $Z_c(4020)$,   $Z_c(4430)$, $Z_c(4600)$","  In this paper, we construct the axialvector and tensor current operators to investigate the ground state tetraquark states and the first radially excited tetraquark states with the quantum numbers $J^{PC}=1^{+-}$ via the QCD sum rules systematically, and observe that there are one axialvector tetraquark candidate for the $Z_c(3900)$ and $Z_c(4430)$, two axialvector tetraquark candidates for the $Z_c(4020)$, three axialvector tetraquark candidates for the $Z_c(4600)$. ","hep-ph"
"1901.08848","Comment on ""Optimal convex approximations of quantum states""","  In a recent paper, M. F. Sacchi [Phys. Rev. A 96, 042325 (2017)] addressed the general problem of approximating an unavailable quantum state by the convex mixing of different available states. For the case of qubit mixed states, we show that the analytical solutions in some cases are invalid. In this Comment, we present complete analytical solutions for the optimal convex approximation. Our solutions can be viewed as correcting and supplementing the results in the aforementioned paper. ","quant-ph"
"1612.02416","Testing the fit of relational models","  Relational models generalize log-linear models to arbitrary discrete sample spaces by specifying effects associated with any subsets of their cells. A relational model may include an overall effect, pertaining to every cell after a reparameterization, and in this case, the properties of the maximum likelihood estimates (MLEs) are analogous to those computed under traditional log-linear models, and the goodness-of-fit tests are also the same. If an overall effect is not present in any reparameterization, the properties of the MLEs are considerably different, and the Poisson and multinomial MLEs are not equivalent. In the Poisson case, if the overall effect is not present, the observed total is not always preserved by the MLE, and thus, the likelihood ratio statistic is not identical with twice the Kullback-Leibler divergence. However, as demonstrated, its general form may be obtained from the Bregman divergence. The asymptotic equivalence of the Pearson chi-squared and likelihood ratio statistics holds, but the generality considered here requires extended proofs. ","stat"
"2001.08658","A Quake Quenching the Vela Pulsar","  The remarkable null pulse coincident with the 2016 glitch in Vela rotation indicates a dynamical event involving the crust and the magnetosphere of the neutron star. We propose that a crustal quake associated with the glitch strongly disturbed the Vela magnetosphere and thus interrupted its radio emission. We present the first global numerical simulations of a neutron starquake. Our code resolves the elastodynamics of the entire crust and follows the evolution of Alfv\'en waves excited in the magnetosphere. We observe Rayleigh surface waves propagating away from the epicentre of the quake, around the circumference of the crust - an instance of the so-called whispering gallery modes. The Rayleigh waves set the initial spatial scale of the magnetospheric disturbance. Once launched, the Aflv\'en waves bounce in the closed magnetosphere, become dephased, and generate strong electric currents, capable of igniting electric discharge. Most likely, the discharge floods the magnetosphere with electron-positron plasma, quenching the radio emission. We find that the observed $\sim 0.2$ s disturbance is consistent with the damping time of the crustal waves if the crust is magnetically coupled to the superconducting core of the neutron star. The quake is expected to produce a weak X-ray burst of short duration. ","astro-ph"
"1809.00247","Non-perturbative renormalization group beyond melonic sector: The   Effective Vertex Expansion method for group fields theories","  Tensor models admit the large $N$ limit dominated by the graphs called melons. The melons are caracterized by the Gurau number $\varpi=0$ and the amplitude of the Feynman graphs are proportional to $N^{-\varpi}$. Other leading order contributions i.e. $\varpi> 0$ called pseudo-melons can be taken into account in the renormalization program. The following paper deals with the renormalization group for a $U(1)$-tensorial group field theory model taking into account these two sectors (melon and pseudo-melon). It generalizes a recent work [arXiv:1803.09902], in which only the melonic sector have been studied. Using the power counting theorem the divergent graphs of the model are identified. Also, the effective vertex expansion is used to generate in detail the combinatorial analysis of these two leading order sectors. We obtained the structure equations, that help to improve the truncation in the Wetterich equation. The set of Ward-Takahashi identities is derived and their compactibility along the flow provides a non-trivial constraints in the approximation shemes. In the symmetric phase the Wetterich flow equation is given and the numerical solution is studied. ","hep-th"
"1806.04540","Deriving photon spin from relativistic quantum equations: Nonlocality of   photon spin and relativistic quantum constraint","  The difficulties encountered up till now in the theory of identifying the spin and orbital angular momentum of the photon stem from the approach of dividing the angular momentum of the photon into spin and orbital parts. Here we derive the spin of the photon from a set of two relativistic quantum equations that was first cast from the free-space Maxwell equations by Darwin in 1932. Much attention is focused on the nonlocal properties of the photon spin that are determined by the relativistic quantum constraint, one of the so-called Darwin equations. Meanwhile, we point out that for the Darwin equations to describe the quantum motion of the photon, the upper and lower parts of the wavefunction cannot be the electric and magnetic fields as Darwin prescribed. Their nonlocal relations are investigated. The Lorentz covariance of the Darwin equations is also proven, to the best of our knowledge, for the first time. ","quant-ph"
"2007.13476","Benchmarking Meta-heuristic Optimization","  Solving an optimization task in any domain is a very challenging problem, especially when dealing with nonlinear problems and non-convex functions. Many meta-heuristic algorithms are very efficient when solving nonlinear functions. A meta-heuristic algorithm is a problem-independent technique that can be applied to a broad range of problems. In this experiment, some of the evolutionary algorithms will be tested, evaluated, and compared with each other. We will go through the Genetic Algorithm\, Differential Evolution, Particle Swarm Optimization Algorithm, Grey Wolf Optimizer, and Simulated Annealing. They will be evaluated against the performance from many points of view like how the algorithm performs throughout generations and how the algorithm's result is close to the optimal result. Other points of evaluation are discussed in depth in later sections. ","cs"
"2004.10057","CommUnet: U-net decoder for convolutional codes in communication","  In recent years, deep neural networks have played a major role solving various challenges in two dimensional image processing.Fully Convolutional Networks (FCN) such as U-net have been shown to be highly successful at segmentation tasks for medical images analysis and denoising images taken in dark venues. This paper harnesses this well-known deep neural network for the channel decoding challenge recently proven to be suitable for deep neural networks.Previous work have successfully managed to decode convolutional codes using different architectures,such as Recurrent Neural Networks(RNN) and Fully Connected Neural Networks(FCNN) with promising results.However,these approaches are extremely costly in latency,computational resources and memory.This paper shows that taking the approach used in two dimensional image processing,by simple manipulation on the data in the preprocessing phase,achieves better results in a Bit Error Rate(BER) measurement with a large discount on the latency and the number of parameters required to maintain the neural decoder. ","eess"
"2007.11774","Seifert fibered and reducible surgeries on hyperbolic fibered knots","  Let $K\subset S^3$ be a hyperbolic fibered knot such that $S^3_{p/q}(K)$, the $\frac pq$--surgery on $K$, is either reducible or an atoroidal Seifert fibered space. We prove that if the monodromy of $K$ is right-veering, then $0\le\frac pq\le 4g(K)$. The upper bound $4g(K)$ cannot be attained if $K$ is an L-space knot. If the monodromy of $K$ is neither right-veering nor left-veering, then $|q|=1$ and the surgery is irreducible.   As a corollary, for any given positive torus knot $T$, if $p/q\ge4g(T)+4$, then $p/q$ is a characterizing slope. This improves earlier bounds of Ni--Zhang and McCoy. We also prove that some finite/cyclic slopes are characterizing. More precisely, $14$ is characterizing for $T_{4,3}$, $17$ is characterizing for $T_{5,3}$, and $4n+1$ is characterizing for $T_{2n+1,2}$ except when $n=5$. By a recent theorem of Tange, this shows that $T_{2n+1,2}$ is the only knot in $S^3$ admitting a lens space surgery while the Alexander polynomial has the form $t^n-t^{n-1}+t^{n-2}+\cdots$.   In the appendix, we prove that if the rank of the second term of the knot Floer homology of a fibered knot is $1$, then the monodromy is either right-veering or left-veering. ","math"
"2006.07933","Comparative study of the biological activities of the aqueous extracts   of two spontaneous plants harvested in the Algerian Sahara","  The present study investigates the insecticidal and herbicidal effects of leaf extracts from two plants were harvested in the Northern Algerian Sahara. These are Cleome arabica (Capparaceae) and Pergularia tomentosa (Asclepiadaceae). The efficacy of the extracts from the plants was evaluated by the reflux extraction method. The phytochemical screening of the aqueous extracts of C. arabica shows a remarkable richness in active principles in comparison with the extract of P. tomentosa; including flavonoids, saponosides, glycosides, terpenes, sterols, deoxyose, polyphenols and total alkaloids. The imago of Tribolium confusum treated with aqueous extracts of C. arabica and P. tomentosa at doses of 80% to 100% respectively have mortality rates of 73.33% to 96.67%, and 36.67% to 86.67%. The lethal time 50 (TL50%) of the aqueous extract of C. arabica was estimated about 6.41 days, and 6.94 days for the extract P. tomentosa for the imago of T. confusum. The extracts of P. tomentosa is less toxic than the extracts of C. arabica. The allelopathic potentials of C. arabica and P. tomentosa tested on germination of the seeds of a weed Dactyloctenium aegyptium (Poaceae) and two cultivated species, including Hordeumvulgare and Triticumdurum (Poaceae), show that the inhibitory effect of extracts of C. arabica is very highly significant. It manifests itself in the growth of the aerial and underground part of the H. vulgar and T. durum. The inhibition rate is more than 84.44% for D. aegyptium seeds treated with the different concentrations. The inhibition rates range from 75.56% to 91.11% for T. durum wheat irrigate at 80% to 100%, but are only 55.56% to 77.78% for barley seeds treated with the same concentrations (80% to 100%). ","q-bio"
"1904.12092","Spatio-Temporal Change of Support Modeling with R","  Spatio-temporal change of support methods are designed for statistical analysis on spatial and temporal domains which can differ from those of the observed data. Previous work introduced a parsimonious class of Bayesian hierarchical spatio-temporal models, which we refer to as STCOS, for the case of Gaussian outcomes. Application of STCOS methodology from this literature requires a level of proficiency with spatio-temporal methods and statistical computing which may be a hurdle for potential users. The present work seeks to bridge this gap by guiding readers through STCOS computations. We focus on the R computing environment because of its popularity, free availability, and high quality contributed packages. The stcos package is introduced to facilitate computations for the STCOS model. A motivating application is the American Community Survey (ACS), an ongoing survey administered by the U.S. Census Bureau that measures key socioeconomic and demographic variables for various populations in the United States. The STCOS methodology offers a principled approach to compute model-based estimates and associated measures of uncertainty for ACS variables on customized geographies and/or time periods. We present a detailed case study with ACS data as a guide for change of support analysis in R, and as a foundation which can be customized to other applications. ","stat"
"1905.05031","${}^8$Be Decay Anomaly and Light $Z'$","  In this proceedings, we discuss a light (17 MeV) $Z'$ solution to the anomaly observed in the decay of Beryllium-8 by the Atomki collaboration. We detail an anomaly free model with minimal particle content which can satisfy all other experimental constraints with gauge couplings $\mathcal{O}(10^{-4})$. ","hep-ph"
"2002.10320","Quantum control of frequency tunable transmon superconducting qubits","  In this work we analyze the implementation of a control-phase gate through the resonance between the $|11\rangle$ and $|20\rangle$ states of two statically coupled transmons. We find that there are many different controls for the transmon frequency that implement the same gate with fidelities around $99.8\%$ ($T_1=T_2^{*}=17$ $\mu$s) and $99.99\%$ ($T_1=T_2^{*}=300$ $\mu$s) within a time that approaches the theoretical limit. All controls can be brought to this accuracy by calibrating the waiting time and the destination frequency near the $|11\rangle-|20\rangle$ resonance. However, some controls, such as those based on the theory of dynamical invariants, are particularly attractive due to reduced leakage, robustness against decoherence, and their limited bandwidth. ","quant-ph"
"1809.08988","Bayesian Double Feature Allocation for Phenotyping with Electronic   Health Records","  We propose a categorical matrix factorization method to infer latent diseases from electronic health records (EHR) data in an unsupervised manner. A latent disease is defined as an unknown biological aberration that causes a set of common symptoms for a group of patients. The proposed approach is based on a novel double feature allocation model which simultaneously allocates features to the rows and the columns of a categorical matrix. Using a Bayesian approach, available prior information on known diseases greatly improves identifiability and interpretability of latent diseases. This includes known diagnoses for patients and known association of diseases with symptoms. We validate the proposed approach by simulation studies including mis-specified models and comparison with sparse latent factor models. In the application to Chinese EHR data, we find interesting results, some of which agree with related clinical and medical knowledge. ","stat"
"1905.05648","Gravitino vs Neutralino LSP at the LHC","  Using the latest LHC data, we analyse and compare the lower limits on the masses of gluinos and the lightest stop in two natural supersymmetric motivated scenarios: one with a neutralino being the lightest supersymmetric particle (LSP) and the other one with gravitino as the LSP and neutralino as the next-to-lightest supersymmetric particle. In the second case our analysis applies to neutralinos promptly decaying to very light gravitinos, which are of cosmological interest, and are generic for low, of order O(100) TeV, messenger scale in gauge mediation models. We find that the lower bounds on the gluino and the lightest stop masses are stronger for the gravitino LSP scenarios due to the extra handle from the decay products of neutralinos. Generally, in contrast to the neutralino LSP case the limits now extend to a region of compressed spectrum. In bino scenarios the highest excluded stop mass increases from 1000 GeV to almost 1400 GeV. Additionally, in the higgsino-like NLSP scenario the higgsinos below 650 GeV are universally excluded and the stop mass limit is $m_{\tilde{t}} > 1150$ GeV, whereas there is no limit on stops in the higgsino LSP model for $m_{\tilde{h}} = 650$ GeV. Nevertheless, we find that the low messenger scale still ameliorates the fine tuning in the electroweak potential. ","hep-ph"
"1910.05131","Towards a $Z_3$-graded approach to quarks' symmetries","  Colour $SU(3)$ group is an exact symmetry of Quantum Chromodynamics, which describes strong interactions between quarks and gluons. Supplemented by two internal symmetries, $SU(2)$ and $U(1)$, it serves as the internal symmetry of the Standard Model, describing as well the electroweak interactions of quarks and leptons. The colour$SU(3)$ symmetry is exact, while two other symmetries are broken by means of the Higgs-Kibble mechanism. The three colours and fractional quarks charges with values $1/3$ and $2/3$ suggest that the cyclic group $Z_3$ may play a crucial role in quark field dynamics. In this paper we consequently apply the $Z_3$ symmetry to field multiplets describing colour quark fields. Generalized Dirac equation for coloured $12$-component spinors is introduced and its properties are discussed. Imposing $Z_3$-graded Lorentz and Poincar\'e covariance leads to enlargement of quark fields multiplets and incorporates additional $Z_2 \times Z_3$ symmetry which leads to the appearance of three generations (families) of distinct quark doublets. ","hep-th"
"2001.03606","R-motivic stable stems","  We compute some R-motivic stable homotopy groups. For $s - w \leq 11$, we describe the motivic stable homotopy groups $\pi_{s,w}$ of a completion of the R-motivic sphere spectrum. We apply the $\rho$-Bockstein spectral sequence to obtain R-motivic Ext groups from the C-motivic Ext groups, which are well-understood in a large range. These Ext groups are the input to the R-motivic Adams spectral sequence. We fully analyze the Adams differentials in a range, and we also analyze hidden extensions by $\rho$, 2, and $\eta$. As a consequence of our computations, we recover Mahowald invariants of many low-dimensional classical stable homotopy elements. ","math"
"2001.11087","Crash Themes in Automated Vehicles: A Topic Modeling Analysis of the   California Department of Motor Vehicles Automated Vehicle Crash Database","  Automated vehicle technology promises to reduce the societal impact of traffic crashes. Early investigations of this technology suggest that significant safety issues remain during control transfers between the automation and human drivers and automation interactions with the transportation system. In order to address these issues, it is critical to understand both the behavior of human drivers during these events and the environments where they occur. This article analyzes automated vehicle crash narratives from the California Department of Motor Vehicles automated vehicle crash database to identify safety concerns and gaps between crash types and current areas of focus in the current research. The database was analyzed using probabilistic topic modeling of open-ended crash narratives. Topic modeling analysis identified five themes in the database: driver-initiated transition crashes, sideswipe crashes during left-side overtakes, and rear-end collisions while the vehicle was stopped at an intersection, in a turn lane, and when the crash involved oncoming traffic. Many crashes represented by the driver-initiated transitions topic were also associated with the side-swipe collisions. A substantial portion of the side-swipe collisions also involved motorcycles. These findings highlight previously raised safety concerns with transitions of control and interactions between vehicles in automated mode and the transportation social network. In response to these findings, future empirical work should focus on driver-initiated transitions, overtakes, silent failures, complex traffic situations, and adverse driving environments. Beyond this future work, the topic modeling analysis method may be used as a tool to monitor emergent safety issues. ","stat"
"2007.10222","Seismic Solar Models from Ledoux discriminant inversions","  The Sun constitutes an excellent laboratory of fundamental physics. With the advent of helioseismology, we were able to probe its internal layers with unprecedented precision. However, the current state of solar modelling is still stained by tedious issues. One of these problems is related to the disagreement between models computed with recent photospheric abundances and helioseismic constraints. We use solar evolutionary models as initial conditions for reintegrations of their structure using Ledoux discriminant inversions. The resulting models are defined as seismic solar models, satisfying the equations of hydrostatic equilibrium. They will allow us to better constrain the internal structure of the Sun and provide complementary information to that of evolutionary models. These seismic models were computed using various reference models with different equations of state, abundances and opacity tables. We check the robustness of our approach by confirming the good agreement of our seismic models in terms of sound speed, density and entropy proxy inversions as well as frequency-separation ratios of low-degree pressure modes. Our method allows us to determine with an excellent accuracy the Ledoux discriminant profile of the Sun and compute full profiles of this quantity. Our models show an agreement with seismic data of ~0.1% in sound speed, density and entropy proxy as well as with the observed frequency-separation ratios. They surpass all standard and non-standard evolutionary models including ad-hoc changes aiming at reproducing helioseismic constraints. The obtained seismic Ledoux discriminant profile as well as the consistent structure obtained from our procedure paves the way for renewed attempts at constraining the solar modelling problem and the missing physical processes acting in the solar interior by breaking free from the hypotheses of evolutionary models. ","astro-ph"
"1909.01841","Neutrino oscillations in a neutrino-dominated accretion disk around a   Kerr BH","  In the binary-driven hypernova (BdHN) model of long gamma-ray bursts, a carbon-oxygen star explodes as a supernova (SN) in presence of a neutron star binary companion in close orbit. Hypercritical (i.e. highly super-Eddington) accretion of the ejecta matter onto the neutron star sets in, making it reach the critical mass with consequent formation of a Kerr black hole (BH). We have recently shown that, during the accretion process onto the neutron star, fast neutrino flavour oscillations occur. Numerical simulations of the above system show that a part of the ejecta keeps bound to the newborn Kerr BH, leading to a new process of hypercritical accretion. We here address, also for this phase of the BdHN, the occurrence of neutrino flavour oscillations given the extreme conditions of high density (up to $10^{12}$ g cm$^{-3}$) and temperatures (up to tens of MeV) inside this disk. We estimate the evolution of the electronic and non-electronic neutrino content within the two-flavour formalism ($\nu_{e}\nu_{x}$) under the action of neutrino collective effects by neutrino self-interactions. We find that neutrino oscillations inside the disk have frequencies between $\sim (10^{5}$-$10^{9})$ s$^{-1}$, leading the disk to achieve flavour equipartition. This implies that the energy deposition rate by neutrino annihilation ($\nu + \bar{\nu} \to e^{-} + e^{+}$) in the vicinity of the Kerr BH, is smaller than previous estimates in the literature not accounting by flavour oscillations inside the disk. The exact value of the reduction factor depends on the $\nu_{e}$ and $\nu_{x}$ optical depths but it can be as high as $\sim 5$. The results of this work are a first step toward the analysis of neutrino oscillations in a novel astrophysical context and, as such, deserve further attention. ","astro-ph"
"1812.06919","Contrasting the effects of adaptation and synaptic filtering on the   timescales of dynamics in recurrent networks","  Neural activity exhibits a vast range of timescales that can be several fold larger than the membrane time constant of individual neurons. Two types of mechanisms have been proposed to explain this conundrum. One possibility is that large timescales are generated by a network mechanism based on positive feedback, but this hypothesis requires fine-tuning of the synaptic connections. A second possibility is that large timescales in the neural dynamics are inherited from large timescales of underlying biophysical processes, two prominent candidates being adaptive ionic currents and synaptic transmission. How the timescales of these processes influence the timescale of the network dynamics has however not been fully explored. To address this question, we analyze large networks of randomly connected excitatory and inhibitory units with additional degrees of freedom that correspond to adaptation or synaptic filtering. We determine the fixed points of the systems, their stability to perturbations and the corresponding dynamical timescales. Furthermore, we apply dynamical mean field theory to study the temporal statistics of the activity in the fluctuating regime, and examine how the adaptation and synaptic timescales transfer from individual units to the whole population. Our overarching finding is that synaptic filtering and adaptation in single neurons have very different effects at the network level. Unexpectedly, the macroscopic network dynamics do not inherit the large timescale present in adaptive currents. In contrast, the timescales of network activity increase proportionally to the time constant of the synaptic filter. Altogether, our study demonstrates that the timescales of different biophysical processes have different effects on the network level, so that the slow processes within individual neurons do not necessarily induce slow activity in large recurrent neural networks. ","q-bio"
"2008.11121","Use of adaptive filtering techniques and deconvolution to obtain low   range sidelobe samples","  In this paper the use of adaptive filtering techniques to obtain better peak sidelobe suppression and integrated sidelobe energy will be discussed with regard to weather radars and obtaining better sensitivity with this technique. The performance of these new coefficient sets obtained with adaptive filter (using RLS optimization) will be discussed and presented. They will also be compared with the existing techniques and their peak sidelobe levels. ","eess"
"2005.03046","Holographic Line Defects in $D=4$, $N=2$ Gauged Supergravity","  We construct solutions of four-dimensional $N=2$ gauged supergravity coupled to vector multiplets which are holographically dual to superconformal line defects. For the gauged STU and the $SU(1,n)/U(1)\times SU(n)$ coset models, we use the solutions to calculate holographic observables such as the expectation value of the defect and one-point functions in the presence of the defect. ","hep-th"
"2002.08431","Number-phase entanglement and Einstein-Podolsky-Rosen steering","  We use the uncertainty relation between the operators associated to the total number of particles and to the relative phase of two bosonic modes to construct entanglement and Einstein-Podolsky-Rosen steering criteria. These can be tested experimentally in a variety of systems, such as optical fields, Bose-Einstein condensates or mechanical oscillators. While known entanglement criteria involving the phase observable typically require to perform interference measurements by recombining the two systems, our criteria can be tested through local measurements at two spatially distinct positions, to investigate the nonlocal nature of quantum correlations. We present simple examples where our criteria are violated, and show their robustness to noise. Apart from being useful for state characterization, they might find application in quantum information protocols, for example based on number-phase teleportation. ","quant-ph"
"1707.01845","Negative association, ordering and convergence of resampling methods","  We study convergence and convergence rates for resampling schemes. Our first main result is a general consistency theorem based on the notion of negative association, which is applied to establish the almost-sure weak convergence of measures output from Kitagawa's (1996) stratified resampling method. Carpenter et al's (1999) systematic resampling method is similar in structure but can fail to converge depending on the order of the input samples. We introduce a new resampling algorithm based on a stochastic rounding technique of Srinivasan (2001), which shares some attractive properties of systematic resampling, but which exhibits negative association and therefore converges irrespective of the order of the input samples. We confirm a conjecture made by Kitagawa (1996) that ordering input samples by their states in $\mathbb{R}$ yields a faster rate of convergence; we establish that when particles are ordered using the Hilbert curve in $\mathbb{R}^d$, the variance of the resampling error is ${\scriptscriptstyle\mathcal{O}}(N^{-(1+1/d)})$ under mild conditions, where $N$ is the number of particles. We use these results to establish asymptotic properties of particle algorithms based on resampling schemes that differ from multinomial resampling. ","stat"
"1905.10343","Two-Dimensional Tomography From Noisy Projection Tilt Series Taken At   Unknown View Angles With Non-Uniform Distribution","  We consider a problem that recovers a 2-D object and the underlying view angle distribution from its noisy projection tilt series taken at unknown view angles. Traditional approaches rely on the estimation of the view angles of the projections, which do not scale well with the sample size and are sensitive to noise. We introduce a new approach using the moment features to simultaneously recover the underlying object and the distribution of view angles. This problem is formulated as constrained nonlinear least squares in terms of the truncated Fourier-Bessel expansion coefficients of the object and is solved by a new alternating direction method of multipliers (ADMM)-based algorithm. Our numerical experiments show that the new approach outperforms the expectation maximization (EM)-based maximum marginalized likelihood estimation in efficiency and accuracy. Furthermore, the hybrid method that uses EM to refine ADMM solution achieves the best performance. ","eess"
"2008.09955","Nanofibril-mediated Fracture Resistance of Bone","  Natural hard composites like human bone possess a combination of strength and toughness that exceeds that of their constituents and of many engineered composites. This augmentation is attributed to their complex hierarchical structure, spanning multiple length scales; in bone, characteristic dimensions range from nanoscale fibrils to microscale lamellae to mesoscale osteons and macroscale organs. The mechanical properties of bone have been studied, with the understanding that the isolated microstructure at micro- and nano-scales gives rise to superior strength compared to that of whole tissue, and the tissue possesses an amplified toughness relative to that of its nanoscale constituents. Nanoscale toughening mechanisms of bone are not adequately understood at sample dimensions that allow for isolating salient microstructural features, because of the challenge of performing fracture experiments on small-sized samples. We developed an in-situ three-point bend experimental methodology that probes site-specific fracture behavior of micron-sized specimens of hard material. Using this, we quantify crack initiation and growth toughness of human trabecular bone with sharp fatigue pre-cracks and blunt notches. Our findings indicate that bone with fatigue cracks is two times tougher than that with blunt cracks. In-situ data-correlated electron microscopy videos reveal this behavior arises from crack-bridging by nanoscale fibril structure. The results reveal a transition between fibril-bridging (~1 $\mu$m) and crack deflection/twist (~500 $\mu$m) as a function of length-scale, and quantitatively demonstrate hierarchy-induced toughening in a complex material. This versatile approach enables quantifying the relationship between toughness and microstructure in various complex material systems and provides direct insight for designing biomimetic composites. ","cond-mat"
"1901.07887","Network-Connected UAV: 3D System Modeling and Coverage Performance   Analysis","  With growing popularity, unmanned aerial vehicles (UAVs) are pivotally extending conventional terrestrial Internet of Things (IoT) into the sky. To enable high-performance two-way communications of UAVs with their ground pilots/users, cellular network-connected UAV has drawn significant interests recently. Among others, an important issue is whether the existing cellular network, designed mainly for terrestrial users, is also able to effectively cover the new UAV users in the three-dimensional (3D) space for both uplink and downlink communications. Such 3D coverage analysis is challenging due to the unique air-ground channel characteristics, the resulted interference issue with terrestrial communication, and the non-uniform 3D antenna gain pattern of ground base station (GBS) in practice. Particularly, high-altitude UAV often possesses a high probability of line-of-sight (LoS) channels with a large number of GBSs, while their random binary (LoS/Non-LoS) channel states and (on/off) activities give rise to exponentially large number of discrete UAV-GBS association/interference states, rendering coverage analysis more difficult. This paper presents a new 3D system model to incorporate UAV users and proposes an analytical framework to characterize their uplink/downlink 3D coverage performance. To tackle the above exponential complexity, we introduce a generalized Poisson multinomial (GPM) distribution to model the discrete interference states, and a novel lattice approximation (LA) technique to approximate the non-lattice GPM variable and obtain the interference distribution efficiently with high accuracy. The 3D coverage analysis is validated by extensive numerical results, which also show effects of key system parameters such as cell loading factor, GBS antenna downtilt, UAV altitude and antenna beamwidth. ","eess"
"2004.05680","Lorentz-violating scalar QED renormalization","  This paper presents divergent contributions of the radiative corrections for a Lorentz-violating extension of the scalar electrodynamics. We initially discuss some features of the model and extract the Feynman rules. Then we compute the one-loop radiative corrections using Feynman parametrization and dimensional regularization in order to evaluate the integrals. We also discuss Furry's theorem validity and renormalization in the present context. ","hep-th"
"1907.00345","Frequentist performances of Bayesian prediction intervals for   random-effects meta-analysis","  The prediction interval has been increasingly used in meta-analyses as a useful measure for assessing the magnitude of treatment effect and between-studies heterogeneity. In calculations of the prediction interval, although the Higgins-Thompson-Spiegelhalter method is used most often in practice, it might not have adequate coverage probability for the true treatment effect of a future study under realistic situations. An effective alternative candidate is the Bayesian prediction interval, which has also been widely used in general prediction problems. However, these prediction intervals are constructed based on the Bayesian philosophy, and their frequentist validities are only justified by large-sample approximations even if non-informative priors are adopted. There has been no certain evidence that evaluated their frequentist performances under realistic situations of meta-analyses. In this study, we conducted extensive simulation studies to assess the frequentist coverage performances of Bayesian prediction intervals with 11 non-informative prior distributions under general meta-analysis settings. Through these simulation studies, we found that frequentist coverage performances strongly depended on what prior distributions were adopted. In addition, when the number of studies was smaller than 10, there were no prior distributions that retained accurate frequentist coverage properties. We also illustrated these methods via applications to eight real meta-analysis datasets. The resultant prediction intervals also differed according to the adopted prior distributions. Inaccurate prediction intervals may provide invalid evidence and misleading conclusions. Thus, if frequentist accuracy is required, Bayesian prediction intervals should be used cautiously in practice. ","stat"
"1902.05633","Quantum Measurements and Contextuality","  In quantum physics the term `contextual' can be used in more than one way. One usage, here called `Bell contextual' since the idea goes back to Bell, is that if $A$, $B$ and $C$ are three quantum observables, with $A$ compatible (i.e., commuting) with $B$ and also with $C$, whereas $B$ and $C$ are incompatible, a measurement of $A$ might yield a different result (indicating that quantum mechanics is contextual) depending upon whether $A$ is measured along with $B$ (the $\{A,B\}$ context) or with $C$ (the $\{A,C\}$ context). An analysis of what projective quantum measurements measure shows that quantum theory is Bell noncontextual: the outcome of a particular $A$ measurement when $A$ is measured along with $B$ would have been exactly the same if $A$ had, instead, been measured along with $C$.   A different definition, here called `globally (non)contextual' refers to whether or not there is ('noncontextual') or is not ('contextual') a single joint probability distribution that simultaneously assigns probabilities in a consistent manner to the outcomes of measurements of a certain collection of observables, not all of which are compatible. A simple example shows that such a joint probability distribution can exist even in a situation where the measurement probabilities cannot refer to properties of a quantum system, and hence lack physical significance, even though mathematically well-defined. It is noted that the quantum sample space, a projective decomposition of the identity, required for interpreting measurements of incompatible properties in different runs of an experiment using different types of apparatus has a tensor product structure, a fact sometimes overlooked. ","quant-ph"
"1811.06810","Sequential games and nondeterministic selection functions","  This paper analyses Escard\'o and Oliva's generalisation of selection functions over a strong monad from a game-theoretic perspective. We focus on the case of the nondeterminism (finite nonempty powerset) monad $\mathcal{P}$. We use these nondeterministic selection functions of type $\mathcal{J}^{\mathcal{P}}_R X = (X \rightarrow R) \rightarrow \mathcal{P} (X)$ to study sequential games, extending previous work linking (deterministic) selection functions to game theory. Similar to deterministic selection functions, which compute a subgame perfect Nash equilibrium play of a game, we characterise those non-deterministic selection functions which have a clear game-theoretic interpretation. We show, surprisingly, no non-deterministic selection function exists which computes the set of all subgame perfect Nash equilibrium plays. Instead we show that there are selection functions corresponding to sequential versions of the iterated removal of strictly dominated strategies. ","cs"
"2006.02590","Relationship between blood pressure and flow rate in arteries using a   modified Windkessel model","  This study examined the flow rate in arteries using the modified Windkessel model, considering various models for blood pressure. An exact solution was derived using a Laplace transform method and the effects of blood pressure on the flow rate in an artery were examined. The effects of the flow resistance, arterial compliance, and inertia of blood on the flow rate were also investigated. The flow rate decreased with increasing inertia of the blood and flow resistance and decreasing arterial compliance. The height and position of the secondary peak were determined by a combination of the flow resistance, arterial compliance, and blood inertance. The results suggest that the risk of hypertension may increase with age because decreases in flow rate due to an increase in flow resistance and a decrease in arterial compliance were more substantial than the increase in flow rate caused by a decrease in blood inertance. The proposed method can provide information to examine how factors, such as aging, disease, and exercise, affect the flow rate in blood vessels. ","q-bio"
"2004.05275","Multi-View Matching (MVM): Facilitating Multi-Person 3D Pose Estimation   Learning with Action-Frozen People Video","  To tackle the challeging problem of multi-person 3D pose estimation from a single image, we propose a multi-view matching (MVM) method in this work. The MVM method generates reliable 3D human poses from a large-scale video dataset, called the Mannequin dataset, that contains action-frozen people immitating mannequins. With a large amount of in-the-wild video data labeled by 3D supervisions automatically generated by MVM, we are able to train a neural network that takes a single image as the input for multi-person 3D pose estimation. The core technology of MVM lies in effective alignment of 2D poses obtained from multiple views of a static scene that has a strong geometric constraint. Our objective is to maximize mutual consistency of 2D poses estimated in multiple frames, where geometric constraints as well as appearance similarities are taken into account simultaneously. To demonstrate the effectiveness of 3D supervisions provided by the MVM method, we conduct experiments on the 3DPW and the MSCOCO datasets and show that our proposed solution offers the state-of-the-art performance. ","cs"
"1910.03531","Causal Inference for Comprehensive Cohort Studies","  In a comprehensive cohort study of two competing treatments (say, A and B), clinically eligible individuals are first asked to enroll in a randomized trial and, if they refuse, are then asked to enroll in a parallel observational study in which they can choose treatment according to their own preference. We consider estimation of two estimands: (1) comprehensive cohort causal effect -- the difference in mean potential outcomes had all patients in the comprehensive cohort received treatment A vs. treatment B and (2) randomized trial causal effect -- the difference in mean potential outcomes had all patients enrolled in the randomized trial received treatment A vs. treatment B. For each estimand, we consider inference under various sets of unconfoundedness assumptions and construct semiparametric efficient and robust estimators. These estimators depend on nuisance functions, which we estimate, for illustrative purposes, using generalized additive models. Using the theory of sample splitting, we establish the asymptotic properties of our proposed estimators. We also illustrate our methodology using data from the Bypass Angioplasty Revascularization Investigation (BARI) randomized trial and observational registry to evaluate the effect of percutaneous transluminal coronary balloon angioplasty versus coronary artery bypass grafting on 5-year mortality. To evaluate the finite sample performance of our estimators, we use the BARI dataset as the basis of a realistic simulation study. ","stat"
"1904.00795","Upper continuity bound on the quantum quasi-relative entropy","  We provide an upper bound on the quasi-relative entropy in terms of the trace distance. The bound is derived for several types of the function, as well for any operator monotone decreasing function and mixed qubit states. We apply the result to the Umegaki relative entropy and the q-entropy. ","quant-ph"
"1809.09639","Sparse Recovery and Dictionary Learning from Nonlinear Compressive   Measurements","  Sparse coding and dictionary learning are popular techniques for linear inverse problems such as denoising or inpainting. However in many cases, the measurement process is nonlinear, for example for clipped, quantized or 1-bit measurements. These problems have often been addressed by solving constrained sparse coding problems, which can be difficult to solve, and assuming that the sparsifying dictionary is known and fixed. Here we propose a simple and unified framework to deal with nonlinear measurements. We propose a cost function that minimizes the distance to a convex feasibility set, which models our knowledge about the nonlinear measurement. This provides an unconstrained, convex, and differentiable cost function that is simple to optimize, and generalizes the linear least squares cost commonly used in sparse coding. We then propose proximal based sparse coding and dictionary learning algorithms, that are able to learn directly from nonlinearly corrupted signals. We show how the proposed framework and algorithms can be applied to clipped, quantized and 1-bit data. ","eess"
"1912.09635","Decoding Quantum Error Correction Codes with Local Variation","  In this paper we investigate the role of local information in the decoding of the repetition and surface error correction codes for the protection of quantum states. Our key result is an improvement in resource efficiency when local information is taken into account during the decoding process: the code distance associated with a given logical error rate is reduced with a magnitude depending on the proximity of the physical error rate to the accuracy threshold of the code. We also briefly discuss an averaged approach with local information for table-lookup and localised decoding schemes, an expected breakdown of these effects for large-scale systems, and the importance of this resource reduction in the near-term. ","quant-ph"
"2007.04177","Modelling excess zeros in count data: A new perspective on modelling   approaches","  We consider models underlying regression analysis of count data in which the observed frequency of zero counts is unusually large, typically with respect to the Poisson distribution. We focus on two alternative modelling approaches: Over-Dispersion (OD) models, and Zero-Inflation (ZI) models, both of which can be seen as generalisations of the Poisson distribution; we refer to these as Implicit and Explicit ZI models, respectively. Although sometimes seen as competing approaches, they can be complementary; OD is a consequence of ZI modelling, and ZI is a by-product of OD modelling. The central objective in such analyses is often concerned with inference on the effect of covariates on the mean, in light of the excess of zeros in the counts. The contribution of our paper is to focus on models for different types of ZI, some of which can only be generated by explicit ZI modelling; and on their characterisation by considering the induced probability of a zero as a function of the zero probability of a base distribution (usually Poisson). We develop the underlying theory for univariate counts. The perspective highlights some of the difficulties encountered in distinguishing the alternative modelling options. ","stat"
"1901.03681","The structure of the Mg II broad line emitting region in Type 1 AGNs","  We investigate the structure of the Mg II broad line emission region in a sample of 284 Type 1 active galactic nuclei (AGNs), through comparing the kinematical parameters of the broad Mg II and broad H$\beta$ lines. We found that the Mg II emitting region has more complex kinematics than the H$\beta$ one. It seems that the \ion{Mg}{ii} broad line originates from two subregions: one which contributes to the line core, which is probably virialized, and the other, 'fountain-like' emitting region, with outflows-inflows nearly orthogonal to the disc, which become suppressed with stronger gravitational influence. This subregion mostly contributes to the emission of the Mg II broad line wings. The kinematics of the Mg II core emitting region is similar to that of the H$\beta$ broad line region (seems to be virialized), and therefore the Full Width at Half Maximum (FWHM) of Mg II still can be used for the black hole (BH) mass estimation in the case where the Mg II core component is dominant. However, one should be careful with using the \ion{Mg}{ii} broad line for the BH mass estimation in the case of very large widths (FWHM$>$ 6000 km s$^{-1}$) and/or in the case of strong blue asymmetry. ","astro-ph"
"1708.03105","Location Name Extraction from Targeted Text Streams using   Gazetteer-based Statistical Language Models","  Extracting location names from informal and unstructured social media data requires the identification of referent boundaries and partitioning compound names. Variability, particularly systematic variability in location names (Carroll, 1983), challenges the identification task. Some of this variability can be anticipated as operations within a statistical language model, in this case drawn from gazetteers such as OpenStreetMap (OSM), Geonames, and DBpedia. This permits evaluation of an observed n-gram in Twitter targeted text as a legitimate location name variant from the same location-context. Using n-gram statistics and location-related dictionaries, our Location Name Extraction tool (LNEx) handles abbreviations and automatically filters and augments the location names in gazetteers (handling name contractions and auxiliary contents) to help detect the boundaries of multi-word location names and thereby delimit them in texts.   We evaluated our approach on 4,500 event-specific tweets from three targeted streams to compare the performance of LNEx against that of ten state-of-the-art taggers that rely on standard semantic, syntactic and/or orthographic features. LNEx improved the average F-Score by 33-179%, outperforming all taggers. Further, LNEx is capable of stream processing. ","cs"
"2003.04666","Refactoring Graphs: Assessing Refactoring over Time","  Refactoring is an essential activity during software evolution. Frequently, practitioners rely on such transformations to improve source code maintainability and quality. As a consequence, this process may produce new source code entities or change the structure of existing ones. Sometimes, the transformations are atomic, i.e., performed in a single commit. In other cases, they generate sequences of modifications performed over time. To study and reason about refactorings over time, in this paper, we propose a novel concept called refactoring graphs and provide an algorithm to build such graphs. Then, we investigate the history of 10 popular open-source Java-based projects. After eliminating trivial graphs, we characterize a large sample of 1,150 refactoring graphs, providing quantitative data on their size, commits, age, refactoring composition, and developers. We conclude by discussing applications and implications of refactoring graphs, for example, to improve code comprehension, detect refactoring patterns, and support software evolution studies. ","cs"
"2004.11868","Using B cell receptor lineage structures to predict affinity","  We are frequently faced with a large collection of antibodies, and want to select those with highest affinity for their cognate antigen. When developing a first-line therapeutic for a novel pathogen, for instance, we might look for such antibodies in patients that have recovered. There exist effective experimental methods of accomplishing this, such as cell sorting and baiting; however they are time consuming and expensive. Next generation sequencing of B cell receptor (BCR) repertoires offers an additional source of sequences that could be tapped if we had a reliable method of selecting those coding for the best antibodies. In this paper we introduce a method that uses evolutionary information from the family of related sequences that share a naive ancestor to predict the affinity of each resulting antibody for its antigen. When combined with information on the identity of the antigen, this method should provide a source of effective new antibodies. We also introduce a method for a related task: given an antibody of interest and its inferred ancestral lineage, which branches in the tree are likely to harbor key affinity-increasing mutations? These methods are implemented as part of continuing development of the partis BCR inference package, available at https://github.com/psathyrella/partis. ","q-bio"
"2004.02613","On Completion of Metric Mappings","  An internal characterization of complete metric mappings (by means of Cauchy nets tied at a point) is given and a construction of the completion of a metric mapping is presented. ","math"
"1806.01765","4-particle Amplituhedronics for 3-5 Loops","  Following the direction of 1712.09990 and 1712.09994, this article continues to excavate more interesting aspects of the 4-particle amplituhedron for a better understanding of the 4-particle integrand of planar N=4 SYM to all loop orders, from the perspective of positive geometry. At 3-loop order, we introduce a much more refined dissection of the amplituhedron to understand its essential structure and maximally simplify its direct calculation, by fully utilizing its symmetry as well as the efficient Mondrian way for reorganizing all contributing pieces. Although significantly improved, this approach immediately encounters its technical bottleneck at 4-loop. Still, we manage to alleviate this difficulty by imitating the traditional (generalized) unitarity cuts, which is to use the so-called positive cuts. Given a basis of dual conformally invariant (DCI) loop integrals, we can figure out the coefficient of each DCI topology using its dlog form via positivity conditions. Explicit examples include all 2+5 non-rung-rule topologies at 4- and 5-loop respectively. These results remarkably agree with previous knowledge, which confirms the validity of amplituhedron up to 5-loop and develops a new approach of determining the coefficient of each distinct DCI loop integral. ","hep-th"
"1906.02810","Beyond $M_{t\bar{t}}$: learning to search for a broad $t\bar t$   resonance at the LHC","  A resonance peak in the invariant mass spectrum has been the main feature of a particle at collider experiments. However, broad resonances not exhibiting such a sharp peak are generically predicted in new physics models beyond the Standard Model. Without a peak, how do we discover a broad resonance at colliders? We use machine learning technique to explore answers beyond common knowledge. We learn that, by applying deep neural network to the case of a $t\bar{t}$ resonance, the invariant mass $M_{t\bar{t}}$ is still useful, but additional information from off-resonance region, angular correlations, $p_T$, and top jet mass are also significantly important. As a result, the improved LHC sensitivities do not depend strongly on the width. The results may also imply that the additional information can be used to improve narrow-resonance searches too. Further, we also detail how we assess machine-learned information. ","hep-ph"
"1903.09520","A lightweight convolutional neural network for image denoising with fine   details preservation capability","  Image denoising is a fundamental problem in image processing whose primary objective is to remove the noise while preserving the original image structure. In this work, we proposed a new architecture for image denoising. We have used several dense blocks to design our network. Additionally, we have forwarded feature extracted in the first layer to the input of every transition layer. Our experimental result suggests that the use of low-level feature helps in reconstructing better texture. Furthermore, we had trained our network with a combination of MSE and a differentiable multi-scale structural similarity index(MS-SSIM). With proper training, our proposed model with a much lower parameter can outperform other models which were with trained much higher parameters. We evaluated our algorithm on two grayscale benchmark dataset BSD68 and SET12. Our model had achieved similar PSNR with the current state of the art methods and most of the time better SSIM than other algorithms. ","eess"
"1909.11838","Basis functions on the grain boundary space: Theory","  With the increasing availability of experimental and computational data concerning the properties and distribution of grain boundaries in polycrystalline materials, there is a corresponding need to efficiently and systematically express functions on the grain boundary space. A grain boundary can be described by the rotations applied to two grains on either side of a fixed boundary plane, suggesting that the grain boundary space is related to the space of rotations. This observation is used to construct an orthornormal function basis, allowing effectively arbitrary functions on the grain boundary space to be written as linear combinations of the basis functions. Moreover, a procedure is developed to construct a smaller set of basis functions consistent with the crystallographic point group symmetries, grain exchange symmetry, and the null boundary singularity. Functions with the corresponding symmetries can be efficiently expressed as linear combinations of the symmetrized basis functions. An example is provided that shows the efficacy of the symmetrization procedure. ","cond-mat"
"1803.10683","Pose2Seg: Detection Free Human Instance Segmentation","  The standard approach to image instance segmentation is to perform the object detection first, and then segment the object from the detection bounding-box. More recently, deep learning methods like Mask R-CNN perform them jointly. However, little research takes into account the uniqueness of the ""human"" category, which can be well defined by the pose skeleton. Moreover, the human pose skeleton can be used to better distinguish instances with heavy occlusion than using bounding-boxes. In this paper, we present a brand new pose-based instance segmentation framework for humans which separates instances based on human pose, rather than proposal region detection. We demonstrate that our pose-based framework can achieve better accuracy than the state-of-art detection-based approach on the human instance segmentation problem, and can moreover better handle occlusion. Furthermore, there are few public datasets containing many heavily occluded humans along with comprehensive annotations, which makes this a challenging problem seldom noticed by researchers. Therefore, in this paper we introduce a new benchmark ""Occluded Human (OCHuman)"", which focuses on occluded humans with comprehensive annotations including bounding-box, human pose and instance masks. This dataset contains 8110 detailed annotated human instances within 4731 images. With an average 0.67 MaxIoU for each person, OCHuman is the most complex and challenging dataset related to human instance segmentation. Through this dataset, we want to emphasize occlusion as a challenging problem for researchers to study. ","cs"
"1808.00302","Neutrino spin and spin-flavour oscillations in transversal matter   currents with standard and non-standard interactions","  After a brief history of two known types of neutrino mixing and oscillations, including neutrino spin and spin-flavour oscillations in the transversal magnetic field, we perform systematic study of a new phenomenon of neutrino spin and spin-flavour oscillations engendered by the transversal matter currents on the bases of the developed quantum treatment of the phenomenon. Possibilities for the resonance amplification of these new types of oscillations by the longitudinal matter currents and longitudinal magnetic fields are analyzed. Neutrino spin-flavour oscillations engendered by the transversal matter currents in the case of non-standard interactions of neutrinos with background matter are also considered ","hep-ph"
"1907.09411","Deep Fault Diagnosis for Rotating Machinery with Scarce Labeled Samples","  Early and accurately detecting faults in rotating machinery is crucial for operation safety of the modern manufacturing system. In this paper, we proposed a novel Deep fault diagnosis (DFD) method for rotating machinery with scarce labeled samples. DFD tackles the challenging problem by transferring knowledge from shallow models, which is based on the idea that shallow models trained with different hand-crafted features can reveal the latent prior knowledge and diagnostic expertise and have good generalization ability even with scarce labeled samples. DFD can be divided into three phases. First, a spectrogram of the raw vibration signal is calculated by applying a Short-time Fourier transform (STFT). From those spectrograms, discriminative time-frequency domain features can be extracted and used to form a feature pool. Then, several candidate Support vector machine (SVM) models are trained with different combinations of features in the feature pool with scarce labeled samples. By evaluating the pretrained SVM models on the validation set, the most discriminative features and best-performed SVM models can be selected, which are used to make predictions on the unlabeled samples. The predicted labels reserve the expert knowledge originally carried by the SVM model. They are combined together with the scarce fine labeled samples to form an Augmented training set (ATS). Finally, a novel 2D deep Convolutional neural network (CNN) model is trained on the ATS to learn more discriminative features and a better classifier. Experimental results on two fault diagnosis datasets demonstrate the effectiveness of the proposed DFD, which achieves better performance than SVM models and the vanilla deep CNN model trained on scarce labeled samples. Moreover, it is computationally efficient and is promising for real-time rotating machinery fault diagnosis. ","eess"
"1902.07163","Gaussian quantum channels beyond the Gaussian functional form: full   characterization of the one-mode case","  We study one-mode Gaussian quantum channels in continuous-variable systems by performing a black-box characterization using complete positivity and trace preserving conditions, and report the existence of two subsets that do not have a functional Gaussian form. Our study covers as particular limit the case of singular channels, thus connecting our results with their known classification scheme based on canonical forms. Our full characterization of Gaussian channels without Gaussian functional form is completed by showing how Gaussian states are transformed under these operations, and by deriving the conditions for the existence of master equations for the non-singular cases. ","quant-ph"
"2007.09648","Resummation and simulation of soft gluon effects beyond leading colour","  We present first results of resumming soft gluon effects in a simulation of high energy collisions beyond the leading-colour approximation. We work to all orders in QCD perturbation theory using a new parton branching algorithm. This amplitude evolution algorithm resembles a parton shower that is able to systematically include colour-suppressed terms. We find that colour suppressed terms can significantly contribute to jet veto cross sections. ","hep-ph"
"2004.07592","Loop Operators in Three-Dimensional $\mathcal{N}=2$ Fishnet Theories","  In this work, we study the line and loop operators in three-dimensional ${\mathcal N}=2$ fishnet theories in detail. We construct the straight line and circular loop operators which are at least classically half-BPS. We develop a new regularization scheme at frame $-1$ which is suitable for the study of the fermionic BPS loops in general super-Chern-Simons-matter theories. We initialize the perturbative computation for the vacuum expectation values of the circular BPS loop operators based on this scheme. We construct the cusped line operators as well, and compute the vacuum expectation values of these cusped line operators up to two-loop order. We find that the universal cusp anomalous dimension vanishes, if we put aside the fact that the generalized potential has a double pole in the $1/\epsilon$ expansion. ","hep-th"
"1812.00179","Coupled-Channel-Induced $S-D$ mixing of Charmonia and Testing Possible   Assignments for $Y(4260)$ and $Y(4360)$","  The mass spectrum and the two-body open-charm decays of the $J^{PC}=1^{--}$ charmonium states are studied with the coupled-channel effects taken into account. The coupled-channel-induced mixing effects among the excited vector charmonia are studied. Based on our calculations of the masses and the decay widths, we find that the tension between the observed properties of $Y(4260)/Y(4360)$ and their conventional charmonia interpretations could be softened. ","hep-ph"
"1907.11964","Analytical solutions for the dynamical clock A+ indicator in a toy model   of pure dynamical friction","  Blue straggler stars are more massive than the average star in globular clusters, as they originate from the merger of two stars. Consequently, they experience dynamical friction, progressively sinking to the cluster center. Recently, several indicators of the degree of dynamical relaxation of a globular cluster have been proposed, based on the observed radial distribution of blue straggler stars. The most successful is the Alessandrini indicator, or A+ for short, which is the integral of the cumulative distribution of the blue straggler stars minus that of a lighter reference population. A+ correlates with the dynamical age of a cluster both in realistic simulations and in observations. Here I calculate the temporal dependence of the A+ indicator analytically in a simplified model of the evolution of the blue straggler star distribution under dynamical friction only. ","astro-ph"
"1912.04172","N-extended Chern-Simons Carrollian supergravities in 2+1 spacetime   dimensions","  In this work we present the ultra-relativistic $\mathcal{N}$-extended AdS Chern-Simons supergravity theories in three spacetime dimensions invariant under $\mathcal{N}$-extended AdS Carroll superalgebras. We first consider the $(2,0)$ and $(1,1)$ cases; subsequently, we generalize our analysis to $\mathcal{N}=(\mathcal{N},0)$, with $\mathcal{N}$ even, and to $\mathcal{N}=(p,q)$, with $p,q>0$. The $\mathcal{N}$-extended AdS Carroll superalgebras are obtained through the Carrollian (i.e., ultra-relativistic) contraction applied to an $so(2)$ extension of $\mathfrak{osp}(2|2)\otimes \mathfrak{sp}(2)$, to $\mathfrak{osp}(2|1)\otimes \mathfrak{osp}(2,1)$, to an $\mathfrak{so}(\mathcal{N})$ extension of $\mathfrak{osp}(2|\mathcal{N})\otimes \mathfrak{sp}(2)$, and to the direct sum of an $\mathfrak{so}(p) \oplus \mathfrak{so}(q)$ algebra and $\mathfrak{osp}(2|p)\otimes \mathfrak{osp}(2,q)$, respectively. We also analyze the flat limit ($\ell \rightarrow \infty$, being $\ell$ the length parameter) of the aforementioned $\mathcal{N}$-extended Chern-Simons AdS Carroll supergravities, in which we recover the ultra-relativistic $\mathcal{N}$-extended (flat) Chern-Simons supergravity theories invariant under $\mathcal{N}$-extended super-Carroll algebras. The flat limit is applied at the level of the superalgebras, Chern-Simons actions, supersymmetry transformation laws, and field equations. ","hep-th"
"1906.00682","CO observations of major merger pairs at z=0: Molecular gas mass and   star formation","  We present CO observations of 78 spiral galaxies in local merger pairs. These galaxies representa subsample of a Ks-band selected sample consisting of 88 close major-merger pairs (HKPAIRs), 44 spiral-spiral (S+S) pairs and 44 spiral-elliptical (S+E) pairs, with separation $<20 h^{-1}$ kpc and mass ratio <2.5. For all objects, the star formation rate (SFR) and dust mass were derived from HERSCHEL PACS and SPIRE data, and the atomic gas mass, MHI, from the Green Bank Telescope HI observations. The complete data set allows us to study the relation between the gas (atomic and molecular) mass, dust mass and SFR in merger galaxies. We derive the molecular gas fraction (MH2/M*), molecular-to-atomic gas mass ratio (MH2/MHI), gas-to-dust mass ratio and SFE (=SFR/MH2) and study their dependences on pair type (S+S compared to S+E), stellar mass and the presence of morphological interaction signs. We find an overall moderate enhancements (~2x) in both molecular gas fraction (MH2/M*), and molecular-to-atomic gas ratio (MH2/MHI) for star-forming galaxies in major-merger pairs compared to non-interacting comparison samples, whereas no enhancement was found for the SFE nor for the total gas mass fraction (MHI+MH2)/M*. When divided into S+S and S+E, low mass and high mass, and with and without interaction signs, there is a small difference in SFE, moderate difference in MH2/M*, and strong differences in MH2/MHI between subsamples. For MH2/MHI, the difference between S+S and S+E subsamples is 0.69+-0.16 dex and between pairs with and without interaction signs is 0.53+-0.18 dex. Together, our results suggest (1) star formation enhancement in close major-merger pairs occurs mainly in S+S pairs after the first close encounter (indicated by interaction signs) because the HI gas is compressed into star-forming molecular gas by the tidal torque; (2) this effect is much weakened in the S+E pairs. ","astro-ph"
"1909.01656","handyG -- rapid numerical evaluation of generalised polylogarithms in   Fortran","  Generalised polylogarithms naturally appear in higher-order calculations of quantum field theories. We present handyG, a Fortran 90 library for the evaluation of such functions, by implementing the algorithm proposed by Vollinga and Weinzierl. This allows fast numerical evaluation of generalised polylogarithms with currently relevant weights, suitable for Monte Carlo integration. ","hep-ph"
"1903.09289","Nonlocality Distillation and Quantum Voids","  Via nonlocality distillation, a number of copies of a given nonlocal correlation can be turned into a new correlation displaying a higher degree of nonlocality. Apart from its clear relevance in situations where nonlocality is a resource, distillation protocols also play an important role in the understanding of information-theoretical principles for quantum theory. Here, we derive a necessary condition for nonlocality distillation from two copies and apply it, among other results, to show that $1$D and $2$D quantum voids --faces of the nonlocal simplex set with no quantum realization-- can be distilled up to PR-boxes. With that, we generalize previous results in the literature. For instance, showing a broad class of post-quantum correlations that make communication complexity trivial and violate the information causality principle. ","quant-ph"
"1903.09895","QED challenges at FCC-ee precision measurements","  The expected experimental precision of the rates and asymmetries in the Future Circular Collider with electron positron beams (FCC-ee) in the centre of the mass energy range 88-365GeV considered for construction in CERN, will be better by a factor 5-200. This will be thanks to very high luminosity, factor up to $10^5$ higher than in the past LEP experiments. This poses the extraordinary challenge of improving the precision of the Standard Model predictions by a comparable factor. In particular the perturbative calculations of the trivial QED effects, which have to be removed from the experimental data, are considered to be a major challenge for almost all quantities to be measured at FCC-ee. The task of this paper is to summarize on the ""state of the art"" in this class of the calculations left from the LEP era and to examine what is to be done to match the precision of the FCC-ee experiments -- what kind of technical advancements are necessary. The above analysis will be done for most important observables of the FCC-ee like the total cross sections near $Z$ and $WW$ threshold, charge asymmetries, the invisible width of $Z$ boson, the spin asymmetry from $\tau$ lepton decay and the luminosity measurement. ","hep-ph"
"1904.04424","The First Two Thousand Years of Star Formation","  Starting from a prestellar core with a size of $1.2\times10^4$ AU, we calculate the evolution of a gravitationally collapsing core until $\sim2000$ yr after protostar formation using a three-dimensional resistive magnetohydrodynamic simulation, in which the protostar is resolved with a spatial resolution of $5.6\times10^{-3}$ AU. Following protostar formation, a rotationally supported disk is formed. Although the disk size is as small as $\sim2-4$ AU, it remains present until the end of the simulation. Since the magnetic field dissipates and the angular momentum is then not effectively transferred by magnetic effects, the disk surface density gradually increases and spiral arms develop due to gravitational instability. The disk angular momentum is then transferred mainly by gravitational torques, which induce an episodic mass accretion onto the central protostar. The episodic accretion causes a highly time-variable mass ejection (the high-velocity jet) near the disk inner edge, where the magnetic field is well coupled with the neutral gas. As the mass of the central protostar increases, the jet velocity gradually increases and exceeds $\sim100$ km s$^{-1}$. The jet opening angle widens with time at its base, while the jet keeps a very good collimation on the large scale. In addition, a low-velocity outflow is driven from the disk outer edge. A cavity-like structure, a bow shock and several knots, all of which are usually observed in star-forming regions, are produced in the outflowing region. ","astro-ph"
"2003.10283","Breaking BEC","  In this work quantum corrections to the classical evolution of a relativistic scalar condensate are studied. The problem is approached by means of two different perturbative approaches: the 2-particle-irreducible (2PI) effective action and the expansion in the self-coupling. In the weak coupling regime, the decoherence of the classical state is observed. The corresponding timescale is identified with the quantum break-time. ","hep-th"
"2004.08761","Lightweight Mask R-CNN for Long-Range Wireless Power Transfer Systems","  Resonant Beam Charging (RBC) is a wireless charging technology which supports multi-watt power transfer over meter-level distance. The features of safety, mobility and simultaneous charging capability enable RBC to charge multiple mobile devices safely at the same time. To detect the devices that need to be charged, a Mask R-CNN based dection model is proposed in previous work. However, considering the constraints of the RBC system, it's not easy to apply Mask R-CNN in lightweight hardware-embedded devices because of its heavy model and huge computation. Thus, we propose a machine learning detection approach which provides a lighter and faster model based on traditional Mask R-CNN. The proposed approach makes the object detection much easier to be transplanted on mobile devices and reduce the burden of hardware computation. By adjusting the structure of the backbone and the head part of Mask R-CNN, we reduce the average detection time from $1.02\mbox{s}$ per image to $0.6132\mbox{s}$, and reduce the model size from $245\mbox{MB}$ to $47.1\mbox{MB}$. The improved model is much more suitable for the application in the RBC system. ","cs"
"2002.06042","Simplified Vehicle-Bridge Interaction for Medium to Long-span Bridges   Subject to Random Traffic Load","  This study introduces a simplified model for bridge-vehicle interaction for medium- to long-span bridges subject to random traffic loads. Previous studies have focused on calculating the exact response of the vehicle or the bridge based on an interaction force derived from the compatibility between two systems. This process requires multiple iterations per time step per vehicle until the compatibility is reached. When a network of vehicles is considered, the compatibility equation turns to a system of coupled equations which dramatically increases the complexity of the convergence process. In this study, we simplify the problem into two sub-problems that are decoupled: (a) a bridge subject to random Gaussian excitation, and (b) individual sensing agents that are subject to a linear superposition of the bridge response and the road profile roughness. The study provides sufficient evidence to confirm the simulation approach is valid with a minimal error when the bridge span is medium to long, and the spatio-temporal load pattern can be modeled as random Gaussian. Quantitatively, the proposed approach is over 1,000 times more computationally efficient when compared to the conventional approach for a 500 m long bridge, with response prediction errors below $0.1\%$. ","eess"
"1804.02921","Distributional Regression Forests for Probabilistic Precipitation   Forecasting in Complex Terrain","  To obtain a probabilistic model for a dependent variable based on some set of explanatory variables, a distributional approach is often adopted where the parameters of the distribution are linked to regressors. In many classical models this only captures the location of the distribution but over the last decade there has been increasing interest in distributional regression approaches modeling all parameters including location, scale, and shape. Notably, so-called non-homogeneous Gaussian regression (NGR) models both mean and variance of a Gaussian response and is particularly popular in weather forecasting. Moreover, generalized additive models for location, scale, and shape (GAMLSS) provide a framework where each distribution parameter is modeled separately capturing smooth linear or nonlinear effects. However, when variable selection is required and/or there are non-smooth dependencies or interactions (especially unknown or of high-order), it is challenging to establish a good GAMLSS. A natural alternative in these situations would be the application of regression trees or random forests but, so far, no general distributional framework is available for these. Therefore, a framework for distributional regression trees and forests is proposed that blends regression trees and random forests with classical distributions from the GAMLSS framework as well as their censored or truncated counterparts. To illustrate these novel approaches in practice, they are employed to obtain probabilistic precipitation forecasts at numerous sites in a mountainous region based on a large number of numerical weather prediction quantities. It is shown that the novel distributional regression forests automatically select variables and interactions, performing on par or often even better than GAMLSS specified either through prior meteorological knowledge or a computationally more demanding boosting approach. ","stat"
"2007.15974","Beamformed Energy Detection in the Presence of an Interferer for   Cognitive mmWave Network","  In this paper, we propose beamformed energy detection (BFED) spectrum sensing scheme for a single secondary user (SU) or a cognitive radio (CR). The SU equipped with multiple antennas is used to detect a primary user (PU) transmission in presence of interferer. Saleh-Valenzuela channel model is used to model the mmWave channel for the considered scenario. In the mmWave band due to high attenuation, there are fewer multipaths and the channel is sparse giving rise to fewer direction of arrivals (DoAs). Sensing in only these paths instead of blind energy detection can reap significant benefits. An analog beamforming weight vector is designed such that beamforming gain in the true DoAs of the PU signal is maximized while minimizing interference from the interferer. For this, a single objective function, which is weighted sum of the two objective functions related to beamforming gain and interference, is formed. The proposed sensing scheme is designed under the knowledge of full CSI at the SU for the PU-SU and Interferer-SU channels. However, as the channel information may not be available at the SU, a second BFED sensing scheme is also proposed when no CSI is available, which only tries to estimate the DoAs to reduce the computational complexity. To model the estimates of DoAs, perturbations are added to the true DoAs. The distribution of the test statistics for both the proposed BFED schemes is derived under the null hypothesis so that the threshold of the Neyman-Pearson detector can be found analytically. The performance of both the schemes is also compared with the traditional energy detector for multi-antenna systems. ","eess"
"2003.03580","Two new methods for identifying proteins based on the domain protein   complexes and topological properties","  The recognition of essential proteins not only can help to understand the mechanism of cell operation, but also help to study the mechanism of biological evolution. At present, many scholars have been discovering essential proteins according to the topological structure of protein network and complexes. While some proteins still can not be recognized. In this paper, we proposed two new methods complex degree centrality (CDC) and complex in-degree and betweenness definition (CIBD) which integrate the local character of protein complexes and topological properties to determine the essentiality of proteins. First, we give the definitions of complex average centrality (CAC) and complex hybrid centrality (CHC) which both describe the properties of protein complexes. Then we propose these new methods CDC and CIBD based on CAC and CHC definitions. In order to access these two methods, different Protein-Protein Interaction (PPI) networks of Saccharomyces cerevisiae, DIP, MIPS and YMBD are used as experimental materials. Experimental results in networks show that the methods of CDC and CIBD can help to improve the precision of predicting essential proteins. ","q-bio"
"1908.06074","Configurational entropy and instability of tachyonic braneworld","  We consider tachyonic braneworld with a bulk cosmological constant and investigate a configurational entropy of various magnitudes of scale factor. It is found that for a bulk negative/zero cosmological constant, the configurational entropy has a global minimum when the magnitude of scale factor reaches the critical value. This result seems to have intriguing implications such that an accelerated rate of the universe and cosmological inflation rate for radiation/matter domination are able to be determined by such critical value. We also find that the configurational entropy almost monotonically decreases for a bulk positive cosmological constant as the magnitude of scale factor grows up. We find an exact solution of tachyonic braneworld in a bulk de Sitter space. It is shown that such system under scalar perturbations is stable for some constraint relation. Furthermore, we also find that tachyonic braneworld model with a bulk negative/zero cosmological constant is always stable under scalar perturbations. ","hep-th"
"2007.00974","A hybrid landmark Aalen-Johansen estimator for transition probabilities   in partially non-Markov multi-state models","  Multi-state models are increasingly being used to model complex epidemiological and clinical outcomes over time. It is common to assume that the models are Markov, but the assumption can often be unrealistic. The Markov assumption is seldomly checked and violations can lead to biased estimation for many parameters of interest. As argued by Datta and Satten (2001), the Aalen-Johansen estimator of occupation probabilities is consistent also in the non-Markov case. Putter and Spitoni (2018) exploit this fact to construct a consistent estimator of state transition probabilities, the landmark Aalen-Johansen estimator, which does not rely on the Markov assumption. A disadvantage of landmarking is data reduction, leading to a loss of power. This is problematic for less traveled transitions, and undesirable when such transitions indeed exhibit Markov behaviour. Using a framework of partially non-Markov multi-state models we suggest a hybrid landmark Aalen-Johansen estimator for transition probabilities. The proposed estimator is a compromise between regular Aalen-Johansen and landmark estimation, using transition specific landmarking, and can drastically improve statistical power. The methods are compared in a simulation study and in a real data application modelling individual transitions between states of sick leave, disability, education, work and unemployment. In the application, a birth cohort of 184951 Norwegian men are followed for 14 years from the year they turn 21, using data from national registries. ","stat"
"1907.12681","Residue guided loop filter for HEVC post processing","  The block-based coding structure in the hybrid coding framework gives rise to the obvious artifacts such as blocking, ringing .etc. Recently, some Convolutional Neural Network (CNN) based works apply reconstruction as the only input to reduce the artifacts. Though the performance of these works relying on powerful learning ability surpasses traditional loop-filter based methods in the High Efficiency Video Coding (HEVC) standard, how to enhance the high frequency signal is still not addressed. In addition to reconstruction, we first propose using the residue as the other input of our CNN-based loop filter. In essence, the residual signal as a high frequency indicator guides the CNN to augment the high frequency signal such as sharp shape and edge information. Second, we find out that the reconstruction and residue signals have different characteristics and should be handled with different network structures. For the reconstruction, we develop an All Frequency (reconstruction) CNN (AF-CNN) adopting the down sampling and up sampling pairs to learn all frequency signal with the global information. For the residue, we devise a High Frequency (residual) CNN (HF-CNN) customizing the Residual Blocks to adapt to the high frequency signal information. To the best of our knowledge, this is the first work that employs residual signal as a vital independent high frequency input to direct the learning of CNN- based loop filtering. We implement the proposed algorithms in the HEVC reference software. The experimental results show that our proposed approach of dual inputs of Residual and Reconstruction with HF-CNN and AF-CNN respectively (RRHA) presents significant BD-rate savings compared with the current CNN-based scheme. ","eess"
"1905.12314","Holographic correlators in AdS$_3$ without Witten diagrams","  We present a formula for the holographic 4-point correlators in AdS$_3 \times S^3$ involving four single-trace operators of dimension $k, k, l, l$. As an input we use the supergravity results for the Heavy-Heavy-Light-Light correlators that can be derived by studying the linear fluctuations around known asymptotically AdS$_3 \times S^3$ geometries. When the operators of dimension $k$ and $l$ are in the same multiplet there are contributions due to the exchange of single-trace operators in the $t$ and $u$ channels, which are not captured by the approach mentioned above. However by rewriting the $s$-channel results in Mellin space we obtain a compact expression for the $s$-channel contribution that makes it possible to conjecture a formula for the complete result. We discuss some consistency checks that our proposal meets. ","hep-th"
"0902.2752","Muon Oscillations","  Muons produced via the $\pi \to \mu \nu_{\mu}$ decay are in a coherent superposition of energy states because the $\nu_{\mu}$ is not a mass eigenstate. This presents an opportunity to access neutrino mixing parameters via muon decay. The oscillation period is long compared to the muon lifetime which presents some experimental challenges. ","hep-ph"
"2005.14149","Evolving to learn: discovering interpretable plasticity rules for   spiking networks","  Continuous adaptation allows survival in an ever-changing world. Adjustments in the synaptic coupling strength between neurons are essential for this capability, setting us apart from simpler, hard-wired organisms. How these adjustments come about is essential both for understanding biological information processing and for developing cognitively performant artificial systems. We suggest an automated approach for discovering biophysically plausible plasticity rules based on the definition of task families, associated performance measures and biophysical constraints. This approach makes the relative weighting of guiding factors explicit, explores large search spaces, encourages diverse sets of hypotheses, and can discover domain-specific solutions. By evolving compact symbolic expressions we ensure the discovered plasticity rules are amenable to intuitive understanding. This is fundamental for successful communication and human-guided generalization, for example to different network architectures or task domains. We demonstrate the flexibility of our approach by discovering efficient plasticity rules in typical learning scenarios. ","q-bio"
"1903.01485","Statistical approach to detection of signals by Monte Carlo singular   spectrum analysis: Multiple testing","  The statistical approach to detection of a signal in noisy series is considered in the framework of Monte Carlo singular spectrum analysis. This approach contains a technique to control both type I and type II errors and also compare criteria. For simultaneous testing of multiple frequencies, a multiple version of MC-SSA is suggested to control the family-wise error rate. ","stat"
"2003.02859","PhaseTracer: tracing cosmological phases and calculating transition   properties","  We present a C++ software package called PhaseTracer for mapping out cosmological phases, and potential transitions between them, for Standard Model extensions with any number of scalar fields. PhaseTracer traces the minima of effective potential as the temperature changes, and then calculates the critical temperatures, at which the minima are degenerate. PhaseTracer is constructed with modularity, flexibility and practicality in mind. It is fast and stable, and can receive potentials provided by other packages such as FlexibleSUSY. PhaseTracer can be useful analysing cosmological phase transitions which played an important role in the very early evolution of the Universe. If they were first order they could generate detectable gravitational waves and/or trigger electroweak baryogenesis to generate the observed matter anti-matter asymmetry of the Universe. The code can be obtained from https://github.com/PhaseTracer/PhaseTracer. ","hep-ph"
"1907.06409","Stabilized Barzilai-Borwein method","  The Barzilai-Borwein (BB) method is a popular and efficient tool for solving large-scale unconstrained optimization problems. Its search direction is the same as for the steepest descent (Cauchy) method, but its stepsize rule is different. Owing to this, it converges much faster than the Cauchy method. A feature of the BB method is that it may generate too long steps, which throw the iterates too far away from the solution. Moreover, it may not converge, even when the objective function is strongly convex. In this paper, a stabilization technique is introduced. It consists in bounding the distance between each pair of successive iterates, which often allows for decreasing the number of BB iterations. When the BB method does not converge, our simple modification of this method makes it convergent. Under suitable assumptions, we prove its global convergence, despite the fact that no line search is involved, and only gradient values are used. Since the number of stabilization steps is proved to be finite, the stabilized version inherits the fast local convergence of the BB method. The presented results of extensive numerical experiments show that our stabilization technique often allows the BB method to solve problems in a fewer iterations, or even to solve problems where the latter fails. ","math"
"1905.02459","Bayesian modeling of two-species bacterial competition growth and   decline rates in milk","  Shiga toxin-producing Escherichia coli O157: H7 is a food-borne pathogen and the major cause of hemorrhagic colitis. Pseudomonas is the genus most frequent psychrotrophic spoilage microorganisms present in milk. Two-species bacterial systems with Escherichia coli O157: H7, non-pathogenic Escherichia coli, and Pseudomonas fluorescens in skimmed milk at 7, 13, 19, or 25 C was studied. Bacterial interactions were modelled after applying a Bayesian approach. No direct correlation between Pseudomonas fluorescent's growth rate and its effect on the maximum population densities of Escherichia coli species was found. The results show the complexity of the interactions between two species into a food model. The use of natural microbiota members to control foodborne pathogens could be useful to improve food safety during the processing and storage of refrigerated foods. ","q-bio"
"1903.09648","Search for high-energy neutrinos from binary neutron star mergers","  To search for transient astrophysical neutrino sources, IceCube's optical and X-ray follow-up program is triggered by two or more neutrino candidates arriving from a similar direction within 100s. However, the rate of such neutrino multiplets was found to be consistent with the expected background of chance coincidences, such that the data does not provide indications for the existence of short-lived transient neutrino sources. Upper limits on the neutrino flux of transient source populations are presented in Aartsen et al. (2019) and we show here how these limits apply to the predicted neutrino emission from binary neutron star mergers. ","astro-ph"
"1907.00035","Densest versus jammed packings of bent-core trimers","  We identify putatively maximally dense packings of tangent-sphere trimers with fixed bond angles ($\theta = \theta_0$) using a novel method, and contrast them to the disordered jammed states they form under quasistatic and dynamic athermal compression. Incommensurability of $\theta_0$ with 3D close-packing does not by itself inhibit formation of dense 3D crystals; all $\theta_0$ allow formation of crystals with $\phi_{max}(\theta_0) > 0.97\phi_{cp}$. Trimers are always able to arrange into periodic structures composed of close-packed bilayers or trilayers of triangular-lattice planes, separated by ``gap layers'' that accomodate the incommensurability. All systems have $\phi_J$ significantly below the monomeric value, indicating that trimers' quenched bond-length and bond-angle constraints always act to promote jamming. $\phi_J$ varies strongly with $\theta_0$; straight ($\theta_0 = 0$) trimers minimize $\phi_J$ while closed ($\theta_0 = 120^\circ$) trimers maximize it. Marginally jammed states of trimers with lower $\phi_J(\theta_0)$ exhibit quantifiably greater disorder, and the lower $\phi_J$ for small $\theta_0$ is apparently caused by trimers' decreasing effective configurational freedom as they approach linearity. ","cond-mat"
"1911.06451","Measurement Error Correction in Particle Tracking Microrheology","  In diverse biological applications, particle tracking of passive microscopic species has become the experimental measurement of choice -- when either the materials are of limited volume, or so soft as to deform uncontrollably when manipulated by traditional instruments. In a wide range of particle tracking experiments, a ubiquitous finding is that the mean squared displacement (MSD) of particle positions exhibits a power-law signature, the parameters of which reveal valuable information about the viscous and elastic properties of various biomaterials. However, MSD measurements are typically contaminated by complex and interacting sources of instrumental noise. As these often affect the high-frequency bandwidth to which MSD estimates are particularly sensitive, inadequate error correction can lead to severe bias in power law estimation and thereby, the inferred viscoelastic properties. In this article, we propose a novel strategy to filter high-frequency noise from particle tracking measurements. Our filters are shown theoretically to cover a broad spectrum of high-frequency noises, and lead to a parametric estimator of MSD power-law coefficients for which an efficient computational implementation is presented. Based on numerous analyses of experimental and simulated data, results suggest our methods perform very well compared to other denoising procedures. ","stat"
"2003.03950","Manifold lifting: scaling MCMC to the vanishing noise regime","  Standard Markov chain Monte Carlo methods struggle to explore distributions that are concentrated in the neighbourhood of low-dimensional structures. These pathologies naturally occur in a number of situations. For example, they are common to Bayesian inverse problem modelling and Bayesian neural networks, when observational data are highly informative, or when a subset of the statistical parameters of interest are non-identifiable. In this paper, we propose a strategy that transforms the original sampling problem into the task of exploring a distribution supported on a manifold embedded in a higher dimensional space; in contrast to the original posterior this lifted distribution remains diffuse in the vanishing noise limit. We employ a constrained Hamiltonian Monte Carlo method which exploits the manifold geometry of this lifted distribution, to perform efficient approximate inference. We demonstrate in several numerical experiments that, contrarily to competing approaches, the sampling efficiency of our proposed methodology does not degenerate as the target distribution to be explored concentrates near low dimensional structures. ","stat"
"2007.07810","Cooling in a parametrically driven optomechanical cavity","  We obtain a master equation for a parametrically driven optomechanical cavity. We use a more correct dissipation model that accounts for the modification of the quasienergy spectrum caused by the driving. When the natural frequency of the mechanical object oscillates periodically around its mean value, the master equation with the improved dissipation model is expressed using Floquet operators. We apply the corresponding master equation to model the laser cooling of the mechanical object. Using an adiabatic approximation, an analytical expression for the number of excitations of the mechanical oscillator can be obtained. We find that the number of excitations can be lower than in the non-time-dependent case. Our results raise the possibility of achieving lower temperatures for the mechanical object if its natural frequency can be controlled as a function of time ","quant-ph"
"2002.12459","Fast Join Project Query Evaluation using Matrix Multiplication","  In the last few years, much effort has been devoted to developing join algorithms in order to achieve worst-case optimality for join queries over relational databases. Towards this end, the database community has had considerable success in developing succinct algorithms that achieve worst-case optimal runtime for full join queries, i.e the join is over all variables present in the input database. However, not much is known about join evaluation with {\em projections} beyond some simple techniques of pushing down the projection operator in the query execution plan. Such queries have a large number of applications in entity matching, graph analytics and searching over compressed graphs. In this paper, we study how a class of join queries with projections can be evaluated faster using worst-case optimal algorithms together with matrix multiplication. Crucially, our algorithms are parameterized by the output size of the final result, allowing for choice of the best execution strategy. We implement our algorithms as a subroutine and compare the performance with state-of-the-art techniques to show they can be improved upon by as much as 50x. More importantly, our experiments indicate that matrix multiplication is a useful operation that can help speed up join processing owing to highly optimized open source libraries that are also highly parallelizable. ","cs"
"2002.01941","The formation of exponential disk galaxies in MOND","  The formation and evolution of galaxies is highly dependent on the dynamics of stars and gas, which is governed by the underlying law of gravity. To investigate how the formation and evolution of galaxies takes place in Milgromian gravity (MOND), we present full hydrodynamical simulations with the Phantom of Ramses (POR) code. These are the first-ever galaxy formation simulations done in MOND with detailed hydrodynamics, including star formation, stellar feedback, radiative transfer and supernovae. These models start from simplified initial conditions, in the form of isolated, rotating gas spheres in the early Universe. These collapse and form late-type galaxies obeying several scaling relations, which was not a priori expected. The formed galaxies have a compact bulge and a disk with exponentially decreasing surface mass density profiles and scale lengths consistent with observed galaxies, and vertical stellar mass distributions with distinct exponential profiles (thin and thick disk). This work thus shows for the first time that disk galaxies with exponential profiles in both gas and stars are a generic outcome of collapsing gas clouds in MOND. These models have a slight lack of stellar angular momentum because of their somewhat compact stellar bulge, which is connected to the simple initial conditions and the negligible later gas accretion. We also analyse how the addition of more complex baryonic physics changes the main resulting properties of the models and find this to be negligibly so in the Milgromian framework. ","astro-ph"
"1906.11251","$T\bar T$ and the mirage of a bulk cutoff","  We use the variational principle approach to derive the large $N$ holographic dictionary for two-dimensional $T\bar T$-deformed CFTs, for both signs of the deformation parameter. The resulting dual gravitational theory has mixed boundary conditions for the non-dynamical graviton; the boundary conditions for matter fields are undeformed. When the matter fields are turned off and the deformation parameter is negative, the mixed boundary conditions for the metric at infinity can be reinterpreted on-shell as Dirichlet boundary conditions at finite bulk radius, in agreement with a previous proposal by McGough, Mezei and Verlinde. The holographic stress tensor of the deformed CFT is fixed by the variational principle, and in pure gravity it coincides with the Brown-York stress tensor on the radial bulk slice with a particular cosmological constant counterterm contribution. In presence of matter fields, the connection between the mixed boundary conditions and the radial ""bulk cutoff"" is lost. Only the former correctly reproduce the energy of the bulk configuration, as expected from the fact that a universal formula for the deformed energy can only depend on the universal asymptotics of the bulk solution, rather than the details of its interior. The asymptotic symmetry group associated with the mixed boundary conditions consists of two commuting copies of a state-dependent Virasoro algebra, with the same central extension as in the original CFT. ","hep-th"
"2006.01330","Weakly Arf rings","  In this paper, we introduce and develop the theory of weakly Arf rings, which is a generalization of Arf rings, initially defined by J. Lipman in 1971. We provide characterizations of weakly Arf rings and study the relation between these rings, the Arf rings, and the strict closedness of rings. Furthermore, we give various examples of weakly Arf rings that come from idealizations, fiber products, determinantal rings, and invariant subrings. ","math"
"1902.01415","A 10d view on the KKLT AdS vacuum and uplifting","  We analyse the ten-dimensional Einstein equations in the KKLT setting. We verify that the quartic gaugino term is needed to remove singularities in the on-shell action as suggested by Hamada et. al. We contrast two approaches that have been taken in the literature when employing the effect of gaugino condensation in the ten-dimensional equations of motion. Here we follow the proposal to insert explicit non-zero fermion bilinar vev into the localised energy-momentum tensor of the 7-branes obtained from varying the 10d on-shell action with respect to the 10d metric. Our procedure is common in semi-classical physics and is manifestly local in 10d. However, it does not lead to the KKLT effective field theory. The alternative procedure of deriving the energy momentum tensor after replacing fermion bilinears by the gaugino vev, might be less well motivated in 10d, but reproduces the results of the KKLT effective field theory. ","hep-th"
"2003.06207","A Note on Early Epidemiological Analysis of Coronavirus Disease 2019   Outbreak using Crowdsourced Data","  Crowdsourcing data can prove of paramount importance in monitoring and controlling the spread of infectious diseases. The recent paper by Sun, Chen and Viboud (2020) is important because it contributes to the understanding of the epidemiology and of the spreading of Covid-19 in a period when most of the epidemic characteristics are still unknown. However, the use of crowdsourcing data raises a number of problems from the statistical point of view which run the risk of invalidating the results and of biasing estimation and hypothesis testing. While the work by Sun, Chen and Viboud (2020) has to be commended, given the importance of the topic for worldwide health security, in this paper we deem important to remark the presence of the possible sources of statistical biases and to point out possible solutions to them ","stat"
"1907.00036","Novel Suboptimal approaches for Hyperparameter Tuning of Deep Neural   Network [under the shelf of Optical Communication]","  Hyperparameter tuning is the main challenge of machine learning (ML) algorithms. Grid search is a popular method in hyperparameter tuning of simple ML algorithms; however, high computational complexity in complex ML algorithms such as Deep Neural Networks (DNN) is the main barrier towards its practical implementation. In this paper, two novel suboptimal grid search methods are presented, which search the grid marginally and alternating. In order to examine these methods, hyperparameter tuning is applied on two different DNN based Optical Communication (OC) systems (Fiber OC, and Free Space Optical (FSO) communication). The hyperparameter tuning of ML algorithms, despite its importance is ignored in ML for OC investigations. In addition, this is the first consideration of both FSO and Fiber OC systems in an ML for OC investigation. Results indicate that despite greatly reducing computation load, favorable performance could be achieved by the proposed methods. In addition, it is shown that the alternating search method has better performance than marginal grid search method. In sum, the proposed structures are cost-effective, and appropriate for real-time applications. ","eess"
"1707.09795","Assessment of approaches for dispersive forces employing graphone as a   case study","  We have studied two interchange layer systems, (i) free standing partly hydrogenated graphene (graphone), and (ii) graphone on the Nickel (111) surface, to assess various density functional theory based computational schemes incorporating van der Waals forces. The various van der Waals methods have been employed ranging from the semiempirical force-field-like correction of Grimme, through non-local van der Waals density functionals, up to the functionals involving exact exchange and the random phase approximation for the correlation. Generally, all computational schemes lead to a similar qualitative picture of hydrogen layer physisorption and chemisorption to graphene. The largest discrepancies between the approaches emerge for the energetics of the investigated systems. Our studies shed light on the physical mechanisms of graphene hydrogenation both in vacuum and in the proximity of metallic surface. In particular, it is revealed that the adsorption of hydrogen atoms affects the nature of the bonding between graphene and the Ni(111) surface, from the weak to strong semi-covalent bonding. On the other hand, it turns out that the adsorption of hydrogen layer to graphene is stronger in the presence of the metallic surface. ","cond-mat"
"1904.10270","PowerDrive: Accurate De-Obfuscation and Analysis of PowerShell Malware","  PowerShell is nowadays a widely-used technology to administrate and manage Windows-based operating systems. However, it is also extensively used by malware vectors to execute payloads or drop additional malicious contents. Similarly to other scripting languages used by malware, PowerShell attacks are challenging to analyze due to the extensive use of multiple obfuscation layers, which make the real malicious code hard to be unveiled. To the best of our knowledge, a comprehensive solution for properly de-obfuscating such attacks is currently missing. In this paper, we present PowerDrive, an open-source, static and dynamic multi-stage de-obfuscator for PowerShell attacks. PowerDrive instruments the PowerShell code to progressively de-obfuscate it by showing the analyst the employed obfuscation steps. We used PowerDrive to successfully analyze thousands of PowerShell attacks extracted from various malware vectors and executables. The attained results show interesting patterns used by attackers to devise their malicious scripts. Moreover, we provide a taxonomy of behavioral models adopted by the analyzed codes and a comprehensive list of the malicious domains contacted during the analysis. ","cs"
"2003.07357","Error Bounds and Applications for Stochastic Approximation with   Non-Decaying Gain","  This work analyzes the stochastic approximation algorithm with non-decaying gains as applied in time-varying problems. The setting is to minimize a sequence of scalar-valued loss functions $f_k(\cdot)$ at sampling times $\tau_k$ or to locate the root of a sequence of vector-valued functions $g_k(\cdot)$ at $\tau_k$ with respect to a parameter $\theta\in R^p$. The available information is the noise-corrupted observation(s) of either $f_k(\cdot)$ or $g_k(\cdot)$ evaluated at one or two design points only. Given the time-varying stochastic approximation setup, we apply stochastic approximation algorithms with non-decaying gains, so that the recursive estimate denoted as $\hat{\theta}_k$ can maintain its momentum in tracking the time-varying optimum denoted as $\theta_k^*$.   Chapter 3 provides a bound for the root-mean-squared error $ \sqrt{E(\|\hat{\theta}_k-\theta_k^*\|^2})$. Overall, the bounds are applicable under a mild assumption on the time-varying drift and a modest restriction on the observation noise and the bias term. After establishing the tracking capability in Chapter 3, we also discuss the concentration behavior of $\hat{\theta}_k $ in Chapter 4. The weak convergence limit of the continuous interpolation of $\hat{\theta}_k$ is shown to follow the trajectory of a non-autonomous ordinary differential equation. Both Chapter 3 and Chapter 4 are probabilistic arguments and may not provide much guidance on the gain-tuning strategies useful for one single experiment run. Therefore, Chapter 5 discusses a data-dependent gain-tuning strategy based on estimating the Hessian information and the noise level. Overall, this work answers the questions ""what is the estimate for the dynamical system $\theta_k^*$"" and ""how much we can trust $\hat{\theta}_k $ as an estimate for $\theta_k^*$."" ","math"
"1905.13463","Drone-assisted deliveries: new formulations for the Flying Sidekick   Traveling Salesman Problem","  In this paper we consider a problem related to deliveries assisted by an unmanned aerial vehicle, so-called drone. In particular we consider the Flying Sidekick Traveling Salesman Problem, where a truck and a drone cooperate to delivery parcels to customers minimizing the completion time. In the following we improve the formulation found in the related literature. We propose three-indexed and two-indexed formulations and a set of inequalities that can be implemented in a branch-and-cut fashion. We could find the optimal solutions for most of the literature instances. Moreover, we consider two versions of the problem: one in which the drone is allowed to wait at the customers, as in the literature, and one where waiting is allowed only in flying mode. The solving methodologies are adapted to both versions. A comparison between the two versions is provided. ","math"
"1908.02017","Subdynamics of a many-particle classical system driven from an   equilibrium state by an external force","  It is shown, that by means of a special projection operator, the Liouville equation for an N-particle distribution function of classical particles, driven from an equilibrium state by an external field, can be exactly converted into a closed linear homogeneous Generalized Master Equations (GMEs) for an s-particle (s<N) distribution function. The obtained linear time-convolution and time-convolutionless GMEs define a subdynamics in the s-particle phase space and contains no inhomogeneous initial correlations terms as compared to the conventional GMEs. No approximation like ""molecular chaos"" or Bogoliubov's principle of weakening of initial correlations is needed. The initial correlations are ""hidden"" in the projection operator and thus they are accounted for in the obtained equations. For the weak interparticle interaction and weak external field, these equations are rewritten in the second order of the perturbation theory. Essentially, that they contain the contribution of initial correlations in the kernel governing the evolution of an s-particle distribution function. In particular, the evolution equation for a one-particle distribution function is obtained and its connection to the nonlinear Landau and the Fokker-Planck equations is discussed. The obtained results are related to the general issues of statistical physics and to the physical applications (plasma physics). ","cond-mat"
"1904.00651","Transit least-squares survey - I. Discovery and validation of an   Earth-sized planet in the four-planet system K2-32 near the 1:2:5:7 resonance","  We apply, for the first time, the Transit Least Squares (TLS) algorithm to search for new transiting exoplanets. TLS is a successor to the Box Least Squares (BLS) algorithm, which has served as a standard tool for the detection of periodic transits. In this proof-of-concept paper, we demonstrate how TLS finds small planets that have previously been missed. We showcase TLS' capabilities using the K2 EVEREST-detrended light curve of the star K2-32 (EPIC205071984) that was known to have three transiting planets. TLS detects these known Neptune-sized planets K2-32b, d, and c in an iterative search and finds an additional transit signal with a high signal detection efficiency (SDE_TLS) of 26.1 at a period of 4.34882 (-0.00075, +0.00069) d. We show that this signal remains detectable (SDE_TLS = 13.2) with TLS in the K2SFF light curve of K2-32, which includes a less optimal detrending of the systematic trends. The signal is below common detection thresholds, however, if searched with BLS in the K2SFF light curve (SDE_BLS = 8.9) as in previous searches. Markov Chain Monte Carlo sampling shows that the radius of this candidate is 1.01 (-0.09, +0.10) Earth radii. We analyze its phase-folded transit light curve using the vespa software and calculate a false positive probability FPP = 3.1e-3, formally validating K2-32e as a planet. Taking into account the multiplicity boost of the system, FPP < 3.1e-4. K2-32 now hosts at least four planets that are very close to a 1:2:5:7 mean motion resonance chain. The offset of the orbital periods of K2-32e and b from a 1:2 mean motion resonance is in very good agreement with the sample of transiting multi-planet systems from Kepler, lending further credence to the planetary nature of K2-32e. We expect that TLS can find many more transits of Earth-sized and smaller planets in the Kepler data that have hitherto remained undetected with BLS and similar algorithms. ","astro-ph"
"2006.03018","Towards Long-term and Archivable Reproducibility","  Reproducible workflow solutions commonly use high-level technologies that were popular when they were created, providing an immediate solution which is unlikely to be sustainable in the long term. We therefore introduce a set of criteria to address this problem and demonstrate their practicality and implementation. The criteria have been tested in several research publications and can be summarized as: completeness (no dependency beyond a POSIX-compatible operating system, no administrator privileges, no network connection and storage primarily in plain text); modular design; minimal complexity; scalability; verifiable inputs and outputs; temporal provenance; linking analysis with narrative; and free-and-open-source software. As a proof of concept, we have implemented ""Maneage"", a solution which stores the project in machine-actionable and human-readable plain-text, enables version-control, cheap archiving, automatic parsing to extract data provenance, and peer-reviewable verification. We show that requiring longevity of a reproducible workflow solution is realistic, without sacrificing immediate or short-term reproducibility and discuss the benefits of the criteria for scientific progress. This paper has itself been written in Maneage, with snapshot 1637cce. ","cs"
"1909.10903","Direct Healthy Life Expectancy Estimates from Life Tables with a   Sullivan Extension. Bridging the Gap Between HALE and Eurostat Estimates","  The analytic derivation of a more general model of survival-mortality and the estimation of a parameter bx related to the Healthy Life Years Lost (HLYL) is followed with the formulation of a computer program providing results similar to those of the World Health Organization for the Healthy Life Expectancy (HALE) and the corresponding HLYL estimates. This program is an extension of the classical life table including more columns to estimate the cumulative mortality, the average mortality, the person life years lost and finally the HLYL parameter bx. Evenmore, a further extension of the Excel program based on the Sullivan method provides estimates of the Healthy Life Expectancy at every year of the lifespan for five different types of estimates that are the Direct, WHO, Eurostat, Equal and Other. Estimates for several countries are presented. It is also presented a methodology and a program to bridge the gap between the World Health Organization (HALE) and Eurostat (HLE) healthy life expectancy estimates. The latest version of this program (SKI-6) appear in the Demographics2020 website. ","q-bio"
"1906.05305","$20'$ Five-Point Function from $AdS_5\times S^5$ Supergravity","  We develop new techniques to compute five-point correlation functions from IIB supergravity on $AdS_5\times S^5$. Our methods rely entirely on symmetry and general consistency conditions, and eschew detailed knowledge of the supergravity effective action. We demonstrate our methods by computing the five-point function of the $\mathbf{20'}$ operator, which is the superconformal primary of the stress tensor multiplet. We also develop systematic methods to compute the five-point conformal blocks in series expansions. Using the explicit expressions of the conformal blocks, we perform a Euclidean OPE analysis of the $\mathbf{20'}$ five-point function. We find expected agreement with non-renormalized quantities and also extract new CFT data at strong coupling. ","hep-th"
"1911.00755","Beyond broad strokes: sociocultural insights from the study of ancient   genomes","  The amount of sequence data obtained from ancient samples has dramatically expanded in the last decade, and so have the types of questions that can now be addressed using ancient DNA. In the field of human history, while ancient DNA has provided answers to long-standing debates about major movements of people, it has also recently begun to inform on other important facets of the human experience. The field is now moving from not only focusing on large-scale supra-regional studies to also taking a more local perspective, shedding light on socioeconomic processes, inheritance rules, marriage practices and technological diffusion. In this review, we summarize recent studies showcasing these types of insights, focusing on the methods used to infer sociocultural aspects of human behaviour. This work often involves working across disciplines that have, until recently, evolved in separation. We argue that multidisciplinary dialogue is crucial for a more integrated and richer reconstruction of human history, as it can yield extraordinary insights about past societies, reproductive behaviours and even lifestyle habits that would not have been possible to obtain otherwise. ","q-bio"
"1804.00888","Grouped Heterogeneous Mixture Modeling for Clustered Data","  Clustered data is ubiquitous in a variety of scientific fields. In this paper, we propose a flexible and interpretable modeling approach, called grouped heterogenous mixture modeling, for clustered data, which models cluster-wise conditional distributions by mixtures of latent conditional distributions common to all the clusters. In the model, we assume that clusters are divided into a finite number of groups and mixing proportions are the same within the same group. We provide a simple generalized EM algorithm for computing the maximum likelihood estimator, and an information criterion to select the numbers of groups and latent distributions. We also propose structured grouping strategies by introducing penalties on grouping parameters in the likelihood function. Under the settings where both the number of clusters and cluster sizes tend to infinity, we present asymptotic properties of the maximum likelihood estimator and the information criterion. We demonstrate the proposed method through simulation studies and an application to crime risk modeling in Tokyo. ","stat"
"1811.04161","When is $Y_{obs}$ missing and $Y_{mis}$ observed?","  In statistical modelling of incomplete data, missingness is encoded as a relation between datasets Y and response patterns R. The partitioning of Y into observed and missing components is often denoted Yobs and Ymis. We point out a mathematical defect in this notation which results from two different mathematical relationships between Y and R not being distinguished, (Yobs, Ymis, R) in which Yobs values are always observed, and Ymis values are always missing, and the overlaying of a missingness pattern onto the marginal distribution for Y, denoted (Yobs, Ymis). With the latter, Yobs and Ymis each denote mixtures of observable and unobservable data. This overlaying of the missingness pattern onto Y creates a link between the mathematics and the meta-mathematics which violates the stochastic relationship encoded in (Y, R). Additionally, in the theory there is a need to compare partitions of Y according to different missingness patterns simultaneously. A simple remedy for these problems is to use four symbols instead of two, and to make the dependence on the missingness pattern explicit. We explain these and related issues. ","stat"
"2008.00726","On the Resolution Probability of Conditional and Unconditional Maximum   Likelihood DoA Estimation","  After decades of research in Direction of Arrival (DoA) estimation, today Maximum Likelihood (ML) algorithms still provide the best performance in terms of resolution capabilities. At the cost of a multidimensional search, ML algorithms achieve a significant reduction of the outlier production mechanism in the threshold region, where the number of snapshots per antenna and/or the signal to noise ratio (SNR) are low. The objective of this paper is to characterize the resolution capabilities of ML algorithms in the threshold region. Both conditional and unconditional versions of the ML algorithms are investigated in the asymptotic regime where both the number of antennas and the number of snapshots are large but comparable in magnitude. By using random matrix theory techniques, the finite dimensional distributions of both cost functions are shown to be Gaussian distributed in this asymptotic regime, and a closed form expression of the corresponding asymptotic covariance matrices is provided. These results allow to characterize the asymptotic behavior of the resolution probability, which is defined as the probability that the cost function evaluated at the true DoAs is smaller than the values that it takes at the positions of the other asymptotic local minima. ","eess"
"1911.11913","Packing Transitions in the Elastogranular Confinement of a Slender Loop","  Confined thin structures are ubiquitous in nature. Spatial and length constraints have led to a number of novel packing strategies at both the micro-scale, as when DNA packages inside a capsid, and the macro-scale, seen in plant root development and the arrangement of the human intestinal tract. By varying the arc length of an elastic loop injected into an array of monodisperse, soft, spherical grains at varying initial number density, we investigate the resulting packing behaviors between a growing slender structure constrained by deformable boundaries. At low initial packing fractions, the elastic loop deforms as though it were hitting a flat surface by periodically folding into the array. Above a critical packing fraction $\phi_c$, local re-orientations within the granular medium create an effectively curved surface leading to the emergence of a distinct circular packing morphology in the adjacent elastic structure. These results will bring new insight into the packing behavior of wires and thin sheets and will be relevant to modeling plant root morphogenesis, burrowing and locomotive strategies of vertebrates & invertebrates, and developing smart, steerable needles. ","cond-mat"
"2005.02800","Log-Regularly Varying Scale Mixture of Normals for Robust Regression","  Linear regression with the classical normality assumption for the error distribution may lead to an undesirable posterior inference of regression coefficients due to the potential outliers. This paper considers the finite mixture of two components with thin and heavy tails as the error distribution, which has been routinely employed in applied statistics. For the heavily-tailed component, we introduce the novel class of distributions; their densities are log-regularly varying and have heavier tails than those of Cauchy distribution, yet they are expressed as a scale mixture of normal distributions and enable the efficient posterior inference by Gibbs sampler. We prove the robustness to outliers of the posterior distributions under the proposed models with a minimal set of assumptions, which justifies the use of shrinkage priors with unbounded densities for the high-dimensional coefficient vector in the presence of outliers. The extensive comparison with the existing methods via simulation study shows the improved performance of our model in point and interval estimation, as well as its computational efficiency. Further, we confirm the posterior robustness of our method in the empirical study with the shrinkage priors for regression coefficients. ","stat"
"1707.00179","On a new closed formula for the solution of second order linear   difference equations and applications","  In this note, we establish a new closed formula for the solution of homogeneous second-order linear difference equations with constant coefficients by using matrix theory. This, in turn, gives new closed formulas concerning all sequences of this type such as the Fibonacci and Lucas sequences. As applications; we show that Binet's formula, in this case, is valid for negative integers as well. Finally, we find new summation formulas relating the elements of such sequences. ","math"
"1811.00585","Vacuum stability conditions of the economical 3-3-1 model from   copositivity","  By applying copositivity criterion to the scalar potential of the economical $3-3-1$ model, we derive necessary and sufficient bounded-from-below conditions at tree level. Although these are a large number of intricate inequalities for the dimensionless parameters of the scalar potential, we present general enlightening relations in this work. Additionally, we use constraints coming from the minimization of the scalar potential by means of the orbit space method, the positivity of the squared masses of the extra scalars, the Higgs boson mass, the $Z'$ gauge boson mass and its mixing angle with the SM $Z$ boson in order to further restrict the parameter space of this model. ","hep-ph"
"2001.05898","NuSTAR and Parkes observations of the transitional millisecond pulsar   binary XSS J12270-4859 in the rotation-powered state","  We report on the first NuSTAR observation of the transitional millisecond pulsar binary XSS J12270-4859 during its current rotation-powered state, complemented with a 2.5yr-long radio monitoring at Parkes telescope and archival XMM-Newton and Swift X-ray and optical data. The radio pulsar is mainly detected at 1.4GHz displaying eclipses over about 40% of the 6.91h orbital cycle. We derive a new updated radio ephemeris to study the 3-79keV light curve that displays a significant orbital modulation with fractional amplitude of 28+/-3%, a structured maximum centred at the inferior conjunction of the pulsar and no cycle-to-cycle or low-high-flaring mode variabilities. The average X-ray spectrum, extending up to about 70keV without a spectral break, is well described by a simple power-law with photon index Gamma = 1.17+/-0.08 giving a 3-79keV luminosity of 7.6(-0.8;+3.8)x10**32 erg/s, for a distance of 1.37(-0.15;+0.69)kpc. Energy resolved orbital light curves reveal that the modulation is not energy dependent from 3keV to 25keV and is undetected with an upper limit of about 10% above 25keV. Comparison with previous X-ray XMM-Newton observations in common energy ranges confirms that the modulation amplitudes vary on timescales of a few months, indicative of a non-stationary contribution of the intrabinary shock formed by the colliding winds of the pulsar and the companion. A more detailed inspection of energy resolved modulations than previously reported gives hints of a mild softening at superior conjunction of the pulsar below 3keV, likely due to the contribution of the thermal emission from the neutron star. The intrabinary shock emission, if extending into the MeV range, would be energetically capable alone to irradiate the donor star. ","astro-ph"
"1809.08959","Uncovering Multi-Site Identifiability Based on Resting-State Functional   Connectomes","  Multi-site studies are becoming important to increase statistical power, enhance generalizability, and to improve the likelihood of pooling relevant subgroups together activities. Even with harmonized imaging sequences, site-dependent variability can mask the advantages of these multi-site studies. The aim of this study was to assess multi-site reproducibility in resting-state functional connectivity fingerprints, and to improve identifiability of functional connectomes. The individual fingerprinting of functional connectivity profiles is promising due to its potential as a robust neuroimaging biomarker. We evaluated, on two independent multi-site datasets, individual fingerprints in test-retest visit pairs within and across two sites and present a generalized framework based on principal component analysis to improve identifiability. Those components that maximized differential identifiability of a training dataset were used as an orthogonal connectivity basis to reconstruct the functional connectomes of training and validation sets. The optimally reconstructed functional connectomes showed a substantial improvement in individual fingerprinting within and across the two sites relative to the original data. A notable increase in ICC values for functional edges and resting-state networks was also observed. Improvements in identifiability were not found to be affected by global signal regression. Post-hoc analyses assessed the effect of the number of fMRI volumes on identifiability and showed that multi-site differential identifiability was for all cases maximized after optimal reconstruction. The generalizability of the optimal set of orthogonal basis of each dataset was evaluated through a leave-one-out procedure. Overall, results demonstrate that the framework presented in this study systematically improves identifiability in resting-state functional connectomes in multi-site studies. ","q-bio"
"2007.07096","Multi-Utility Market: Framework for a Blockchain Exchange Platform for   Sustainable Development","  Water and other resources are becoming scarcer every day, and developing countries are the neediest for an immediate intervention. Water, as a national need, is considered to be one of the main causes for conflicts in the 21st century. Peer-to-peer trading is one of the most convenient, scalable and sustainable solutions but faces organization challenges such as: the absence of suitable business models motivating normal users to sell their generated resources, currency and financial settlement complexities, and single utility markets. We propose a multi-utility trading platform, based on blockchain technology which can address the challenges faced by peer-to-peer trading. This platform meets the needs of developing countries in particular as well as rural areas of developed countries. The open nature of our proposed design makes it suitable for adoption and use by various stakeholders. ","cs"
"1902.07126","Sub-ns timing accuracy for satellite quantum communications","  Satellite quantum communications have rapidly evolved in the past few years, culminating in the proposal, development, and deployment of satellite missions dedicated to quantum key distribution and the realization of fundamental tests of quantum mechanics in space. However, in comparison with the more mature technology based on fiber optics, several challenges are still open, such as the capability of detecting, with high temporal accuracy, single photons coming from orbiting terminals. Satellite laser ranging, commonly used to estimate satellite distance, could also be exploited to overcome this challenge. For example, high repetition rates and a low background noise can be obtained by determining the time-of-flight of faint laser pulses that are retro-reflected by geodynamics satellites and then detected on Earth at the single-photon level. Here we report an experiment with regard to achieving a temporal accuracy of approximately 230 ps in the detection of an optical signal of few photons per pulse reflected by satellites in medium Earth orbit, at a distance exceeding 7500 km, by using commercially available detectors. Lastly, the performance of the Matera Laser Ranging Observatory is evaluated in terms of the detection rate and the signal-to-noise ratio for satellite quantum communications. ","quant-ph"
"1912.01392","Hopf brace, braid equation and bicrossed coproduct","  In this paper, we mainly give some equivalent characterisations of Hopf braces, show that the category $\mathcal{CB}(A)$ of Hopf braces is equivalent to the category $\mathcal{C}(A)$ of bijective 1-cocycles, and prove that the category $\mathcal{CB}(A)$ of Hopf braces is also equivalent to the category $\mathcal{M}(A)$ of Hopf matched pairs. Moreover, we construct many more Hopf braces on polynomial Hopf algebras, Long copaired Hopf algebras and Drinfel'd doubles of finite dimensional Hopf algebras, and give a sufficient and necessary condition for a given bicrossed coproduct $A\bowtie H$ to be a Hopf brace if $A$ or $H$ is a Hopf brace. ","math"
"1908.02014","Decorrelation Deep Learning for Fingerprint-based Indoor Localization","  Indoor localization is of particular interest due to its immense practical applications. However, the rich multipath and high penetration loss of indoor wireless signal propagation make this task arduous. Though recently studied fingerprint-based techniques can handle the multipath effects, the sensitivity of the localization performance to channel fluctuation is a drawback. To address the latter challenge, we adopt an artificial multi-layer neural network (MNN) to learn the complex channel impulse responses (CIRs) as fingerprint measurements. However, the performance of the location classification using MNN critically depends on the correlation among the training data. Therefore, we design two different decorrelation filters that preprocess the training data for discriminative learning. The first one is a linear whitening filter combined with the principal component analysis (PCA), which forces the covariance matrix of different feature dimensions to be identity. The other filter is a nonlinear quantizer that is optimized to minimize the distortion incurred by the quantization. Numerical results using indoor channel models illustrate the significant improvement of the proposed decorrelation MNN (DMNN) compared to other benchmarks. ","eess"
"1612.03885","Uniqueness from locality and BCFW shifts","  We introduce a BCFW shift which can be used to recursively build the full Yang-Mills tree-level amplitude as a function of polarization vectors. Furthermore, in line with the recent results of arXiv:1612.02797, we conjecture that the Yang-Mills tree-level scattering amplitude is uniquely fixed by locality and demanding the usual asymptotic behavior under a sufficient number of shifts. Unitarity therefore emerges from locality and constructability. We prove this statement at the leading order in the soft expansion. ","hep-th"
"1907.07051","Damping of slow magnetoacoustic oscillations by the misbalance between   heating and cooling processes in the solar corona","  Rapidly decaying slow magnetoacoustic waves are regularly observed in the solar coronal structures, offering a promising tool for a seismological diagnostics of the coronal plasma, including its thermodynamical properties. The effect of damping of standing slow magnetoacoustic oscillations in the solar coronal loops is investigated accounting for the field-aligned thermal conductivity and a wave-induced misbalance between radiative cooling and some unspecified heating rates. The non-adiabatic terms were allowed to be arbitrarily large, corresponding to the observed values. The thermal conductivity was taken in its classical form, and a power-law dependence of the heating function on the density and temperature was assumed. The analysis was conducted in the linear regime and in the infinite magnetic field approximation. The wave dynamics is found to be highly sensitive to the characteristic time scales of the thermal misbalance. Depending on certain values of the misbalance time scales three regimes of the wave evolution were identified, namely the regime of a suppressed damping, enhanced damping where the damping rate drops down to the observational values, and acoustic over-stability. The specific regime is determined by the dependences of the radiative cooling and heating functions on thermodynamical parameters of the plasma in the vicinity of the perturbed thermal equilibrium. The comparison of the observed and theoretically derived decay times and oscillation periods allows us to constrain the coronal heating function. For typical coronal parameters, the observed properties of standing slow magnetoacoustic oscillations could be readily reproduced with a reasonable choice of the heating function. ","astro-ph"
"1805.09902","Generic Conditions for Forecast Dominance","  Recent studies have analyzed whether one forecast method dominates another under a class of consistent scoring functions. While the existing literature focuses on empirical tests of forecast dominance, little is known about the theoretical conditions under which one forecast dominates another. To address this question, we derive a new characterization of dominance among forecasts of the mean functional. We present various scenarios under which dominance occurs. Unlike existing results, our results allow for the case that the forecasts' underlying information sets are not nested, and allow for uncalibrated forecasts that suffer, e.g., from model misspecification or parameter estimation error. We illustrate the empirical relevance of our results via data examples from finance and economics. ","stat"
"1908.11655","Sign-sensitivities for reaction networks: an algebraic approach","  This paper presents an algebraic framework to study sign-sensitivities for reaction networks modeled by means of systems of ordinary differential equations. Specifically, we study the sign of the derivative of the concentrations of the species in the network at steady state with respect to a small perturbation on the parameter vector. We provide a closed formula for the derivatives that accommodates common perturbations, and illustrate its form with numerous examples. We argue that, mathematically, the study of the response to the system with respect to changes in total amounts is not well posed, and that one should rather consider perturbations with respect to the initial conditions. We find a sign-based criterion to determine, without computing the sensitivities, whether the sign depends on the steady state and parameters of the system. This is based on earlier results of so-called injective networks. Finally, we address systems with multiple steady states and the restriction to stable steady states. ","q-bio"
"2008.01274","Lifting at higher levels in the D1D5 CFT","  The D1D5P system has a large set of BPS states at its orbifold point. Perturbing away from this 'free' point leads to some states joining up into long supermultiplets and lifting, while other states remain BPS. We consider the simplest orbifold which exhibits this lift: that with $N=2$ copies of the free $c=6$ CFT. We write down the number of lifted and unlifted states implied by the index at all levels upto $6$. We work to second order in the perturbation strength $\lambda$. For levels upto $4$, we find the wavefunctions of the lifted states, their supermultiplet structure and the value of the lift. All states that are allowed to lift by the index are in fact lifted at order $O(\lambda^2)$. We observe that the unlifted states in the untwisted sector have an antisymmetry between the copies in the right moving Ramond ground state sector, and extend this observation to find classes of states for arbitrary $N$ that will remain unlifted to $O(\lambda^2)$. ","hep-th"
"1906.11265","CapsNets Continuing the Convolutional Quest","  Capsule networks are ideal tools to combine event-level and subjet information at the LHC. After benchmarking our capsule network against standard convolutional networks, we show how multi-class capsules extract a resonance decaying to top quarks from both, QCD di-jet and the top continuum backgrounds. We then show how its results can be easily interpreted. Finally, we use associated top-Higgs production to demonstrate that capsule networks can work on overlaying images to go beyond calorimeter information. ","hep-ph"
"1908.11064","Coarse-to-fine Kidney Segmentation Framework Incorporating with Abnormal   Detection and Correction","  In this paper, we formulated the kidney segmentation task in a coarse-to-fine fashion, predicting a coarse label based on the entire CT image and a fine label based on the coarse segmentation and separated image patches. A key difference between the two stages lies in how input images were preprocessed; for the coarse segmentation, each 2D CT slice was normalized to be of the same image size (but possible different pixel size), and for the fine segmentation, each 2D CT slice was first resampled to be of the same pixel size and then cropped to be of the same image size. In other words, the image inputs to the coarse segmentation were 2D CT slices of the same image size whereas those to the fine segmentation were 2D MR patches of the same image size as well as the same pixel size. In addition, we design an abnormal detection method based on component analysis and use another 2D convolutional neural network to correct these abnormal regions between two stages. A total of 168 CT images were used to train the proposed framework and the evaluations were conducted qualitatively on other 42 testing images. The proposed method showed promising results and achieved 94.53 \% averaged DSC in testing data. ","eess"
"1904.12495","Associated Weber-Orr transform, Biot-Savart Law and explicit solution of   2D Stokes system in exterior of the disc","  In this article we derive the explicit solution of 2-D Stokes system in exterior of the disc with no-slip condition on inner boundary and given velocity $\mathbf{v}_\infty$ at infinity. It turned out it is the first application of the associated Weber-Orr transform to mathematical physics in comparison to classical Weber-Orr transform which is used in many researches. From no-slip condition for velocity field we will obtain Robin-type boundary condition for vorticity. Then the initial-boundary value problem for vorticity will be solved with help of the associated Weber-Orr transform. Also the explicit formula of Biot-Savart Law in polar coordinates will be given. ","math"
"1811.12623","Reservoir Computing with Random Skyrmion Textures","  The Reservoir Computing (RC) paradigm posits that sufficiently complex physical systems can be used to massively simplify pattern recognition tasks and nonlinear signal prediction. This work demonstrates how random topological magnetic textures present sufficiently complex resistance responses for the implementation of RC as applied to A/C current pulses. In doing so, we stress how the applicability of this paradigm hinges on very general dynamical properties which are satisfied by a large class of physical systems where complexity can be put to computational use. By harnessing the complex resistance response exhibited by random magnetic skyrmion textures and using it to demonstrate pattern recognition, we explain how spintronically accessible magnetic systems offer an advantage in the search for an ideal reservoir computer. The low-power properties of compact skyrmion fabrics, coupled with their CMOS integrability operating on similar length and timescales, open the door for their RC employment geared towards industrial application. ","cond-mat"
"1903.11181","Towards a way to distinguish between IHDM and the Scotogenic at CLIC","  A study about the phenomenology of IHDM and Scotogenic model and how the contributions could be very different using the same observable. ","hep-ph"
"1911.03919","Relations for Massive Spinors","  Recently introduced massive spinors are written as 2-vectors consisting of two massless spinors with opposite helicities. With this notation a couple of relations between them can be derived easily, entirely avoiding the spinor indices. The high energy limit of three point amplitudes is discussed shortly. Finally we add some comments on recursion relations with massive particles. ","hep-ph"
"2004.15018","Failure of monotonicity in epidemic models","  We discuss the failure of monotonicity properties for even simple compartmental epidemic models, for the case where transmission rates are non-constant. We also identify a special case in which monotonicity holds. ","q-bio"
"1912.13516","Consistent truncations of supergravity and $\frac{1}{2}$-BPS RG flows in   $4d$ SCFTs","  With the purpose of holographically describing flows from a large family of four dimensional ${\cal N}=1$ and ${\cal N}=2$ conformal field theories, we discuss truncations of seven dimensional supergravity to five dimensions. We write explicitly the reduced gauged supergravity and find BPS equations for simple configurations. Lifting these flows to eleven dimensions or Massive IIA supergravity, we present string duals to RG flows from strongly coupled conformal theories when deformed by marginal and/or relevant operators. We further discuss observables common to infinite families of ${\cal N}=1$ and ${\cal N}=2$ QFTs in this context. ","hep-th"
"1907.04221","Quantum key distribution based on the quantum eraser","  Quantum information and quantum foundations are becoming popular topics for advanced undergraduate courses. Many of the fundamental concepts and applications in these two fields, such as delayed choice experiments and quantum encryption, are comprehensible to undergraduates with basic knowledge of quantum mechanics. In this paper, we show that the quantum eraser, usually used to study the duality between wave and particle properties, can also serve as a generic platform for quantum key distribution. We present a pedagogical example of an algorithm to securely share random keys using the quantum eraser platform and propose its implementation with quantum circuits. ","quant-ph"
"1906.09946","Multiresolution expansions and wavelets in Gelfand-Shilov spaces","  We study approximation properties generated by highly regular scaling functions and orthonormal wavelets. These properties are conveniently described in the framework of Gelfand-Shilov spaces. Important examples of multiresolution analyses for which our results apply arise in particular from Dziuba\'{n}ski-Hern\'{a}ndez construction of band-limited wavelets with subexponential decay. Our results are twofold. Firstly, we obtain approximation properties of multiresolution expansions of Gelfand-Shilov functions and (ultra)distributions. Secondly, we establish convergence of wavelet series expansions in the same regularity framework. ","math"
"1910.10725","F-theory Flux Vacua and Attractor Equations","  We examine the vacuum structure of 4D effective theories of moduli fields in spacetime compactifications with quantized background fluxes. Imposing the no-scale structure for the volume deformations, we numerically investigate the distributions of flux vacua of the effective potential in complex structure moduli and axio-dilaton directions for two explicit examples in Type IIB string theory and F-theory compactifications. It turns out that distributions of non-supersymmetric flux vacua exhibit a non-increasing functional behavior of several on-shell quantities with respect to the string coupling. We point out that this phenomena can be deeply connected with a previously-reported possible correspondence between the flux vacua in moduli stabilization problem and the attractor mechanism in supergravity, and our explicit demonstration implies that such a correspondence generically exist even in the framework of F-theory. In particular, we confirm that the solutions of the effective potential we explicitly evaluated in Type IIB and F-theory flux compactifications indeed satisfy the generalized form of the attractor equations simultaneously. ","hep-th"
"1906.11219","Low-redshift tests of cosmologies with a time-varying gravitational   constant","  In this work we investigate cosmologies with a time-varying gravitational constant, $G(t)$, as an alternative to having a cosmological constant. Since, it is known in the literature that, in general relativity, having a variable gravitational constant breaks the conservation of energy unless further dynamical components are added, we consider a Newtonian approach, in which the energy conservation is ensured. We investigate whether these cosmologies are able to reproduce the cosmological acceleration without a cosmological constant, nor any other sort of dark energy fluid. After constructing the Friedmann-Lema\^itre equation for a late-stage, matter dominated universe by starting with Newton's second law, where $G$ is taken as a function of time, we create specific models to test against cosmological observations. In this Friedmann-Lema\^itre equation we obtain a second gravitational constant, $G^*$, related to the original $G$ in the acceleration equation. For the tests we focus on the acceleration period and use low-redshift probes: type Ia supernovae (SNIa), baryon acoustic oscillations, and cosmic chronometers, taking also into account a possible change in the supernova intrinsic luminosity with redshift. As a result, we obtain several models without a cosmological constant with similar or even slightly better $\chi^2$ values than the standard $\Lambda$CDM cosmology. When SNIa luminosity dependence on redshift is added, a model with a $G$ exponentially decreasing to zero today can explain the observations. In the cases where SNIa are assumed to be standard candles, the observations favour a negative $G$ at large scales to produce cosmic acceleration. We conclude that these models offer a viable interpretation of the late-time universe observations. ","astro-ph"
"1902.01994","Scheduling and Trade-off Analysis for Multi-Source Multi-Processor   Systems with Divisible Loads","  The main goal of parallel processing is to provide users with performance that is much better than that of single processor systems. The execution of jobs is scheduled, which requires certain resources in order to meet certain criteria. Divisible load is a special but widely used type of data which can be divided into arbitrary sizes and independently processed in parallel. It can be used in applications which are processing a great amount of similar data units. ","cs"
"1801.00436","Sample-based calibration for cryogenic broadband microwave reflectometry   measurements","  The characteristic frequencies of a system provide important information on the phenomena that govern its physical properties. In this framework, there has recently been renewed interest in cryogenic microwave characterization for condensed matter systems since it allows to probe energy scales of the order of a few $\mu$eV. However, broadband measurements of the absolute value of a sample response in this frequency range are extremely sensitive to its environment and require a careful calibration. In this paper, we present an \textit{in situ} calibration method for cryogenic broadband microwave reflectometry experiments that is both simple to implement and through which the effect of the sample electromagnetic environment can be minimized. The calibration references are here provided by the sample itself, at three reference temperatures where its impedance is assumed or measured, and not by external standards as is usual. We compare the frequency-dependent complex impedance (0.1--2 GHz) of an a-Nb$_{15}$Si$_{85}$ superconducting thin film obtained through this Sample-Based Calibration (SBC) and through an Open-Short-Load Standard Calibration (SC) when working at very low temperature (0.02--4 K) and show that the SBC allows us to obtain the absolute response of the sample. This method brings the calibration planes as close as possible to the sample, so that the environment electrodynamic response does not affect the measurement, provided it is temperature independent. This results in a heightened sensitivity, for a given experimental set--up. ","cond-mat"
"1811.04957","Circular polarization of the cosmic microwave background from vector and   tensor perturbations","  Circular polarization of the cosmic microwave background (CMB) can be induced by Faraday conversion of the primordial linearly polarized radiation as it propagates through a birefringent medium. Recent work has shown that the dominant source of birefringence from primordial density perturbations is the anisotropic background CMB. Here we extend prior work to allow for the additional birefringence that may arise from primordial vector and tensor perturbations. We derive the formulas for the power spectrum of the induced circular polarization and apply those to the standard cosmology. We find the root-variance of the induced circular polarization to be $\sqrt{<V^2>}\sim 3\times 10^{-14}$ for scalar perturbations and $\sqrt{<V^2>}\sim 7\times 10^{-18} (r/0.06)$ for tensor perturbations with a tensor-to-scalar ratio $r$. ","astro-ph"
"1902.06488","Well-posedness of a non-local model for material flow on conveyor belts","  In this paper, we focus on finite volume approximation schemes to solve a non-local material flow model in two space dimensions. Based on the numerical discretisation with dimensional splitting, we prove the convergence of the approximate solutions, where the main difficulty arises in the treatment of the discontinuity occurring in the flux function. In particular, we compare a Roe-type scheme to the well-established Lax-Friedrichs method and provide a numerical study highlighting the benefits of the Roe discretisation. Besides, we also prove the L1-Lipschitz continuous dependence on the initial datum, ensuring the uniqueness of the solution. ","math"
"1907.08546","The Dynamical Diquark Model: Fine Structure and Isospin","  We incorporate fine-structure corrections into the dynamical diquark model of multiquark exotic hadrons. These improvements include effects due to finite diquark size, spin-spin couplings within the diquarks, and most significantly, isospin-dependent couplings in the form of pionlike exchanges assumed to occur between the light quarks within the diquarks. Using a simplified two-parameter interaction Hamiltonian, we obtain fits in which the isoscalar $J^{PC} = 1^{++}$ state---identified as the $X(3872)$---appears naturally as the lightest exotic (including all states that are predicted by the model but have not yet been observed), while the $Z_c(3900)$ and $Z_c(4020)$ decay predominantly to $J/\psi$ and $\eta_c$, respectively, in accord with experiment. We explore implications of this model for the excited tetraquark multiplets and the pentaquarks. ","hep-ph"
"1907.01955","Smoothness and norm attainment of bounded bilinear operators between   Banach spaces","  We study the smoothness and the norm attainment of bounded bilinear operators between Banach spaces, using the concepts of Birkhoff-James orthogonality and semi-inner-products. In the finite-dimensional case, we characterize Birkhoff-James orthogonality of bilinear operators in terms of the norm attainment set. This yields a nice characterization of smoothness of bilinear operators between Banach spaces, in the finite-dimensional case. Without any restriction on the dimension of the space, we obtain a complete characterization of the norm attainment set of a bounded bilinear operator using semi-inner-products, which is particularly useful when the concerned Banach spaces are smooth. ","math"
"1909.06555","Pressure-Induced Re-entrant transition in NbS3 Phases: Combined Raman   Scattering and X-ray Diffraction Study","  We report the evolution of charge density wave states under pressure for two NbS3 phases triclinic (phase I) and monoclinic (phase II) at room temperature. Raman and X-ray diffraction (XRD) techniques are applied. The x-ray studies on the monoclinic phase under pressure show a compression of the lattice at different rates below and above 7 GPa but without a change in space group symmetry. The Raman spectra of the two phases evolve similarly with pressure; all peaks almost disappear in the 6-8 GPa range, indicating a transition from an insulating to a metallic state, and peaks at new positions appear above 8 GPa. The results suggest suppression of the ambient charge-density waves and their subsequent recovery with new orderings above 8 GPa. ","cond-mat"
"2007.01240","Statistical characterization and classification of astronomical   transients with Machine Learning in the era of the Vera C. Rubin Observatory","  Astronomy has entered the multi-messenger data era and Machine Learning has found widespread use in a large variety of applications. The exploitation of synoptic (multi-band and multi-epoch) surveys, like LSST (Legacy Survey of Space and Time), requires an extensive use of automatic methods for data processing and interpretation. With data volumes in the petabyte domain, the discrimination of time-critical information has already exceeded the capabilities of human operators and crowds of scientists have extreme difficulty to manage such amounts of data in multi-dimensional domains. This work is focused on an analysis of critical aspects related to the approach, based on Machine Learning, to variable sky sources classification, with special care to the various types of Supernovae, one of the most important subjects of Time Domain Astronomy, due to their crucial role in Cosmology. The work is based on a test campaign performed on simulated data. The classification was carried out by comparing the performances among several Machine Learning algorithms on statistical parameters extracted from the light curves. The results make in evidence some critical aspects related to the data quality and their parameter space characterization, propaedeutic to the preparation of processing machinery for the real data exploitation in the incoming decade. ","astro-ph"
"2001.04010","Adaptive Acquisition Schemes for Photon-Limited Free-Space Optical   Communications","  Acquisition and tracking systems form an important component of free-space optical communications due to directional nature of the optical signal. Acquisition subsystems are needed in order to search and locate the receiver terminal in an uncertainty/search region with very narrow laser beams. In this paper, we have proposed and analyzed two adaptive search schemes for acquisition systems that perform better---for the low probability of detection---than the spiral scanning approach. The first of these schemes, the adaptive spiral search, provides a better acquisition time performance by dividing the search region into a number of smaller subregions, and prioritizing search in regions of higher probability mass. The second technique---the shotgun approach---searches the region in a random manner by sampling the search region according to a Gaussian distribution. The adaptive spiral scheme outperforms the shotgun approach in terms of acquisition time, especially if the number of search subregions is large enough. However, a higher pointing accuracy is required by the adaptive spiral search in order to search the region precisely. On the other hand, the shotgun scanning approach does not require such stringent pointing accuracy. ","eess"
"1703.04864","Optimization for L1-Norm Error Fitting via Data Aggregation","  We propose a data aggregation-based algorithm with monotonic convergence to a global optimum for a generalized version of the L1-norm error fitting model with an assumption of the fitting function. The proposed algorithm generalizes the recent algorithm in the literature, aggregate and iterative disaggregate (AID), which selectively solves three specific L1-norm error fitting problems. With the proposed algorithm, any L1-norm error fitting model can be solved optimally if it follows the form of the L1-norm error fitting problem and if the fitting function satisfies the assumption. The proposed algorithm can also solve multi-dimensional fitting problems with arbitrary constraints on the fitting coefficients matrix. The generalized problem includes popular models such as regression and the orthogonal Procrustes problem. The results of the computational experiment show that the proposed algorithms are faster than the state-of-the-art benchmarks for L1-norm regression subset selection and L1-norm regression over a sphere. Further, the relative performance of the proposed algorithm improves as data size increases. ","stat"
"2002.00675","T-dualization of G\""{o}del string cosmologies via Poisson-Lie T-duality   approach","  Using the homogeneous G\""{o}del spacetimes we find some new solutions for the field equations of bosonic string effective action up to first order in $\alpha'$ including both dilaton and axion fields. We then discuss in detail the (non-)Abelian T-dualization of G\""{o}del string cosmologies via Poisson-Lie (PL) T-duality approach. In studying Abelian T-duality of the models we get seven dual models in such a way that they are constructed by one-, two- and three-dimensional Abelian Lie groups acting freely on the target space manifold. The results of our study show that the Abelian T-dual models are, under some of the special conditions, self-dual. Afterwards, non-Abelian duals of the G\""{o}del spacetimes are constructed by two- and three-dimensional non-Abelian Lie groups such as $A_2$, $A_2 \oplus A_1$ and $SL(2, \mathbb{R})$. It is shown that the non-Abelian dual models are conformally invariant to the order $\alpha'$ only for the case of $\beta=1$. Following that, the PL self-duality of $AdS_3 \times \mathbb{R}$ space ($\beta=1$ case) is discussed. ","hep-th"
"1803.01651","A balance index for phylogenetic trees based on rooted quartets","  We define a new balance index for rooted phylogenetic trees based on the symmetry of the evolutive history of every set of 4 leaves. This index makes sense for multifurcating trees and it can be computed in time linear in the number of leaves. We determine its maximum and minimum values for arbitrary and bifurcating trees, and we provide exact formulas for its expected value and variance on bifurcating trees under Ford's $\alpha$-model and Aldous' $\beta$-model and on arbitrary trees under the $\alpha$-$\gamma$-model. ","q-bio"
"1907.10063","Anomaly free Froggatt-Nielsen models of flavor","  We introduce two anomaly free versions of Froggatt-Nielsen (FN) models, based on either $G_{\rm FN}=U(1)^3$ or $G_{\rm FN}=U(1)$ horizontal symmetries, that generate the SM quark and lepton flavor structures. The structure of these ""inverted"" FN models is motivated by the clockwork mechanism: the chiral fields, singlets under $G_{\rm FN}$, are supplemented by chains of vector-like fermions charged under $G_{\rm FN}$. Unlike the traditional FN models the hierarchy of quark and lepton masses is obtained as an expansion in $M/\langle \phi\rangle$, where $M$ is the typical vector-like fermion mass, and $\langle \phi\rangle$ the flavon vacuum expectation value. The models can be searched for through deviations in flavor observables such as $K-\bar K$ mixing, $\mu\to e$ conversion, etc., where the present bounds restrict the masses of vector-like fermions to be above ${\mathcal O}(10^7~{\rm GeV})$. If $G_{\rm FN}$ is gauged, the models can also be probed by searching for the flavorful $Z'$ gauge bosons. In principle, the $Z'$s can be very light, and can be searched for using precision flavor, astrophysics, and beam dump experiments. ","hep-ph"
"1904.00492","Leading exponential finite size corrections for non-diagonal form   factors","  We derive the leading exponential finite volume corrections in two dimensional integrable models for non-diagonal form factors in diagonally scattering theories. These formulas are expressed in terms of the infinite volume form factors and scattering matrices. If the particles are bound states then the leading exponential finite-size corrections ($\mu$-terms) are related to virtual processes in which the particles disintegrate into their constituents. For non-bound state particles the leading exponential finite-size corrections (F-terms) come from virtual particles traveling around the finite world. In these F-terms a specifically regulated infinite volume form factor is integrated for the momenta of the virtual particles. The F-term is also present for bound states and the $\mu$-term can be obtained by taking an appropriate residue of the F-term integral. We check our results numerically in the Lee-Yang and sinh-Gordon models based on newly developed Hamiltonian truncations. ","hep-th"
"1811.08294","Minimal surfaces with mixed three-form flux","  We study minimal area world sheets ending on two concentric circumferences on the boundary of Euclidean $AdS_{3}$ with mixed R-R and NS-NS three-form fluxes. We solve the problem by reducing the system to a one-dimensional integrable model. We find that the NS-NS flux term either brings the surface near to the boundary or separates the circumferences. In the limit of pure NS-NS flux the solution adheres to the boundary in the former case and the outer radius diverges in the latter. We further construct the underlying elliptic spectral curve, which allows us to analyze the deformation of other related minimal surfaces. We show that in the regime of pure NS-NS flux the elliptic curve degenerates. ","hep-th"
"1901.01881","On curves with Poritsky property","  For a given closed convex planar curve $\gamma$ with smooth boundary and a given $p>0$, the string construction yields a family of nested billiards $\Gamma_p$ for which $\gamma$ is a caustic. The action of the corresponding reflections $T_p$ on the tangent lines to $\gamma$ induces their actions on the tangency points: a family of string diffeomorphisms $\mathcal T_p:\gamma\to\gamma$. We say that $\gamma$ has string Poritsky property, if it admits a parameter $t$ (called Poritsky string length) in which all the transformations $\mathcal T_p$ with small $p$ are translations $t\mapsto t+c_p$. These definitions also make sense for germs of curves $\gamma$. Poritsky property is closely related to the famous Birkhoff Conjecture. It is classically known that each conic has string Poritsky property. In 1950 H.Poritsky proved the converse: each germ of planar curve with Poritsky property is a conic. In the present paper we extend this Poritsky's result to germs of curves on simply connected complete surfaces with Riemannian metric of constant curvature and to outer billiards on all these surfaces. In the general case of curves with Poritsky property on any two-dimensional surface with Riemannian metric we prove the two following results: 1) the Poritsky string length coincides with Lazutkin parameter, introduced by V.F.Lazutkin in 1973, up to additive and multiplicative constants; 2) a germ of $C^5$-smooth curve with Poritsky property is uniquely determined by its 4-th jet. In the Euclidean case the latter statement follows from the above-mentioned Poritsky's result. ","math"
"1809.02819","Photonic emulation of two-dimensional materials with antiferromagnetic   order","  We introduce an electromagnetic metamaterial - a spin-valley photonic topological insulator (SV-PTI) - that emulates a wide class of theoretically predicted gapped two-dimensional materials with antiferromagnetic order coupled to the valley degree of freedom. First-principles electromagnetic simulations and an analytic model reveal that a single parameter controls the propagation properties of the chiral states at the domain wall between two SV-PTIs: their group velocity, polarization, and the existence/absence of topological protection. The latter is determined by the geometry of the line of the least frequency separation between the bandgap-forming propagation bands. Topologically-protected compression of electromagnetic energy via group velocity control is enabled by SV-PTIs. ","cond-mat"
"1903.01701","Metal-insulator transition and dominant $d+id$ pairing symmetry in   twisted bilayer graphene","  Motivated by recent experimental studies that have found signatures of a correlated insulator phase and tuning superconductivity in twisted bilayer graphene, we study the temperature-dependent conductivity, the spin correlation and the superconducting pairing correlation within a two-orbital Hubbard model on an emergent honeycomb lattice. The evaluation of the temperature dependence of the conductivity demonstrates that there is a metal-insulator transition, and the Mott phase at strong coupling is accompanied by antiferromagnetic order. The electronic correlation drives a $d+id$ superconducting pairing to be dominant over a wide filling region. All of the dc conductivity, the spin correlation and the superconductivity are suppressed as the interlayer coupling strength increases, and the critical $U_c$ for the metal-insulator transition is also reduced. Our intensive numerical results reveal that twisted bilayer graphene should be a uniquely tunable platform for exploring strongly correlated phenomena. ","cond-mat"
"2004.11101","On the variety of Euclidean point sets","  We construct a continuum of non-homeomorphic compact subspaces of the real line R without singleton components. Thus from the purely topological point of view the real line contains not only more closed sets than open sets but also more closures of open sets than open sets. On the other hand, we show that this discrepancy vanishes either if the topological point of view is sharpened in the metrical or in the order-theoretical direction, or if R is replaced with R^n for dimension n>1. Furthermore, we track down a continuum of topological types of closed and totally disconnected subsets of R. In doing so we also track down a continuum of metrical types of infinite, discrete subsets of the unit interval [0,1]. (As a consequence, any countably infinite discrete space has a continuum of non-homeomorphic metrizable compactifications.) ","math"
"2005.12736","Magnetorheological effect in elastomers containing uniaxial   ferromagnetic particles","  The description of the collective magnetorheological effect induced by magnetic field in magnetoactive elastomers is proposed. The condition of consistency is used between magnetic and mechanic momenta of forces exerted on magnetically uniaxial ferromagnetic particles in elastomer at their magnetization. The study shows that even in the case of small concentration of particles, the value of magnetically-induced shear can be anomalously large, reaching up to tens of percent. The deformation of magnetoactive elastomer can evolve critically, as a second-order phase transition, if magnetic field is aligned along the easy axis of particles. ","cond-mat"
"2007.14896","Survey on Congestion Detection and Control in Connected Vehicles","  The dynamic nature of vehicular ad hoc network (VANET) induced by frequent topology changes and node mobility, imposes critical challenges for vehicular communications. Aggravated by the high volume of information dissemination among vehicles over limited bandwidth, the topological dynamics of VANET causes congestion in the communication channel, which is the primary cause of problems such as message drop, delay, and degraded quality of service. To mitigate these problems, congestion detection, and control techniques are needed to be incorporated in a vehicular network. Congestion control approaches can be either open-loop or closed loop based on pre-congestion or post congestion strategies. We present a general architecture of vehicular communication in urban and highway environment as well as a state-of-the-art survey of recent congestion detection and control techniques. We also identify the drawbacks of existing approaches and classify them according to different hierarchical schemes. Through an extensive literature review, we recommend solution approaches and future directions for handling congestion in vehicular communications. ","cs"
"1808.10157","Universal Scaling Laws for Shear Induced Dilation in Frictional Granular   Media","  Compressed frictional granular matter cannot flow without dilation. Upon forced shearing to generate flow, the amount of dilation may depend on the initial preparation and a host of material variables. On the basis of both experiments and numerical simulations we show that as a result of training by repeated compression-decompression cycles the amount of dilation induced by shearing the system depends only on the shear rate and on the (pre-shearing) packing fraction. Relating the rheological response to structural properties allows us to derive a scaling law for the amount of dilation after $n$ cycles of compression-decompression. The resulting scaling law has a universal exponent that for trained systems is independent of the inter-granules force laws, friction parameters and strain rate. The amplitude of the scaling law is analytically computable, and it depends only on the shear rate and the asymptotic packing fraction. ","cond-mat"
"1810.03317","Phase diagram for a logistic system under bounded stochasticity","  Extinction is the ultimate absorbing state of any stochastic birth-death process, hence the time to extinction is an important characteristic of any natural population. Here we consider logistic and logistic-like systems under the combined effect of demographic and bounded environmental stochasticity. Three phases are identified: an inactive phase where the mean time to extinction $T$ increases logarithmically with the initial population size, an active phase where $T$ grows exponentially with the carrying capacity $N$, and temporal Griffiths phase, with power-law relationship between $T$ and $N$. The system supports an exponential phase only when the noise is bounded, in which case the continuum (diffusion) approximation breaks down within the Griffiths phase. This breakdown is associated with a crossover between qualitatively different survival statistics and decline modes. To study the power-law phase we present a new WKB scheme which is applicable both in the diffusive and in the non-diffusive regime. ","q-bio"
"1911.10245","Coded LoRa Frame Error Rate Analysis","  In this work, we study the coded frame error rate (FER) of LoRa under additive white Gaussian noise (AWGN) and under carrier frequency offset (CFO). To this end, we use existing approximations for the bit error rate (BER) of the LoRa modulation under AWGN and we present a FER analysis that includes the channel coding, interleaving, and Gray mapping of the LoRa physical layer. We also derive the LoRa BER under carrier frequency offset and we present a corresponding FER analysis. We compare the derived frame error rate expressions to Monte Carlo simulations to verify their accuracy. ","eess"
"1904.11594","Bayesian Variable Selection for Multi-Outcome Models Through Shared   Shrinkage","  Variable selection over a potentially large set of covariates in a linear model is quite popular. In the Bayesian context, common prior choices can lead to a posterior expectation of the regression coefficients that is a sparse (or nearly sparse) vector with a few non-zero components, those covariates that are most important. This article extends the global-local shrinkage idea to a scenario where one wishes to model multiple response variables simultaneously. Here, we have developed a variable selection method for a K-outcome model (multivariate regression) that identifies the most important covariates across all outcomes. The prior for all regression coefficients is a mean zero normal with coefficient-specific variance term that consists of a predictor-specific factor (shared local shrinkage parameter) and a model-specific factor (global shrinkage term) that differs in each model. The performance of our modeling approach is evaluated through simulation studies and a data example. ","stat"
"1910.14661","Photo-thermoelectric properties and their use in study of transport   properties of both carriers from a single bulk sample","  We describe a theory on photo-thermoelectric properties of a semiconductor, which include photo-conductivity, photo-Seebeck coefficient, and photo-Hall effect. We demonstrate that these properties provide a powerful tool for the study of carrier transport in semiconductors. Even though photo-carrier generation is a complicated process which often prohibits quantitative analysis as their species or numbers are not known. Using bulk samples seems even less likely as the photo-carrier only affect a thin layer. Our method will allow researchers to bypass these difficulties, to use only measured properties and determine both electron and hole mobilities as well as the ratio between electrons and holes from a bulk sample. We provide initial experiment verification of our theory in the end using two distinctively different semiconductors. ","cond-mat"
"1907.02410","Topological Open/Closed String Dualities: Matrix Models and Wave   Functions","  We sharpen the duality between open and closed topological string partition functions for topological gravity coupled to matter. The closed string partition function is a generalised Kontsevich matrix model in the large dimension limit. We integrate out off-diagonal degrees of freedom associated to one source eigenvalue, and find an open/closed topological string partition function, thus proving open/closed duality. We match the resulting open partition function to the generating function of intersection numbers on moduli spaces of Riemann surfaces with boundaries and boundary insertions. Moreover, we connect our work to the literature on a wave function of the KP integrable hierarchy and clarify the role of the extended Virasoro generators that include all time variables as well as the coupling to the open string observable. ","hep-th"
"2004.08063","Outage Analysis for Intelligent Reflecting Surface Assisted Vehicular   Communication Networks","  Vehicular communication is an important application of the fifth generation of mobile communication systems (5G). Due to its low cost and energy efficiency, intelligent reflecting surface (IRS) has been envisioned as a promising technique that can enhance the coverage performance significantly by passive beamforming. In this paper, we analyze the outage probability performance in IRS-assisted vehicular communication networks. We derive the expression of outage probability by utilizing series expansion and central limit theorem. Numerical results show that the IRS can significantly reduce the outage probability for vehicles in its vicinity. The outage probability is closely related to the vehicle density and the number of IRS elements, and better performance is achieved with more reflecting elements. ","eess"
"2007.01094","Propagation of smallness and size estimate in the second order elliptic   equation with discontinuous complex Lipschitz conductivity","  In this paper, we would like to derive three-ball inequalities and propagation of smallness for the complex second order elliptic equation with discontinuous Lipschitz coefficients. As an application of such estimates, we study the size estimate problem by one pair of Cauchy data on the boundary. The main ingredient in the derivation of three-ball inequalities and propagation of smallness is a local Carleman proved in our recent paper [FVW]. ","math"
"2006.06898","Some polynomial maps with Jacobian rank two or three","  In the paper, we first classify all polynomial maps of the form $H=(u(x,y,z),v(x,y,z), h(x,y))$ in the case that $JH$ is nilpotent and $\deg_zv\leq 1$. After that, we generalize the structure of $H$ to $H=\big(H_1(x_1,x_2,\ldots,x_n),\allowbreak b_3x_3+\cdots+b_nx_n+H_2^{(0)}(x_2),H_3(x_1,x_2),\ldots,H_n(x_1,x_2)\big)$. ","math"
"1905.08432","Formation of disc galaxies around z~2","  We present combined evolution of morphological and stellar properties of galaxies on the two sides of z=2 (2.0<z<4.0 and 1.5<z<2.0) in CDFS, with ground-based spectroscopic redshifts. We perform bulge-disc decomposition on their images in J and H filters, from the 3DHST Legacy Survey obtained using HST/WFC3. Combining morphological information with stellar properties, we provide a detailed account of the formation/growth of discs and spheroids around z~2. The fraction of 2-component (bulge+disc) systems increases from ~46% for z>2 to ~70% for z<2, compensating for the fall in population of pure discs and pure spheroids. All quiescent outliers of our full sample on the main-sequence, are 2-component systems, belonging to the lower redshift range (z<2). The doubling of stellar mass of 2-component systems and decrease in their SFR by the same factor, suggests that mechanisms involved in morphological transformations are also responsible for the quenching of their star formation activity. Interestingly, while there is substantial increase in the size (~2.5 times) and mass (~5 times) of pure discs, from z>2 to z<2, pure spheroids maintain roughly the same values. Additionally, while bulge hosting discs witness an expansion in scale length (~1.3 times), their bulge sizes as well as bulge to total light ratio see no evolution, suggesting that z~2 is pre-dominantly a disc formation period. ","astro-ph"
"1904.07420","The phylogeny number in the aspect of triangles and diamonds of a graph","  Given an acyclic digraph $D$, the competition graph of $D$, denoted by $C(D)$, is the simple graph having vertex set $V(D)$ and edge set $\{uv \mid (u, w), (v, w) \in A(D) \text{ for some } w \in V(D) \}$. The phylogeny graph of an acyclic digraph $D$, denoted by $P(D)$, is the graph with the vertex set $V(D)$ and the edge set $E(U(D)) \cup E(C(D))$ where $U(D)$ denotes the underlying graph of $D$. The notion of phylogeny graphs was introduced by Roberts and Sheng~\cite{roberts1997phylogeny} as a variant of competition graph. Moral graphs having arisen from studying Bayesian networks are the same as phylogeny graphs. In this paper, we integrate the existing theorems computing phylogeny numbers of connected graph with a small number of triangles into one proposition: for a graph $G$ containing at most two triangle, $ |E(G)|-|V(G)|-2t(G)+d(G)+1 \le p(G) \le |E(G)|-|V(G)|-t(G)+1 $ where $t(G)$ and $d(G)$ denote the number of triangles and the number of diamond in $G$, respectively. Then we show that these inequalities hold for graphs with many triangles. In the process of showing it, we derive a useful theorem which plays a key role in deducing various meaningful results including a theorem that answers a question given by Wu~{\it et al.}~\cite{Wu2019}. ","math"
"1902.02762","Self-sufficient Receiver with Wireless Energy Transfer in a Multi-access   Network","  In this letter, we consider the control of an energy self-sufficient receiver in a multi-access network with simultaneous wireless information and energy transfer. Multiple transmitters send data to a common receiver whose only source of energy is a finite size battery which is recharged only from the energy harvested from incoming RF signals. The nodes access the channel randomly resulting in a packet collision when multiple transmitters simultaneously access the channel. The receiver takes samples from the received RF signal to calculate the probability of a collision. The objective is to maximize the receiver goodput subject to the instantaneous availability of receiver energy. We develop an asymptotically optimal dynamic control algorithm, where the receiver makes an energy harvesting or decoding decision according to the current channel measurements and battery level. ","eess"
"1903.02506","A Modulation Format Correction Formula for the Gaussian Noise Model in   the Presence of Inter-Channel Stimulated Raman Scattering","  A closed-form formula is derived, which corrects for the modulation format dependence of the Gaussian Noise (GN) model in the presence of inter-channel stimulated Raman scattering (ISRS). The analytical result enables a rapid estimate of the nonlinear interference (NLI) for arbitrary modulation formats and avoids the need for complex integral evaluations and split-step simulations. It is shown that the modulation format dependent NLI can be approximated by two contributions, one originating from a single span and one asymptotic contribution for a large number of spans. The asymptotic contribution is solved in closed-form for an arbitrary link function, making the result applicable for generic fiber systems using lumped, distributed or hybrid amplification schemes. The methodology is applied to the ISRS GN model and a modulation format correction formula in closed-form is derived which accounts for an arbitrary number of spans, inter-channel stimulated Raman scattering, arbitrary launch power distributions and wavelength dependent dispersion and attenuation. The proposed formula is validated by numerical simulations over the entire C+L band for multiple fiber types. ","eess"
"1904.07681","Strengthening in multi-principal element alloys with   local-chemical-order roughened dislocation pathways","  High-entropy alloys (HEAs) were presumed to have a configurational entropy as high as that of an ideally mixed solid solution (SS) of multiple elements in near-equal proportions. However, enthalpic interactions inevitably render such chemically disordered SSs rare and metastable, except at very high temperatures. Here we highlight a structural feature that sets these concentrated SSs apart from traditional solvent-solute ones: the HEAs possess a wide variety of (local) chemical ordering (LCO). Our atomistic simulations employing an empirical interatomic potential for NiCoCr reveal that the LCO of the multi-principal-element SS changes conspicuously with alloy processing conditions, producing a wide range of generalized planar fault energy in terms of both its sample-average and spatial variation. We further demonstrate that the LCO heightens the ruggedness of the energy landscape and raises activation barriers governing dislocation activities. This not only influences the selection of dislocation pathways in slip, faulting, twinning, and martensitic transformation, but also increases the lattice friction to dislocation motion via a new mechanism of nanoscale segment detrapping that elevates the mechanical strength. All these open a vast playground not accessible to ground-state SSs or intermetallics, offering rich opportunities to tune properties. ","cond-mat"
"1911.00448","Bayesian Multivariate Nonlinear State Space Copula Models","  In this paper we propose a flexible class of multivariate nonlinear non-Gaussian state space models, based on copulas. More precisely, we assume that the observation equation and the state equation are defined by copula families that are not necessarily equal. For each time point, the resulting model can be described by a C-vine copula truncated after the first tree, where the root node is represented by the latent state. Inference is performed within the Bayesian framework, using the Hamiltonian Monte Carlo method, where a further D-vine truncated after the first tree is used as prior distribution to capture the temporal dependence in the latent states. Simulation studies show that the proposed copula-based approach is extremely flexible, since it is able to describe a wide range of dependence structures and, at the same time, allows us to deal with missing data. The application to atmospheric pollutant measurement data shows that our approach is suitable for accurate modeling and prediction of data dynamics in the presence of missing values. Comparison to a Gaussian linear state space model and to Bayesian additive regression trees shows the superior performance of the proposed model with respect to predictive accuracy. ","stat"
"2005.14348","Superconducting and Antiferromagnetic Properties of Dual-Phase V$_3$Ga","  The binary compound V$_3$Ga can exhibit two near-equilibrium phases, consisting of the A15 structure that is superconducting, and the Heusler D0$_3$ structure that is semiconducting and antiferromagnetic. Density functional theory calculations show that the two phases are closely degenerate, being separated by only ~10 meV/atom. Magnetization measurements on bulk-grown samples show superconducting behavior below 14 K. These results indicate the possibility of using V$_3$Ga for quantum technology devices utilizing both superconductivity and antiferromagnetism at the same temperature. ","cond-mat"
"2008.05591","Neurodegenerative damage reduces firing coherence in a continuous   attractor model of grid cells","  Grid cells in the dorsolateral band of the medial entorhinal cortex(dMEC) display strikingly regular periodic firing patterns on a lattice of positions in 2-D space. This helps animals to encode relative spatial location without reference to external cues. The dMEC is damaged in the early stages of Alzheimer's Disease, which affects navigation ability of a disease victim, reducing the synaptic density of neurons in the network. Within an established 2-dimensional continuous attractor neural network model of grid cell activity, we introduce damage parameterized by radius and by the strength of the synaptic output for neurons in the damaged region. The proportionality of the grid field flow on the dMEX to the velocity of the model organism is maintained, but when we examine the coherence of the grid cell firing field in the form of the Fourier transform (Bragg peaks) of the grid lattice, we find that a wide range of damage radius and strength induces an incoherent structure with only a single central peak, adjacent to narrow bands of striped (two additional peaks), which abut an orthorhombic pattern (four additional peaks), that abuts the undamaged hexagonal region (six additional peaks). Within the damaged region, grid cells show no Bragg peaks, and outside the damaged region the central Bragg peak strength is largely unaffected. There is a re-entrant region of normal grid firing for very large damage area. We anticipate that the modified grid cell behavior can be observed in non-invasive fMRI imaging of the dMEC. ","q-bio"
"1907.00901","Emergence of correlations in highly biased Consensus Models in seed   initial configuration","  We study the consensus probability in Voter Model and Invasion Process starting from a seed initial configuration. In the case where the opinions have the same strength or slightly different (weak bias) this function was computed analytically by Sood, Antal and Redner and depends only on the degree of the promoter individual. We check numerically through large scale simulations the above mentioned theory and we find that in the case of strong bias a correlation between the consensus probability and other centrality measures emerge and Sood et al's theory is broken. ","cond-mat"
"1904.01166","The Configuration of the Perivascular System Transporting Macromolecules   in the CNS (PREPRINT)","  Large blood vessels entering the CNS are surrounded by perivascular spaces that communicate with the cerebrospinal fluid and, at their termini, with the interstitial space. Solutes and particles can translocate along these perivascular conduits, reportedly in both directions. Recently, this prompted a renewed interest in the intrathecal therapy delivery route for CNS-targeted therapeutics. However, the extent of the CNS coverage by the perivascular system is unknown, making the outcome of drug administration to the CSF uncertain. We traced the translocation of model macromolecules from the CSF into the CNS of rats and non-human primates. Conduits transporting macromolecules were found to extend throughout the parenchyma from both external and internal (fissures) CNS boundaries, excluding ventricles, in large numbers, on average ca. 40 channels per mm2 in rats and non-human primates. The high density and depth of extension of the perivascular channels suggest that the perivascular route can be suitable for delivery of therapeutics to parenchymal targets throughout the CNS. ","q-bio"
"2008.02609","On the relationship between (secure) multi-party computation and   (secure) federated learning","  The contribution of this short note, contains the following two parts: in the first part, we are able to show that the federate learning (FL) procedure presented by Kairouz et al. \cite{Kairouz1901}, is a random processing. Namely, an $m$-ary functionality for the FL procedure can be defined in the context of multi-party computation (MPC); Furthermore, an instance of FL protocol along Kairouz et al.'s definition can be viewed as an implementation of the defined $m$-ary functionality. As such, an instance of FL procedure is also an instance of MPC protocol. In short, FL is a subset of MPC.   To privately computing the defined FL (m-ary) functionality, various techniques such as homomorphic encryption (HE), secure multi-party computation (SMPC) and differential privacy (DP) have been deployed. In the second part, we are able to show that if the underlying FL instance privately computes the defined $m$-ary functionality in the simulation-based framework, then the simulation-based FL solution is also an instance of SMPC. Consequently, SFL is a subset of SMPC. ","cs"
"2007.00265","Enhancing the Association in Multi-Object Tracking via Neighbor Graph","  Most modern multi-object tracking (MOT) systems follow the tracking-by-detection paradigm. It first localizes the objects of interest, then extracting their individual appearance features to make data association. The individual features, however, are susceptible to the negative effects as occlusions, illumination variations and inaccurate detections, thus resulting in the mismatch in the association inference. In this work, we propose to handle this problem via making full use of the neighboring information. Our motivations derive from the observations that people tend to move in a group. As such, when an individual target's appearance is seriously changed, we can still identify it with the help of its neighbors. To this end, we first utilize the spatio-temporal relations produced by the tracking self to efficiently select suitable neighbors for the targets. Subsequently, we construct neighbor graph of the target and neighbors then employ the graph convolution networks (GCN) to learn the graph features. To the best of our knowledge, it is the first time to exploit neighbor cues via GCN in MOT. Finally, we test our approach on the MOT benchmarks and achieve state-of-the-art performance in online tracking. ","cs"
"1903.00171","NLO QCD corrections to exclusive electroproduction of quarkonium","  The process of exclusive electroproduction of vector quarkonium (EEQ), $e p\to epV$, is per se an interesting topic in studies of quarkonium production mechanism, QCD description of diffractive interaction and nucleon structure. We investigate this process in the framework of nonrelativistic QCD and QCD collinear factorization at the next-to-leading order QCD accuracy. The perturbative convergence behavior is discussed in a large range of photon virtuality $Q^2$. The $J/\psi$ large-$Q^2$ electroproduction data at HERA can be well explained, and the $\Upsilon$ differential production rate is predicted. The uncertainties in theoretical predictions with radiative corrections are greatly reduced. Notice the EEQ process is extremely sensitive to the gluon distribution in nucleon, the generalized parton distribution, our results will constraint the gluon density with high precision while confronting to the future experimental data. For the sake of comparing convenience, the analytic expressions are provided. ","hep-ph"
"1912.12363","TASE: Reducing latency of symbolic execution with transactional memory","  We present the design and implementation of a tool called TASE that uses transactional memory to reduce the latency of symbolic-execution applications with small amounts of symbolic state. Execution paths are executed natively while operating on concrete values, and only when execution encounters symbolic values (or modeled functions) is native execution suspended and interpretation begun. Execution then returns to its native mode when symbolic values are no longer encountered. The key innovations in the design of TASE are a technique for amortizing the cost of checking whether values are symbolic over few instructions, and the use of hardware-supported transactional memory (TSX) to implement native execution that rolls back with no effect when use of a symbolic value is detected (perhaps belatedly). We show that TASE has the potential to dramatically improve some latency-sensitive applications of symbolic execution, such as methods to verify the behavior of a client in a client-server application. ","cs"
"1904.06990","Analysis of the anomalous quartic $WWWW$ couplings at the LHeC and the   FCC-he","  The quartic gauge boson couplings that identify the strengths of the gauge boson self-interactions are exactly determined by the non-Abelian gauge nature of the Standard Model. The examination of these couplings at $ep$ collisions with high center-of-mass energy and high integrated luminosity provides an important opportunity to test the validity of the Standard Model and the existence of new physics beyond the Standard Model. The quartic gauge boson couplings can contribute directly to multi-boson production at colliders. Therefore, we examine the potential of the process $ep \rightarrow \nu_{e}W^{+}W^{-} j$ at the Large Hadron Electron Collider and the Future Circular Collider-hadron electron to study non-standard $WWWW$ couplings in a model independent way by means of the effective Lagrangian approach. We present an investigation on measuring $W^{+}W^{-}$ production in pure leptonic and semileptonic decay channels. In addition, we calculate the sensitivity limits at $95\%$ Confidence Level on the anomalous $\frac{f_{M0}}{\Lambda^{4}}$, $\frac{f_{M1}}{\Lambda^{4}}$, $\frac{f_{M7}}{\Lambda^{4}}$, $\frac{f_{S0}}{\Lambda^{4}}$, $\frac{f_{S1}}{\Lambda^{4}}$, $\frac{f_{T0}}{\Lambda^{4}}$, $\frac{f_{T1}}{\Lambda^{4}}$ and $\frac{f_{T2}}{\Lambda^{4}}$ couplings obtained by dimension-8 operators through the process $ep \rightarrow \nu_{e}W^{+}W^{-} j$ for the Large Hadron Electron Collider and the Future Circular Hadron Electron Collider's different center-of-mass energies and integrated luminosities. Our results show that with the process $ep \rightarrow \nu_{e}W^{+}W^{-} j$ at the Large Hadron Electron Collider and the Future Circular Collider-hadron electron the sensitivity estimated on the anomalous $WWWW$ couplings can be importantly strengthened. ","hep-ph"
"1912.01612","Physical Models for the Clustering of Obscured and Unobscured Quasars","  Clustering measurements of obscured and unobscured quasars show that obscured quasars reside in more massive dark matter halos than their unobscured counterparts. These results are inconsistent with simple unified (torus) scenarios, but might be explained by models in which the distribution of obscuring material depends on Eddington ratio or galaxy stellar mass. We test these possibilities by constructing simple physical models to compare to observed AGN populations. We find that previously observed relationships between obscuration and Eddington ratio or stellar mass are not sufficient reproduce the observed quasar clustering results ($\langle \log M_{\text{halo}}/M_{\odot} \rangle = 12.94 ^{+ 0.10}_{- 0.11}$ and $\langle \log M_{\text{halo}}/M_{\odot} \rangle = 12.49 ^{+ 0.08}_{- 0.08}$ for obscured and unobscured populations, respectively) while maintaining the observed fraction of obscured quasars (30-65$\%$). This work suggests that evolutionary models, in which obscuration evolves on the typical timescale for black hole growth, are necessary to understand the observed clustering of mid-IR selected quasars. ","astro-ph"
"1911.11434","Gravitational Anomalies in nAdS$_2$/nCFT$_1$","  We revisit the holographic description of the near horizon geometry of the BTZ black hole in AdS$_3$ gravity, with a gravitational Chern-Simons term included. After a dimensional reduction of the three dimensional theory, we use the framework of nAdS$_2$/nCFT$_1$ to describe the near horizon physics. This setup allows us to contrast the role of the gravitational and conformal anomaly inherited from AdS$_3$/CFT$_2$ in the symmetry breaking mechanism of nAdS$_2$/nCFT$_1$. Our results display how boundary conditions in the 3D spacetime, combined with the gravitational anomaly, affect the holographic description of the near horizon of the black hole relative to the physics near the AdS$_3$ boundary. ","hep-th"
"2008.10220","Liouville results and asymptotics of solutions of a quasilinear elliptic   equation with supercritical source gradient term","  We consider the elliptic quasilinear equation --$\Delta$ m u = u p |$\nabla$u| q in R N with q $\ge$ m and p > 0, 1 < m < N. Our main result is a Liouville-type property, namely, all the positive C 1 solutions in R N are constant. We also give their asymptotic behaviour : all the solutions in an exterior domain R N \B r0 are bounded. The solutions in B r0 \ {0} can be extended as a continuous functions in B r0. The solutions in R N \ {0} has a finite limit l $\ge$ 0 as |x| $\rightarrow$ $\infty$. Our main argument is a Bernstein estimate of the gradient of a power of the solution, combined with a precise Osserman's type estimate for the equation satisfied by the gradient. ","math"
"2005.07833","Thermal order in holographic CFTs and no-hair theorem violation in black   branes","  We present a large class of holographic models where the boundary ${\mathbb R}^{2,1}$ dimensional conformal field theory has a thermal phase with a spontaneously broken global symmetry. The dual black branes in a Poincare patch of asymptotically $AdS_4$ violate the no-hair theorem. ","hep-th"
"2003.00948","Constraints on non-Newtonian gravity and axionlike particles from   measuring the Casimir force in nanometer separation range","  We obtain constraints on the Yukawa-type corrections to Newton's gravitational law and on the coupling constant of axionlike particles to nucleons following from the experiment on measuring the Casimir force between an Au-coated microsphere and a silicon carbide plate. For this purpose, both the Yukawa-type force and the force due to two-axion exchange between nucleons are calculated in the experimental configuration. In the interaction range of Yukawa force exceeding 1 nm and for axion masses above 17.8 eV, the obtained constraints are much stronger than those found previously from measuring the lateral Casimir force between sinusoidally corrugated surfaces. These results are compared with the results of other laboratory experiments on constraining non-Newtonian gravity and axionlike particles in the relevant interaction ranges. ","hep-ph"
"1907.04953","Application of a pixel color- and coordinate-based K-means clustering   algorithm and RGB color imaging for quantification of rice sheath blight   infection","  Red-green-blue (RGB) digital image-based detection is a promising alternative approach to the existing subjectivity-prone and labor-intensive plant disease quantification methods. K-means clustering (KMC) is a widely used algorithm for processing plant disease RGB images. Because the KMC algorithm clusters pixels based only on color similarity, it has limited utility for quantifying diseases that produce necrotic, coalescing, and water-soaked lesions. Here, we present a pixel color- and coordinate-based K-Means clustering (PCC-KMC) algorithm that is capable of RGB image analysis based on color (normalized RGB values) and spatial information (column and row coordinates) of pixels for quantification of rice sheath blight (ShB) disease. The performance of PCC-KMC was tested using RGB images of ShB-infected stems of the rice lines Jasmine 85, Lemont, and 301194. In contrast to KMC, which clustered randomly scattered pixels of similar color, PCC-KMC successfully segmented diseased regions into biologically-relevant clusters and thereby correctly indicated the pattern of ShB progression. PCC-KMC also enabled the quantification of disease in terms of the percentage of stem area with symptoms and the distance of disease progression from the inoculation site. The results indicate that the PCC-KMC algorithm can be used for the automated quantification of lesions caused by SbB on rice and of lesions caused by other pathogens on other plants. ","q-bio"
"1804.03550","Two Stream 3D Semantic Scene Completion","  Inferring the 3D geometry and the semantic meaning of surfaces, which are occluded, is a very challenging task. Recently, a first end-to-end learning approach has been proposed that completes a scene from a single depth image. The approach voxelizes the scene and predicts for each voxel if it is occupied and, if it is occupied, the semantic class label. In this work, we propose a two stream approach that leverages depth information and semantic information, which is inferred from the RGB image, for this task. The approach constructs an incomplete 3D semantic tensor, which uses a compact three-channel encoding for the inferred semantic information, and uses a 3D CNN to infer the complete 3D semantic tensor. In our experimental evaluation, we show that the proposed two stream approach substantially outperforms the state-of-the-art for semantic scene completion. ","cs"
"1805.06756","Holographic Viscoelastic Hydrodynamics","  Relativistic fluid hydrodynamics, organized as an effective field theory in the velocity gradients, has zero radius of convergence due to the presence of non-hydrodynamic excitations. Likewise, the theory of elasticity of brittle solids, organized as an effective field theory in the strain gradients, has zero radius of convergence due to the process of the thermal nucleation of cracks. Viscoelastic materials share properties of both fluids and solids. We use holographic gauge theory/gravity correspondence to study all order hydrodynamics of relativistic viscoelastic media. ","hep-th"
"2004.07705","Asymmetric dark matter from semi-annihilation","  We show that a general semi-annihilation scenario, in which a pair of dark matter (DM) particles annihilate to an anti-DM, and an unstable state that can mix with or decay to standard model states, can lead to particle anti-particle asymmetry in the DM sector. The present DM abundance, including the CP-violation in the DM sector and the resulting present asymmetry are determined entirely by a single semi-annihilation process at next-to-leading order. For large CP-violation in this process, we find that a nearly complete asymmetry can be obtained in the DM sector, with the observed DM density being dominated by the (anti-)DM particle. The presence of additional pair-annihilation processes can modify the ratio of DM and anti-DM number densities further, if the pair-annihilation is active subsequent to the decoupling of the semi-annihilation. For such a scenario, the required CP-violation for generating the same present asymmetry is generically much smaller, as compared to the scenario with only semi-annihilation present. We show that a minimal model with a complex scalar DM with cubic self-interactions can give rise to both semi- and pair-annihilations, with the required CP-violation generated at one-loop level. We also find that the upper bound on the DM mass from S-matrix unitarity in the purely asymmetric semi-annihilation scenario, with maximal CP-violation, is around 15 GeV, which is much stronger than in the WIMP and previously considered asymmetric DM cases, due to the required large non-zero chemical potential for such asymmetric DM. ","hep-ph"
"2004.12441","Manipulation Detection in Satellite Images Using Deep Belief Networks","  Satellite images are more accessible with the increase of commercial satellites being orbited. These images are used in a wide range of applications including agricultural management, meteorological prediction, damage assessment from natural disasters, and cartography. Image manipulation tools including both manual editing tools and automated techniques can be easily used to tamper and modify satellite imagery. One type of manipulation that we examine in this paper is the splice attack where a region from one image (or the same image) is inserted (spliced) into an image. In this paper, we present a one-class detection method based on deep belief networks (DBN) for splicing detection and localization without using any prior knowledge of the manipulations. We evaluate the performance of our approach and show that it provides good detection and localization accuracies in small forgeries compared to other approaches. ","eess"
"1908.04701","Automated Brain Metastases Detection Framework for T1-Weighted   Contrast-Enhanced 3D MRI","  Brain Metastases (BM) complicate 20-40% of cancer cases. BM lesions can present as punctate (1 mm) foci, requiring high-precision Magnetic Resonance Imaging (MRI) in order to prevent inadequate or delayed BM treatment. However, BM lesion detection remains challenging partly due to their structural similarities to normal structures (e.g., vasculature). We propose a BM-detection framework using a single-sequence gadolinium-enhanced T1-weighted 3D MRI dataset. The framework focuses on detection of smaller (< 15 mm) BM lesions and consists of: (1) candidate-selection stage, using Laplacian of Gaussian approach for highlighting parts of a MRI volume holding higher BM occurrence probabilities, and (2) detection stage that iteratively processes cropped region-of-interest volumes centered by candidates using a custom-built 3D convolutional neural network (""CropNet""). Data is augmented extensively during training via a pipeline consisting of random gamma correction and elastic deformation stages; the framework thereby maintains its invariance for a plausible range of BM shape and intensity representations. This approach is tested using five-fold cross-validation on 217 datasets from 158 patients, with training and testing groups randomized per patient to eliminate learning bias. The BM database included lesions with a mean diameter of ~5.4 mm and a mean volume of ~160 mm3. For 90% BM-detection sensitivity, the framework produced on average 9.12 false-positive BM detections per patient (standard deviation of 3.49); for 85% sensitivity, the average number of false-positives declined to 5.85. Comparative analysis showed that the framework produces comparable BM-detection accuracy with the state-of-art approaches validated for significantly larger lesions. ","eess"
"2002.02387","On BF-type higher-spin actions in two dimensions","  We propose a non-abelian higher-spin theory in two dimensions for an infinite multiplet of massive scalar fields and infinitely many topological higher-spin gauge fields together with their dilaton-like partners. The spectrum includes local degrees of freedom although the field equations take the form of flatness and covariant constancy conditions because fields take values in a suitable extension of the infinite-dimensional higher-spin algebra $hs[\lambda]$. The corresponding action functional is of BF-type and generalizes the known topological higher-spin Jackiw-Teitelboim gravity. ","hep-th"
"2004.01970","BAE: BERT-based Adversarial Examples for Text Classification","  Modern text classification models are susceptible to adversarial examples, perturbed versions of the original text indiscernible by humans but which get misclassified by the model. We present BAE, a powerful black box attack for generating grammatically correct and semantically coherent adversarial examples. BAE replaces and inserts tokens in the original text by masking a portion of the text and leveraging a language model to generate alternatives for the masked tokens. Compared to prior work, we show that BAE performs a stronger attack on three widely used models for seven text classification datasets. ","cs"
"1908.05295","Low-energy effective field theory below the electroweak scale: matching   at one loop","  We compute the one-loop matching between the Standard Model Effective Field Theory and the low-energy effective field theory below the electroweak scale, where the heavy gauge bosons, the Higgs particle, and the top quark are integrated out. The complete set of matching equations is derived including effects up to dimension six in the power counting of both theories. We present the results for general flavor structures and include both the $CP$-even and $CP$-odd sectors. The matching equations express the masses, gauge couplings, as well as the coefficients of dipole, three-gluon, and four-fermion operators in the low-energy theory in terms of the parameters of the Standard Model Effective Field Theory. Using momentum insertion, we also obtain the matching for the $CP$-violating theta angles. Our results provide an ingredient for a model-independent analysis of constraints on physics beyond the Standard Model. They can be used for fixed-order calculations at one-loop accuracy and represent a first step towards a systematic next-to-leading-log analysis. ","hep-ph"
"1907.03455","Signal Reconstruction using Blind Super-resolution with Arbitrary   Sampling","  In this paper the problem of blind super-resolution of sparse signals using arbitrary sampling scheme and atomic lift is discussed. After comprehensive description on blind superresolution problem, it is shown that using Prolate Spheroidal Wave Functions (PSWFs), it is possible to derive a new SemiDefinite Program (SDP) for the blind super-resolution problem. Unlike the previous results, the newly proposed SDP can localize spikes without magnitude recovery. Several numerical simulations were conducted to compare the performance of the proposed method with the recent related research. ","eess"
"2006.00447","Point Process Regression","  Point processes in time have a wide range of applications that include the claims arrival process in insurance or the analysis of queues in operations research. Due to advances in technology, such samples of point processes are increasingly encountered. A key object of interest is the local intensity function. It has a straightforward interpretation that allows to understand and explore point process data. We consider functional approaches for point processes, where one has a sample of repeated realizations of the point process. This situation is inherently connected with Cox processes, where the intensity functions of the replications are modeled as random functions. Here we study a situation where one records covariates for each replication of the process, such as the daily temperature for bike rentals. For modeling point processes as responses with vector covariates as predictors we propose a novel regression approach for the intensity function that is intrinsically nonparametric. While the intensity function of a point process that is only observed once on a fixed domain cannot be identified, we show how covariates and repeated observations of the process can be utilized to make consistent estimation possible, and we also derive asymptotic rates of convergence without invoking parametric assumptions. ","stat"
"1911.12018","Non-Autoregressive Coarse-to-Fine Video Captioning","  It is encouraged to see that many progresses have been made to bridge videos and natural language. However, mainstream video captioning methods depend heavily on autoregressive decoding to generate captions sequentially, raising issues like slow inference speed and the lack of relevant details or diversity in generated descriptions. In this paper, we propose a non-autoregressive decoding based model with a coarse-to-fine captioning procedure, i.e., Non-Autoregressive Coarse-to-Fine model, to alleviate these defects. In implementations, we employ a bi-directional self-attention based network as our language model for achieving parallelization to speed up inference, based on which we decompose the captioning procedure into two stages, where the model has different focuses. Specifically, given that visual words (e.g., nouns and verbs) directly determine the semantic correctness of captions, we design a mechanism of generating visual words to require the model to capture relevant details from videos, which will manifest as a coarse-grained sentence ""template"". Thereafter, we devise dedicated decoding algorithms that not only fill in the ""template"" with suitable words but also modify inappropriate expressions via iterative refinement to obtain a fine-grained description. Extensive experiments on two mainstream video captioning benchmarks, i.e., MSVD and MSR-VTT, demonstrate that our approach achieves state-of-the-art performance, generates diverse descriptions, and obtains high inference efficiency. ","cs"
"1905.02037","Asymptotic H\""older Regularity for the Ellipsoid Process","  We obtain an asymptotic H\""older estimate for functions satisfying a dynamic programming principle arising from a so-called ellipsoid process. By the ellipsoid process we mean a generalization of the random walk where the next step in the process is taken inside a given space dependent ellipsoid. This stochastic process is related to elliptic equations in non-divergence form with bounded and measurable coefficients, and the regularity estimate is stable as the step size of the process converges to zero. The proof, which requires certain control on the distortion and the measure of the ellipsoids but not continuity assumption, is based on the coupling method. ","math"
"1807.03036","A Model of Neutrino Mass, Baryon Asymmetry, and Asymmetric Dark Matter   with $SU(2)_D\otimes U(1)_{D'}$ Dark Sector","  I suggest a new extension of the standard model of particle physics, which introduces a dark sector with the $SU(2)_{D}\otimes U(1)_{D'}$ symmetry besides the SM sector. The new particles of the model all inhabit in the dark sector. The dark gauge symmetry breaking will bring about fruitful physics beyond the SM. The tiny neutrino mass is generated through the Dirac-type seesaw mechanism. The inflaton decay can not only provide the universe inflation and reheating, but also lead to the baryon asymmetry and the asymmetric cold dark matter. In short, the model provides an unification of the neutrino mass, the baryon asymmetry, the asymmetric CDM and the inflation, and it can account for their common origin. Finally, it is very possible to test the model predictions and probe the dark sector physics in near future experiments. ","hep-ph"
"1905.08719","The Calder\'on problem for a space-time fractional parabolic equation","  In this article we study an inverse problem for the space-time fractional parabolic operator $(\partial_t-\Delta)^s+Q$ with $0<s<1$ in any space dimension. We uniquely determine the unknown bounded potential $Q$ from infinitely many exterior Dirichlet-to-Neumann type measurements. This relies on Runge approximation and the dual global weak unique continuation properties of the equation under consideration. In discussing weak unique continuation of our operator, a main feature of our argument relies on a Carleman estimate for the associated fractional parabolic Caffarelli-Silvestre extension. Furthermore, we also discuss constructive single measurement results based on the approximation and unique continuation properties of the equation. ","math"
"1910.07947","LHC bounds on coloured scalars","  We analyze the constraints on coloured scalar bosons imposed by the current LHC data at $\sqrt{s}=13$ TeV. Specifically, we consider an additional electroweak doublet of colour-octet scalars, satisfying the principle of Minimal Flavour Violation in order to fulfill the stringent experimental limits on flavour-changing neutral currents. We demonstrate that coloured scalars with masses below 800 GeV are already excluded, provided they are not fermiophobic. ","hep-ph"
"1907.11861","Deep convolution neural network model for automatic risk assessment of   patients with non-metastatic nasopharyngeal carcinoma","  Nasopharyngeal Carcinoma (NPC) is endemic cancer in the south-east Asia. With the advent of intensity-modulated radiotherapy excellent locoregional control are being achieved. Consequently, this had led to pretreatment clinical staging classification to be less prognostic of outcomes such as recurrence after treatment. Alternative pretreatment strategies for prognosis of NPC after treatment are needed to provide better risk stratification for NPC. In this study we proposed a deep convolution neural network model based on contrast-enhanced T1 (T1C) and T2 weighted (T2) MRI scan to predict 3-year disease progression of NPC patient after primary treatment. We retrospective obtained 596 non-metastatic NPC patients from four independent centres in Hong Kong and China. Our model first performs a segmentation of the primary NPC tumour to localise the tumour, and then uses the segmentation mask as prior knowledge along with the T1C and T2 scan to classify 3-year disease progression. For segmentation, we adapted and modified a VNet to encode both T1C and T2 scan and also encoding to classify T and overall stage classification. Our modified network performed better than baseline VNet with T1C and network with no T and overall classification. The classification result for 3-year disease progression achieved an AUC of 0.828 in the validation set but did not generalised well for the test set which consist of 146 patients from a different centre to the training data (AUC = 0.69). Our preliminary results show that deep learning may offer prognostication of disease progression of NPC patients after treatment. One advantage of our model is that it does not require manual segmentation of the region of interest, hence reducing clinician's burden. Further development in generalising multicentre data set are needed before clinical application of deep learning models in assessment of NPC. ","eess"
"2002.09736","Model-assisted estimation through random forests in finite population   sampling","  Surveys are used to collect data on a subset of a finite population. Most often, the interest lies in estimating finite population parameters such as population totals and means. In some surveys, auxiliary information is available at the population level. This information may be incorporated in the estimation procedures to increase their precision. Model-assisted procedures may be based on parametric or nonparametric models. In this paper, we propose a new class of model-assisted procedures based on random forests based on partitions built at the population level as well as at the sample level. We derive associated variance estimators and we establish the theoretical properties of the proposed procedures. A model-calibration procedure that has the ability to handle multiple survey variables is discussed. Finally, the results of a simulation study suggest that the proposed point and estimation procedures perform well in term of bias, efficiency and coverage in a wide variety of settings. ","stat"
"1908.08468","Discovery of tidally-perturbed pulsations in the eclipsing binary U Gru:   a pioneering system for tidal asteroseismology","  The interior physics of stars is currently not well constrained for early-type stars. This is particularly pertinent for multiple systems as binary interaction becomes more prevalent for more massive stars, which strongly affects their evolution. High-precision photometry from the Transiting Exoplanet Survey Satellite (TESS) mission offers the opportunity to remedy the dearth of observations of pulsating stars that show evidence of binary interaction, specifically pulsating mass-accreting components of semi-detached Algol-type eclipsing binary (oEA) systems. We present the TESS light curve of the circular eclipsing binary system U Gru (TIC 147201138), which shows evidence for free heat-driven pressure modes and a series of tidally-perturbed pressure modes. We highlight the asteroseismic potential of studying pulsating stars in binary systems, and demonstrate how tidal asteroseismology can be applied to infer the influence of binary interaction on stellar structure. ","astro-ph"
"2005.08173","Infrared Dark Clouds and high-mass star formation activity in Galactic   Molecular Clouds","  Ever since their discovery, Infrared dark clouds (IRDCs) are generally considered to be the sites just at the onset of high-mass (HM) star formation. In recent years, it has been realized that not all IRDCs harbour HM Young Stellar Objects (YSOs). Only those IRDCs satisfying a certain mass-size criterion, or equivalently above a certain threshold density, are found to contain HMYSOs. In all cases, IRDCs provide ideal conditions for the formation of stellar clusters. In this paper, we study the massive stellar content of IRDCs to re-address the relation between IRDCs and HM star formation. For this purpose, we have identified all IRDCs associated to a sample of 12 Galactic molecular clouds (MCs). The selected MCs have been the target of a systematic search for YSOs in an earlier study. The catalogued positions of YSOs have been used to search all YSOs embedded in each identified IRDC. In total, we have found 834 YSOs in 128 IRDCs. The sample of IRDCs have mean surface densities of 319 Mo/pc2, mean mass of 1062 Mo, and a mass function power-law slope -1.8, which are similar to the corresponding properties for the full sample of IRDCs and resulting physical properties in previous studies. We find that all those IRDCs containing at least one intermediate to high-mass young star satisfy the often-used mass-size criterion for forming HM stars. However, not all IRDCs satisfying the mass-size criterion contain HM stars. We find that the often used mass-size criterion corresponds to 35% probability of an IRDC forming a massive star. Twenty five (20%) of the IRDCs are potential sites of stellar clusters of mass more than 100 Mo. ","astro-ph"
"2005.08512","Thermodynamics of Chiral Fermion System in a Uniform Magnetic Field","  We construct the grand partition function of the system of chiral fermions in a uniform magnetic field from Landau levels, through which all thermodynamic quantities can be obtained. Taking use of Abel-Plana formula, these thermodynamic quantities can be expanded as series with respect to a dimensionless variable $b=2eB/T^{2}$. We find that the series expansions of energy density, pressure, magnetization intensity and magnetic susceptibility contain a singular term with $\ln b^{2}$, while particle number density, entropy density and heat capacity are power series of $b^{2}$. The asymptotic behaviors of these thermodynamic quantities in extreme conditions are also discussed. ","hep-th"
"2001.06375","A comprehensive analysis of weak transition form factors for doubly   heavy baryons in the light front approach","  The transition form factors for doubly heavy baryons into a spin-$1/2$ or spin-$3/2$ ground-state baryon induced by both the charged current and the flavor changing neutral current are systematically studied within the light-front quark model. In the transition the two spectator quarks have two spin configurations and both are considered in this calculation. We use an updated vertex functions, and inspired by the flavor SU(3) symmetry, we also provide a new approach to derive the flavor-spin factors. With the obtained transition form factors, we perform a phenomenological study of the corresponding semi-leptonic decays of doubly heavy baryons induced by the $c\to d/s \ell^+\nu$, $b\to c/u\ell^-\bar \nu$ and $b\to d/s\ell^+\ell^-$. Results for partial decay widths, branching ratios and the polarization ratios $\Gamma_{L}/\Gamma_{T}$s are given. We find that most branching ratios for the semi-leptonic decays induced by the $c\to d,s$ transitions are at the order of $10^{-3}\sim10^{-2}$, which might be useful for the search of other doubly-heavy baryons. Uncertainties in form factors, the flavor SU(3) symmetry and sources of symmetry breaking effects are discussed. We find that the SU(3) symmetry breaking effects could be sizable in charmed baryon decays while in the bottomed case, the SU(3) symmetry breaking effects are less significant. Our results can be examined at the experimental facilities in the future. ","hep-ph"
"1711.11511","Thermostat-assisted continuously-tempered Hamiltonian Monte Carlo for   Bayesian learning","  We propose a new sampling method, the thermostat-assisted continuously-tempered Hamiltonian Monte Carlo, for Bayesian learning on large datasets and multimodal distributions. It simulates the Nos\'e-Hoover dynamics of a continuously-tempered Hamiltonian system built on the distribution of interest. A significant advantage of this method is that it is not only able to efficiently draw representative i.i.d. samples when the distribution contains multiple isolated modes, but capable of adaptively neutralising the noise arising from mini-batches and maintaining accurate sampling. While the properties of this method have been studied using synthetic distributions, experiments on three real datasets also demonstrated the gain of performance over several strong baselines with various types of neural networks plunged in. ","stat"
"2004.11471","A Tool for Facilitating OCR Postediting in Historical Documents","  Optical character recognition (OCR) for historical documents is a complex procedure subject to a unique set of material issues, including inconsistencies in typefaces and low quality scanning. Consequently, even the most sophisticated OCR engines produce errors. This paper reports on a tool built for postediting the output of Tesseract, more specifically for correcting common errors in digitized historical documents. The proposed tool suggests alternatives for word forms not found in a specified vocabulary. The assumed error is replaced by a presumably correct alternative in the post-edition based on the scores of a Language Model (LM). The tool is tested on a chapter of the book An Essay Towards Regulating the Trade and Employing the Poor of this Kingdom (Cary ,1719). As demonstrated below, the tool is successful in correcting a number of common errors. If sometimes unreliable, it is also transparent and subject to human intervention. ","cs"
"2005.05931","On matter-free Higher Spin Gravities in 3d: (partially)-massless fields   and general structure","  We study the problem of interacting theories with (partially)-massless and conformal higher spin fields without matter in three dimensions. A new class of theories that have partially-massless fields is found, which significantly extends the well-known class of purely massless theories. More generally, it is proved that the complete theory has to have a form of the flatness condition for a connection of a Lie algebra, which, provided there is a non-degenerate invariant bilinear form, can be derived from the Chern-Simons action. We also point out the existence of higher spin theories without the dynamical graviton in the spectrum. As an application of a more general statement that the frame-like formulation can be systematically constructed starting from the metric one by employing a combination of the local BRST cohomology technique and the parent formulation approach, we also obtain an explicit uplift of any given metric-like vertex to its frame-like counterpart. This procedure is valid for general gauge theories while in the case of higher spin fields in d-dimensional Minkowski space one can even use as a starting point metric-like vertices in the transverse-traceless gauge. In particular, this gives the fully off-shell lift for transverse-traceless vertices. ","hep-th"
"2008.03410","OCMR (v1.0)--Open-Access Multi-Coil k-Space Dataset for Cardiovascular   Magnetic Resonance Imaging","  Cardiovascular MRI (CMR) is a non-invasive imaging modality that provides excellent soft-tissue contrast without the use of ionizing radiation. Physiological motions and limited speed of MRI data acquisition necessitate development of accelerated methods, which typically rely on undersampling. Recovering diagnostic quality CMR images from highly undersampled data has been an active area of research. Recently, several data acquisition and processing methods have been proposed to accelerate CMR. The availability of data to objectively evaluate and compare different reconstruction methods could expedite innovation and promote clinical translation of these methods. In this work, we introduce an open-access dataset, called OCMR, that provides multi-coil k-space data from 53 fully sampled and 212 prospectively undersampled cardiac cine series. ","eess"
"1905.01215","Collective Dynamics and Control for Multiple Unmanned Surface Vessels","  A multi-unmanned surface vessel (USV) formation control system is established on a novel platform composed of three 1.2 meter-long hydraulic jet propulsion surface vessels, a differential GPS reference station, and inter-vessel Zigbee communication modules. The system is also equipped with an upper level collective multi-USV protocol and a lower level vessel dynamics controller. The system is capable of chasing and surrounding a target vessel. The results are supported by rigorous theoretical analysis in terms of asymptotical surrounding behavior and trajectory regulation. Extensive experiments are conducted to demonstrate the effectiveness and efficiency of the proposed hardware and software architectures. ","cs"
"2001.04989","A large, deep 3 deg$^2$ survey of H$\alpha$, [OIII], and [OII] emitters   from LAGER: constraining luminosity functions","  We present our measurements of the H$\alpha$, [OIII], and [OII] luminosity functions as part of the Lyman Alpha Galaxies at Epoch of Reionization (LAGER) survey using our samples of 1577 $z = 0.47$ H$\alpha$-, 3933 $z = 0.93$ [OIII]-, and 5367 $z = 1.59$ [OII]-selected emission line galaxies in a single 3 deg$^2$ CTIO/Blanco DECam pointing of the COSMOS field. Our observations reach 5$\sigma$ depths of $8.2\times10^{-18}$ erg s$^{-1}$ cm$^{-2}$ and comoving volumes of $(1-7)\times10^{5}$ Mpc$^3$ making our survey one of the deepest narrowband surveys. We measure the observed luminosity functions and find best-fits of $\phi^\star = 10^{-3.16\pm0.09}$ Mpc$^{-3}$ and $L^\star = 10^{41.72\pm0.09}$ erg s$^{-1}$ for H$\alpha$, $\phi^\star = 10^{-2.16^{+0.10}_{-0.12}}$ Mpc$^{-3}$ and $L^\star = 10^{41.38^{+0.07}_{-0.06}}$ erg s$^{-1}$ for [OIII], and $\phi^\star = 10^{-1.97^{+0.07}_{-0.07}}$ Mpc$^{-3}$ and $L^\star = 10^{41.66\pm0.03}$ erg s$^{-1}$ for [OII], with $\alpha$ fixed to $-1.75$, $-1.6$, and $-1.3$, respectively. An excess of bright $> 10^{42}$ erg s$^{-1}$ [OIII] emitters is observed and may be due to AGN contamination. Dust corrections are applied assuming $A_{\rm{H}\alpha} = 1$ mag. We also design our own empirical rest-frame $g - r$ calibration using SDSS DR12 data, test it against our $z = 0.47$ H$\alpha$ emitters with $z$COSMOS $1$D spectra, and calibrate it for $(g - r)$ between $-0.8$ and $1.3$ mag. Dust and AGN-corrected star formation rate densities (SFRDs) are measured as $\log_{10}\rho_{\rm{SFR}}/(\rm{M}_\odot\ \rm{yr}^{-1}\ \rm{Mpc}^{-3}) = -1.63\pm0.04$, $-1.07\pm0.06$, and $-0.90\pm0.10$ for H$\alpha$, [OIII], and [OII], respectively. We find our [OIII] and [OII] samples fully trace cosmic star formation activity at their respective redshifts in comparison to multi-wavelength SFRDs, while the H$\alpha$ sample traces $\sim 70$ percent of the total $z = 0.47$ SFRD. ","astro-ph"
"1910.08676","Precision of analytical approximations in calculations of Atmospheric   Leptons","  We use the Matrix Cascade Equation code (MCEq) to evaluate the range of applicability of simple analytic approximations parameterized by spectrum-weighted moments and power-law spectral indices that vary slowly with energy. We compare spectra of leptons as a function of zenith angle and energy between MCEq and the analytic approximation. We also compare fluxes obtained with different models of hadronic interactions. The goal is to quantify the effects of the approximations inherent in the simpler formulas in order to determine their limitations and the conditions under which they may be used. Specifically we look for the range of phase space for which the errors in the approximate formulas are smaller than the differences among several different hadronic interaction models. Potential applications include the muon charge ratio, the fraction of prompt leptons from decay of charm and seasonal variations of muons and neutrinos. ","astro-ph"
"1903.04237","Comparing the Properties of GMCs in M33 from Simulations and   Observations","  We compare the properties of clouds in simulated M33 galaxies to those observed in the real M33. We apply a friends of friends algorithm and CPROPS to identify clouds, as well as a pixel by pixel analysis. We obtain very good agreement between the number of clouds, and maximum mass of clouds. Both are lower than occurs for a Milky Way-type galaxy and thus are a function of the surface density, size and galactic potential of M33. We reproduce the observed dependence of molecular cloud properties on radius in the simulations, and find this is due to the variation in gas surface density with radius. The cloud spectra also show good agreement between the simulations and observations, but the exact slope and shape of the spectra depends on the algorithm used to find clouds, and the range of cloud masses included when fitting the slope. Properties such as cloud angular momentum, velocity dispersions and virial relation are also in good agreement between the simulations and observations, but do not necessarily distinguish between simulations of M33 and other galaxy simulations. Our results are not strongly dependent on the level of feedback used here (10 and 20%) although they suggest that 15% feedback efficiency may be optimal. Overall our results suggest that the molecular cloud properties are primarily dependent on the gas and mass surface density, and less dependent on the localised physics such as the details of stellar feedback, or the numerical code used. ","astro-ph"
"1912.03181","Background Field Method for Nonlinear Sigma Models in Nonrelativistic   String Theory","  We continue the study of nonrelativistic string theory in background fields. Nonrelativistic string theory is described by a nonlinear sigma model that maps a relativistic worldsheet to a non-Lorentzian and non-Riemannian target space geometry, which is known to be string Newton-Cartan geometry. We develop the covariant background field method in this non-Riemannian geometry. We apply this background field method to compute the beta-functions of the nonlinear sigma model that describes nonrelativistic string theory on a string Newton-Cartan geometry background, in presence of a Kalb-Ramond two-form and dilaton field. ","hep-th"
"2005.10119","On the use of cross-validation for the calibration of the tuning   parameter in the adaptive lasso","  The adaptive lasso is a popular extension of the lasso, which was shown to generally enjoy better theoretical performance, at no additional computational cost in comparison to the lasso. The adaptive lasso relies on a weighted version of the $L_1$-norm penalty used in the lasso, where weights are typically derived from an initial estimate of the parameter vector. Irrespective of the method chosen to obtain this initial estimate, the performance of the corresponding version of the adaptive lasso critically depends on the value of the tuning parameter, which controls the magnitude of the weighted $L_1$-norm in the penalized criterion. In this article, we show that the standard cross-validation, although very popular in this context, has a severe defect when applied for the calibration of the tuning parameter in the adaptive lasso. We further propose a simple cross-validation scheme which corrects this defect. Empirical results from a simulation study confirms the superiority of our approach, in terms of both support recovery and prediction error. Although we focus on the adaptive lasso under linear regression models, our work likely extends to other regression models, as well as to the adaptive versions of other penalized approaches, including the group lasso, fused lasso, and data shared lasso ","stat"
"2008.03453","Performance Analysis of Cellular-V2X with Adaptive and Selective Power   Control","  LTE based Cellular Vehicle-To-Everything (C-V2X) allows vehicles to communicate with each other directly without the need for infrastructure and is expected to be a critical enabler for connected and autonomous vehicles. V2X communication based safety applications are built on periodic broadcast of basic safety messages with vehicle state information. Vehicles use this information to identify collision threats and take appropriate countermeasures. As the vehicle density increases, these broadcasts can congest the communication channel resulting in increased packet loss; fundamentally impacting the ability to identify threats in a timely manner. To address this issue, it is important to incorporate a congestion control mechanism. Congestion management scheme based on rate and power control has proved to be effective for DSRC. In this paper, we investigate the suitability of similar congestion control to C-V2X with particular focus on transmit power control. In our evaluation, we include periodic basic safety messages and high priority event messages that are generated when an event such as hard braking occurs. Our study reveals that while power control does not improve packet delivery performance of basic safety messages, it is beneficial to high priority event message delivery. In this paper, we investigate the reasons for this behavior using simulations and analysis. ","cs"
"1906.06219","FeTi$_2$O$_5$: a spin Jahn-Teller transition enhanced by cation   substitution","  We have used muon-spin rotation, heat capacity and x-ray diffraction measurements in combination with density functional theory and dipole field calculations to investigate the crystal and magnetic structure of FeTi$_2$O$_5$. We observe a long range ordered state below $T_{\rm N}$=41.8(5) K with indications of significant correlations existing above this temperature. We determine candidate muon stopping sites in this compound, and find that our data are consistent with the spin Jahn-Teller driven antiferromagnetic ground state with $\boldsymbol{k}$=(1/2,1/2,0) reported for CoTi$_2$O$_5$ ($T_{\rm N}$=26 K). By comparing our data with calculated dipolar fields we can restrict the possible moment size and directions of the Fe$^{2+}$ ions. ","cond-mat"
"1905.07742","Radiative transitions and magnetic moments of the charmed and bottom   vector mesons in chiral perturbation theory","  In this work, we systematically study the radiative decays and magnetic moments of the charmed and bottom vector mesons with chiral perturbation theory up to one-loop level. We present the results in SU(2) and SU(3) cases with the mass splitting in loop diagrams kept and unkept, respectively. The obtained decay rates for $D^\ast$ and $B^\ast$ mesons in SU(3) case with the mass splitting kept are: $\Gamma_{\bar{D}^{\ast 0}\to \bar{D}^0\gamma}=16.2^{+6.5}_{-6.0}$ keV, $\Gamma_{D^{\ast-}\to D^-\gamma}=0.73^{+0.7}_{-0.3}$ keV, $\Gamma_{D_s^{\ast-}\to D_s^-\gamma}= 0.32^{+0.3}_{-0.3}$ keV, and $\Gamma_{B^{\ast+}\to B^+\gamma}=0.58^{+0.2}_{-0.2}$ keV, $\Gamma_{B^{\ast0}\to B^0\gamma}=0.23^{+0.06}_{-0.06}$ keV, $\Gamma_{B_s^{\ast0}\to B_s^0\gamma}=0.04^{+0.03}_{-0.03}$ keV. The decay width for $D^{\ast-}\to D^-\gamma$ is consistent with the experimental measurement. As a byproduct, the full widths of $\bar{D}^{\ast0}$ and $D_s^{\ast-}$ are $\Gamma_{\mathrm{tot}}(\bar{D}^{\ast0})\simeq77.7^{+26.7}_{-20.5}~\mathrm{keV}$ and $ \Gamma_{\mathrm{tot}}(D_s^{\ast-})\simeq0.62^{+0.45}_{-0.50}~\mathrm{keV}$, respectively. We also calculate the magnetic moments of the heavy vector mesons. The analytical chiral expressions derived in our work shall be helpful for the extrapolations of lattice QCD simulations in the coming future. ","hep-ph"
"2005.08861","Bacterial Metabolic Heterogeneity: from Stochastic to Deterministic   Models","  We revisit the modeling of the diauxic growth of a pure microorganism on two distinct sugars which was first described by Monod. Most available models are deterministic and make the assumption that all cells of the microbial ecosystem behave homogeneously with respect to both sugars, all consuming the first one and then switching to the second when the first is exhausted. We propose here a stochastic model which describes what is called ""metabolic heterogeneity"". It allows to consider small populations as in microfluidics as well as large populations where billions of individuals coexist in the medium in a batch or chemostat. We highlight the link between the stochastic model and the deterministic behavior in real large cultures using a large population approximation. Then the influence of model parameter values on model dynamics is studied, notably with respect to the lag-phase observed in real systems depending on the sugars on which the microorganism grows. It is shown that both metabolic parameters as well as initial conditions play a crucial role on system dynamics. ","q-bio"
"1907.11330","Identification of New Assembly Mode in the Heliconical Nematic Phase via   Tender Resonant X-ray Scattering","  Helical structures are exciting and are utilized in numerous applications ranging from biotechnology to displays to medicine. Accurate description and understanding of resonance effects in helical structures provides crucial knowledge on molecular packing beyond positional ordering. We exam-ined the manifestation of resonance effects in a nematic phase with heliconical structure, the so called twist bend nematic (NTB) via tender resonant X-ray scattering (TReXS) at the sulfur K-edge. We demonstrate for the first time quantitatively that the energy dependence of the scattering peak in the NTB phase follows the energy dependence of the complex refractive indices measured by X-ray absorption. This allows us to identify a new self-assembly mode for specific sets of liquid crystal dimers in the NTB phase. We anticipate that new avenues in the exploration of complex orientational structures both in static as well as in dynamic modes induced by external stimuli will be pursued. ","cond-mat"
"1905.09799","Conformally Soft Theorem In Gravity","  A central feature of scattering amplitudes in gravity or gauge theory is the existence of a variety of energetically soft theorems which put constraints on the amplitudes. Celestial amplitudes which are obtained from momentum-space amplitudes by a Mellin transform over the external particle energies cannot obey the usual energetically soft theorems. Instead, the symmetries of the celestial sphere imply that the scattering of conformally soft particles whose conformal weights under the 4D Lorentz group SL(2,C) are taken to zero obey special relations. Such conformally soft theorems have recently been found for gauge theory. Here, I show conformally soft factorization of celestial amplitudes for gravity and identify it as the celestial analogue of Weinberg's soft graviton theorem. ","hep-th"
"1905.10704","Continued Fractions and Factoring","  Legendre found that the continued fraction expansion of $\sqrt N$ having odd period leads directly to an explicit representation of $N$ as the sum of two squares. Similarly, it is shown here that the continued fraction expansion of $\sqrt N$ having even period directly produces a factor of a composite $N$. Shanks' infrastructural method is then revisited, and some consequences of its application to factorization by means of the continued fraction expansion of $\sqrt N$ are derived. ","math"
"1907.06834","Noise Removal of FTIR Hyperspectral Images via MMSE","  Fourier transform infrared (FTIR) hyperspectral imaging systems are deployed in various fields where spectral information is exploited. Chemical warfare agent (CWA) detection is one of such fields and it requires a fast and accurate process from the measurement to the visualization of detection results, including noise removal. A general concern of existing noise removal algorithms is a trade-off between time and performance. This paper suggests a minimum mean square error (MMSE) approach as an efficient noise removal algorithm for FTIR hyperspectral images. The experimental result shows that the MMSE estimator spends less time to achieve comparable performance to the existing algorithms. ","eess"
"1903.00768","An Experimental Study of Shor's Factoring Algorithm on IBM Q","  We study the results of a compiled version of Shor's factoring algorithm on the ibmqx5 superconducting chip, for the particular case of $N=15$, $21$ and $35$. The semi-classical quantum Fourier transform is used to implement the algorithm with only a small number of physical qubits and the circuits are designed to reduce the number of gates to the minimum. We use the square of the statistical overlap to give a quantitative measure of the similarity between the experimentally obtained distribution of phases and the predicted theoretical distribution one for different values of the period. This allows us to assign a period to the experimental data without the use of the continued fraction algorithm. A quantitative estimate of the error in our assignment of the period is then given by the overlap coefficient. ","quant-ph"
"2006.12343","Reconfigurable Intelligent Surface Enhanced Device-to-Device   Communications","  Reconfigurable intelligent surface (RIS) technology is a promising method to enhance the device-to-device (D2D) communications. To maximize the sum rate of the cellular and D2D networks, a joint optimization of the position and the phase shift of RIS in D2D communications is considered in this paper. To solve the non-convex sum rate maximum problem, we propose a novel convolutional neural network (CNN) based deep Q-network (DQN) that jointly optimizes the RIS position and its phase shift with lower complexity. Numerical results illustrate that the proposed algorithm can achieve higher sum rate compared to the benchmark algorithms, meanwhile meeting the quality of service (QoS) requirements at D2D receivers and the base station (BS). ","eess"
"2001.10562","Correlation functions in massive Landau-Ginzburg orbifolds and tests of   dualities","  In this paper we discuss correlation function computations in massive topological Landau-Ginzburg orbifolds, extending old results of Vafa. We then apply these computations to provide further tests of the nonabelian mirrors proposal and two-dimensional Hori-Seiberg dualities with $(S)O_{\pm}$ gauge groups and their mirrors. ","hep-th"
"2004.14247","White Paper on Broadband Connectivity in 6G","  This white paper explores the road to implementing broadband connectivity in future 6G wireless systems. Different categories of use cases are considered, from extreme capacity with peak data rates up to 1 Tbps, to raising the typical data rates by orders-of-magnitude, to support broadband connectivity at railway speeds up to 1000 km/h. To achieve these goals, not only the terrestrial networks will be evolved but they will also be integrated with satellite networks, all facilitating autonomous systems and various interconnected structures. We believe that several categories of enablers at the infrastructure, spectrum, and protocol/ algorithmic levels are required to realize the intended broadband connectivity goals in 6G. At the infrastructure level, we consider ultra-massive MIMO technology (possibly implemented using holographic radio), intelligent reflecting surfaces, user-centric and scalable cell-free networking, integrated access and backhaul, and integrated space and terrestrial networks. At the spectrum level, the network must seamlessly utilize sub-6 GHz bands for coverage and spatial multiplexing of many devices, while higher bands will be used for pushing the peak rates of point-to-point links. The latter path will lead to THz communications complemented by visible light communications in specific scenarios. At the protocol/algorithmic level, the enablers include improved coding, modulation, and waveforms to achieve lower latencies, higher reliability, and reduced complexity. Different options will be needed to optimally support different use cases. The resource efficiency can be further improved by using various combinations of full-duplex radios, interference management based on rate-splitting, machine-learning-based optimization, coded caching, and broadcasting. ","eess"
"1906.08199","Wannier basis method for KAM effect in quantum mechanics","  The effect of Kolmogorov-Arnold-Moser (KAM) theorem in quantum systems is manifested in dividing eigenstates into regular and irregular states. We propose an effective method based on Wannier basis in phase space to illustrate this division of eigenstates. The quantum kicked-rotor model is used to illustrate this method, which allows us to define the area and effective dimension of each eigenstate to distinguish quantitatively regular and irregular eigenstates. This Wannier basis method also allows us to define the length of a Planck cell in the spectrum that measures how many Planck cells the system will traverse if it starts at the given Planck cell. Moreover, with this Wannier approach, we are able to clarify the distinction between KAM effect and Anderson localization. ","quant-ph"
"1812.05158","Interference-induced localization in quantum random walk on clean cyclic   graph","  We quantitatively differentiate between the spreads of discrete-time quantum and classical random walks on a cyclic graph. Due to the closed nature of any cyclic graph, there is additional ""collision""- like interference in the quantum random walk along with the usual interference in any such walk on any graph, closed or otherwise. We find that the quantum walker remains localized in comparison to the classical one, even in the absence of disorder, a phenomenon that is potentially attributable to the additional interference in the quantum case. This is to be contrasted with the situation on open graphs, where the quantum walker, being effectively denied the collision-like interference, garners a much higher spread than its classical counterpart. We use Shannon entropy of the position probability distribution to quantify spread of the walker in both quantum and classical cases. We find that for a given number of vertices on a cyclic graph, the entropy with respect to number of steps for the quantum walker saturates, on average, to a value lower than that for the corresponding classical one. We also analyze variations of the entropies with respect to system size, and look at the corresponding asymptotic growth rates. ","quant-ph"
"2004.07358","Ab-initio electronic transport in narrow gap semiconductors using the   Wigner distribution","  Electronic transport properties of semiconductors with small band gaps are often not well described by semiclassical methods, such as the Boltzmann transport equation, because of the missing interaction between carriers whose band energy differences are closer than their linewidth. This limits accuracy of predictions for many topological insulators and materials with complex structure and disorder. We develop a new first-principles formalism that uses the Wigner transform to generalize semiclassical transport models to this regime by including additional quantum effects. We apply the formalism to Bi$_2$Se$_3$, and show that its bulk electronic transport properties at low doping concentrations are dominated by the Zener effect, a mechanism in which carriers transfer charge by tunnelling across the band gap. ","cond-mat"
"1902.09237","Orbital and physical parameters of the close binary system: GJ 9830 (HIP   116259)","  We present the complete set of physical and geometrical parameters of the visual close binary system GJ\,9830 for the first time by using Al-Wardat's complex method. This method combines magnitude difference from speckle interferometry, synthetic spectral energy distributions of the binary components which are constructed depending on grids of Kurucz blanketed models (Atlas9), along with the orbital solution by using Tokovinin's dynamical method to estimate the parameters of the individual components. The analysis of the system by using synthetic photometry resulted in the following set of parameters: $T_{\rm eff.}=6220\pm 100$ \,K, $\rm log~g=4.30\pm 0.12$, $R=1.10\pm0.08\,R_\odot$ for the primary component and $T_{\rm eff.}=4870\pm 100$\,K, $\rm log~g=4.60\pm 0.11$, $R=0.709\pm0.07\,R_\odot$ for the secondary component. The recently published dynamical parallax from \textit{Gaia} space mission was used to calculate the total mass of the binary system as $1.75\pm0.06\, \mathcal{M}_\odot$ which coincides with those estimated by using Al-Wardat's method as $ \mathcal{M}^{A}=1.18\pm0.10\, \mathcal{M}_\odot$, $ \mathcal{M}^{B}=0.75\pm0.08\, \mathcal{M}_\odot$.   The analysis of the system reveals that both components belong to main sequence stars with an age around $1.4\pm0.50$\,Gyr. The evolutionary tracks and isochrones of the system's components are discussed, and the fragmentation process is suggested as the most likely process for the formation of the system. ","astro-ph"
"1807.03401","High-Resolution Mammogram Synthesis using Progressive Generative   Adversarial Networks","  The ability to generate synthetic medical images is useful for data augmentation, domain transfer, and out-of-distribution detection. However, generating realistic, high-resolution medical images is challenging, particularly for Full Field Digital Mammograms (FFDM), due to the textural heterogeneity, fine structural details and specific tissue properties. In this paper, we explore the use of progressively trained generative adversarial networks (GANs) to synthesize mammograms, overcoming the underlying instabilities when training such adversarial models. This work is the first to show that generation of realistic synthetic medical images is feasible at up to 1280x1024 pixels, the highest resolution achieved for medical image synthesis, enabling visualizations within standard mammographic hanging protocols. We hope this work can serve as a useful guide and facilitate further research on GANs in the medical imaging domain. ","cs"
"2003.01095","Hidden symmetries generate rigid folding mechanisms in periodic origami","  We consider the zero-energy deformations of periodic origami sheets with generic crease patterns. Using a mapping from the linear folding motions of such sheets to force-bearing modes in conjunction with the Maxwell-Calladine index theorem we derive a relation between the number of linear folding motions and the number of rigid body modes that depends only on the average coordination number of the origami's vertices. This supports the recent result by Tachi which shows periodic origami sheets with triangular faces exhibit two-dimensional spaces of rigidly foldable cylindrical configurations. We also find, through analytical calculation and numerical simulation, branching of this configuration space from the flat state. The same counting argument leads to pairing of spatially varying modes at opposite wavenumber in triangulated origami, preventing topological polarization but permitting a family of zero energy deformations in the bulk that may be used to reconfigure the origami sheet. ","cond-mat"
"1912.08508","Optimizing Pilots and Analog Processing for Channel Estimation in   Cell-Free Massive MIMO With One-Bit ADCs","  In a cell-free cloud radio access network (C-RAN) architecture, uplink channel estimation is carried out by a centralized baseband processing unit (BBU) connected to distributed remote radio heads (RRHs). When the RRHs have multiple antennas and limited radio front-end resources, the design of uplink channel estimation is faced with the challenges posed by reduced radio frequency (RF) chains and one-bit analog-to-digital converters (ADCs) at the RRHs. This work tackles the problem of jointly optimizing the pilot sequences and the pre-RF chains analog combiners with the goal of minimizing the sum of mean squared errors (MSEs) of the estimated channel vectors at the BBU. The problem formulation models the impact of the ADC operation by leveraging Bussgang's theorem. An efficient solution is developed by means of an iterative alternating optimization algorithm. Numerical results validate the advantages of the proposed joint design compared to baseline schemes that randomly choose either pilots or analog combiners. ","eess"
"1912.02734","Solving Advanced Argumentation Problems with Answer Set Programming","  Powerful formalisms for abstract argumentation have been proposed, among them abstract dialectical frameworks (ADFs) that allow for a succinct and flexible specification of the relationship between arguments, and the GRAPPA framework which allows argumentation scenarios to be represented as arbitrary edge-labelled graphs. The complexity of ADFs and GRAPPA is located beyond NP and ranges up to the third level of the polynomial hierarchy. The combined complexity of Answer Set Programming (ASP) exactly matches this complexity when programs are restricted to predicates of bounded arity. In this paper, we exploit this coincidence and present novel efficient translations from ADFs and GRAPPA to ASP. More specifically, we provide reductions for the five main ADF semantics of admissible, complete, preferred, grounded, and stable interpretations, and exemplify how these reductions need to be adapted for GRAPPA for the admissible, complete and preferred semantics. Under consideration in Theory and Practice of Logic Programming (TPLP). ","cs"
"2007.04870","Decision making via generalized Bajraktarevi\'c means","  We define decision-making functions which arise from studying the multidimensional generalization of the weighted Bajraktarevi\'c means. It allows a nonlinear approach to optimization problems.   These functions admit several interesting (from the point of view of decision-making) properties, for example, delegativity (which states that each subgroup of decision-makers can aggregate their decisions and efforts), casuativity (each decision affects the final outcome except two trivial cases) and convexity-type properties.   Beyond establishing the most important properties of such means, we solve their equality problem, we introduce a notion of synergy and characterize the null-synergy decision-making functions of this type. ","math"
"1904.10955","Buried Black Hole Growth in IR-selected Mergers: New Results from   Chandra","  Observations and theoretical simulations suggest that a significant fraction of merger-triggered accretion onto supermassive black holes is highly obscured, particularly in late-stage galaxy mergers, when the black hole is expected to grow most rapidly. Starting with the Wide-Field Infrared Survey Explorer all-sky survey, we identified a population of galaxies whose morphologies suggest ongoing interaction and which exhibit red mid-infrared colors often associated with powerful active galactic nuclei (AGNs). In a follow-up to our pilot study, we now present Chandra/ACIS and XMM-Newton X-ray observations for the full sample of the brightest 15 IR-preselected mergers. All mergers reveal at least one nuclear X-ray source, with 8 out of 15 systems exhibiting dual nuclear X-ray sources, highly suggestive of single and dual AGNs. Combining these X-ray results with optical line ratios and with near-IR coronal emission line diagnostics, obtained with the near-IR spectrographs on the Large Binocular Telescope, we confirm that 13 out of the 15 mergers host AGNs, two of which host dual AGNs. Several of these AGNs are not detected in the optical. All X-ray sources appear X-ray weak relative to their mid-infrared continuum, and of the nine X-ray sources with sufficient counts for spectral analysis, eight reveal strong evidence of high absorption with column densities of $N_\mathrm{H} \gtrsim 10^{23}$~cm$^{-2}$. These observations demonstrate that a significant population of single and dual AGNs are missed by optical studies, due to high absorption, adding to the growing body of evidence that the epoch of peak black hole growth in mergers occurs in a highly obscured phase. ","astro-ph"
"2008.04557","Metastable Potts Droplets","  The existence and limits of metastable droplets have been calculated using finite-system renormalization-group theory, for q-state Potts models in spatial dimension d=3. The dependence of the droplet critical sizes on magnetic field, temperature, and number of Potts states q has been calculated. The same method has also been used for the calculation of hysteresis loops across first-order phase transitions in these systems. The hysteresis loop sizes and shapes have been deduced as a function of magnetic field, temperature, and number of Potts states q. The uneven appearance of asymmetry in the hysteresis loop branches has been noted. The method can be extended to criticality and phase transitions in metastable phases, such as in surface-adsorbed systems and water. ","cond-mat"
"1905.12435","Distinguished bases and monodromy of complex hypersurface singularities","  We give a survey on some aspects of the topological investigation of isolated singularities of complex hypersurfaces by means of Picard-Lefschetz theory. We focus on the concept of distinguished bases of vanishing cycles and the concept of monodromy. ","math"
"1906.07729","Cluster Cosmology with the Velocity Distribution Function of the HeCS-SZ   Sample","  We apply the Velocity Distribution Function (VDF) to a sample of Sunyaev-Zel'dovich (SZ)-selected clusters, and we report preliminary cosmological constraints in the $\sigma_8$-$\Omega_m$ cosmological parameter space. The VDF is a forward-modeled test statistic that can be used to constrain cosmological models directly from galaxy cluster dynamical observations. The method was introduced in Ntampaka et al. (2017) and employs line-of-sight velocity measurements to directly constrain cosmological parameters; it is less sensitive to measurement error than a standard halo mass function approach. The method is applied to the Hectospec Survey of Sunyaev-Zeldovich-Selected Clusters (HeCS-SZ) sample, which is a spectroscopic follow up of a Planck-selected sample of 83 galaxy clusters. Credible regions are calculated by comparing the VDF of the observed cluster sample to that of mock observations, yielding $\mathcal{S}_8 \equiv \sigma_8 \left(\Omega_m/0.3\right)^{0.25} = 0.751\pm0.037$. These constraints are in tension with the Planck Cosmic Microwave Background (CMB) TT fiducial value, which lies outside of our 95% credible region, but are in agreement with some recent analyses of large scale structure that observe fewer massive clusters than are predicted by the Planck fiducial cosmological parameters. ","astro-ph"
"1901.10803","Derivation and application of effective interface conditions for   continuum mechanical models of cell invasion through thin membranes","  We consider a continuum mechanical model of cell invasion through thin membranes. The model consists of a transmission problem for cell volume fraction complemented with continuity of stresses and mass flux across the surfaces of the membranes. We reduce the original problem to a limiting transmission problem whereby each thin membrane is replaced by an effective interface, and we develop a formal asymptotic method that enables the derivation of a set of biophysically consistent transmission conditions to close the limiting problem. The formal results obtained are validated via numerical simulations showing that the relative error between the solutions to the original transmission problem and the solutions to the limiting problem vanishes when the thickness of the membranes tends to zero. In order to show potential applications of our effective interface conditions, we employ the limiting transmission problem to model cancer cell invasion through the basement membrane and the metastatic spread of ovarian carcinoma. ","q-bio"
"1908.05099","Shape-Aware Complementary-Task Learning for Multi-Organ Segmentation","  Multi-organ segmentation in whole-body computed tomography (CT) is a constant pre-processing step which finds its application in organ-specific image retrieval, radiotherapy planning, and interventional image analysis. We address this problem from an organ-specific shape-prior learning perspective. We introduce the idea of complementary-task learning to enforce shape-prior leveraging the existing target labels. We propose two complementary-tasks namely i) distance map regression and ii) contour map detection to explicitly encode the geometric properties of each organ. We evaluate the proposed solution on the public VISCERAL dataset containing CT scans of multiple organs. We report a significant improvement of overall dice score from 0.8849 to 0.9018 due to the incorporation of complementary-task learning. ","cs"
"1910.01480","Robust reconstruction of fluorescence molecular tomography with an   optimized illumination pattern","  Fluorescence molecular tomography (FMT) is an emerging powerful tool for biomedical research. There are two factors that influence FMT reconstruction most effectively. The first one is the regularization techniques. Traditional methods such as Tikhonov regularization suffer from low resolution and poor signal to noise ratio. Therefore sparse regularization techniques have been introduced to improve the reconstruction quality. The second factor is the illumination pattern. A better illumination pattern ensures the quantity and quality of the information content of the data set thus leading to better reconstructions. In this work, we take advantage of the discrete formulation of the forward problem to give a rigorous definition of an illumination pattern as well as the admissible set of patterns. We add restrictions in the admissible set as different types of regularizers to a discrepancy functional, generating another inverse problem with the illumination pattern as unknown. Both inverse problems of reconstructing the fluorescence distribution and finding the optimal illumination pattern are solved by fast efficient iterative algorithms. Numerical experiments have shown that with a suitable choice of the regularization parameters the two-step approach converges to an optimal illumination pattern quickly and the reconstruction result is improved significantly, regardless of the initial illumination setting. ","eess"
"1904.01167","Multi-layer Unmanned Aerial Vehicle Networks: Modeling and Performance   Analysis","  Since various types of unmanned aerial vehicles (UAVs) with different hardware capabilities are introduced, we establish a foundation for the multi-layer aerial network (MAN). First, the MAN is modeled as K layer ANs, and each layer has UAVs with different densities, floating altitudes, and transmission power. To make the framework applicable for various scenarios in MAN, we consider the transmitter- and the receiver-oriented node association rules as well as the air-to-ground and air-to-air channel models, which form line of sight links with a location-dependent probability. We then newly analyze the association probability, the main link distance distribution, successful transmission probability (STP), and area spectral efficiency (ASE) of MAN. The upper bounds of the optimal densities that maximize STP and ASE are also provided. Finally, in the numerical results, we show the optimal UAV densities of an AN that maximize the ASE and the STP decrease with the altitude of the network. We also show that when the total UAV density is fixed for two layer AN, the use of single layer in higher(lower) altitude only for all UAVs can achieve better performance for low(high) total density case, otherwise, distributing UAVs in two layers, i.e., MAN, achieves better performance. ","eess"
"1906.05687","Low Photon Budget Phase Retrieval with Perceptual Loss Trained Deep   Neural Networks","  Deep neural networks (DNNs) are efficient solvers for ill-posed problems and have been shown to outperform classical optimization techniques in several computational imaging problems. DNNs are trained by solving an optimization problem implies the choice of an appropriate loss function, i.e., the function to optimize. In a recent paper [A. Goy \textit{et al.}, Phys. Rev. Lett. 121(24), 243902 (2018)], we showed that DNNs trained with the negative Pearson correlation coefficient as the loss function are particularly fit for photon-starved phase retrieval problems, which are fundamentally affected by strong Poison noise. In this paper we demonstrate that the use of a perceptual loss function significantly improves the reconstructions. ","eess"
"2003.12266","Dual Attention in Time and Frequency Domain for Voice Activity Detection","  Voice activity detection (VAD) is a challenging task in low signal-to-noise ratio (SNR) environment, especially in non-stationary noise. To deal with this issue, we propose a novel attention module that can be integrated in Long Short-Term Memory (LSTM). Our proposed attention module refines each LSTM layer's hidden states so as to make it possible to adaptively focus on both time and frequency domain. Experiments are conducted on various noisy conditions using Aurora 4 database. Our proposed method obtains the 95.58 % area under the ROC curve (AUC), achieving 22.05 % relative improvement compared to baseline, with only 2.44 % increase in the number of parameters. Besides, we utilize focal loss for alleviating the performance degradation caused by imbalance between speech and non-speech sections in training sets. The results show that the focal loss can improve the performance in various imbalance situations compared to the cross entropy loss, a commonly used loss function in VAD. ","eess"
"1906.03105","Reconciling Hierarchical Forecasts via Bayes' Rule","  We present a novel approach for reconciling hierarchical forecasts, based on Bayes rule. We define a prior distribution for the bottom time series of the hierarchy, based on the bottom base forecasts. Then we update their distribution via Bayes rule, based on the base forecasts for the upper time series. Under the Gaussian assumption, we derive the updating in closed-form. We derive two algorithms, which differ as for the assumed independencies. We discuss their relation with the MinT reconciliation algorithm and with the Kalman filter, and we compare them experimentally. ","stat"
"1906.09990","Self-repairing Classification Algorithms for Chemical Sensor Array","  Chemical sensors are usually affected by drift, have low fabrication reproducibility and can experience failure or breaking events over the long term. Albeit improvements in fabrication processes are often slow and inadequate for completely surmounting these issues, data analysis can be used as of now to improve the available device performances. The present paper illustrates an algorithm, called Self-Repairing (SR), developed for repairing classification models after the occurrences of failures in sensor arrays. The procedure considers replacing broken sensors with replicas and eventually Self-Repairing algorithm trains these blank elements. Unlike the habitual alternatives reported in literature, SR performs this operation without the need of a whole new recalibration, references gas measurements or transfer dataset and, at the same time, without interrupting the on-going procedure of gas identification. Furthermore, Self-Repairing algorithm can utilize most of the standard classifiers as core algorithm; in this paper SR has been applied to k-NN, PLS-DA and LDA as examples. Models have been tested in a synthetic and real scenario considering sensor arrays affected by drift and eventually by failures. Real experiment has been performed with a set of metal oxide sensors over an 18-months period. Finally, the algorithm has been compared with standard version of chosen classifiers (k-NN, LDA and PLS-DA) showing superior performances of Self-Repairing and increasing the tolerance versus consecutive failures. ","eess"
"2008.03217","Controllable supercurrent in mesoscopic superconductor-normal   metal-ferromagnet crosslike Josephson structures","  A nonmonotonic dependence of the critical Josephson supercurrent on the injection current through a normal metal/ferromagnet weak link from a single domain ferromagnetic strip has been observed experimentally in nanofabricated planar crosslike S-N/F-S Josephson structures. This behavior is explained by 0-pi and pi-0 transitions, which can be caused by the suppression and Zeeman splitting of the induced superconductivity due to interaction between N and F layers, and the injection of spin-polarized current into the weak link. A model considering both effects has been developed. It shows the qualitative agreement between the experimental results and the theoretical model in terms of spectral supercurrent-carrying density of states of S-N/F-S structure and the spin-dependent double-step nonequilibrium quasiparticle distribution. ","cond-mat"
"1903.02594","Systems of Oscillators Designed for a Specific Conscious Percept","  As put forward by neuroscientists, the mechanisms of consciousness can be elucidated by revealing correlations between neural dynamics and specific conscious percepts. Recently, I have elaborated on the mathematical formulation for a system of processes that are mutually connected to be isomorphic to a conscious percept of a point in space. Importantly, in such a system, any process can be derived through all other processes that form its complement, or interpretation. To generate such a solution, I am proposing a dynamical system of oscillators coupled in a manner to preserve the properties of a percept. Specifically, I crafted a dynamical system that retains the mutual relationships among processes, forming an operational map isomorphic to a distance matrix that mimics a percept of space-like properties. The study and results pave a novel way to analyze the dynamics of neural-like (oscillatory) processes with a purpose of extracting the information relevant to specific conscious percepts, which will facilitate the search for neural correlates of consciousness. ","q-bio"
"2002.11696","Chiral perturbation theory for nonzero chiral imbalance","  We construct the most general low-energy effective lagrangian including local parity violating terms parametrized by an axial chemical potential or chiral imbalance $\mu_5$, up to ${\cal O}(p^4)$ order in the chiral expansion for two light flavours. For that purpose, we work within the Chiral Perturbation Theory framework where only pseudo-NGB fields are included, following the external source method. The $\cal{O}(p^2)$ lagrangian is only modified by constant terms, while the $\cal{O}(p^4)$ one includes new terms proportional to $\mu_5^2$ and new low-energy constants (LEC), which are renormalized and related to particular observables. In particular, we analyze the corrections to the pion dispersion relation and observables related to the vacuum energy density, namely the light quark condensate, the chiral and topological susceptibilities and the chiral charge density, providing numerical determinations of the new LEC when possible. In particular, we explore the dependence of the chiral restoration temperature $T_c$ with $\mu_5$. An increasing $T_c(\mu_5)$ is consistent with our fits to lattice data of the ChPT-based expressions. Although lattice uncertainties are still large and translate into the new LEC determination, a consistent physical description of those observables emerges from our present work, providing a theoretically robust model-independent framework for further study of physical systems where parity-breaking effects may be relevant, such as heavy-ion collisions. ","hep-ph"
"2001.09680","Complex emission patterns: fluctuations and bistability of polar-cap   potentials","  Development of the ion-proton pulsar model extends it to the limit of large unscreened polar-cap potentials, for example, as in the Vela pulsar, in which ion charges differ only by small increments from their complete screening values. It is shown that the atomic number Z of an ion following its passage from the canonical Z_0 = 26 value through the electromagnetic shower region to the surface is not necessarily time-independent but can vary between fixed limits in an irregular or quasi-periodic way in a characteristic time of the order of 10^4 s. Thus at a certain Z the system may transition to an unstable state of higher electric potential and it is argued that this is the physical basis for mode-changes, long-term nulls, periodic or otherwise. The model requires an orientation of magnetic dipole moment relative to rotational spin giving a positive corotational charge density. Success of the model would fix the particle composition of the remaining parts of the magnetosphere, including the Y-point and is therefore relevant to X-ray and gamma-ray emission processes. ","astro-ph"
"2005.09955","A Route to School Informational Intervention for Air Pollution Exposure   Reduction","  Walking and cycling are promoted to encourage sustainable travel behavior among children and adults. School children during their travel episode to-and-from school are disproportionately exposed to air pollution due to multiple reasons such as proximity to high traffic roads and peak volumes. This paper presents a route to school informational intervention that was developed incorporating approaches and methods suggested in the literature for effective behavioral interventions. The intervention was implemented using escorting parents/guardians (N=104) of school children of Antwerp, Belgium to adopt school routes with least exposure to pollutants. Collected data and its analysis revealed that 60% participants (N= 62) could benefit themselves by adopting the suggested cleanest routes to school, of whom a significant proportion of participants (i.e. 34%, N= 35) have a difference of average NO2 concentration between the alternative and current route of around 10{\mu}g/m3. This information about alternatives routes with their potential benefits was presented to each participant via defined study protocols. 18 Based on the feedback of participants that could potentially adopt suggested alternatives, 77% (N=48) have switched their routes. These results indicated that intervention was effective, and it can bring higher benefits when implemented on a wider scale. ","stat"
"1908.08218","Multipartite Entanglement Measure and Complete Monogamy Relation","  Although many different entanglement measures have been proposed so far, much less is known in the multipartite case, which leads to the previous monogamy relations in literatures are not complete. We establish here a strict framework for defining multipartite entanglement measure (MEM): apart from the postulates of bipartite measure, a genuine MEM should additionally satisfy the unification condition and the hierarchy condition. We then come up with a complete monogamy formula for the unified MEM and a tightly complete monogamy relation for the genuine MEM. Consequently, we propose MEMs which are multipartite extensions of entanglement of formation (EoF), concurrence, tangle, Tsallis $q$-entropy of entanglement, R\'{e}nyi $\alpha$-entropy of entanglement, the convex-roof extension of negativity and negativity, respectively. We show that (i) the extensions of EoF, concurrence, tangle, and Tsallis $q$-entropy of entanglement are genuine MEMs, (ii) multipartite extensions of R\'{e}nyi $\alpha$-entropy of entanglement, negativity and the convex-roof extension of negativity are unified MEMs but not genuine MEMs, and (iii) all these multipartite extensions are completely monogamous and the ones which are defined by the convex-roof structure (except for the R\'{e}nyi $\alpha$-entropy of entanglement and the convex-roof extension of negativity) are not only completely monogamous but also tightly completely monogamous. In addition, we find a class of tripartite states that one part can maximally entangled with other two parts simultaneously according to the definition of maximally entangled mixed state (MEMS) in [Quantum Inf. Comput. 12, 0063 (2012)]. Consequently, we improve the definition of maximally entangled state (MES) and prove that there is no MEMS and that the only MES is the pure MES. ","quant-ph"
"2002.07443","An Evaluation of Monte Carlo-Based Hyper-Heuristic for Interaction   Testing of Industrial Embedded Software Applications","  Hyper-heuristic is a new methodology for the adaptive hybridization of meta-heuristic algorithms to derive a general algorithm for solving optimization problems. This work focuses on the selection type of hyper-heuristic, called the Exponential Monte Carlo with Counter (EMCQ). Current implementations rely on the memory-less selection that can be counterproductive as the selected search operator may not (historically) be the best performing operator for the current search instance. Addressing this issue, we propose to integrate the memory into EMCQ for combinatorial t-wise test suite generation using reinforcement learning based on the Q-learning mechanism, called Q-EMCQ. The limited application of combinatorial test generation on industrial programs can impact the use of such techniques as Q-EMCQ. Thus, there is a need to evaluate this kind of approach against relevant industrial software, with a purpose to show the degree of interaction required to cover the code as well as finding faults. We applied Q-EMCQ on 37 real-world industrial programs written in Function Block Diagram (FBD) language, which is used for developing a train control management system at Bombardier Transportation Sweden AB. The results of this study show that Q-EMCQ is an efficient technique for test case generation. Additionally, unlike the t-wise test suite generation, which deals with the minimization problem, we have also subjected Q-EMCQ to a maximization problem involving the general module clustering to demonstrate the effectiveness of our approach. ","cs"
"1905.04104","Constructing black hole solutions in supergravity theories","  We perform a detailed analysis of black hole solutions in supergravity models. After a general introduction on black holes in general relativity and supersymmetric theories, we provide a detailed description of ungauged extended supergravities and their dualities. Therefore, we analyze the general form of black hole configurations for these models, their near-horizon behavior and characteristic of the solution. An explicit construction of a black hole solution with its physical implications is given for the STU-model. The second part of this review is dedicated to gauged supergravity theories. We describe a step-by-step gauging procedure involving the embedding tensor formalism, to be used to obtain a gauged model starting from an ungauged one. Finally, we analyze general black hole solutions in gauged models, providing an explicit example for the $\,\mathcal{N}=2$, $\,D=4$ case. A brief review on special geometry is also provided, with explicit results and relations for supersymmetric black hole solutions. ","hep-th"
"2005.00435","Protein-protein modelling using cryo-EM restraints","  The recent improvements in cryo-electron microscopy (cryo-EM) in the past few years are now allowing to observe molecular complexes at atomic resolution. As a consequence, numerous structures derived from cryo-EM are now available in the Protein Data Bank. However, if for some complexes atomic resolution is reached, this is not true for all. This is also the case in cryo-electron tomography where the achievable resolution is still limited. Furthermore the resolution in a cryo-EM map is not a constant, with often outer regions being of lower resolution, possibly linked to conformational variability. Although those low to medium resolution EM maps (or regions thereof) cannot directly provide atomic structure of large molecular complexes, they provide valuable information to model the individual components and their assembly into them. Most approaches for this kind of modelling are performing rigid fitting of the individual components into the EM density map. While this would appear an obvious option, they ignore key aspects of molecular recognition, the energetics and flexibility of the interfaces. Moreover, these often restricts the modelling to a unique source of data, the EM density map. In this chapter, we describe a protocol where an EM map is used as restraint in HADDOCK to guide the modelling process. ","q-bio"
"1902.11148","Decay of the pseudoscalar glueball and its first excited state into   scalar and pseudoscalar mesons and their first excited states","  We expand the study of the pseudoscalar glueball and its first excited state by constructing an interaction Lagrangian which produces the two- and three-body decays of the pseudoscalar glueball, $J^{PC}=0^{-+}$, into the (pseudo)scalar and the excited (pseudo)scalar mesons as well as by constructing other two different chiral Lagrangians which describe the two- and three-body decays of the first excited pseudoscalar glueball, $J^{PC}=0^{*-+}$, into the (pseudo)scalar and the excited (pseudo)scalar mesons. We compute the decay channels for the ground state of a pseudoscalar glueball with a mass of $2.6$ GeV and for the first excited pseudoscalar glueball with a mass $3.7$ GeV, following predictions from Lattice QCD in the quenched approximation. These states and channels are within reach of PANDA experiment at the upcoming FAIR facility experiment and ongoing BESIII experiment. In our approach, the various branching ratios are a parameter-free prediction. ","hep-ph"
"2002.11870","A Structure-based Memory Maintenance Model for Neural Tracking of   Linguistic Structures","  It is recently demonstrated that cortical activity can track the time courses of phrases and sentences during speech listening. Here, we propose a plausible neural processing framework to explain this phenomenon. It is argued that the brain maintains the neural representation of a linguistic unit, i.e., a word or a phrase, in a processing buffer until the unit is integrated into a higher-level structure. After being integrated, the unit is removed from the buffer and becomes activated long-term memory. In this model, the duration each unit is maintained in the processing buffer depends on the linguistic structure of the speech input. It is shown that the number of items retained in the processing buffer follows the time courses of phrases and sentences, in line with neurophysiological data, whether the syntactic structure of a sentence is mentally parsed using a bottom-up or top-down predictive model. This model generates a range of testable predictions about the link between linguistic structures, their dynamic psychological representations and their neural underpinnings. ","q-bio"
"2008.04172","A single-cell mathematical model of SARS-CoV-2 induced pyroptosis and   the anti-inflammatory response to the drug tranilast","  Pyroptosis is an inflammatory mode of cell death that contributes to the cytokine storm associated with severe cases of coronavirus disease 2019 (COVID-19). Central to pyroptosis induced by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is the formation of the NLRP3 inflammasome. Inflammasome formation, and by extension pyroptosis, may be inhibited by certain anti-inflammatory drugs. One such drug, tranilast, is currently being evaluated as a COVID-19 treatment target in a clinical trial. In this study, we present a single-cell mathematical model that captures the formation of the NLRP3 inflammasome, pyroptotic cell death and drug-responses to tranilast. The model is formulated in terms of a system of ordinary differential equations (ODEs) that describe the dynamics of proteins involved in pyroptosis. The model demonstrates that tranilast delays the formation of the NLRP3 inflammasome, and thus may alter the mode of cell death from inflammatory (pyroptosis) to non-inflammatory (e.g., apoptosis). ","q-bio"
"1907.12330","Conditioning Convolutional Segmentation Architectures with Non-Imaging   Data","  We compare two conditioning mechanisms based on concatenation and feature-wise modulation to integrate non-imaging information into convolutional neural networks for segmentation of anatomical structures. As a proof-of-concept we provide the distribution of class labels obtained from ground truth masks to ensure strong correlation between the conditioning data and the segmentation maps. We evaluate the methods on the ACDC dataset, and show that conditioning with non-imaging data improves performance of the segmentation networks. We observed conditioning the U-Net architectures was challenging, where no method gave significant improvement. However, the same architecture without skip connections outperforms the baseline with feature-wise modulation, and the relative performance increases as the training size decreases. ","eess"
"1811.00638","Simple Sensitivity Analysis for Differential Measurement Error","  Simple sensitivity analysis results are given for differential measurement error of either the exposure or the outcome. In the case of differential measurement error of the outcome it is shown that the true effect of the exposure on the outcome on the risk ratio scale must be at least as large as the observed association between the exposure and the mis-measured outcome divided by the maximum strength of differential measurement error, assessed as the risk ratio of the controlled direct effect of the exposure on mis-measured outcome not through the true outcome. In the case of differential measurement error of the exposure it is shown that the true effect on the risk ratio scale of the exposure on the outcome must be at least as large as the observed association between the mis-measured exposure measurement and the outcome divided by the maximum strength of differential measurement error, assessed as the risk ratio of the effect of the outcome on mis-measured exposure measurement conditional on the true exposure. The results can also be immediately used to indicate the minimum strength of differential measurement error that would be needed to explain away an observed association between an exposure measurement and an outcome measurement. ","stat"
"1910.05830","SPARKS II.: Complex organic molecules in accretion shocks around a hot   core precursor","  Classical hot cores are rich in molecular emission, and they show a high abundance of complex organic molecules (COMs). The emergence of molecular complexity is poorly constrained in the early evolution of hot cores. Using the Atacama Large Millimeter Array we put observational constraints on the physical location of COMs in a high-mass protostellar envelope associated with the G328.2551-0.5321 clump. The protostar is single down to ~400au scales and we resolve the emission region of COMs. Using thermodynamic equilibrium modelling of the available 7.5 GHz bandwidth around ~345 GHz, we detect emission from 10 COMs, and identify a line of deuterated water (HDO). The most extended emission originates from methanol, methyl formate and formamide. Together with HDO, these molecules are found to be associated with both the accretion shocks and the inner envelope, for which we estimate a moderate temperature of $T_{\rm kin}\sim$110 K. Our findings reveal a significant difference in the distribution of COMs. O-bearing COMs, such as ethanol, acetone, and ethylene glycol are almost exclusively found and show a higher abundance towards the accretion shocks with $T_{\rm kin}\sim$180 K. Whereas N-bearing COMs with a CN group, such as vinyl and ethyl cyanide peak on the central position, thus the protostar and the accretion disk. This is the first observational evidence for a large column density of COMs seen towards accretion shocks at the centrifugal barrier at the inner envelope. Since the molecular composition is dominated by that of the accretion shocks and the radiatively heated hot inner region is very compact, we propose this source to be a precursor to a classical, radiatively heated hot core. ","astro-ph"
"2006.06653","All Tree-Level Correlators for M-theory on $AdS_7 \times S^4$","  We present a constructive derivation of all four-point tree-level holographic correlators for eleven dimensional supergravity on $AdS_7 \times S^4$. These correlators correspond to four-point functions of arbitrary one-half BPS operators in the six-dimensional $(2,0)$ theory at large central charge. The crucial observation is that the polar part of the correlators in Mellin space is fully captured by a drastically simpler Maximally R-symmetry Violating (MRV) amplitude, while the contact part is fully fixed by superconformal Ward identities and the flat space limit. ","hep-th"
"1902.00463","Recursion Relations for Anomalous Dimensions in the 6d $(2,0)$ Theory","  We derive recursion relations for the anomalous dimensions of double-trace operators occurring in the conformal block expansion of four-point stress tensor correlators in the 6d $(2,0)$ theory, which encode higher-derivative corrections to supergravity in $AdS_7 \times S^4$ arising from M-theory. As a warm-up, we derive analogous recursion relations for four-point functions of scalar operators in a toy non-supersymmetric 6d conformal field theory. ","hep-th"
"1906.01402","Forward scattering amplitudes of pp and p\=p with crossing symmetry and   scaling properties","  We analyse the pp and p\=p elastic scattering amplitudes using the data of several CERN and FERMILAB experiments, revisiting ideas proposed by Andr\'e Martin based on analytic continuation and crossing symmetry. Introducing a new form for the scaling function together with the analytical forms from COMPETE at $t=0$ we show that the data are consistent with the crossing symmetry of the scattering amplitudes from $\sqrt{s}= $ 23 GeV to 13 TeV for $-t\leq 0.2$ GeV$^{2}$. Analiticity and crossing symmetry automatically satisfy the dispersion relations and their derivatives. The real part reproduces the zero predicted by Martin, which is crucial to describe with precision the differential cross section in the forward range at high energies. Since the free parameters of the model are energy independent, the analytical form of the amplitude allows predictions for intermediate and higher energies. ","hep-ph"
"1910.07017","Bayesian variable selection in hierarchical difference-in-differences   models","  A popular method for estimating a causal treatment effect with observational data is the difference-in-differences (DiD) model. In this work, we consider an extension of the classical DiD setting to the hierarchical context in which data cannot be matched at the most granular level (e.g., individual-level differences are unobservable). We propose a Bayesian hierarchical difference-in-differences (HDiD) model which estimates the treatment effect by regressing the treatment on a latent variable representing the mean change in group-level outcome. We present theoretical and empirical results showing that an HDiD model that fails to adjust for a particular class of confounding variables, or confounding with the baseline (pre-treatment) outcomes, biases the treatment effect estimate. We propose and implement various approaches to perform variable selection using a structured Bayesian spike-and-slab model in the HDiD context. Our proposed methods leverage the temporal structure within the DiD context to select those covariates that lead to unbiased and efficient estimation of the causal treatment effect. We evaluate the methods' properties through theoretical results and simulation, and we use them to assess the impact of primary care redesign of clinics in Minnesota on the management of diabetes outcomes from 2008 to 2017. ","stat"
"1909.04043","Massive spheroids can form in single minor mergers","  Understanding how rotationally-supported discs transform into dispersion-dominated spheroids is central to our comprehension of galaxy evolution. Morphological transformation is largely merger-driven. While major mergers can efficiently create spheroids, recent work has highlighted the significant role of other processes, like minor mergers, in driving morphological change. Given their rich merger histories, spheroids typically exhibit large fractions of `ex-situ' stellar mass, i.e. mass that is accreted, via mergers, from external objects. This is particularly true for the most massive galaxies, whose stellar masses typically cannot be attained without a large number of mergers. Here, we explore an unusual population of extremely massive (M* > 10^11 MSun) spheroids, in the Horizon-AGN simulation, which exhibit anomalously low ex-situ mass fractions, indicating that they form without recourse to significant merging. These systems form in a single minor-merger event (with typical merger mass ratios of 0.11 - 0.33), with a specific orbital configuration, where the satellite orbit is virtually co-planar with the disc of the massive galaxy. The merger triggers a catastrophic change in morphology, over only a few hundred Myrs, coupled with strong in-situ star formation. While this channel produces a minority (~5 per cent) of such galaxies, our study demonstrates that the formation of at least some of the most massive spheroids need not involve major mergers -- or any significant merging at all -- contrary to what is classically believed. ","astro-ph"
"2004.07342","Mathematical modeling of blood flow through arterial bifurcation","  The blood vascular system consists of blood vessels such as arteries, arterioles, capillaries and veins that convey blood throughout the body. The pressure difference which exists between the ends of the vessels provides the living force required to the flow of blood. In this study, we have used a model that is appropriate for use with blood flow simulation applications. We study the effect of decomposition of plaques and or tumour cells on the velocity profile, pressure of the incompressible, Newtonian fluid. We consider two different cases; vessels with bifurcation and without bifurcations and we display all the results through using Commercial software COMSOL Multiphysics 5.2. ","q-bio"
"1710.11031","E11 and the non-linear dual graviton","  The non-linear duality relation between the gravity and dual gravity fields are found in E theory by carrying out $E_{11}$ variations of previously found duality relations. We also find the dual graviton equation of motion up to the addition of some very specific terms whose coefficients are not determined. Using the calculations in this paper this ambiguity was resolved in reference [15] where the full non-linear dual gravity equation was found. As a result the equations of motion in E theory have now been found at the full non-linear level up to, and including, level three, which contains the dual graviton field. When truncated to contain fields at levels three and less, and the spacetime is restricted to be the familiar eleven dimensional space time, the equations are equivalent to those of eleven dimensional supergravity. ","hep-th"
"2002.09273","Success-Odds: An improved Win-Ratio","  Multiple and combined endpoints involving also non-normal outcomes appear in many clinical trials in various areas in medicine. In some cases, the outcome can be observed only on an ordinal or dichotomous scale. Then the success of two therapies is assessed by comparing the outcome of two randomly selected patients from the two therapy groups by 'better', 'equal' or 'worse'. These outcomes can be described by the probabilities $p^-=P(X<Y)$, $p_0=P(X=Y)$, and $p^+ =P(X~>~Y)$. For a clinician, however, these quantities are less intuitive. Therefore, Noether (1987) introduced the quantity $\lambda=p^+ / p^-$ assuming continuous distributions. The same quantity was used by Pocock et al. (2012) and by Wang and Pocock (2016) also for general non-normal outcomes and has been called 'win-ratio' $\lambda_{WR}$. Unlike Noether (1987), Wang and Pocock (2016) explicitly allowed for ties in the data. It is the aim of this manuscript to investigate the properties of $\lambda_{WR}$ in case of ties. It turns out that it has the strange property of becoming larger if the data are observed less accurately, i.e. include more ties. Thus, in case of ties, the win-ratio looses its appealing property to describe and quantify an intuitive and well interpretable treatment effect. Therefore, a slight modification of $\lambda_{WR} = \theta / (1-\theta)$ is suggested, namely the so-called 'success-odds' where $\theta=p^+ + \frac12 p_0$ is called a success of a therapy if $\theta>\frac12$. In the case of no ties, $\lambda_{SO}$ is identical to $\lambda_{WR}$. A test for the hypothesis $\lambda_{SO}=1$ and range preserving confidence intervals for $\lambda_{SO}$ are derived. By two counterexamples it is demonstrated that generalizations of both the win-ratio and the success-odds to more than two treatments or to stratified designs are not straightforward and need more detailed considerations. ","stat"
"2004.08854","Planar Bichromatic Bottleneck Spanning Trees","  Given a set $P$ of $n$ red and blue points in the plane, a \emph{planar bichromatic spanning tree} of $P$ is a spanning tree of $P$, such that each edge connects between a red and a blue point, and no two edges intersect. In the bottleneck planar bichromatic spanning tree problem, the goal is to find a planar bichromatic spanning tree $T$, such that the length of the longest edge in $T$ is minimized. In this paper, we show that this problem is NP-hard for points in general position. Moreover, we present a polynomial-time $(8\sqrt{2})$-approximation algorithm, by showing that any bichromatic spanning tree of bottleneck $\lambda$ can be converted to a planar bichromatic spanning tree of bottleneck at most $8\sqrt{2}\lambda$. ","cs"
"1903.00997","Gaussian fluctuations for the directed polymer partition function for   $d\geq 3$ and in the whole $L^2$-region","  We consider the discrete directed polymer model with i.i.d. environment and we study the fluctuations of the tail $n^{(d-2)/4}(W_\infty - W_n)$ of the normalized partition function. It was proven by Comets and Liu, that for sufficiently high temperature, the fluctuations converge in distribution towards the product of the limiting partition function and an independent Gaussian random variable. We extend the result to the whole $L^2$-region, which is predicted to be the maximal high-temperature region where the Gaussian fluctuations should occur under the considered scaling. To do so, we manage to avoid the heavy 4th-moment computation and instead rely on the local limit theorem for polymers and homogenization. ","math"
"1812.09469","Eigenvalue instantons in the spectral form factor of random matrix model","  We study the late time plateau behavior of the spectral form factor in the Gaussian Unitary Ensemble (GUE) random matrix model. The time derivative of the spectral form factor in the plateau regime is not strictly zero, but non-zero due to a non-perturbative correction in the $1/N$ expansion. We argue that such a non-perturbative correction comes from the eigenvalue instanton of random matrix model and we explicitly compute the instanton correction as a function of time. ","hep-th"
"1901.08038","Taming boundary condition changing operator anomalies with the tachyon   vacuum","  Motivated by the appearance of associativity anomalies in the context of superstring field theory, we give a generalized solution built from boundary condition changing operators which can be associated to a generic tachyon vacuum in the $KBc$ subalgebra of the Okawa form. We articulate sufficient conditions on the choice of tachyon vacuum to ensure that ambiguous products do not appear in the equations of motion. ","hep-th"
"1807.05347","Smart Grid Monitoring Using Power Line Modems: Anomaly Detection and   Localization","  The main subject of this paper is the sensing of network anomalies that span from harmless impedance changes at some network termination to more or less pronounced electrical faults, considering also cable degradation over time. In this paper, we present how to harvest information about such anomalies in distribution grids using high frequency signals spanning from few kHz to several MHz. Given the wide bandwidth considered, we rely on power line modems as network sensors. We firstly discuss the front-end architectures needed to perform the measurement and then introduce two algorithms to detect, classify and locate the different kinds of network anomalies listed above. Simulation results are finally presented. They validate the concept of sensing in smart grids using power line modems and show the efficiency of the proposed algorithms. ","eess"
"2002.08191","Involutions of alternating links","  Let $L$ be an alternating prime non-split link in $S^3$. We use the category of flypes between reduced alternating diagrams for $L$ to classify involutions on $L$. As consequences, we show that the quotient of an alternating periodic link is alternating, and that all freely 2-periodic alternating links have an even number of components. ","math"
"1907.04165","Global Cardinality Constraints Make Approximating Some Max-2-CSPs Harder","  Assuming the Unique Games Conjecture, we show that existing approximation algorithms for some Boolean Max-2-CSPs with cardinality constraints are optimal. In particular, we prove that Max-Cut with cardinality constraints is UG-hard to approximate within \approx 0.858, and that Max-2-Sat with cardinality constraints is UG-hard to approximate within \approx 0.929. In both cases, the previous best hardness results were the same as the hardness of the corresponding unconstrained Max-2-CSP (\approx 0.878 for Max-Cut, and \approx 0.940 for Max-2-Sat). The hardness obtained for Max-2-Sat applies to monotone Max-2-Sat instances, meaning that we also obtain tight inapproximability for the Max-k-Vertex-Cover problem. ","cs"
"1905.10067","A note on higher spin symmetry in the IIB matrix model with the operator   interpretation","  We study the IIB matrix model in an interpretation where the matrices are differential operators defined on curved spacetimes. In this interpretation, coefficients of higher derivative operators formally appear to be massless higher spin fields. In this paper, we examine whether the unitary symmetry of the matrices includes appropriate higher spin gauge symmetries. We focus on fields that are bosonic and relatively simple in the viewpoint of the representation of Lorentz group. We find that the additional auxiliary fields need to be introduced in order to see the higher spin gauge symmetries explicitly. At the same time, we point out that a part of these extra fields are gauged-away, and the rest of part can be written in terms of a totally symmetric tensor field. The transformation to remove its longitudinal components exists as well. As a result, we observe that the independent physical DoF are the transverse components of that symmetric field, and that the theory describes the corresponding higher spin field. We also find that the field is not the Fronsdal field, rather the generalization of curvature. ","hep-th"
"1812.09592","Multicarrier Chirp-Division Multiplexing for Wireless Communications","  We propose a multicarrier chirp-division multiplexing (MCDM) system in which orthogonal chirp waveforms are utilized as frequency subcarriers. Orthogonal characteristics of chirp subcarriers are analyzed in respect to cross-correlation coefficients among subcarriers. Moreover, orthogonal chirp transform (OCT) is developed to implement MCDM systems. In addition, we design a low complexity receiver, including packet synchronization, carrier frequency offset compensation, channel estimation, and symbol detection. Proposed MCDM systems have both advantages of chirp waveforms and multicarrier architectures. Computational complexity of our proposed detector is discussed in detail. The bit-error-rate (BER) performance of the MCDM system is evaluated in simulations and indoor radio frequency (RF) experiments. We have demonstrated effectiveness of MCDM systems both in simulation and experimental results, comparing to orthogonal frequency division multiplexing (OFDM) systems. Moreover, MCDM can be further applied to higher order modulations for enabling higher data rates for RF wireless communications. ","eess"
"1902.00540","New insight into EM radiation from spinning dust and its influence on   the Cosmic Microwave Background","  Dust is ubiquitous in the Universe and its influence on the observed Electromagnetic (EM) radiation needs to be correctly addressed. In recent years it became clear that scattering of EM radiation from interstellar dust grains could change the local properties of the observed Cosmic Microwave Background (CMB) radiation. Here we consider the relevant processes of emission and scattering of EM radiation from spinning dust particles, and discuss their possible influence on the CMB. In particular, we show that scattered radiation can establish a correlation between different spectral components of galactic dipolar emission. This could explain the observed correlation between the CMB and the 100-micron thermal emission form interstellar dust. Another important property of CMB is related with its polarisation anisotropies, and the observation of a cosmological B-mode. We show that scattering of CMB radiation from dust grains in the presence of a static magnetic field could indeed create a B-mode spectral component, which is very similar to that due to primordial gravitational waves. This can be described by a kind of Cotton-Mutton effect on the CMB radiation. ","astro-ph"
"1911.06377","Cooling to absolute zero: The unattainability principle","  The unattainability principle (UP) is an operational formulation of the third law of thermodynamics stating the impossibility to bring a system to its ground state in finite time. In this work, several recent derivations of the UP are presented, with a focus on the set of assumptions and allowed sets of operations under which the UP can be formally derived. First, we discuss derivations allowing for arbitrary unitary evolutions as the set of operations. There the aim is to provide fundamental bounds on the minimal achievable temperature, which are applicable with almost full generality. These bounds show that perfect cooling requires an infinite amount of a given resource -- worst-case work, heat bath's size and dimensionality or non-equilibrium states among others -- which can in turn be argued to imply that an infinite amount of time is required to access those resources. Secondly, we present derivations within a less general set of operations conceived to capture a broad class of currently available experimental settings. In particular, the UP is here derived within a model of linear and driven quantum refrigerators consisting on a network of harmonic oscillators coupled to several reservoirs at different temperatures. ","quant-ph"
"2002.06025","Joint Optimization of Waveform Covariance Matrix and Antenna Selection   for MIMO Radar With Application to Aerial Drones","  Controlling the radar beam-pattern by optimizing the transmit covariance matrix is a well-established approach for performance enhancement in multiple-input-multiple-output (MIMO) radars. In this paper, we investigate the joint optimization of the waveform covariance matrix and the antenna position vector for a MIMO radar system to approximate a given transmit beam-pattern, as well as to minimize the cross-correlation of the received waveforms reflected back from the targets. We formulate this design task as a non-convex optimization problem and then propose a cyclic optimization approach to efficiently approximate its solution. We further propose a local binary search algorithm in order to efficiently design the corresponding antenna positions. We show that the proposed method can be extended to the more general case of approximating the given beam-pattern using a minimal number of antennas as well as optimizing their positions. Our numerical investigations demonstrate a great performance both in terms of accuracy and computational complexity, making the proposed framework a good candidate for usage in real-time radar waveform processing applications such as MIMO radar transmit beamforming for aerial drones that are in motion. ","eess"
"2001.10731","Properties of the simplest inhomogeneous and homogeneous   Tree-Tensor-States for Long-Ranged Quantum Spin Chains with or without   disorder","  The simplest Tree-Tensor-States (TTS) respecting the Parity and the Time-Reversal symmetries are studied in order to describe the ground states of Long-Ranged Quantum Spin Chains with or without disorder. Explicit formulas are given for the one-point and two-point reduced density matrices that allow to compute any one-spin and two-spin observable. For Hamiltonians containing only one-body and two-body contributions, the energy of the TTS can be then evaluated and minimized in order to obtain the optimal parameters of the TTS. This variational optimization of the TTS parameters is compared with the traditional block-spin renormalization procedure based on the diagonalization of some intra-block renormalized Hamiltonian. ","cond-mat"
"2006.08384","Equivalence of weak and viscosity solutions in fractional   non-homogeneous problems","  We establish the equivalence between the notions of weak and viscosity solutions for non-homogeneous equations whose main operator is the fractional p-Laplacian and the lower order term depends on $x$, $u$ and $D_s^p u$, being the last one a type of fractional derivative. ","math"
"2002.10950","TRAPPIST-1 Habitable Atmosphere Intercomparison (THAI). Motivations and   protocol version 1.0","  Upcoming telescopes such as the James Webb Space Telescope (JWST), or the Extremely Large Telescope (ELTs), may soon be able to characterize, through transmission, emission or reflection spectroscopy, the atmospheres of rocky exoplanets orbiting nearby M dwarfs. One of the most promising candidates is the late M dwarf system TRAPPIST-1 which has seven known transiting planets for which Transit Timing Variation (TTV) measurements suggest that they are terrestrial in nature, with a possible enrichment in volatiles. Among these seven planets, TRAPPIST-1e seems to be the most promising candidate to have habitable surface conditions, receiving ~66 % of the Earth's incident radiation, and thus needing only modest greenhouse gas inventories to raise surface temperatures to allow surface liquid water to exist. TRAPPIST-1e is therefore one of the prime targets for JWST atmospheric characterization. In this context, the modeling of its potential atmosphere is an essential step prior to observation. Global Climate Models (GCMs) offer the most detailed way to simulate planetary atmospheres. However, intrinsic differences exist between GCMs which can lead to different climate prediction and thus observability of gas and/or cloud features in transmission and thermal emission spectra. Such differences should preferably be known prior to observations. In this paper we present a protocol to inter-compare planetary GCMs. Four testing cases are considered for TRAPPIST-1e but the methodology is applicable to other rocky exoplanets in the Habitable Zone. The four test cases included two land planets composed with a modern Earth and pure CO2 atmospheres, respectively, and two aqua planets with the same atmospheric compositions. Currently, there are four participating models (LMDG, ROCKE-3D, ExoCAM, UM), however this protocol is intended to let other teams participate as well. ","astro-ph"
"1809.06318","Orbit Space Curvature as a Source of Mass in Quantum Gauge Theory","  It has long been realized that the natural orbit space for non-abelian Yang-Mills dynamics is a positively curved (infinite dimensional) Riemannian manifold. Expanding on this result I.M. Singer proposed that strict positivity of the corresponding Ricci tensor (computable through zeta function regularization) could play a fundamental role in establishing that the associated Schroedinger operator admits a spectral gap. His argument was based on representing the (regularized) kinetic term in the Schroedinger operator as a Laplace-Beltrami operator on this positively curved orbit space. We revisit Singer's proposal and show how, when the contribution of the Yang-Mills potential energy is taken into account, the role of the original orbit space Ricci tensor is instead played by a Bakry-Emery Ricci tensor computable from the ground state wave functional of the quantum theory. We next review our ongoing Euclidean-signature-semi-classical program for deriving asymptotic expansions for such wave functionals and discuss how, by keeping the dynamical nonlinearities and non-abelian gauge invariances intact at each level of the analysis, our approach surpasses that of conventional perturbation theory for the generation of approximate wave functionals. Though our main focus is on Yang-Mills theory we derive the orbit space curvature for scalar electrodynamics and prove that, whereas the Maxwell factor remains flat, the interaction naturally induces positive curvature in the (charged) scalar factor of the resulting orbit space. This has led us to the conjecture that such orbit space curvature effects could furnish a source of mass for ordinary Klein-Gordon type fields provided the latter are (minimally) coupled to gauge fields, even in the abelian case. Finally we discuss the potential applicability of our Euclidean-signature program to the Wheeler-DeWitt equation of canonical quantum gravity. ","hep-th"
"1807.02676","The mixed quantum Rabi model","  The analytical exact solutions to the mixed quantum Rabi model (QRM) including both one- and two-photon terms are found by using Bogoliubov operators. Transcendental functions in terms of $4 \times 4$ determinants responsible for the exact solutions are derived. These so-called $G$-functions with pole structures can be reduced to the previous ones in the unmixed QRMs. The zeros of $G$-functions reproduce completely the regular spectra. The exceptional eigenvalues can also be obtained by another transcendental function. From the pole structure, we can derive two energy limits when the two-photon coupling strength tends to the collapse point. All energy levels only collapse to the lower one, which diverges negatively. The level crossings in the unmixed QRMs are relaxed to avoided crossings in the present mixed QRM due to absence of parity symmetry. In the weak two-photon coupling regime, the mixed QRM is equivalent to an one-photon QRM with an effective positive bias, suppressed photon frequency and enhanced one-photon coupling, which may pave a highly efficient and economic way to access the deep-strong one-photon coupling regime. ","quant-ph"
"1811.05871","Excitation of E1-forbidden Atomic Transitions with Electric, Magnetic or   Mixed Multipolarity in Light Fields Carrying Orbital and Spin Angular   Momentum","  Photons carrying a well-defined orbital angular momentum have been proven to modify spectroscopic selection rules in atomic matter. Excitation profiles of electric quadrupole transitions have been measured with single trapped $^{40}$Ca$^+$ ions for varying polarizations. We further develop the photo-absorption formalism to study the case of arbitrary alignment of the beam's optical axis with respect to the ion's quantization axis and mixed multipolarity. Thus, predictions for M1-dominated $^{40}Ar^{13+}$, E3-driven $^{171}Yb^+$ and $^{172}Yb^+$, and B-like $^{20}Ne^{5+}$ are presented. The latter case displays novel effects, coming from the presence of a strong photon -- magnetic dipole coupling. ","quant-ph"
"2007.09229","Multiplicity-free key polynomials","  The key polynomials, defined by A. Lascoux-M.-P. Sch\""utzenberger, are characters for the Demazure modules of type A. We classify multiplicity-free key polynomials. The proof uses two combinatorial models for key polynomials. The first is due to A. Kohnert. The second is by S. Assaf-D. Searles, in terms of quasi-key polynomials. Our argument proves a sufficient condition for a quasi-key polynomial to be multiplicity-free. ","math"
"2001.08230","Landau Quasiparticles in Weak Power-Law Liquids","  The failure of Landau-Fermi liquid theory is often considered a telltale sign of universal, scale-invariant behavior in the emergent field theory of interacting fermions. Nevertheless, there exist borderline cases where weak scale invariance coupled with particle-hole asymmetry can coexist with the Landau quasiparticle paradigm. In this letter, I show explicitly that a Landau-Fermi liquid can exist for weak power-law scaling of the retarded Green's function. Such an exotic variant of the traditional Fermi liquid, although exhibiting a finite quasiparticle weight and large quasiparticle lifetime, is shown to always be incompatible with Luttinger's theorem for any non-trivial scaling. This result yields evidence for a Fermi liquid-like ground state in the high-field, underdoped pseudogap phase of the high-temperature cuprate superconductors. ","cond-mat"
"1811.11720","A GPU compatible quasi-Monte Carlo integrator interfaced to pySecDec","  The purely numerical evaluation of multi-loop integrals and amplitudes can be a viable alternative to analytic approaches, in particular in the presence of several mass scales, provided sufficient accuracy can be achieved in an acceptable amount of time. For many multi-loop integrals, the fraction of time required to perform the numerical integration is significant and it is therefore beneficial to have efficient and well-implemented numerical integration methods. With this goal in mind, we present a new stand-alone integrator based on the use of (quasi-Monte Carlo) rank-1 shifted lattice rules. For integrals with high variance we also implement a variance reduction algorithm based on fitting a smooth function to the inverse cumulative distribution function of the integrand dimension-by-dimension. Additionally, the new integrator is interfaced to pySecDec to allow the straightforward evaluation of multi-loop integrals and dimensionally regulated parameter integrals. In order to make use of recent advances in parallel computing hardware, our integrator can be used both on CPUs and CUDA compatible GPUs where available. ","hep-ph"
"2002.05311","Probing the top-Higgs boson FCNC couplings via the $h\to \gamma\gamma$   channel at the HE-LHC and FCC-hh","  We investigate the sensitivity of future searches for the top-Higgs boson Flavour Changing Neutral Current (FCNC) couplings $tqh$~($q= u, c$) at the proposed High Energy Large Hadron Collider~(HE-LHC) and Future Circular Collider in hadron-hadron mode (FCC-hh). We perform a full simulation for two processes in the $h\to \gamma\gamma$ decay channel (where $h$ is the discovered Higgs state): single top quark FCNC production in association with the Higgs boson (plus a jet) and top quark pair production with FCNC decays $t\to qh$. All the relevant backgrounds are considered in a cut based analysis to obtain the limits on the Branching Ratios (BRs) of $t\to uh$ and $t\to ch$. It is shown that, at the HE-LHC with an integrated luminosity of 15 ab$^{-1}$ and at the FCC-hh with an integrated luminosity of 30 ab$^{-1}$, {{the BR($t\to uh$) (BR($t\to ch$)) can be probed, respectively, to $7.0~(8.5)\times 10^{-5}$ and $2.3~(3.0) \times 10^{-5}$ at the 95\% Confidence Level (CL) (assuming a 10\% systematic uncertainty on the background), which is almost two orders of magnitude better than the current 13 TeV LHC experimental results. ","hep-ph"
"1805.03220","Leibniz-Chern-Simons Theory and Phases of Exceptional Field Theory","  We discuss a generalization of Chern-Simons theory in three dimensions based on Leibniz (or Loday) algebras, which are generalizations of Lie algebras. Special cases of such theories appear in gauged supergravity, where the Leibniz algebra is defined in terms of the global (Lie) symmetry algebra of the ungauged limit and an embedding tensor. We show that the Leibniz algebra of generalized diffeomorphisms in exceptional field theory can similarly be obtained from a Lie algebra that describes the enhanced symmetry of an `ungauged phase' of the theory. Moreover, we show that a `topological phase' of ${\rm E}_{8(8)}$ exceptional field theory can be interpreted as a Chern-Simons theory for an algebra unifying the three-dimensional Poincar\'e algebra and the Leibniz algebra of ${\rm E}_{8(8)}$ generalized diffeomorphisms. ","hep-th"
"1707.02601","MUBs and SIC-POVMs of a spin-1 system from the Majorana approach","  In the Majorana or stellar representation of quantum states, an arbitrary (pure) state of a spin-1 system is represented by a pair of points on the unit sphere or, equivalently, by a pair of unit vectors. This paper presents an expression for the squared modulus of the inner product of two spin-1 states in terms of their Majorana vectors and uses it to give a geometrical construction of the MUBs and SIC-POVMs of a spin-1 system. The results are not new and duplicate those obtained earlier by other methods, but the Majorana approach nevertheless illuminates them from an unusual point of view. In particular, it reveals the MUBs and SICs as symmetrical collections of vectors in ordinary three-dimensional space, rather than as rays in a projective Hilbert space. While it does not appear feasible to extend this treatment to higher spin systems, the spin-1 case exhibits sufficient subtlety and complexity to be worth spelling out for its pedagogical and historical interest. ","quant-ph"
"2003.08621","Recasting direct detection limits within micrOMEGAs and implication for   non-standard Dark Matter scenarios","  Direct detection experiments obtain 90% upper limits on the elastic scattering cross sections of dark matter with nucleons assuming point-like interactions and standard astrophysical and cosmological parameters. In this paper we provide a recasting of the limits from XENON1T, PICO-60, CRESST-III and DarkSide-50 and include them in micrOMEGAs. The code can then be used to directly impose constraints from these experiments on generic dark matter models under different assumptions about the DM velocity distribution or on the nucleus form factors. Moreover new limits on the elastic scattering cross sections can be obtained in the presence of a light t-channel mediator or of millicharged particles. ","hep-ph"
"1903.06062","In-plane anisotropic faceting of ultralarge and thin single-crystalline   colloidal SnS nanosheets","  The colloidal synthesis of large thin two-dimensional (2D) nanosheets is fascinating but challenging, since the growth along the lateral and vertical dimensions need to be controlled independently. In-plane anisotropy in 2D nanosheets is attracting more attention as well. We present a new synthesis for large colloidal single-crystalline SnS nanosheets with the thicknesses down to 7 nm and lateral sizes up to 8 um. The synthesis uses trioctylphosphine-S (TOP-S) as sulfur source and oleic acid (with or without TOP) as ligands. Upon adjusting the capping ligand amount, the growth direction can be switched between anisotropic directions (armchair and zigzag) and isotropic directions (""ladder"" directions), leading to an edge-morphology anisotropy. This is the first report on solution-phase synthesis of large thin SnS NSs with tunable edge faceting. Furthermore, electronic transport measurements show strong dependency on the crystallographic directions confirming structural anisotropy. ","cond-mat"
"1905.05075","Intelligent Physical Layer Security Approach for V2X Communication","  Intelligent transportation systems (ITS) with advanced sensing and computing technologies are expected to support a whole new set of services including pedestrian and vehicular safety, internet access for vehicles, and eventually, driverless cars. Wireless communication is a major driving factor behind ITS, enabling reliable communication between vehicles, infrastructure, pedestrians and network, generally referred to as vehicle to everything (V2X) communication. However, the broadcast nature of wireless communication renders it prone to jamming, eavesdropping and spoofing attacks which can adversely affect ITS. Keeping in view this issue, we suggest the use of an intelligent security framework for V2X communication security, referred to as intelligent V2X security (IV2XS), to provide a reliable and robust solution capable of adapting to different conditions, scenarios and user requirements. We also identify the conditions that impact the security and describe the open challenges in achieving a realistic IV2XS system. ","eess"
"2004.00441","Galactic halo size in the light of recent AMS-02 data","  The vertical diffusive halo size of the Galaxy, $L$, is a key parameter for dark matter indirect searches. It can be better determined thanks to recent AMS-02 data. We set constraints on $L$ from Be/B and $^{10}$Be/Be data, and we performed a consistency check with positron data. We detail the dependence of Be/B and $^{10}$Be/Be on $L$ and forecast on which energy range better data would be helpful for future $L$ improvements. We used USINE v3.5 for the propagation of nuclei, and $e^+$ were calculated with the pinching method of Boudaud et al. (2017). The current AMS-02 Be/B ($\sim3\%$ precision) and ACE-CRIS $^{10}$Be/Be ($\sim 10\%$ precision) data bring similar and consistent constraints on $L$. The AMS-02 Be/B data alone constrain $L=5^{+3}_{-2}$~kpc at a 68\% confidence level (spanning different benchmark transport configurations), a range for which most models do not overproduce positrons. Future experiments need to deliver percent-level accuracy on $^{10}$Be/$^9$Be anywhere below 10 GV to further constrain $L$. Forthcoming AMS-02, HELIX, and PAMELA $^{10}$Be/$^9$Be results will further test and possibly tighten the limits derived here. Elemental ratios involving radioactive species with different lifetimes (e.g. Al/Mg and Cl/Ar) are also awaited to provide complementary and robuster constraints. ","astro-ph"
"2005.06858","Single-atom heat engine as a sensitive thermal probe","  We propose employing a quantum heat engine as a sensitive probe for thermal baths. In particular, we study a single-atom Otto engine operating in an open thermodynamic cycle. Owing to its cyclic nature, the engine is capable of translating small temperature differences between two baths into a macroscopic oscillation in a flywheel. We present analytical and numerical modeling of the quantum dynamics of the engine and estimate it to be capable of detecting temperature differences as small as 2 $\mu$K. This sensitivity can be further improved by utilizing quantum resources such as squeezing of the ion motion. The proposed scheme does not require quantum state initialization and is able to detect small temperature differences even at high base temperatures. ","quant-ph"
"1908.01614","Efficient accessible bounds to the classical capacity of quantum   channels","  We present a method to detect lower bounds to the classical capacity of quantum communication channels by means of few local measurements (i.e. without complete process tomography), reconstruction of sets of conditional probabilities, and classical optimisation. The method does not require any a priori information about the channel. We illustrate its performance for significant forms of noisy channels. ","quant-ph"
"1912.04187","On the local systolic optimality of Zoll contact forms","  We prove a normal form for contact forms close to a Zoll one and deduce that Zoll contact forms on any closed manifold are local maximizers of the systolic ratio. Corollaries of this result are: (i) sharp local systolic inequalities for Riemannian and Finsler metrics close to Zoll ones, (ii) the perturbative case of a conjecture of Viterbo on the symplectic capacity of convex bodies, (iii) a generalization of Gromov's non-squeezing theorem in the intermediate dimensions for symplectomorphisms that are close to linear ones. ","math"
"1704.02351","Channel Noise Effects on Neural Synchronization","  Synchronization in neural networks is strongly tied to the implementation of cognitive processes, but abnormal neuronal synchronization has been linked to a number of brain disorders such as epilepsy and schizophrenia. Here we examine the effects of channel noise on the synchronization of small Hodgkin-Huxley neuronal networks. The principal feature of a Hodgkin-Huxley neuron is the existence of protein channels that transition between open and closed states with voltage dependent rate constants. The Hodgkin-Huxley model assumes infinitely many channels, so fluctuations in the number of open channels do not affect the voltage. However, real neurons have finitely many channels which lead to fluctuations in the membrane voltage and modify the timing of the spikes, which may in turn lead to large changes in the degree of synchronization. We demonstrate that under mild conditions, neurons in the network reach a steady state synchronization level that depends only on the number of neurons in the network. The channel noise only affects the time it takes to reach the steady state synchronization level. ","q-bio"
"1702.07515","On the Dynamical Stability and Instability of Parker Problem","  We investigate a perturbation problem for the three-dimensional compressible isentropic viscous magnetohydrodynamic system with zero resistivity in the presence of a modified gravitational force in a vertical strip domain in which the velocity of the fluid is non-slip on the boundary, and focus on the stabilizing effect of the (equilibrium) magnetic field through the non-slip boundary condition. We show that there is a discriminant $\Xi$, depending on the known physical parameters, for the stability/instability of the perturbation problem. More precisely, if $\Xi<0$, then the perturbation problem is unstable, i.e., the Parker instability occurs, while if $\Xi>0$ and the initial perturbation satisfies some relations, then there exists a global (perturbation) solution which decays algebraically to zero in time, i.e., the Parker instability does not happen. The stability results in this paper reveal the stabilizing effect of the magnetic field through the non-slip boundary condition and the importance of boundary conditions upon the Parker instability, and demonstrate that a sufficiently strong magnetic field can prevent the Parker instability from occurring. In addition, based on the instability results, we further rigorously verify the Parker instability under Schwarzschild's or Tserkovnikov's instability conditions in the sense of Hadamard for a horizontally periodic domain. ","math"
"1902.00983","All Fermion Masses and Mixings in an Intersecting D-brane World","  It is shown that neutrino mixing angles which are consistent with current experimental observations may be naturally obtained in a Pati-Salam model constructed from intersecting D6 branes on a $T^6/(Z_2 \times Z_2)$ orientifold. The Dirac mass matrices in the model are naturally the same as those which are obtained by imposing a $\mathbf{\Delta(27)}$ flavor symmetry, which allows for near-tribimaximal mixing in the neutrino sector. In addition, it is possible to obtain the correct mass matrices for quarks and charged leptons, as well as nearly the correct CKM matrix. An RGE analysis of the neutrino mass parameters, including the seesaw mechanism assuming a specific form for the right-handed neutrino mass matrix is performed, and it is found that the neutrino mixing angles at the electroweak scale are $\theta_{12}=35.0^{\circ}$, $\theta_{23}=47.1^{\circ}$, and $\theta_{13}=8.27^{\circ}$. In addition,the neutrino mass-squared differences are found to be $\Delta m^2_{32} = 0.00252$ eV$^2$ and $\Delta m^2_{21} = 0.0000739$ eV$^2$ with $m_1=0.0146$ eV, $m_2=0.0170$ eV, and $m_3=0.0530$ eV. ","hep-ph"
"1807.06589","Nucleon parton distributions from hadronic quantum fluctuations","  A physical model is presented for the non-perturbative parton distributions in the nucleon. This is based on quantum fluctuations of the nucleon into baryon-meson pairs convoluted with Gaussian momentum distributions of partons in hadrons. The hadronic fluctuations, here developed in terms of hadronic chiral perturbation theory, occur with high probability and generate sea quarks as well as dynamical effects also for valence quarks and gluons. The resulting parton momentum distributions $f(x,Q_0^2)$ at low momentum transfers are evolved with conventional DGLAP equations from perturbative QCD to larger scales. This provides parton density functions $f(x,Q^2)$ for the gluon and all quark flavors with only five physics-motivated parameters. By tuning these parameters, experimental data on deep inelastic structure functions can be reproduced and interpreted. The contribution to sea quarks from hadronic fluctuations explains the observed asymmetry between $\bar{u}$ and $\bar{d}$ in the proton. The strange-quark sea is strongly suppressed at low $Q^2$, as observed. ","hep-ph"
"1910.13206","Semileptonic $B_c$ meson decays to S-wave charmonium states","  We study the semileptonic decays of $B_c$ meson to S-wave charmonium states in the framework of relativistic independent quark model based on an average flavor-independent confining potential $U(r)$ in the scalar-vector harmonic form $U(r)=\frac{1}{2}(1+\gamma^0)(ar^2+V_0)$, where ($a$, $V_0$) are the potential parameters.The form factors for $B_c^+\to \eta_c /\psi e^+\nu_e$ transitions are studied in the physical kinematic range. Our predicted branching ratios (BR) for transitions to ground state charmonia are found comparatively large $\sim $ $10^{-2}$, compared to those for transitions to radially excited 2S and 3S states. Like all other mpdel predictions, our predicted BR are obtained in the hierarchy: BR($B_c^+\to \eta_c /\psi (3S)$) $<$ BR($B_c^+\to \eta_c/ \psi (2S)$) $<$ BR($B_c^+\to \eta_c /\psi (1S)$). The longitudinal ($\Gamma_L$) and transverse polarization ($\Gamma_T$) for $B_c \to \psi(ns)$ decay modes are predicted in the small and large $q^2$ - region as well as in the whole physical region. The ratios for such transitions are obtained $\frac {\Gamma_L}{\Gamma_T} < 1$ throughout the kinematic range which means the $B_c^+$ meson transitions to vector meson charmonium states take place predominantly in transverse polarization mode. The theoretical predictions on these transitions could be tested in the on-going and forthcoming experiments at LHCb. ","hep-ph"
"1912.09505","Animal behavior facilitates eco-evolutionary dynamics","  The mechanisms underlying eco-evolutionary dynamics (the feedback between ecological and evolutionary processes) are often unknown. Here, we propose that classical theory from behavioral ecology can provide a greater understanding of the mechanisms underlying eco-evolutionary dynamics, and thus improve predictions about the outcomes of these dynamics. ","q-bio"
"1903.03608","F-theory models with 3 to 8 U(1) factors on K3 surfaces","  In this study, we construct four-dimensional F-theory models with 3 to 8 U(1) factors on products of K3 surfaces. We provide explicit Weierstrass equations of elliptic K3 surfaces with Mordell-Weil ranks of 3 to 8. We utilize the method of quadratic base change to glue pairs of rational elliptic surfaces together to yield the aforementioned types of K3 surfaces. The moduli of elliptic K3 surfaces constructed in the study include Kummer surfaces of specific complex structures. We show that the tadpole cancels in F-theory compactifications with flux when these Kummer surfaces are paired with appropriately selected attractive K3 surfaces. We determine the matter spectra on F-theory on the pairs. ","hep-th"
"1707.09343","Almost $\eta$-Ricci solitons in $(LCS)_n$-manifolds","  We consider almost $\eta$-Ricci solitons in $(LCS)_n$-manifolds satisfying certain curvature conditions. We provide a lower and an upper bound for the norm of the Ricci curvature in the gradient case, derive a Bochner-type formula for an almost $\eta$-Ricci soliton and state some consequences of it on an $(LCS)_n$-manifold. ","math"
"1510.06871","mgm: Estimating Time-Varying Mixed Graphical Models in High-Dimensional   Data","  We present the R-package mgm for the estimation of k-order Mixed Graphical Models (MGMs) and mixed Vector Autoregressive (mVAR) models in high-dimensional data. These are a useful extensions of graphical models for only one variable type, since data sets consisting of mixed types of variables (continuous, count, categorical) are ubiquitous. In addition, we allow to relax the stationarity assumption of both models by introducing time-varying versions MGMs and mVAR models based on a kernel weighting approach. Time-varying models offer a rich description of temporally evolving systems and allow to identify external influences on the model structure such as the impact of interventions. We provide the background of all implemented methods and provide fully reproducible examples that illustrate how to use the package. ","stat"
"2007.10440","Fundamental quantum limits in ellipsometry","  We establish the ultimate limits that quantum theory imposes on the accuracy attainable in optical ellipsometry. We show that the standard quantum limit, as usual reached when the incident light is in a coherent state, can be surpassed with the use of appropriate squeezed states and, for tailored beams, even pushed to the ultimate Heisenberg limit. ","quant-ph"
"2008.02556","Exploiting Aharonov-Bohm oscillations to probe Klein tunneling in   tunable pn-junctions in graphene","  One of the unique features of graphene is that the Fermi wavelength of its charge carriers can be tuned electrostatically over a wide range. This allows in principle to tune the transparency of a pn-junction electrostatically, as this depends on the ratio between the physical extension of the junction and the electron wavelength, i.e. on the effective width of the junction itself. However, this simple idea - which would allow to switch smoothly between a Veselago lens and a Klein-collimator - has proved to be difficult to demonstrate experimentally because of the limited amount of independently-tunable parameters available in most setups. In this work, we present transport measurements in a quasi-ballistic Aharonov-Bohm graphene ring with gate tunable pn-junctions in one arm, and show that the interference patterns provide unambiguous information on the Klein tunneling efficiency and on the junctions effective width. We find a phase coherence length on the order of 1.5 $\mu$m and a gate-controlled transparency ranging from 35-100%. Our results are in excellent agreement with a parameter-free semiclassical description. ","cond-mat"
"2003.14091","A functional near-infrared spectroscopy-based frontoparietal   connectivity neurofeedback training method for cognitive functions promotion","  An innovative approach which can promote cognitive functions effectively and efficiently is an urgent need for healthy elderly and patients with cognitive impairment. In this study, we proposed a novel functional near-infrared spectroscopy (fNIRS)-based frontoparietal functional connectivity (FC) neurofeedback training paradigm related to working memory. Compared with conventional cognitive training studies, we chose the frontoparietal network, a key brain region for cognitive function modulation as neurofeedback, resulting in strong targeting effect. In the experiment, ten participants received three 20 min cognitive training sessions with fNIRS-based frontoparietal FC as neurofeedback, and the other ten participants served as the normal control (NC) group. Frontoparietal FC was significantly increased in the tested group (p = 0.005) and the cognitive functions (memory and attention) were significantly promoted compared to the NC group. Follow-up evaluations indicated that the training effect can last for over half a month. The proposed method shows great potential to be developed as a fast, effective and widespread training approach for cognitive functions enhancement and rehabilitation applications. ","q-bio"
"2007.15043","Non-Uniform Sampling of Fixed Margin Uniform Matrices","  Data sets in the form of binary matrices are ubiquitous across scientific domains, and researchers are often interested in identifying and quantifying noteworthy structure. One approach is to compare the observed data to that which might be obtained under a null model. Here we consider sampling from the space of binary matrices which satisfy a set of marginal row and column sums. Whereas existing sampling methods have focused on uniform sampling from this space, we introduce modified versions of two elementwise swapping algorithms which sample according to a non-uniform probability distribution defined by a weight matrix, which gives the relative probability of a one for each entry. We demonstrate that values of zero in the weight matrix, i.e. structural zeros, are generally problematic for swapping algorithms, except when they have special monotonic structure. We explore the properties of our algorithms through simulation studies, and illustrate the potential impact of employing a non-uniform null model using a classic bird habitation dataset. ","stat"
"2004.02392","Signal processing on simplicial complexes","  Theoretical development and applications of graph signal processing (GSP) have attracted much attention. In classical GSP, the underlying structures are restricted in terms of dimensionality. A graph is a combinatorial object that models binary relations, and it does not directly model complex n-ary relations. One possible high dimensional generalization of graphs are simplicial complexes. They are a step between the constrained case of graphs and the general case of hypergraphs. In this paper, we develop a signal processing framework on simplicial complexes, such that we recover the traditional GSP theory when restricted to signals on graphs. It is worth mentioning that the framework works much more generally, though the focus of the paper is on simplicial complexes. We demonstrate how to perform signal processing with the framework using numerical examples. ","eess"
"2008.08484","Lorentz and CPT tests with charge-to-mass ratio comparisons in Penning   traps","  Applications of the general theory of quantum electrodynamics with Lorentz- and CPT-violating operators of mass dimensions up to six are presented to Penning-trap experiments comparing charge-to-mass ratios between particles and antiparticles. Perturbation theory is used to derive Lorentz- and CPT-violating contributions to the energy levels and cyclotron frequencies of confined particles and antiparticles. We show that whether the experimental {\it interpreted} quantity $(|q|/m)_{\overline{w}}/(|q|/m)_{w} - 1$ is a clean measure of a CPT test depends on the context of the relevant theory. Existing experimental results of charge-to-mass ratio comparisons are used to obtain first-time constraints on 69 coefficients for Lorentz and CPT violation. ","hep-ph"
"1908.05662","Pixel space convolution for cosmic microwave background experiments","  Cosmic microwave background experiments have experienced an exponential increase in complexity, data size and sensitivity. One of the goals of current and future experiments is to characterize the B-mode power spectrum, which would be considered a strong evidence supporting inflation. The signal associated with inflationary B-modes is very weak, and so a successful detection requires exquisite control over systematic effects, several of which might arise due to the interaction between the electromagnetic properties of the telescope beam, the scanning strategy and the sky model. In this work, we present the Pixel Space COnvolver (PISCO), a new software tool capable of producing mock data streams for a general CMB experiment. PISCO uses a fully polarized representation of the electromagnetic properties of the telescope. PISCO also exploits the massively parallel architecture of Graphic Processing Units to accelerate the main calculation. This work shows the results of applying PISCO in several scenarios, included a realistic simulation of an ongoing experiment, the Cosmology Large Angular Scale Surveyor. ","astro-ph"
"1908.00593","Learned backprojection for sparse and limited view photoacoustic   tomography","  Filtered backprojection (FBP) is an efficient and popular class of tomographic image reconstruction methods. In photoacoustic tomography, these algorithms are based on theoretically exact analytic inversion formulas which results in accurate reconstructions. However, photoacoustic measurement data are often incomplete (limited detection view and sparse sampling), which results in artefacts in the images reconstructed with FBP. In addition to that, properties such as directivity of the acoustic detectors are not accounted for in standard FBP, which affects the reconstruction quality, too. To account for these issues, in this papers we propose to improve FBP algorithms based on machine learning techniques. In the proposed method, we include additional weight factors in the FBP, that are optimized on a set of incomplete data and the corresponding ground truth photoacoustic source. Numerical tests show that the learned FBP improves the reconstruction quality compared to the standard FBP. ","eess"
"1707.06502","Systematic Studies of Exact ${\cal O}(\alpha^2L)$ CEEX EW Corrections in   a Hadronic MC for Precision $Z/\gamma^*$ Physics at LHC Energies","  With an eye toward the precision physics of the LHC, such as the recent measurement of $M_W$ by the ATLAS Collaboration, we present here systematic studies relevant to the assessment of the expected size of multiple photon radiative effects in heavy gauge boson production with decay to charged lepton pairs. We use the new version 4.22 of ${\cal KK}$MC-hh so that we have CEEX EW exact ${\cal O}(\alpha^2 L)$ corrections in a hadronic MC and control over the corresponding EW initial-final interference (IFI) effects as well. In this way, we illustrate the interplay between cuts of the type used in the measurement of $M_W$ at the LHC and the sizes of the expected responses of the attendant higher order corrections. We find that there are per cent to per mille level effects in the initial-state radiation, fractional per mille level effects in the IFI and per mille level effects in the over-all ${\cal O}(\alpha^2 L)$ corrections that any treatment of EW corrections at the per mille level should consider. Our results have direct applicability to current LHC experimental data analyses. ","hep-ph"
"2006.16267","XENON1T solar axion and the Higgs boson emerging from the dark","  In a recent letter we proposed a new non-thermal mechanism of Dark Matter production based on vacuum misalignment, where both the Higgs boson and a very light pseudo-scalar $\eta$ emerge from the Dark sector. In this letter, we identify the parameter space in a composite scenario where the light pseudo-scalar can be produced in the sun and explain the XENON1T excess in electron recoil data. The model's Dark Matter candidate has a mass around $50$ TeV and out of range for Direct Detection. Testable predictions include Gravitational waves at frequencies in the Hz range from a cosmological phase transition, an exotic decay $Z \to \gamma + \mbox{inv.}$ with rates $4 \div 16 \cdot 10^{-12}$ testable at a future Tera-Z collider, and an enhancement by $17\div 40$ % of the branching ratio $K_L \to \pi^0 + \mbox{inv.}$, not enough to explain the KOTO anomaly. All these predictions may be confirmed by future experiments. ","hep-ph"
"1906.04192","Cation Disorder and Lithium Insertion Mechanism of Wadsley--Roth   Crystallographic Shear Phases","  Wadsley--Roth crystallographic shear phases form a family of compounds that have attracted attention due to their excellent performance as lithium-ion battery electrodes. The complex crystallographic structure of these materials poses a challenge for first-principles computational modelling and hinders the understanding of their structural, electronic and dynamic properties. In this article, we study three different niobium-tungsten oxide crystallographic shear phases (Nb$_{12}$WO$_{33}$, Nb$_{14}$W$_{3}$O$_{44}$, Nb$_{16}$W$_5$O$_{55}$) using an enumeration-based approach and first-principles density-functional theory calculations. We report common principles governing the cation disorder, lithium insertion mechanism, and electronic structure of these materials. Tungsten preferentially occupies tetrahedral and block-central sites within the block-type crystal structures. The lithium insertion proceeds via a three-step mechanism, associated with an anisotropic evolution of the host lattice. Our calculations reveal an important connection between long-range and local structural changes: in the second step of the mechanism, the removal of local structural distortions leads to the contraction of the lattice along specific crystallographic directions, buffering the volume expansion of the material. Niobium-tungsten oxide shear structures host small amounts of localised electrons during initial lithium insertion due to the confining effect of the blocks, but quickly become metallic upon further lithiation. We argue that the combination of local, long-range, and electronic structural evolution over the course of lithiation is beneficial to the performance of these materials as battery electrodes. The mechanistic principles we establish arise from the compound-independent crystallographic shear structure, and are therefore likely to apply to Ti/Nb oxide or pure Nb oxide shear phases. ","cond-mat"
"1912.06317","Point-ahead demonstration of a transmitting antenna for satellite   quantum communication","  A low-divergence beam is an essential prerequisite for a high-efficiency longdistance optical link, particularly for satellite-based quantum communication. A point-ahead angle, caused by satellite motion, is always several times larger than the divergence angle of the signal beam. We design a novel transmitting antenna with a point-ahead function, and provide an easy-to-perform calibration method with an accuracy better than 0.2 urad. Subsequently, our antenna establishes an uplink to the quantum satellite, Micius, with a link loss of 41-52 dB over a distance of 500-1,400 km. The results clearly confirm the validity of our model, and provide the ability to conduct quantum communications. Our approach can be adopted in various free space optical communication systems between moving platforms. ","quant-ph"
"1904.00076","High-order discretization of a stable time-domain integral equation for   3D acoustic scattering","  We develop a high-order, explicit method for acoustic scattering in three space dimensions based on a combined-field time-domain integral equation. The spatial discretization, of Nystr\""om type, uses Gaussian quadrature on panels combined with a special treatment of the weakly singular kernels arising in near-neighbor interactions. In time, a new class of convolution splines is used in a predictor-corrector algorithm. Experiments on a torus and a perturbed torus are used to explore the stability and accuracy of the proposed scheme. This involved around one thousand solver runs, at up to 8th order and up to around 20,000 spatial unknowns, demonstrating 5-9 digits of accuracy. In addition we show that parameters in the combined field formulation, chosen on the basis of analysis for the sphere and other convex scatterers, work well in these cases. ","math"
"1911.05393","Unveiling domain wall dynamics of ferrimagnets in thermal magnon   currents: competition of angular momentum transfer and entropic torque","  Control of magnetic domain wall motion holds promise for efficient manipulation and transfer of magnetically stored information. Thermal magnon currents, generated by temperature gradients, can be used to move magnetic textures, from domain walls, to magnetic vortices and skyrmions. In the last years, theoretical studies have centered in ferro- and antiferromagnetic spin structures, where domain walls always move towards the hotter end of the thermal gradient. Here we perform numerical studies using atomistic spin dynamics simulations and complementary analytical calculations to derive an equation of motion for the domain wall velocity. We demonstrate that in ferrimagnets, domain wall motion under thermal magnon currents shows a much richer dynamics. Below the Walker breakdown, we find that the temperature gradient always pulls the domain wall towards the hot end by minimizating its free energy, in agreement with the observations for ferro- and antiferromagnets in the same regime. Above Walker breakdown, the ferrimagnetic domain wall can show the opposite, counterintuitive behavior of moving towards the cold end. We show that in this case, the motion to the hotter or the colder ends is driven by angular momentum transfer and therefore strongly related to the angular momentum compensation temperature, a unique property of ferrimagnets where the intrinsic angular momentum of the ferrimagnet is zero while the sublattice angular momentum remains finite. In particular, we find that below the compensation temperature the wall moves towards the cold end, whereas above it, towards the hot end. Moreover, we find that for ferrimagnets, there is a torque compensation temperature at which the domain wall dynamics shows similar characteristics to antiferromagnets, that is, quasi-inertia-free motion and the absence of Walker breakdown. ","cond-mat"
"2004.11882","Molecular dynamics study of the competitive binding of hydrogen peroxide   and water molecules with the DNA phosphate groups","  The hydrogen peroxide is present in the living cell at small concentrations that increase under the action of the heavy ion beams in the process of anticancer therapy. The interactions of hydrogen peroxide with DNA, proteins and other biological molecules are poorly understood. In the present work the competitive binding of the hydrogen peroxide and water molecules with the DNA double helix backbone has been studied using the molecular dynamics method. The simulations have been carried out for the DNA double helix in a water solution with hydrogen peroxide molecules and Na$^{+}$ counterions. The obtained radial distribution functions of counterions, H$_2$O$_2$ and H$_2$O molecules with respect to the oxygen atoms of DNA phosphate groups have been used for the analysis of the formation of different complexes. The calculated mean residence times show that a hydrogen peroxide molecule stays at least twice as long near the phosphate group (up to 7 ps) than a water molecule (about 3 ps). The hydrogen peroxide molecules form more stable complexes with the phosphate groups of the DNA backbone than water molecules do. ","q-bio"
"1911.07286","Bound states and perturbation theory","  A perturbative expansion for QED and QCD bound states is formulated in $A^0=0$ gauge. The constituents of each Fock state are bound by their instantaneous interaction. In QCD an O($\alpha_s^0$) confining potential arises from a homogeneous solution of Gauss' constraint. The potential is uniquely determined by the QCD action, up to a universal scale. The Cornell potential is reproduced for quarkonia, and corresponding ones found for higher Fock states, baryons and glueballs. ","hep-ph"
"1901.01357","Connected sum of CR manifolds with positive CR Yamabe constant","  Suppose $M_{1}$ and $M_{2}$ are $3$-dimensional closed (compact without boundary) CR manifolds with positive CR Yamabe constant. In this note, we show that the connected sum of $M_{1}$ and $M_{2}$ also admits a CR structure with positive CR Yamabe constant. ","math"
"2003.13774","Spontaneous Rotation of Ferrimagnetism Driven by Antiferromagnetic Spin   Canting","  Spin-reorientation phase transitions that involve the rotation of a crystal$'$s magnetization have been well characterized in distorted-perovskite oxides such as the orthoferrites. In these systems spin reorientation occurs due to competing rare-earth and transition metal anisotropies coupled via $f$-$d$ exchange. Here, we demonstrate an alternative paradigm for spin reorientation in distorted perovskites. We show that the $R_2\mathrm{CuMnMn_4O_{12}}$ (R = Y or Dy) triple A-site columnar-ordered quadruple perovskites have three ordered magnetic phases and up to two spin-reorientation phase transitions. Unlike the spin-reorientation phenomena in other distorted perovskites, these transitions are independent of rare-earth magnetism, but are instead driven by an instability towards antiferromagnetic spin canting likely originating in frustrated Heisenberg exchange interactions, and the competition between Dzyaloshinskii-Moriya and single-ion anisotropies. ","cond-mat"
"1908.06388","Drug Release Management for Dynamic TDMA-Based Molecular Communication","  In this paper, we design a drug release mechanism for dynamic time division multiple access (TDMA)-based molecular communication via diffusion (MCvD). In the proposed scheme, the communication frame is divided into several time slots over each of which a transmitter nanomachine is scheduled to convey its information by releasing the molecules into the medium. To optimize the number of released molecules and the time duration of each time slot (symbol duration), we formulate a multi-objective optimization problem whose objective functions are the bit error rate (BER) of each transmitter nanomachine. Based on the number of released molecules and symbol durations, we consider four cases, namely: ""static-time static-number of molecules"" (STSN), ""static-time dynamic-number of molecules"" (STDN), ""dynamic-time static-number of molecules"" (DTSN), and ""dynamic-time dynamic-number of molecules"" (DTDN). We consider three types of medium in which the molecules are propagated, namely: ""mild diffusive environment"" (MDE), ""moderate diffusive environment"" (MODE), and ""severe diffusive environment"" (SDE). For the channel model, we consider a 3-dimensional (3D) diffusive environment, such as blood, with drift in three directions. Simulation results show that the STSN approach is the least complex one with BER around $\text{10}^{\text{-2}}$, but, the DTDN is the most complex scenario with the BER around $\text{10}^{\text{-8}}$. ","eess"
"2003.14303","Studying the Effect of Digital Stain Separation of Histopathology Images   on Image Search Performance","  Due to recent advances in technology, digitized histopathology images are now widely available for both clinical and research purposes. Accordingly, research into computerized image analysis algorithms for digital histopathology images has been progressing rapidly. In this work, we focus on image retrieval for digital histopathology images. Image retrieval algorithms can be used to find similar images and can assist pathologists in making quick and accurate diagnoses. Histopathology images are typically stained with dyes to highlight features of the tissue, and as such, an image analysis algorithm for histopathology should be able to process colour images and determine relevant information from the stain colours present. In this study, we are interested in the effect that stain separation into their individual stain components has on image search performance. To this end, we implement a basic k-nearest neighbours (kNN) search algorithm on histopathology images from two publicly available data sets (IDC and BreakHis) which are: a) converted to greyscale, b) digitally stain-separated and c) the original RGB colour images. The results of this study show that using H\&E separated images yields search accuracies within one or two percent of those obtained with original RGB images, and that superior performance is observed using the H\&E images in most scenarios we tested. ","eess"
"2007.02899","The XMM-Newton serendipitous survey IX. The fourth XMM-Newton   serendipitous source catalogue","  Sky surveys produce enormous quantities of data on extensive regions of the sky. The easiest way to access this information is through catalogues of standardised data products. {\em XMM-Newton} has been surveying the sky in the X-ray, ultra-violet, and optical bands for 20 years. The {\em XMM-Newton} Survey Science Centre has been producing standardised data products and catalogues to facilitate access to the serendipitous X-ray sky. Using improved calibration and enhanced software, we re-reduced all of the 14041 {\em XMM-Newton} X-ray observations, of which 11204 observations contained data with at least one detection and with these we created a new, high quality version of the {\em XMM-Newton} serendipitous source catalogue, 4XMM-DR9. 4XMM-DR9 contains 810795 detections down to a detection significance of 3 $\sigma$, of which 550124 are unique sources, which cover 1152 degrees$^{2}$ (2.85\%) of the sky. Filtering 4XMM-DR9 to retain only the cleanest sources with at least a 5 $\sigma$ detection significance leaves 433612 detections. Of these detections, 99.6\% have no pileup. Furthermore, 336 columns of information on each detection are provided, along with images. The quality of the source detection is shown to have improved significantly with respect to previous versions of the catalogues. Spectra and lightcurves are also made available for more than 288000 of the brightest sources (36\% of all detections). ","astro-ph"
"1903.03564","Quantum Process Randomness","  We study the optimization of any quantum process by minimizing the ""randomness"" in the measurement result at the output of that quantum process. We conceptualize and propose a measure of such randomness and inquire whether an optimization of the quantum process based on that measure, can reach the point where the process operates with maximum fidelity. We consider approximate quantum cloning and teleportation processes, and find, in particular, that the optimal approximate state-dependent quantum cloning machine obtained by maximizing the fidelity is different from that obtained by minimizing the randomness. ","quant-ph"
"2006.14273","Discussion of 'Detecting possibly frequent change-points: Wild Binary   Segmentation 2 and steepest-drop model selection'","  We discuss the theoretical guarantee provided by the WBS2.SDLL proposed in Fryzlewicz (2020) and explore an alternative, MOSUM-based candidate generation method for the SDLL. ","stat"
"2008.08668","Self-Organized Networks with Long-Range Interactions: Tandem Darwinian   Evolution of $\alpha$ and $\beta$ Tubulin","  Cytoskeletons are self-organized networks based on polymerized proteins: actin, tubulin, and driven by motor proteins, such as myosin, kinesin and dynein. Their positive Darwinian evolution enables them to approach optimized functionality (self-organized criticality). Our theoretical analysis uses hydropathic waves to identify and contrast the functional differences between the polymerizing $\alpha$ and $\beta$ tubulin monomers, which are similar in length and secondary structures, as well as having indistinguishable phylogenetic trees. We show how evolution has improved water-driven flexibility especially for $\alpha$ tubulin, and thus facilitated heterodimer microtubule assembly, in agreement with recent atomistic simulations and topological models. We conclude that the failure of phylogenetic analysis to identify functionally specific positive Darwinian evolution has been caused by 20th century technical limitations. These are overcome using 21st century quantitative mathematical methods based on thermodynamic scaling and hydropathic modular averaging. Our most surprising result is the identification of large level sets, especially in hydrophobic extrema, with both thermodynamically first- and second-order scaled water waves. Our calculations include explicitly long-range water-protein interactions described by fractals. We also suggest a much-needed corrective for large protein drug development costs. ","q-bio"
"1906.01100","A Dyadic IRT Model","  We propose a dyadic Item Response Theory (dIRT) model for measuring interactions of pairs of individuals when the responses to items represent the actions (or behaviors, perceptions, etc.) of each individual (actor) made within the context of a dyad formed with another individual (partner). Examples of its use include the assessment of collaborative problem solving, or the evaluation of intra-team dynamics. The dIRT model generalizes both Item Response Theory (IRT) models for measurement and the Social Relations Model (SRM) for dyadic data. The responses of an actor when paired with a partner are modeled as a function of not only the actor's inclination to act and the partner's tendency to elicit that action, but also the unique relationship of the pair, represented by two directional, possibly correlated, interaction latent variables. Generalizations are discussed, such as accommodating triads or larger groups. Estimation is performed using Markov-chain Monte Carlo implemented in Stan, making it straightforward to extend the dIRT model in various ways. Specifically, we show how the basic dIRT model can be extended to accommodate latent regressions, multilevel settings with cluster-level random effects, as well as joint modeling of dyadic data and a distal outcome. A simulation study demonstrates that estimation performs well. We apply our proposed approach to speed-dating data and find new evidence of pairwise interactions between participants, describing a mutual attraction that is inadequately characterized by individual properties alone. ","stat"
"2008.01963","Structure-SLAM: Low-Drift Monocular SLAM in Indoor Environments","  In this paper a low-drift monocular SLAM method is proposed targeting indoor scenarios, where monocular SLAM often fails due to the lack of textured surfaces. Our approach decouples rotation and translation estimation of the tracking process to reduce the long-term drift in indoor environments. In order to take full advantage of the available geometric information in the scene, surface normals are predicted by a convolutional neural network from each input RGB image in real-time. First, a drift-free rotation is estimated based on lines and surface normals using spherical mean-shift clustering, leveraging the weak Manhattan World assumption. Then translation is computed from point and line features. Finally, the estimated poses are refined with a map-to-frame optimization strategy. The proposed method outperforms the state of the art on common SLAM benchmarks such as ICL-NUIM and TUM RGB-D. ","cs"
"1907.09523","An end-to-end (deep) neural network applied to raw EEG, fNIRs and body   motion data for data fusion and BCI classification task without any   pre-/post-processing","  Brain computer interfaces (BCI) using EEG, fNIRS and body motion (MoCap) data are getting more attention due to the fact that fNIRS and MoCap are not prone to movement artifacts similar to other brain imaging techniques such as EEG. Advancements in deep learning (neural networks) would allow the use of raw data for efficient feature extraction without any pre-/post-processing. In this work, we are performing human activity recognition (BCI classification task) for 5 activity classes using an end-to-end (deep) neural network (NN) (from input all the way to the output) on raw fNIRS, EEG and MoCap data. Our core contribution is focused on applying an end-to-end NN model without any pre-/post-processing on the data. The entire NN model is being trained using backpropagation algorithm. Our end-to-end model is composed of a four-layered MLP: input layer, two hidden layers (using fully connected (dense) layer, batch normalization and leaky-RELU as non-linearity and activation function), and output layer using softmax. We have reached minimum 90\% accuracy on the test dataset for the classification task on 10 subjects data and 5 classes of activity. ","eess"
"1909.00472","Latent Space Modelling of Hypergraph Data","  The increasing prevalence of relational data describing interactions among a target population has motivated a wide literature on statistical network analysis. In many applications, interactions may involve more than two members of the population and this data is more appropriately represented by a hypergraph. In this paper, we present a model for hypergraph data which extends the latent space distance model of Hoff et al. (2002) and, by drawing a connection to constructs from computational topology, we develop a model whose likelihood is inexpensive to compute. We obtain posterior samples via an MCMC scheme and we rely on Bookstein coordinates to remove the identifiability issues associated with the latent representation. We demonstrate that the latent space construction imposes desirable properties on the hypergraphs generated in our framework and provides a convenient visualisation of the data. Furthermore, through simulation, we investigate the flexibility of our model and consider estimating predictive distributions. Finally, we explore the application of our model to two real world datasets. ","stat"
"2003.09848","Dynamical-Invariant-based Holonomic Quantum Gates: Theory and Experiment","  Among existing approaches to holonomic quantum computing, the adiabatic holonomic quantum gates (HQGs) suffer errors due to decoherence, while the non-adiabatic HQGs either require additional Hilbert spaces or are difficult to scale. Here, we report a systematic, scalable approach based on dynamical invariants to realize HQGs without using additional Hilbert spaces. While presenting the theoretical framework of our approach, we design and experimentally evaluate single-qubit and two-qubits HQGs for the nuclear magnetic resonance system. The single-qubit gates acquire average fidelity 0.9972 by randomized benchmarking, and the controlled-NOT gate acquires fidelity 0.9782 by quantum process tomography. Our approach is also platform-independent, and thus may open a way to large-scale holonomic quantum computation. ","quant-ph"
"1809.01161","Hadronic tau decays as New Physics probes in the LHC era","  We analyze the sensitivity of hadronic tau decays to non-standard interactions within the model-independent framework of the Standard Model Effective Field Theory (SMEFT). Both exclusive and inclusive decays are studied, using the latest lattice data and QCD dispersion relations. We show that there are enough theoretically clean channels to disentangle all the effective couplings contributing to these decays, with the $\tau \to \pi\pi\nu_\tau$ channel representing an unexpected powerful New Physics probe. We find that the ratios of non-standard couplings to the Fermi constant are bound at the sub-percent level. These bounds are complementary to the ones from electroweak precision observables and $p p \to \tau \nu_\tau$ measurements at the LHC. The combination of tau decay and LHC data puts tighter constraints on lepton universality violation in the gauge boson-lepton vertex corrections. ","hep-ph"
"2002.07716","Synaptic clock as a neural substrate of consciousness","  In this study the temporal aspect of consciousness is analyzed. We start from the notion that while conscious experience seems to change constantly, yet for any contents of experience to be consciously perceived they must last for some non-zero duration of time, which appears to constitute a certain conflict. We posit that, in terms of phenomenological analysis of consciousness, the temporal aspect, and this apparent conflict in particular, is the most basic property, likely inherent to any conceivable form of consciousness. We then put forward arguments for the synaptic clock to be a content-specific neural substrate of consciousness, showing how it would correspond to this temporal aspect. This proposal is considered in light of the information integration theory of consciousness, and other theories that relate consciousness to processes of learning and memory. It is outlined how this can offer a concrete way of relating the properties of consciousness directly to the neural plasticity mechanisms of learning and memory. In this regard, we propose a viewpoint, in which an association between different contents of conscious experience can be created in a form of relational memory only if they occur at the very same moment of subjective time, with moments of subjective time having different durations depending on the type of information processed, proportional to the time units of corresponding synaptic clocks, and being in principle different for different brain regions and nervous systems in different animal species. Finally, using this viewpoint, we consider the two alternative views on the structure of consciousness, namely a static and a dynamic one, and argue in favor of the latter, proposing that consciousness can be best understood if change is considered its only dimension. ","q-bio"
"1904.07384","Modelling DESTINY+ interplanetary and interstellar dust measurements en   route to the active asteroid (3200) Phaethon","  The JAXA/ISAS spacecraft DESTINY$^+$ will be launched to the active asteroid (3200) Phaethon in 2022. Among the proposed core payload is the DESTINY+ Dust Analyzer (DDA) which is an upgrade of the Cosmic Dust Analyzer flown on the Cassini spacecraft to Saturn (Srama et al. 2011). We use two up-to-date computer models, the ESA Interplanetary Meteoroid Engineering Model (IMEM, Dikarev et al. 2005), and the interstellar dust module of the Interplanetary Meteoroid environment for EXploration model (IMEX; Sterken2013 et al., Strub et al. 2019) to study the detection conditions and fluences of interplanetary and interstellar dust with DDA. Our results show that a statistically significant number of interplanetary and interstellar dust particles will be detectable with DDA during the 4-years interplanetary cruise of DESTINY+. The particle impact direction and speed can be used to descriminate between interstellar and interplanetary particles and likely also to distinguish between cometary and asteroidal particles. ","astro-ph"
"1908.01844","Attractors and asymptotic dynamics of open discrete-time quantum walks   on cycles","  Open quantum walks often lead to a classical asymptotic behavior. Here, we look for a simple open quantum walk whose asymptotic behavior can be non-classical. We consider a discrete-time quantum walk on n-cycle subject to a random coin-dependent phase shift at a single position. This finite system, whose evolution is described by only two Kraus operators, can exhibit all kinds of asymptotic behavior observable in quantum Markov chains: it either evolves towards a maximally mixed state, or partially mixed state, or tends to an oscillatory motion on an asymptotic orbit. We find that the asymptotic orbits do not have a product structure, therefore the corresponding states can manifest entanglement between the position and the coin degrees of freedom, even if the system started in a product state. ","quant-ph"
"1811.03101","Variations on the Vev Flip-Flop: Instantaneous Freeze-out and Decaying   Dark Matter","  In this work we consider a simple model for dark matter and identify regions of parameter space where the relic abundance is set via kinematic thresholds, which open and close due to thermal effects. We discuss instantaneous freeze-out, where dark matter suddenly freezes-out when the channel connecting dark matter to the thermal bath closes, and decaying dark matter, where dark matter freezes-out while relativistic and later decays when a kinematic threshold temporarily opens. These mechanisms can occur in the vicinity of a one-step or a two-step phase transition. In all cases thermal effects provide this dynamic behaviour, while ensuring that dark matter remains stable until the present day. ","hep-ph"
"1910.10233","Flexible Bayesian modelling in dichotomous item response theory using   mixtures of skewed item curves","  Most Item Response Theory (IRT) models for dichotomous responses are based on probit or logit link functions which assume a symmetric relationship between the responses and the latent traits of individuals submitted to a test. Such an assumption restricts the use of such models to situations in which all items have symmetric behavior. Similar constraint is imposed by the asymmetric models proposed in the literature as it is required that all items have an asymmetric behavior. Such assumptions are inappropriate for great part of the tests which, in general, are composed by both symmetric and asymmetric items. Furthermore, a straightforward extension of the existing models in the literature of would require a prior selection of the items' symmetry/asymmetry status. This paper proposes a Bayesian IRT model that accounts for symmetric and asymmetric items in a flexible though parsimonious way. That is achieved by assigning a point-mass mixture prior to the skewness parameter of the item, allowing for an analysis under the model selection or model averaging approaches. Asymmetric item curves are design through the centred skew normal distribution which has a particularly appealing parametrisation in terms of parameter interpretation and computational efficiency. An efficient MCMC algorithm is proposed to perform Bayesian inference and its performance is investigated in some simulated examples. Finally, the proposed methodology is applied to a data set from a large scale educational exam in Brazil. ","stat"
"1811.09624","Existence of soliton configurations in $\mathcal{N}=2$ scalar field   theory","  In this article, we study the existence of kink soliton configurations in two interacting scalar field theories. We study two simple examples of such theories of which the first is a $SO(2)$ invariant field theory. As the second example, the well-known Montonen-Sarker-Trullinger-Bishop -hence, the MSTB model is considered which is not an $SO(2)$ invariant field theory. The existence of the kink soliton configurations is shown in terms of a system of first-order ordinary differential equations. Further for the MSTB model, it is also shown that the non-conserved $U(1)$ current is also solitary in nature. Furthermore, we also show that all the information regarding the dynamics of these models can be obtained from the dynamics of a single field variable. ","hep-th"
"1905.04283","Visuospatial short-term memory and dorsal visual gray matter volume","  Visual short-term memory (VSTM) is an important cognitive capacity that varies across the healthy adult population and is affected in several neurodevelopmental disorders. It has been suggested that neuroanatomy places limits on this capacity through a map architecture that creates competition for cortical space. This suggestion has been supported by the finding that primary visual (V1) gray matter volume (GMV) is positively associated with VSTM capacity. However, evidence from neurodevelopmental disorders suggests that the dorsal visual stream more broadly is vulnerable and atypical volumes of other map-containing regions may therefore play a role. For example, Turner syndrome is associated with concomitantly reduced volume of the right intraparietal sulcus (IPS) and deficits in VSTM. As posterior IPS regions (IPS0-2) contains topographic maps, together this suggests that posterior IPS volumes may also associate with VSTM. In this study, we assessed VSTM using two tasks, as well as a composite score, and used voxel-based morphometry of T1-weighted magnetic resonance images to assess GMV in V1 and right IPS0-2 in 32 healthy young adults (16 female). For comparison with previous work, we also assessed associations between VSTM and voxel-wise GMV on a whole-brain basis. We found that total brain volume (TBV) significantly correlated with VSTM, and that correlations between VSTM and regional GMV were substantially reduced in strength when controlling for TBV. In our whole-brain analysis, we found that VSTM was associated with GMV of clusters centered around the right putamen and left Rolandic operculum, though only when TBV was not controlled for. Our results suggest that VSTM ability is unlikely to be accounted for by the volume of an individual cortical region and may instead rely on distributed structural properties. ","q-bio"
"1911.05477","Turning genome-wide association study findings into opportunities for   drug repositioning","  Drug development is a very costly and lengthy process, while repositioned or repurposed drugs could be brought into clinical practice within a shorter time-frame and at a much reduced cost. The past decade has observed a massive growth in the amount of data from genome-wide association studies (GWAS). The rich information contained in GWAS data has great potential to guide drug discovery or repositioning. Here we provide an overview of different computational approaches which employ GWAS data to guide drug repositioning. These methods include selection of top candidate genes from GWAS as drug targets, deducing drug candidates based on drug-drug and disease-disease similarity, searching for reversed expression profiles between drugs and diseases, pathway-based methods as well as repositioning based on analysis of biological networks. Each method is illustrated with examples, and their respective strengths and limitations are discussed. Finally we discussed several areas for future research. ","q-bio"
"1901.02152","Double-Robust Estimation in Difference-in-Differences with an   Application to Traffic Safety Evaluation","  Difference-in-differences (DID) is a widely used approach for drawing causal inference from observational panel data. Two common estimation strategies for DID are outcome regression and propensity score weighting. In this paper, motivated by a real application in traffic safety research, we propose a new double-robust DID estimator that hybridizes regression and propensity score weighting. We particularly focus on the case of discrete outcomes. We show that the proposed double-robust estimator possesses the desirable large-sample robustness property. We conduct a simulation study to examine its finite-sample performance and compare with alternative methods. Our empirical results from a Pennsylvania Department of Transportation data suggest that rumble strips are marginally effective in reducing vehicle crashes. ","stat"
"1906.06192","On the Degree Sequences of Multigraphs with Edge Additions and Deletions","  The degree sequence of a graph is a numerical method to characterize the properties of graphs. Generalized forms of degree sequences exist for complete graphs and complete graphs. Nikolopolus et al. characterized the number of spanning trees from edge deletions and edge additions. Instead of investigating the number of spanning trees of graphs that arise from edge additions and deletions, we sought to characterize degree sequences of such graphs. We conjecture a characterization for the degree sequence of the addition and edge deletion for many families of graphs including threshold graphs and complete multigraphs.   Keywords: multigraphs, split graphs, degree sequence, threshold graph, Havel-Hakimi, Ruch-Gutman, Edge Deletion ","math"
"1912.05136","Graph algebras","  This introduction to graphs and graph algebras provides the optimal bound for the number of all paths of length $k$ in a graph with $N\geq k$ edges and no loops. Our proof relies on a construction of a number of terminating algorithms that reshape such graphs without ever decreasing the number of paths of length $k$. The key two algorithms work in turns each of them ending with a graph to which the other algorithm can be applied. Finally, one arrives at a specific graph realizing the optimal bound. Herein graph algebras mean path algebras and Leavitt path algebras. For the ground field $\mathbb{C}$ of complex numbers, the latter are viewed as dense subalgebras in their universal C*-completions called graph C*-algebras. ","math"
"1902.07769","Development of Head-Mounted Projection Displays for Distributed,   Collaborative, Augmented Reality Applications","  Distributed systems technologies supporting 3D visualization and social collaboration will be increasing in frequency and type over time. An emerging type of head-mounted display referred to as the head-mounted projection display (HMPD) was recently developed that only requires ultralight optics (i.e., less than 8 g per eye) that enables immersive multiuser, mobile augmented reality 3D visualization, as well as remote 3D collaborations. In this paper a review of the development of lightweight HMPD technology is provided, together with insight into what makes this technology timely and so unique. Two novel emerging HMPD-based technologies are then described: a teleportal HMPD(T-HMPD) enabling face-to-face communication and visualization of shared 3D virtual objects, and a mobile HMPD (M-HMPD) designed for outdoor wearable visualization and communication. Finally, the use of HMPD in medical visualization and training, as well as in infospaces, two applications developed in the ODA and MIND labs respectively, are discussed. ","cs"
"1903.00809","Fracture Functions in Different Kinematic Regions and Their   Factorizations","  Fracture functions are parton distributions of an initial hadron in the presence of an almost collinear particle observed in the final state. They are important ingredients in QCD factorization for processes where a particle is produced diffractively. There are different fracture functions for a process in different kinematic regions. We take the production of a lepton pair combined with a diffractively produced particle in hadron collisions to discuss this. Those fracture functions can be factorized further if there are large energy scales involved. They can be factorized with twist-2 parton distribution functions and fragmentation functions. We perform one-loop calculations to illustrate the factorization in the case with the diffractively produced particle as a real photon. Evolution equations of different fracture functions are derived from our explicit calculations. They agree with expectations. These equations can be used for re-summations of large log terms in perturbative expansions. ","hep-ph"
"1905.11895","Mesh Refinement Method for Solving Bang-Bang Optimal Control Problems   Using Direct Collocation","  A mesh refinement method is developed for solving bang-bang optimal control problems using direct collocation. The method starts by finding a solution on a coarse mesh. Using this initial solution, the method then determines automatically if the Hamiltonian is linear with respect to the control, and, if so, estimates the locations of the discontinuities in the control. The switch times are estimated by determining the roots of the switching functions, where the switching functions are determined using estimates of the state and costate obtained from the collocation method. The accuracy of the switch times is then improved on subsequent meshes by dividing the original optimal control problem into multiple domains and including variables that define the locations of the switch times. While in principle any collocation method can be used, in this research the previously developed Legendre-Gauss-Radau collocation method is employed because it provides an accurate approximation of the costate which in turn improves the approximation of the switching functions. The method of this paper is designed to be used with a previously developed mesh refinement method in order to accurately approximate the solution in segments where the solution is smooth. The method is demonstrated on three examples where it is shown to accurately determine the switching structure of a bang-bang optimal control problem. When compared with previously developed mesh refinement methods, the results demonstrate that the method developed in this paper improves computational efficiency when solving bang-bang optimal control problems. ","math"
"1905.09524","Berry-phase-based quantum gates assisted by transitionless quantum   driving","  We propose a novel proposal for geometric quantum gates using three- or two-level systems, in which a controllable variable, the detuning between the driving frequency and the atomic energy spacing, is introduced to realize geometric transformations. In particular, we can have two instantaneous eigenstates with opposite eigenvalues constituting a closed loop in the parameter space. The accumulated dynamical phase is then exactly cancelled when the loop is completed, which is beyond the traditional parallel-transport restriction. We apply the transitionless quantum driving, which renders revisions in both amplitudes and phases of the driving fields, to enhance the speed and the fidelity of geometric transformation in both universal single-qubit gates and nontrivial double-qubit gates. Gate fidelity under decoherence is also estimated. ","quant-ph"
"1802.03176","Monocrystalline free standing 3D yttrium iron garnet magnon nano   resonators","  Nano resonators in which mechanical vibrations and spin waves can be coupled are an intriguing concept that can be used in quantum information processing to transfer information between different states of excitation. Until now, the fabrication of free standing magnetic nanostructures which host long lived spin wave excitatons and may be suitable as mechanical resonators seemed elusive. We demonstrate the fabrication of free standing monocrystalline yttrium iron garnet (YIG) 3D nanoresonators with nearly ideal magnetic properties. The freestanding 3D structures are obtained using a complex lithography process including room temperature deposition and lift-off of amorphous YIG and subsequent crystallization by annealing. The crystallization nucleates from the substrate and propagates across the structure even around bends over distances of several micrometers to form e.g. monocrystalline resonators as shown by transmission electron microscopy. Spin wave excitations in individual nanostructures are imaged by time resolved scanning Kerr microscopy. The narrow linewidth of the magnetic excitations indicates a Gilbert damping constant of only $\alpha = 2.6 \times 10^{-4}$ rivalling the best values obtained for epitaxial YIG thin film material. The new fabrication process represents a leap forward in magnonics and magnon mechanics as it provides 3D YIG structures of unprecedented quality. At the same time it demonstrates a completely new route towards the fabrication of free standing crystalline nano structures which may be applicable also to other material systems. ","cond-mat"
"2008.00551","Integration of Dirac's Efforts to construct Lorentz-covariant Quantum   Mechanics","  The lifelong efforts of Paul A. M. Dirac were to construct localized quantum systems in the Lorentz covariant world. In 1927, he noted that the time-energy uncertainty should be included in the Lorentz-covariant picture. In 1945, he attempted to construct a representation of the Lorentz group using a normalizable Gaussian function localized both in the space and time variables. In 1949, he introduced his instant form to exclude time-like oscillations. He also introduced the light-cone coordinate system for Lorentz boosts. Also in 1949, he stated the Lie algebra of the inhomogeneous Lorentz group can serve as the uncertainty relations in the Lorentz-covariant world. It is possible to integrate these three papers to produce the harmonic oscillator wave function which can be Lorentz-transformed. In addition, Dirac, in 1963, considered two coupled oscillators to derive the Lie algebra for the generators of the $O(3,\,2)$ de Sitter group, which has ten generators. It is proven possible to contract this group to the inhomogeneous Lorentz group with ten generators, which constitute the fundamental symmetry of quantum mechanics in Einstein's Lorentz-covariant world. ","quant-ph"
"1809.03321","Partial coherence and quantum correlation with fidelity and affinity   distances","  A fundamental task in any physical theory is to quantify certain physical quantity in a meaningful way. In this paper we show that both fidelity distance and affinity distance satisfy the strong contractibility, and the corresponding resource quantifiers can be used to characterize a large class of resource theories. Under two assumptions, namely, convexity of ""free states"" and closure of free states under ""selective free operations"", our general framework of resource theory includes quantum resource theories of entanglement, coherence, partial coherence and superposition. In partial coherence theory, we show that fidelity partial coherence of a bipartite state is equal to the minimal error probability of a mixed quantum state discrimination (QSD) task and vice versa, which complements the main result in [Xiong and Wu, J. Phys. A: Math. Theor. 51, 414005 (2018)]. We also compute the analytic expression of fidelity partial coherence for $(2,n)$ bipartite X-states. At last, we study the correlated coherence in the framework of partial coherence theory. We show that partial coherence of a bipartite state, with respect to the eigenbasis of a subsystem, is actually a measure of quantum correlation. ","quant-ph"
"1901.05846","The detection of non-Gaussian vibrations with improved spatial   resolution and signal-to-noise ratio in distributed sensing","  In fiber-optic distributed sensing, vibration signals are mostly assumed to follow Gaussian distribution for the simplicity of signal processing. However, in real applications, vibration signals often behave as non-Gaussian processes, which have rarely been highly considered. In this paper, a higher-order cumulants algorithm based phase-sensitive optical time-domain reflectometry (OTDR) is proposed to detect and analyze non-Gaussian vibration signals accompanied with noises. When disturbances are applied on the sensing fiber, the distribution probability of Rayleigh backscattering signals will deviate from the ideal Gaussian distribution. The non-Gaussian vibration is then extracted from Gaussian noises based on the probability density distribution. Simulations and experiments are carried out. The experimental results show that the demonstrated method can measure non-Gaussian vibrations with improved signal-to-noise ratio and spatial resolution. ","eess"
"1901.03435","Decision Directed Channel Estimation Based on Deep Neural Network k-step   Predictor for MIMO Communications in 5G","  We consider the use of deep neural network (DNN) to develop a decision-directed (DD)-channel estimation (CE) algorithm for multiple-input multiple-output (MIMO)-space-time block coded systems in highly dynamic vehicular environments. We propose the use of DNN for k-step channel prediction for space-time block code (STBC)s, and show that deep learning (DL)-based DD-CE can removes the need for Doppler spread estimation in fast time-varying quasi stationary channels, where the Doppler spread varies from one packet to another. Doppler spread estimation in this kind of vehicular channels is remarkably challenging and requires a large number of pilots and preambles, leading to lower power and spectral efficiency. We train two DNNs which learn real and imaginary parts of the MIMO fading channels over a wide range of Doppler spreads. We demonstrate that by those DNNs, DD-CE can be realized with only rough priori knowledge about Doppler spread range. For the proposed DD-CE algorithm, we also analytically derive the maximum likelihood (ML) decoding algorithm for STBC transmission. The proposed DL-based DD-CE is a promising solution for reliable communication over the vehicular MIMO fading channels without accurate mathematical models. This is because DNN can intelligently learn the statistics of the fading channels. Our simulation results show that the proposed DL-based DD-CE algorithm exhibits lower propagation error compared to existing DD-CE algorithms while the latters require perfect knowledge of the Doppler rate. ","eess"
"1811.12630","Quantum topology identification with deep neural networks and quantum   walks","  Topologically ordered materials may serve as a platform for new quantum technologies such as fault-tolerant quantum computers. To fulfil this promise, efficient and general methods are needed to discover and classify new topological phases of matter. We demonstrate that deep neural networks augmented with external memory can use the density profiles formed in quantum walks to efficiently identify properties of a topological phase as well as phase transitions. On a trial topological ordered model, our method's accuracy of topological phase identification reaches 97.4%, and is shown to be robust to noise on the data. Furthermore, we demonstrate that our trained DNN is able to identify topological phases of a perturbed model and predict the corresponding shift of topological phase transitions without learning any information about the perturbations in advance. These results demonstrate that our approach is generally applicable and may be used to identify a variety of quantum topological materials. ","quant-ph"
"2002.09522","Resonant Quantum Search with Monitor Qubits","  We present an algorithm for the generalized search problem (searching $k$ marked items among $N$ items) based on a continuous Hamiltonian and exploiting resonance. This resonant algorithm has the same time complexity $O(\sqrt{N/k})$ as the Grover algorithm. A natural extension of the algorithm, incorporating auxiliary ""monitor"" qubits, can determine $k$ precisely, if it is unknown. The time complexity of our counting algorithm is $O(\sqrt{N})$, similar to the best quantum approximate counting algorithm, or better, given appropriate physical resources. ","quant-ph"
"1911.00485","Stacking Order in Graphite Films Controlled by Van der Waals Technology","  In graphite crystals, layers of graphene reside in three equivalent, but distinct, stacking positions typically referred to as A, B, and C projections. The order in which the layers are stacked defines the electronic structure of the crystal, providing an exciting degree of freedom which can be exploited for designing graphitic materials with unusual properties including predicted high-temperature superconductivity and ferromagnetism. However, the lack of control of the stacking sequence limits most research to the stable ABA form of graphite. Here we demonstrate a strategy to control the stacking order using van der Waals technology. To this end, we first visualise the distribution of stacking domains in graphite films and then perform directional encapsulation of ABC-rich graphite crystallites with hexagonal boron nitride (hBN). We found that hBN-encapsulation which is introduced parallel to the graphite zigzag edges preserves ABC stacking, while encapsulation along the armchair edges transforms the stacking to ABA. The technique presented here should facilitate new research on the important properties of ABC graphite. ","cond-mat"
"1904.00592","ResUNet-a: a deep learning framework for semantic segmentation of   remotely sensed data","  Scene understanding of high resolution aerial images is of great importance for the task of automated monitoring in various remote sensing applications. Due to the large within-class and small between-class variance in pixel values of objects of interest, this remains a challenging task. In recent years, deep convolutional neural networks have started being used in remote sensing applications and demonstrate state of the art performance for pixel level classification of objects. \textcolor{black}{Here we propose a reliable framework for performant results for the task of semantic segmentation of monotemporal very high resolution aerial images. Our framework consists of a novel deep learning architecture, ResUNet-a, and a novel loss function based on the Dice loss. ResUNet-a uses a UNet encoder/decoder backbone, in combination with residual connections, atrous convolutions, pyramid scene parsing pooling and multi-tasking inference. ResUNet-a infers sequentially the boundary of the objects, the distance transform of the segmentation mask, the segmentation mask and a colored reconstruction of the input. Each of the tasks is conditioned on the inference of the previous ones, thus establishing a conditioned relationship between the various tasks, as this is described through the architecture's computation graph. We analyse the performance of several flavours of the Generalized Dice loss for semantic segmentation, and we introduce a novel variant loss function for semantic segmentation of objects that has excellent convergence properties and behaves well even under the presence of highly imbalanced classes.} The performance of our modeling framework is evaluated on the ISPRS 2D Potsdam dataset. Results show state-of-the-art performance with an average F1 score of 92.9\% over all classes for our best model. ","cs"
"1901.03493","Quantum error correction assisted quantum metrology without entanglement","  In this article we study the role that quantum resources play in quantum error correction assisted quantum metrology (QECQM) schemes. We show that there exist classes of such problems where entanglement is not necessary to retrieve noise free evolution and Heisenberg scaling in the long time limit. Over short time scales, noise free evolution is also possible even without any form of quantum correlations. In particular, for qubit probes, we show that whenever noise free quantum metrology is possible via QECQM, entanglement free schemes over long time scales and correlation free schemes over short time scales are always possible. ","quant-ph"
"2006.05680","Quantum-Critical Spin-Density Waves in Iron-Selenide High-Tc   Superconductors","  Hidden spin-density waves (hSDW) with Neel ordering vector (pi,pi) have been proposed recently as parent groundstates to electron-doped iron-selenide superconductors. Doping such groundstates can result in visible electron-type Fermi surface pockets and faint hole-type Fermi surface pockets at the corner of the folded Brillouin zone. A Cooper pair instability that alternates in sign between the electron-type and the hole-type Fermi surfaces has recently been predicted. The previous is due to the interaction of electrons and holes with hidden spin fluctuations connected with hSDW order that is near a quantum-critical point. Quantum criticality is tuned in by increasing the strength of Hund's Rule from the hSDW state. We find that the exchange of hidden spin fluctuations by electrons/holes in the critical hSDW state results in asymptotic freedom. In particular, the strength of spin-flip interactions becomes weaker and weaker on length scales that are shorter and shorter compared to the range of hSDW order. We then argue that string states that connect well-separated particle/hole excitations in the hSDW are robust. This suggests a picture where the hole degrees of freedom mentioned previously are confined. ","cond-mat"
"2007.04340","Information content in the redshift-space galaxy power spectrum and   bispectrum","  We present a Fisher information study of the statistical impact of galaxy bias and selection effects on the estimation of key cosmological parameters from galaxy redshift surveys; in particular, the angular diameter distance, Hubble parameter, and linear growth rate at a given redshift, the cold dark matter density, and the tilt and running of the primordial power spectrum. The line-of-sight-dependent selection contributions we include here are known to exist in real galaxy samples. We determine the maximum wavenumber included in the analysis by requiring that the next-order corrections to the galaxy power spectrum or bispectrum, treated here at next-to-leading and leading order, respectively, produce shifts of $\lesssim 0.25\sigma$ on each of the six cosmological parameters. With the galaxy power spectrum alone, selection effects can deteriorate the constraints severely, especially on the linear growth rate. Adding the galaxy bispectrum helps break parameter degeneracies significantly. We find that a joint power spectrum-bispectrum analysis of a Euclid-like survey can still measure the linear growth rate to 10% precision after complete marginalization over selection bias. We also discuss systematic parameter shifts arising from ignoring selection effects and/or other bias parameters, and emphasize that it is necessary to either control selection effects at the percent level or marginalize over them. We obtain similar results for the Roman Space Telescope and HETDEX. ","astro-ph"
"1901.07577","The evolution of ultra-diffuse galaxies in nearby galaxy clusters from   the Kapteyn IAC WEAVE INT Clusters Survey ($\texttt{KIWICS}$)","  We study the population of ultra-diffuse galaxies (UDGs) in a set of eight nearby ($z <$ 0.035) galaxy clusters, from the Kapteyn IAC WEAVE INT Clusters Survey ($\texttt{KIWICS}$). We report the discovery of 442 UDG candidates in our eight field of views, with 247 of these galaxies lying at projected distances < 1 R$_{200}$ from their host cluster. With the aim of testing theories about their formation, we study the scaling relations of UDGs comparing with different types of galaxies, finding that in the full parameter space they behave as dwarf galaxies and their colors do not seem to correlate with their effective radii. To investigate the influence of the environment on the evolution of UDGs we analyze their structural properties as functions of the projected clustercentric distance and the mass of their host cluster. We find no systematic trends for the stellar mass nor effective radius as function of the projected distance. However, the fraction of blue UDGs seems to be lower towards the center of clusters, and UDGs in the inner and outer regions of clusters have different S\'ersic index and axis ratio distributions. Specifically, the axis ratio distributions of the outer and inner UDGs resemble the axis ratio distributions of, respectively, late-type dwarfs and dwarf ellipticals in the Fornax Cluster suggesting an environmentally-driven evolution and another link between UDGs and dwarf galaxies. In general our results suggest strong similarities between UDGs and smaller dwarf galaxies in their structural parameters and their transformation within clusters. ","astro-ph"
"2004.05919","Block copolymer-nanorod co-assembly in thin films: effects of rod-rod   interaction and confinement","  Simulations and experiments of nanorods (NRs) show that co-assembly with block copolymer (BCP) melts leads to the formation of a superstructure of side-to-side NRs perpendicular to the lamellar axis. A mesoscopic model is validated against scanning electron microscopy (SEM) images of CdSe NRs mixed with polystyrene-block-poly(methyl methacrylate). It is then used to study the co-assembly of anisotropic nanoparticles (NPs) with a length in the same order of magnitude as the lamellar spacing. The phase diagram of BCP/NP is explored as well as the time evolution of the NR. NRs that are slightly larger than the lamellar spacing are found to rotate and organise side-to-side with a tilted orientation with respect to the interface. Strongly interacting NPs are found to dominate the co-assembly while weakly interacting nanoparticles are less prone to form aggregates and tend to form well-ordered configurations. ","cond-mat"
"1502.01368","Sparse Representation Classification Beyond L1 Minimization and the   Subspace Assumption","  The sparse representation classifier (SRC) has been utilized in various classification problems, which makes use of L1 minimization and works well for image recognition satisfying a subspace assumption. In this paper we propose a new implementation of SRC via screening, establish its equivalence to the original SRC under regularity conditions, and prove its classification consistency under a latent subspace model and contamination. The results are demonstrated via simulations and real data experiments, where the new algorithm achieves comparable numerical performance and significantly faster. ","stat"
"1703.03882","Generalized full matching and extrapolation of the results from a   large-scale voter mobilization experiment","  Matching is an important tool in causal inference. The method provides a conceptually straightforward way to make groups of units comparable on observed characteristics. The use of the method is, however, limited to situations where the study design is fairly simple and the sample is moderately sized. We illustrate the issue by revisiting a large-scale voter mobilization experiment that took place in Michigan for the 2006 election. We ask what the causal effects would have been if the treatments in the experiment were scaled up to the full population. Matching could help us answer this question, but no existing matching method can accommodate the six treatment arms and the 6,762,701 observations involved in the study. To offer a solution this and similar empirical problems, we introduce a generalization of the full matching method and an associated algorithm. The method can be used with any number of treatment conditions, and it is shown to produce near-optimal matchings. The worst case maximum within-group dissimilarity is no worse than four times the optimal solution, and simulation results indicate that its performance is considerably closer to the optimal solution on average. Despite its performance, the algorithm is fast and uses little memory. It terminates, on average, in linearithmic time using linear space. This enables investigators to construct well-performing matchings within minutes even in complex studies with samples of several million units. ","stat"
"2004.00344","Circuit complexity for generalised coherent states in thermal field   dynamics","  In this work, we study the circuit complexity for generalized coherent states in thermal systems by adopting the covariance matrix approach. We focus on the coherent thermal (CT) state, which is non-Gaussian and has a nonvanishing one-point function. We find that even though the CT state cannot be fully determined by the symmetric two-point function, the circuit complexity can still be computed in the framework of the covariance matrix formalism by properly enlarging the covariance matrix. Now the group generated by the unitary is the semiproduct of translation and the symplectic group. If the reference state is Gaussian, the optimal geodesic is still be generated by a horizontal generator such that the circuit complexity can be read from the generalized covariance matrix associated to the target state by taking the cost function to be $F_2$. For a single harmonic oscillator, we discuss carefully the complexity and its formation in the cases that the reference states are Gaussian and the target space is excited by a single mode or double modes. We show that the study can be extended to the free scalar field theory. ","hep-th"
"1909.05156","Robustness-optimized quantum error correction","  Quantum error correction codes are usually designed to correct errors regardless of their physical origins. In large-scale devices, this is an essential feature. In smaller-scale devices, however, the main error sources are often understood, and this knowledge could be exploited for more efficient error correction. Optimizing the quantum error correction protocol is therefore a promising strategy in smaller devices. Typically, this involves tailoring the protocol to a given decoherence channel by solving an appropriate optimization problem. Here we introduce a new optimization-based approach, which maximizes the robustness to faults in the recovery. Our approach is inspired by recent experiments, where such faults have been a significant source of logical errors. We illustrate this approach with a three-qubit model, and show how near-term experiments could benefit from more robust quantum error correction protocols. ","quant-ph"
"1904.00407","Application of Cluster Variation and Path Probability Methods to the   Tetragonal-Cubic Phase Transition in ZrO2","  Cluster variation method (CVM) and path probability method (PPM) have generally been employed to study replacive phase transitions in alloy systems. Recently, displacive phase transitions have been explored within the realm of replacive phase transition in the CVM theoretical framework by viewing displaced atoms as different atomic species, i.e., by converting a freedom of atomic displacement to a configurational freedom. The same methodology is applied to the PPM calculations in this work, and the kinetics of displacive phase transition from tetragonal to cubic phases in ZrO2 are investigated as well as their equilibrium states. ","cond-mat"
"2007.00006","The role of galactic dynamics in shaping the physical properties of   giant molecular clouds in Milky Way-like galaxies","  We examine the role of the large-scale galactic-dynamical environment in setting the properties of giant molecular clouds in Milky Way-like galaxies. We perform three high-resolution simulations of Milky Way-like discs with the moving-mesh hydrodynamics code Arepo, yielding a statistical sample of $\sim 80,000$ giant molecular clouds and $\sim 55,000$ HI clouds. We account for the self-gravity of the gas, momentum and thermal energy injection from supernovae and HII regions, mass injection from stellar winds, and the non-equilibrium chemistry of hydrogen, carbon and oxygen. By varying the external gravitational potential, we probe galactic-dynamical environments spanning an order of magnitude in the orbital angular velocity, gravitational stability, mid-plane pressure and the gradient of the galactic rotation curve. The simulated molecular clouds are highly overdense ($\sim 100\times$) and over-pressured ($\sim 25\times$) relative to the ambient interstellar medium. Their gravo-turbulent and star-forming properties are decoupled from the dynamics of the galactic mid-plane, so that the kpc-scale star formation rate surface density is related only to the number of molecular clouds per unit area of the galactic mid-plane. Despite this, the clouds display clear, statistically-significant correlations of their rotational properties with the rates of galactic shearing and gravitational free-fall. We find that galactic rotation and gravitational instability can influence their elongation, angular momenta, and tangential velocity dispersions. The lower pressures and densities of the HI clouds allow for a greater range of significant dynamical correlations, mirroring the rotational properties of the molecular clouds, while also displaying a coupling of their gravitational and turbulent properties to the galactic-dynamical environment. ","astro-ph"
"1907.10222","Local Stability of Einstein Metrics Under the Ricci Iteration","  We provide a sufficient condition for the local stability of closed Einstein manifolds of positive Ricci curvature under the Ricci iteration in terms of the spectrum of the Lichnerowicz Laplacian acting on divergence-free tensor fields. We use this result to consider the stability of several Einstein manifolds under the Ricci iteration, including symmetric spaces of compact type. ","math"
"2003.08923","RF-Rhythm: Secure and Usable Two-Factor RFID Authentication","  Passive RFID technology is widely used in user authentication and access control. We propose RF-Rhythm, a secure and usable two-factor RFID authentication system with strong resilience to lost/stolen/cloned RFID cards. In RF-Rhythm, each legitimate user performs a sequence of taps on his/her RFID card according to a self-chosen secret melody. Such rhythmic taps can induce phase changes in the backscattered signals, which the RFID reader can detect to recover the user's tapping rhythm. In addition to verifying the RFID card's identification information as usual, the backend server compares the extracted tapping rhythm with what it acquires in the user enrollment phase. The user passes authentication checks if and only if both verifications succeed. We also propose a novel phase-hopping protocol in which the RFID reader emits Continuous Wave (CW) with random phases for extracting the user's secret tapping rhythm. Our protocol can prevent a capable adversary from extracting and then replaying a legitimate tapping rhythm from sniffed RFID signals. Comprehensive user experiments confirm the high security and usability of RF-Rhythm with false-positive and false-negative rates close to zero. ","eess"
"1911.01333","Using image-extracted features to determine heart rate and blink   duration for driver sleepiness detection","  Heart rate and blink duration are two vital physiological signals which give information about cardiac activity and consciousness. Monitoring these two signals is crucial for various applications such as driver drowsiness detection. As there are several problems posed by the conventional systems to be used for continuous, long-term monitoring, a remote blink and ECG monitoring system can be used as an alternative. For estimating the blink duration, two strategies are used. In the first approach, pictures of open and closed eyes are fed into an Artificial Neural Network (ANN) to decide whether the eyes are open or close. In the second approach, they are classified and labeled using Linear Discriminant Analysis (LDA). The labeled images are then be used to determine the blink duration. For heart rate variability, two strategies are used to evaluate the passing blood volume: Independent Component Analysis (ICA); and a chrominance based method. Eye recognition yielded 78-92% accuracy in classifying open/closed eyes with ANN and 71-91% accuracy with LDA. Heart rate evaluations had a mean loss of around 16 Beats Per Minute (BPM) for the ICA strategy and 13 BPM for the chrominance based technique. ","cs"
"1812.11266","Online Low Frequency Oscillation Detection and Analysis System with an   Ensemble Filter","  The widespread deployment of phasor measurement unit (PMU) overpower systems makes it possible to monitor and analyze grid dynamics in real-time. Low-frequency oscillation is harmful to power system equipment and operation, and in the worst-case scenario may lead to cascading failures. Therefore, it is critical to detect and identify them as soon as they appear. This paper presents an online low-frequency oscillation detection and analysis (LFODA) system, which has the merit of significantly reducing the chance of false alarm via a voting schema and a time-serial filter. A novel algorithm based on density-based spatial clustering of applications with noise (DBSCAN) is proposed to classify oscillation modes as well as to group their corresponding buses/monitoring sites. Performance of the LFODA system is evaluated through experiments using both simulated and real-world PMU data. ","eess"
"1809.08482","Equivalence between a topological and non-topological quantum dot -   hybrid structures","  In this work, we demonstrate an equivalence on the single-electron transport properties between systems of different nature, a topological quantum system and a (conventional) non-topological one. Our results predicts that the Fano resonances obtained in a T-shaped double quantum dot system coupled to two normal leads and one superconducting lead (QD-QD-S) are identical to the obtained in a ring system composed of a quantum dot coupled to two Majorana bound states confined at the ends of a one dimensional topological superconductor nanowire (QD-MBSs). We show that the non-zero value of the Fano (anti)resonance in the conductance of the QD-MBSs systems is due to a complex Fano factor qM , which is identical to the complex Fano factor qS of the QD-QD-S. The complex nature of qS can be understood as a sign of a phase introduced by the superconducting lead in the QD-QD-S. It is because of this phase that the equivalence between the QD-QD-S and the QD-MBSs is possible. We believe that our results can motivate further theoretical and experimental works toward the understanding of transport properties of topological quantum hybrid structures from conventional non-topological quantum systems. ","cond-mat"
"1807.05546","Entangling three qubits without ever touching","  All identical particles are inherently correlated from the outset, regardless of how far apart their creation took place. In this paper, this fact is used for extraction of entanglement from independent particles unaffected by any interactions. Specifically, we are concerned with operational schemes for generation of all tripartite entangled states, essentially the GHZ state and the W state, which prevent the particles from touching one another over the entire evolution. The protocols discussed in the paper require only three particles in linear optical setups with equal efficiency for boson, fermion or anyon statistics. Within this framework indistinguishability of particles presents itself as a useful resource of entanglement accessible for practical applications. ","quant-ph"
"2003.02937","A Nearest-Neighbor Based Nonparametric Test for Viral Remodeling in   Heterogeneous Single-Cell Proteomic Data","  An important problem in contemporary immunology studies based on single-cell protein expression data is to determine whether cellular expressions are remodeled post infection by a pathogen. One natural approach for detecting such changes is to use non-parametric two-sample statistical tests. However, in single-cell studies, direct application of these tests is often inadequate because single-cell level expression data from uninfected populations often contains attributes of several latent sub-populations with highly heterogeneous characteristics. As a result, viruses often infect these different sub-populations at different rates in which case the traditional nonparametric two-sample tests for checking similarity in distributions are no longer conservative. We propose a new nonparametric method for Testing Remodeling Under Heterogeneity (TRUH) that can accurately detect changes in the infected samples compared to possibly heterogeneous uninfected samples. Our testing framework is based on composite nulls and is designed to allow the null model to encompass the possibility that the infected samples, though unaltered by the virus, might be dominantly arising from under-represented sub-populations in the baseline data. The TRUH statistic, which uses nearest neighbor projections of the infected samples into the baseline uninfected population, is calibrated using a novel bootstrap algorithm. We demonstrate the non-asymptotic performance of the test via simulation experiments and derive the large sample limit of the test statistic, which provides theoretical support towards consistent asymptotic calibration of the test. We use the TRUH statistic for studying remodeling in tonsillar T cells under different types of HIV infection and find that unlike traditional tests, TRUH based statistical inference conforms to the biologically validated immunological theories on HIV infection. ","stat"
"2007.11226","Primordial black hole origin for thermal gamma-ray bursts","  A binary black hole (BH) astrophysical scenario where a mass-constrained ($10^{-17} - 10^{-11}$ solar masses) primordial black hole (PBH) undergoes a spiral fall onto its heavier component (such as a supermassive black hole (SMBH)) is described as an intense gamma-ray emission event. As the infalling BH approaches the Schwarschild surface of its companion, the PBH evaporation rate becomes more strongly enhanced due to the PBH blueshifted emission towards the SMBH, until a complete evaporation occurs before reaching the central BH horizon. Accordingly, our numerically calculated PBH flux density $F_{\nu}$ and $\nu F_{\nu}$ fluence spectrum show an increasing Planck-like spectral dependence consistent with the first instants of thermal-dominant gamma-ray bursts (GRBs), providing a plausible confirmation of such low-mass primordial ultracompact objects. ","astro-ph"
"2003.07804","Atomic Scale Insights Into The Mechanical Characteristics of Monolayer   1T-Titanium Disulphide: A Molecular Dynamics Study","  In this work, we report on the mechanical responses and fracture behavior of pristine and defected monolayer 1T-Titanium Disulfide using classical molecular dynamics simulation. We investigated the effect of temperature, strain rate and defect ratio on the uniaxial tensile properties in both armchair and zigzag direction. We found that monolayer TiS2 shows isotropic uniaxial tensile properties except for failure strain which is greater in zigzag direction than armchair direction. We also observed a negative correlation of ultimate tensile strength, failure strain and young's modulus with temperature and defect ratio. Results depicts that strain rate has no effect on the young's modulus of monolayer TiS2 but higher strain rate results in higher ultimate tensile strength and failure strain. ","cond-mat"
"1901.07374","A damage and failure implementation for the simulation of ductile solids   with Total-Lagrangian Smooth Particle Hydrodynamics","  Smooth-Particle-Hydrodynamics is gaining popularity for the simulation of solids subjected to machining, wear, and impacts. Its attractiveness is due to its abilities to simulate problems involving large deformations resulting from the absence of mesh, recent improvements in stability conferred by the development of Total-Lagrangian version of SPH (TLSPH), but also its availability in the open-source software LAMMPS. This implementation features a damage model similar to the `pseudo-spring' method which creates instabilities when used for the simulation of ductile materials. In this contribution, we present a new damage and failure model for TLSPH suitable for ductile materials. In this implementation, not only the constitutive equations but also the TLSPH approximation are modified in order to take into account the change in material properties as well as the presence of discontinuities due to the initiation and growth of damage. This new approach is accompanied by the implementation of the Cockroft-Latham, Johnson-Cook, and Gurson-Tvergaard-Needleman damage criteria. The predictive capabilities of the implementation of this new damage model are then tested and compared against both experimental and results of Finite Element simulations. ","cond-mat"
"1909.09408","ACFNet: Attentional Class Feature Network for Semantic Segmentation","  Recent works have made great progress in semantic segmentation by exploiting richer context, most of which are designed from a spatial perspective. In contrast to previous works, we present the concept of class center which extracts the global context from a categorical perspective. This class-level context describes the overall representation of each class in an image. We further propose a novel module, named Attentional Class Feature (ACF) module, to calculate and adaptively combine different class centers according to each pixel. Based on the ACF module, we introduce a coarse-to-fine segmentation network, called Attentional Class Feature Network (ACFNet), which can be composed of an ACF module and any off-the-shell segmentation network (base network). In this paper, we use two types of base networks to evaluate the effectiveness of ACFNet. We achieve new state-of-the-art performance of 81.85% mIoU on Cityscapes dataset with only finely annotated data used for training. ","cs"
"2004.08109","Impact of the energetic landscape on polariton condensates propagation   along a coupler","  Polariton condensates propagation is strongly dependent on the particular energy landscape the particles are moving upon, in which the geometry of the pathway laid for their movement plays a crucial role. Bends in the circuits trajectories affect the condensates speed and oblique geometries introduce an additional discretization of the polaritons momenta due to the mixing of short and long axis wavevectors on the propagating eigenvalues. In this work, we study the nature of the propagation of condensates along the arms of a polariton coupler, by a combination of time-resolved micro-tomography measurements and a theoretical model based on a mean field approximation where condensed polaritons are described by an equation for the slow varying amplitude of the polariton field coupled to an equation for the density of incoherent excitons. ","cond-mat"
"2008.01711","Radar Adaptive Detection Architectures for Heterogeneous Environments","  In this paper, four adaptive radar architectures for target detection in heterogeneous Gaussian environments are devised. The first architecture relies on a cyclic optimization exploiting the Maximum Likelihood Approach in the original data domain, whereas the second detector is a function of transformed data which are normalized with respect to their energy and with the unknown parameters estimated through an Expectation-Maximization-based alternate procedure. The remaining two architectures are obtained by suitably combining the estimation procedures and the detector structures previously devised. Performance analysis, conducted on both simulated and measured data, highlights that the architecture working in the transformed domain guarantees the constant false alarm rate property with respect to the interference power variations and a limited detection loss with respect to the other detectors, whose detection thresholds nevertheless are very sensitive to the interference power. ","eess"
"1903.00626","Secrecy Performance of Antenna-Selection-Aided MIMOME Channels with   BPSK/QPSK Modulations","  This paper studies the secrecy performance of multiple-input multiple-output (MIMO) wiretap channels, also termed as multiple-input multiple-output multiple-eavesdropper (MIMOME) channels, under transmit antenna selection (TAS) and BPSK/QPSK modulations. In the main channel between the transmitter and the legitimate receiver, a single transmit antenna is selected to maximizes the instantaneous Signal to Noise Ratio (SNR) at the receiver. At the receiver and the eavesdropper, selection combination (SC) is utilized. By assuming Rayleigh flat fading, we first derive the closed-form approximated expression for the ergodic secrecy rate when the channel state information of the eavesdropper (CSIE) is available at the transmitter. Next, analytical formulas for the approximated and asymptotic secrecy outage probability (SOP) are also developed when CSIE is unavailable. Besides theoretical derivations, simulation results are provided to demonstrate the approximation precision of the derived results. Furthermore, the asymptotic results reveal that the secrecy diversity order degrades into 0 due to the finitealphabet inputs, which is totally different from that driven by the Gaussian inputs. ","eess"
"2001.06267","Designing unimodular sequence with good auto-correlation properties via   Block Majorization-Minimization method","  Constant modulus sequence having lower side-lobe levels in its auto-correlation function plays an important role in the applications like SONAR, RADAR and digital communication systems. In this paper, we consider the problem of minimizing the Integrated Sidelobe Level (ISL) metric, to design a complex unimodular sequence of any length. The underlying optimization problem is solved iteratively using the Block Majorization-Minimization(MM) technique, which ensures that the resultant algorithm to be monotonic. We also show a computationally efficient way to implement the algorithm using Fast Fourier Transform (FFT) and Inverse Fast Fourier Transform (IFFT) operations. Numerical experiments were conducted to compare the proposed algorithm with the state-of-the art algorithms and was found that the proposed algorithm performs better in terms of computational complexity and speed of convergence. ","eess"
"1911.05064","Classification of materials with phonon angular momentum and microscopic   origin of angular momentum","  We group materials into five symmetry classes and determine in which of these classes will phonons generically carry angular momentum. In some classes of materials, phonons acquire angular momentum via the forces induced by relative displacements of atoms out of their equilibrium positions. However, for other materials, such as ferromagnetic iron, phonon angular momentum arises from the forces induced by relative velocities of atoms. These latter effects are driven by the spin-orbit interaction. ","cond-mat"
"2006.11761","Circuit implementation of bucket brigade qRAM for quantum state   preparation","  In this short review I aim to explain how we can construct a circuit implementation of the bucketbrigade qRAM first proposed in [1]. Used with classical data, this qRAM model can be used incombination with the quantum accessible data structure [2] to prepare arbitrary quantum statesquickly and repeatedly, once the data to be prepared is in memory ","quant-ph"
"2003.08491","Decay Properties of Conventional and Hybrid $B_c$ Mesons","  Spectrum, radial wave functions at origin, decay constants, weak decay widths, life time and branching ratios for radially excited conventional and hybrid $B_c$ mesons are derived within non-relativistic quark model framework employing Schr$\ddot{\textrm{o}}$dinger equation by shooting method. Calculated results are compared with available theoretical results and experimental observations. This work may help in identifying the new discovered $B_c$ meson states at CDF ,LHCb and ATLAS. ","hep-ph"
"1911.11809","Constraints on Neutrino Emission from Nearby Galaxies Using the 2MASS   Redshift Survey and IceCube","  The distribution of galaxies within the local universe is characterized by anisotropic features. Observatories searching for the production sites of astrophysical neutrinos can take advantage of these features to establish directional correlations between a neutrino dataset and overdensities in the galaxy distribution in the sky. The results of two correlation searches between a seven-year time-integrated neutrino dataset from the IceCube Neutrino Observatory, and the 2MASS Redshift Survey (2MRS) catalog are presented here. The first analysis searches for neutrinos produced via interactions between diffuse intergalactic Ultra-High Energy Cosmic Rays (UHECRs) and the matter contained within galaxies. The second analysis searches for low-luminosity sources within the local universe, which would produce subthreshold multiplets in the IceCube dataset that directionally correlate with galaxy distribution. No significant correlations were observed in either analyses. Constraints are presented on the flux of neutrinos originating within the local universe through diffuse intergalactic UHECR interactions, as well as on the density of standard candle sources of neutrinos at low luminosities. ","astro-ph"
"1712.07417","Quantum approaches to music cognition","  Quantum cognition emerged as an important discipline of mathematical psychology during the last two decades. Using abstract analogies between mental phenomena and the formal framework of physical quantum theory, quantum cognition demonstrated its ability to resolve several puzzles from cognitive psychology. Until now, quantum cognition essentially exploited ideas from projective (Hilbert space) geometry, such as quantum probability or quantum similarity. However, many powerful tools provided by physical quantum theory, e.g., symmetry groups have not been utilized in the field of quantum cognition research sofar. Inspired by seminal work by Guerino Mazzola on the symmetries of tonal music, our study aims at elucidating and reconciling static and dynamic tonal attraction phenomena in music psychology within the quantum cognition framework. Based on the fundamental principles of octave equivalence, fifth similarity and transposition symmetry of tonal music that are reflected by the structure of the circle of fifths, we develop different wave function descriptions over this underlying tonal space. We present quantum models for static and dynamic tonal attraction and compare them with traditional computational models in musicology. Our approach replicates and also improves predictions based on symbolic models of music perception. ","q-bio"
"1907.05135","Towards a Better Understanding of Randomized Greedy Matching","  There has been a long history for studying randomized greedy matching algorithms since the work by Dyer and Frieze~(RSA 1991). We follow this trend and consider the problem formulated in the oblivious setting, in which the algorithm makes (random) decisions that are essentially oblivious to the input graph.   We revisit the \textsf{Modified Randomized Greedy (MRG)} algorithm by Aronson et al.~(RSA 1995) that is proved to be $(0.5+\epsilon)$-approximate. In particular, we study a weaker version of the algorithm named \textsf{Random Decision Order (RDO)} that in each step, randomly picks an unmatched vertex and matches it to an arbitrary neighbor if exists. We prove the \textsf{RDO} algorithm is $0.639$-approximate and $0.531$-approximate for bipartite graphs and general graphs respectively. As a corollary, we substantially improve the approximation ratio of \textsf{MRG}.   Furthermore, we generalize the \textsf{RDO} algorithm to the edge-weighted case and prove that it achieves a $0.501$ approximation ratio. This result solves the open question by Chan et al.~(SICOMP 2018) about the existence of an algorithm that beats greedy in this setting. As a corollary, it also solves the open questions by Gamlath et al.~(SODA 2019) in the stochastic setting. ","cs"
"1908.04827","A bayesian-like approach to derive chemical abundances in Type-2 Active   Galactic Nuclei based on photoionization models","  We present a new methodology for the analysis of the emission lines of the interstellar medium in the Narrow Line Regions around type-2 Active Galactic Nuclei. Our aim is to provide a recipe that can be used for large samples of objects in a consistent way using different sets of optical emission-lines that takes into the account possible variations from the (O/H)-(N/O) relation to use [N II] lines. Our approach consists of a bayesian-like comparison between certain observed emission-line ratios sensitive to total oxygen abundance, nitrogen-to-oxygen ratio and ionization parameter with the predictions from a large grid of photoionization models calculated under the most usual conditions in this environment. We applied our method to a sample of Seyfert 2 galaxies with optical emission-line fluxes and determinations of their chemical properties from detailed models in the literature. Our results agree within the errors with other results and confirm the high metallicity of the objects of the sample, with N/O values consistent wit a large secondary production of N, but with a large dispersion. The obtained ionization parameters for this sample are much larger than those for star-forming object at the same metallicity. ","astro-ph"
"1907.08230","How many different clonotypes do immune repertoires contain?","  Immune repertoires rely on diversity of T-cell and B-cell receptors to protect us against foreign threats. The ability to recognize a wide variety of pathogens is linked to the number of different clonotypes expressed by an individual. Out of the estimated $\sim 10^{12}$ different B and T cells in humans, how many of them express distinct receptors? We review current and past estimates for these numbers. We point out a fundamental limitation of current methods, which ignore the tail of small clones in the distribution of clone sizes. We show that this tail strongly affects the total number of clones, but it is impractical to access experimentally. We propose that combining statistical models with mechanistic models of lymphocyte clonal dynamics offers possible new strategies for estimating the number of clones. ","q-bio"
"1906.08549","Designing Game of Theorems","  ""Theorem proving is similar to the game of Go. So, we can probably improve our provers using deep learning, like DeepMind built the super-human computer Go program, AlphaGo."" Such optimism has been observed among participants of AITP2017. But is theorem proving really similar to Go? In this paper, we first identify the similarities and differences between them and then propose a system in which various provers keep competing against each other and changing themselves until they prove conjectures provided by users. ","cs"
"2003.03638","Minimizing the number of optimizations for efficient community dynamic   flux balance analysis","  Dynamic flux balance analysis uses a quasi-steady state assumption to calculate an organism's metabolic activity at each time-step of a dynamic simulation, using the well-known technique of flux balance analysis. For microbial communities, this calculation is especially costly and involves solving a linear constrained optimization problem for each member of the community at each time step. However, this is unnecessary and inefficient, as prior solutions can be used to inform future time steps. Here, we show that a basis for the space of internal fluxes can be chosen for each microbe in a community and this basis can be used to simulate forward by solving a relatively inexpensive system of linear equations at most time steps. We can use this solution as long as the resulting metabolic activity remains within the optimization problem's constraints (i.e. the solution to the linear system of equations remains a feasible to the linear program). As the solution becomes infeasible, it first becomes a feasible but degenerate solution to the optimization problem, and we can solve a different but related optimization problem to choose an appropriate basis to continue forward simulation. We demonstrate the efficiency and robustness of our method by comparing with currently used methods on a four species community, and show that our method requires at least $91\%$ fewer optimizations to be solved. For reproducibility, we prototyped the method using Python. Source code is available at \verb|https://github.com/jdbrunner/surfin_fba|. ","q-bio"
"2004.10414","Theoretical Analysis of Multi Integrating RX Front-Ends for Lossy   Broad-Band Channels","  In this paper, we present a theoretical analysis of different integrating front-ends employed in broad-band communications through \textit{lossy} channels. Time-domain receivers for broad-band communication typically deal with large integrated noise due to its high bandwidth of operation. However, unlike traditional wireline systems that are typically not noise-limited, channels with high channel-loss render the input signal swing to be very small imposing several challenges in RX design as the circuits operate in the noise-limited regime. This simultaneous high integrated noise and low signal-swing limits the maximum achievable data-rate for a target bit-error-rate (BER) and deteriorates the energy-efficiency of the RX. In this work, transient, noise and gain performance of different standard signaling blocks have been obtained with closed-form expressions and are validated through spice-simulations. Multi-integrator cascade has been proposed which provides significant gain with relatively lower power consumption than the standard gain elements. Also, maximum achievable data-rate and optimum energy efficiency for different channel losses have been obtained theoretically for different architectures revealing their advantages and limitations. All the pertaining circuits have been designed in 65 nm CMOS process with a 1 V supply voltage. ","eess"
"2001.03092","De Novo Assembly of Uca minax Transcriptome from Next Generation   Sequencing","  High-throughput cDNA sequencing (RNA-seq) is a very powerful technique to quantify gene expression in an unbiased way. The Crustacean family is among the groups of organisms sparsely represented in current genomic databases. Here we present transcriptome data from Uca minax (red-jointed fiddler crab) as an opportunity to extend our knowledge. Next generation sequencing was performed on six tissue samples from Uca minax using the Illumina HiSeq system. Six Transcriptome libraries were created using Trinity; a free, open-source software tool for de novo transcriptome assembly of high-throughput mRNA sequencing (RNA-seq) data with the absence of a reference genome. In addition, several tools that aid in management of data were used, such as RSEM, Bowtie, Blast, and IGV; a tool for visualizing RNA-seq analysis results. Fast quality control (FastQC) analysis of the raw sequenced files revealed that both adapter and PCR primer sequences were prevalently present, which may require a preprocessing step. ","q-bio"
"1904.03531","Decoding hand kinematics from population responses in sensorimotor   cortex during grasping","  The hand, a complex effector comprising dozens of degrees of freedom of movement, endows us with the ability to flexibly, precisely, and effortlessly interact with objects. The neural signals associated with dexterous hand movements in primary motor cortex (M1) and somatosensory cortex (SC) have received comparatively less attention than have those that are associated with proximal limb control. To fill this gap, we trained three monkeys to grasp objects varying in size, shape and orientation while tracking their hand postures and recording single-unit activity from M1 and SC. We then decoded their hand kinematics across 30 joints from population activity in these areas. We found that we could accurately decode kinematics with a small number of neural signals and that performance was higher for decoding joint angles than joint angular velocities, in contrast to what has been found with proximal limb decoders. We conclude that cortical signals can be used for dexterous hand control in brain machine interface applications and that postural representations in SC may be exploited via intracortical stimulation to close the sensorimotor loop. ","q-bio"
"1910.04932","Measuring Impact of Climate Change on Tree Species: analysis of JSDM on   FIA data","  One of the first beings affected by changes in the climate are trees, one of our most vital resources. In this study tree species interaction and the response to climate in different ecological environments is observed by applying a joint species distribution model to different ecological domains in the United States. Joint species distribution models are useful to learn inter-species relationships and species response to the environment. The climates' impact on the tree species is measured through species abundance in an area. We compare the model's performance across all ecological domains and study the sensitivity of the climate variables. With the prediction of abundances, tree species populations can be predicted in the future and measure the impact of climate change on tree populations. ","q-bio"
"1908.06627","T-duality constraint on R-R couplings","  It has been speculated that the metric, $B$-field and dilaton couplings in the low energy effective action of string theory at any order of $\alpha'$ may be found by imposing the gauge symmetries and by imposing the T-duality constraint on the effective action. We speculate that the Ramond-Ramond (R-R) couplings may also be found in this approach. In this paper, we perform the calculations explicitly at the supergravity level and found the democratic form of the R-R couplings. ","hep-th"
"1904.05383","Trusted CI Experiences in Cybersecurity and Service to Open Science","  This article describes experiences and lessons learned from the Trusted CI project, funded by the US National Science Foundation to serve the community as the NSF Cybersecurity Center of Excellence. Trusted CI is an effort to address cybersecurity for the open science community through a single organization that provides leadership, training, consulting, and knowledge to that community. The article describes the experiences and lessons learned of Trusted CI regarding both cybersecurity for open science and managing the process of providing centralized services to a broad and diverse community. ","cs"
"1906.09732","Dynamic Palindrome Detection","  Lately, there is a growing interest in dynamic string matching problems. Specifically, the dynamic Longest Common Factor problem has been researched and some interesting results has been reached. In this paper we examine another classic string problem in a dynamic setting - finding the longest palindrome substring of a given string. We show that the longest palindrome can be maintained in poly-logarithmic time per symbol edit. ","cs"
"1903.05464","Channel Protection using Random Modulation","  This paper shows that modulation protects a bandlimited signal against convolutive interference. A signal $s(t)$, bandlimited to $B$Hz, is modulated (pointwise multiplied) with a known random sign sequence $r(t)$, alternating at a rate $Q$, and the resultant \textit{spread spectrum} signal $s(t) \odot r(t)$ is convolved against an $M$-tap channel impulse response $h(t)$ to yield the observed signal $y(t)= (s(t)\odot r(t))\circledast h(t),$ where $\odot$ and $\circledast$ denote pointwise multiplication, and circular convolution, respectively.   We show that both $s(t)$, and $h(t)$ can be provably recovered using a simple gradient descent scheme by alternating the binary waveform $r(t)$ at a rate $Q \gtrsim B + M$(to within log factors and a signal coherences) and sampling $y(t)$ at a rate $Q$. We also present a comprehensive set of phase transitions to depict the trade-off between $Q$, $M$, and $B$ for successful recovery. Moreover, we show stable recovery results under noise. ","eess"
"1906.12044","Steady-state squeezing and entanglement in a dissipatively coupled NOPO   network","  We investigate the steady-state photon-number squeezing and quantum entanglement in a network of nondegenerate optical parametric oscillators (NOPOs). We treat each NOPO with Shen's Raman laser model, whose lasing mode provides a photon-number-squeezed state. Two dissipatively coupled NOPOs satisfy Hillery-Zubairy's $HZ1$ entanglement criterion if they are pumped far above the threshold and the dissipative coupling is sufficiently larger than the NOPO cavity loss. ","quant-ph"
"1805.01353","Electroweak and QCD corrections to $Z$-boson production with one $b$ jet   in a massive 5 Flavor Scheme","  We compute the $O(\alpha_s \alpha^2)$ and $O(\alpha_s^2 \alpha)$ contributions to the production cross section of a $Z$ boson with one $b$ jet at the Large Hadron Collider (LHC), and study their phenomenological relevance for LHC physics. The accurate prediction of hadronic $Z+b$-jet production is needed to control a background that greatly affects both the measurement of Higgs-boson properties and searches of new physics at the LHC. At the same time it could enable the first precise measurement of the $b$-quark parton distribution function. In this context $b$-quark mass effects become relevant and need to be studied with care, both at the level of the hard process and at the level of the initial- and final-state parton evolution. It is the aim of this paper to explore some of these issues in the framework of a massive 5 Flavor Scheme and to assess the need for both the inclusion of electroweak corrections, in addition to QCD corrections, and $b$-quark mass effects in the prediction of total and differential cross sections for hadronic $Z+b$-jet production. ","hep-ph"
"2005.11499","Flexible Two-point Selection Approach for Characteristic Function-based   Parameter Estimation of Stable Laws","  Stable distribution is one of the attractive models that well describes fat-tail behaviors and scaling phenomena in various scientific fields. The approach based upon the method of moments yields a simple procedure for estimating stable law parameters with the requirement of using momental points for the characteristic function, but the selection of points is only poorly explained and has not been elaborated. We propose a new characteristic function-based approach by introducing a technique of selecting plausible points, which could bring the method of moments available for practical use. Our method outperforms other state-of-art methods that exhibit a closed-form expression of all four parameters of stable laws. Finally, the applicability of the method is illustrated by using several data of financial assets. Numerical results reveal that our approach is advantageous when modeling empirical data with stable distributions. ","stat"
"1906.00728","Awareness as inference in a higher-order state space","  Humans have the ability to report the contents of their subjective experience - we can say to each other, ""I am aware of X"". The decision processes that support these reports about mental contents remain poorly understood. In this article I propose a computational framework that characterises awareness reports as metacognitive decisions (inference) about a generative model of perceptual content. This account is motivated from the perspective of how flexible hierarchical state spaces are built during learning and decision-making. Internal states supporting awareness reports, unlike those covarying with perceptual contents, are simple and abstract, varying along a one-dimensional continuum from absent to present. A critical feature of this architecture is that it is both higher-order and asymmetric: a vast number of perceptual states is nested under ""present"", but a much smaller number of possible states nested under ""absent"". Via simulations I show that this asymmetry provides a natural account of observations of ""global ignition"" in brain imaging studies of awareness reports. ","q-bio"
"1910.02680","Properties of excited charmed-bottom mesons","  We calculate the spectrum of $B_c$ mesons using a non-relativistic quark potential model. Using the calculated wave functions, we compute the radiative widths of $B_c$ excited states. The strong decay widths are calculated in a modified $^3P_0$ model, assuming harmonic oscillator wave functions. The hadronic transition rates of $B_c$ mesons are calculated using the Kuang-Yan approach. These results are used to determine branching ratios of possible decay channels of several $B_c$ excited states. Calculated branching ratios are then combined with production cross section of $B_c$ states at the LHC to suggest strategies to find missing excited states of $B_c$ mesons. ","hep-ph"
"1904.06213","Generalized Presentation Attack Detection: a face anti-spoofing   evaluation proposal","  Over the past few years, Presentation Attack Detection (PAD) has become a fundamental part of facial recognition systems. Although much effort has been devoted to anti-spoofing research, generalization in real scenarios remains a challenge. In this paper we present a new open-source evaluation framework to study the generalization capacity of face PAD methods, coined here as face-GPAD. This framework facilitates the creation of new protocols focused on the generalization problem establishing fair procedures of evaluation and comparison between PAD solutions. We also introduce a large aggregated and categorized dataset to address the problem of incompatibility between publicly available datasets. Finally, we propose a benchmark adding two novel evaluation protocols: one for measuring the effect introduced by the variations in face resolution, and the second for evaluating the influence of adversarial operating conditions. ","cs"
"1904.08451","On Topological Properties of the Set of Stabilizing Feedback Gains","  This work presents a fairly complete account on various topological and metrical aspects of feedback stabilization for single-input-single-output (SISO) continuous and discrete time linear-time-invariant (LTI) systems. In particular, we prove that the set of stabilizing output feedback gains for a SISO system with n states has at most $\lceil{\frac{n}{2}}\rceil$ connected components. Furthermore, our analysis yields an algorithm for determining intervals of stabilizing gains for general continuous and discrete LIT systems; the proposed algorithm also computes the number of unstable roots in each unstable interval. Along the way, we also make a number of observations on the set of stabilizing state feedback gains for MIMO systems. ","cs"
"1906.06269","Equivalence between non-Markovian dynamics and correlation backflows","  The information encoded into an open quantum system that evolves under a Markovian dynamics is always monotonically non-increasing. Nonetheless, for a given quantifier of the information contained in the system, it is in general not clear if for all non-Markovian dynamics it is possible to observe a non-monotonic evolution of this quantity, namely a backflow. We address this problem by considering correlations of finite-dimensional bipartite systems. For this purpose, we consider a class of correlation measures and prove that if the dynamics is non-Markovian there exists at least one element from this class that provides a correlation backflow. Moreover, we provide a set of initial probe states that accomplish this witnessing task. This result provides the first one-to-one relation between non-Markovian dynamics of finite-dimensional quantum systems and correlation backflows. ","quant-ph"
"1811.03018","Neutrino predictions from a left-right symmetric flavored extension of   the standard model","  We propose a left-right symmetric electroweak extension of the Standard Model based on the $\Delta \left( 27\right)$ family symmetry. The masses of all electrically charged Standard Model fermions lighter than the top quark are induced by a Universal Seesaw mechanism mediated by exotic fermions. The top quark is the only Standard Model fermion to get mass directly from a tree level renormalizable Yukawa interaction, while neutrinos are unique in that they get calculable radiative masses through a low-scale seesaw mechanism. The scheme has generalized $\mu-\tau$ symmetry and leads to a restricted range of neutrino oscillations parameters, with a nonzero neutrinoless double beta decay amplitude lying at the upper ranges generically associated to normal and inverted neutrino mass ordering. ","hep-ph"
"2006.10294","Cardy Limits of 6d Superconformal Theories","  We explore the supersymmetric partition functions of 6d SCFTs on $\mathbb{R}^4\times T^2$ with non-vanishing charges for compatible global symmetries. We utilize the elliptic genera for self-dual strings and compute the free energy of 6d SCFTs in the Cardy limit. For a 6d (2,0) theory on $N$ M5-brane, we obtain the free energy proportional to $N^3$. We find that the origin of $N^3$ comes from the condensation of the self-dual strings, whose total number is proportional to ${N^3-N\over 6}$. We further extend our analysis to the general E-string theory and obtain its Cardy free energy. ","hep-th"
"1705.09403","Sensitivity limits on heavy-light mixing $|U_{\mu N}|^2$ from lepton   number violating $B$ meson decays","  We consider the lepton number violating decays $B \to \mu^{\pm} \mu^{\pm} \pi^{\mp}$ and $B \to D^{(*)} \mu^{\pm} \mu^{\pm} \pi^{\mp}$ which may be detected at LHCb and Belle-II experiments; and $B \to \mu^{\pm} \mu^{\pm} e^{\mp} \nu$ and $B \to D^{(*)} \mu^{\pm} \mu^{\pm} e^{\mp} \nu$ decays which may be detected at Belle-II experiment. The projected total number of produced $B$ mesons is $4.8 \times 10^{12}$ at LHCb upgrade and $5 \times 10^{10}$ at Belle-II. For the case that the above decays are not detected, we deduce the new upper bounds (sensitivity limits) for the mixing parameter $|U_{\mu N}|^2$ of heavy sterile neutrino with sub-eV light neutrino, as a function of the sterile neutrino mass in the interval $1.75 \ {\rm GeV} < M_N < 5.0 \ {\rm GeV}$. We take into account the probability of decay of the sterile neutrino $N$ within the detector, taking as the effective detector length $L=2.3 \ m$ at LCHb upgrade and $L=1 \ m$ at Belle-II. In the interval $1.75 \ {\rm GeV} < M_N < 3 \ {\rm GeV}$, the most stringent bounds can be obtained with the decays $B \to \mu^{\pm} \mu^{\pm} \pi^{\mp}$ at LHCb upgrade. The sensitivity limits are expected to be in general more stringent at LHCb upgrade than at Belle-II, principally because the number of produced $B$ mesons in LHCb upgrade is expected to be by about two orders of magnitude larger than at Belle-II. We conclude that the LHCb upgrade and Belle-II experiments have the potential to either find a new heavy Majorana neutrino $N$, or to improve significantly the sensitivity limits (upper bounds) on the heavy-light mixing parameter $|U_{\mu N}|^2$, particularly in the mass range $1.75 \ {\rm GeV} < M_N < 3 \ {\rm GeV}$. This work is a continuation and refinement of our previous work [1] on the subject. ","hep-ph"
"1904.03893","Solutions with prescribed local blow-up surface for the nonlinear wave   equation","  We prove that any sufficiently differentiable space-like hypersurface of ${\mathbb R}^{1+N} $ coincides locally around any of its points with the blow-up surface of a finite-energy solution of the focusing nonlinear wave equation $\partial_{tt} u - \Delta u=|u|^{p-1} u$ on ${\mathbb R} \times {\mathbb R} ^N$, for any $1\leq N\leq 4$ and $1 < p \le \frac {N+2} {N-2}$. We follow the strategy developed in our previous work [arXiv 1812.03949] on the construction of solutions of the nonlinear wave equation blowing up at any prescribed compact set. Here to prove blowup on a local space-like hypersurface, we first apply a change of variable to reduce the problem to blowup on a small ball at $t=0$ for a transformed equation. The construction of an appropriate approximate solution is then combined with an energy method for the existence of a solution of the transformed problem that blows up at $t=0$. To obtain a finite-energy solution of the original problem from trace arguments, we need to work with $H^2\times H^1$ solutions for the transformed problem. ","math"
"2003.11156","Seabed classification using physics-based modeling and machine learning","  In this work model-based methods are employed along with machine learning techniques to classify sediments in oceanic environments based on the geoacoustic properties of a two-layer seabed. Two different scenarios are investigated. First, a simple low-frequency case is set up, where the acoustic field is modeled with normal modes. Four different hypotheses are made for seafloor sediment possibilities and these are explored using both various machine learning techniques and a simple matched-field approach. For most noise levels, the latter has an inferior performance to the machine learning methods. Second, the high-frequency model of the scattering from a rough, two-layer seafloor is considered. Again, four different sediment possibilities are classified with machine learning. For higher accuracy, 1D Convolutional Neural Networks (CNNs) are employed. In both cases we see that the machine learning methods, both in simple and more complex formulations, lead to effective sediment characterization. Our results assess the robustness to noise and model misspecification of different classifiers. ","eess"
"1809.08404","Combinatorial Designs for Deep Learning","  Deep learning is a machine learning methodology using multi-layer neural network. A multi-layer neural network can be regarded as a chain of complete bipartite graphs. The nodes of the first partita is the input layer and the last is the output layer. The edges of a bipartite graph function as weights which are represented as a matrix. The values of i-th partita are computed by multiplication of the weight matrix and values of (i-1)-th partita. Using mass training and teacher data, the weight parameters are estimated little by little. Overfitting (or Overlearning) refers to a model that models the `training data` too well. It then becomes difficult for the model to generalize to new data which were not in the training set. The most popular method to avoid overfitting is called dropout. Dropout deletes a random sample of activations (nodes) to zero during the training process. A random sample of nodes causes more irregular frequency of dropout edges. There is a similar sampling concept in the area of design of experiments. We propose a combinatorial design on dropout nodes from each partita which balances the frequency of edges. We analyze and construct such designs in this paper. ","math"
"1906.08685","LHC sensitivity to singly-charged scalars decaying into electrons and   muons","  Current LHC searches for non-supersymmetric singly-charged scalars, based on Two-Higgs-Doublet models, in general focus the analysis on third-generation fermions in the final state. However, singly-charged scalars in alternative extensions of the scalar sector involve Yukawa couplings not proportional to the mass of the fermions. Assuming the scalar decays into electrons and muons, it can manifest cleaner experimental signatures. In this paper we suggest that a singly-charged scalar singlet, with electroweak production, can start to be probed in the near future with dedicated search strategies. Depending on the strength of the Yukawa couplings, two independent scenarios are considered: direct pair-production (small couplings) and single-production via virtual neutrino exchange (large couplings). We show that, up to a mass as large as 500 GeV, most of the parameter space could be excluded at the 95% C.L. in a high-luminosity phase of the LHC. Our results also apply to other frameworks, provided the singly-charged scalar exhibits similar production patterns and dominant decay modes. ","hep-ph"
"1806.09016","Studying minijets and MPI with rapidity correlations","  We propose and carry a detailed study of an observable sensitive to different mechanisms of minijet production. The class of observables measures how the transverse momenta of hadrons produced in association with various trigger objects are balanced as a function of rapidity. It is shown that the observables are sensitive to the model parameters relevant to the minijet production mechanisms: low-$p_{\rm T}$ cut-off regulating jet cross-section, transverse distribution of partons in protons, and parton distribution functions. We perform our test at different charge-particle multiplicities and collision energies. The MC models, which describe many features of the LHC data, are found to predict quite different results demonstrating high discriminating power of the proposed observables. We also review mechanisms and components of \sc{Herwig}, \sc{Pythia}, and \sc{Sherpa} Monte Carlo models relevant to the minijet production. ","hep-ph"
"1905.09556","Experimental test of error-disturbance uncertainty relation with   continuous variables","  Uncertainty relation is one of the fundamental principle in quantum mechanics and plays an important role in quantum information science. We experimentally test the error-disturbance uncertainty relation (EDR) with continuous variables for Gaussian states. Two conjugate continuous-variable observables, amplitude and phase quadratures of an optical mode, are measured simultaneously by using a heterodyne measurement system. The EDR with continuous variables for a coherent state, a squeezed state and a thermal state are verified experimentally. Our experimental results demonstrate that Heisenberg's EDR with continuous variables is violated, yet Ozawa's and Branciard's EDR with continuous variables are validated. ","quant-ph"
"2007.09962","On a geometric method for the identifiability of forms","  We introduce a new criterion which tests if a given decomposition of a given ternary form $T$ of even degree is unique. The criterion is based on the analysis of the Hilbert function of the projective set of points $Z$ associated to the decomposition, and on the Terracini's Lemma which describes tangent spaces to secant varieties. The criterion works in a range for the length of the decomposition which is equivalent to the range in which the reshaped Kruskal's criterion (see [1]) works. Our criterion determines an algorithm for the identifiability of $T$ which is sensibly faster than algorithms based on the reshaped Kruskal's criterion, especially when the set of points $Z$ is not in general position. ","math"
"2001.04768","Experimental characterisation of unsharp qubit observables and   sequential measurement incompatibility via quantum random access codes","  Unsharp measurements are increasingly important for foundational insights in quantum theory and quantum information applications. Here, we report an experimental implementation of unsharp qubit measurements in a sequential communication protocol, based on a quantum random access code. The protocol involves three parties; the first party prepares a qubit system, the second party performs operations which return both a classical and quantum outcome, and the latter is measured by the third party. We demonstrate a nearly-optimal sequential quantum random access code that outperforms both the best possible classical protocol and any quantum protocol which utilises only projective measurements. Furthermore, while only assuming that the involved devices operate on qubits and that detected events constitute a fair sample, we demonstrate the noise-robust characterisation of unsharp measurements based on the sequential quantum random access code. We apply this characterisation towards quantifying the degree of incompatibility of two sequential pairs of quantum measurements. ","quant-ph"
"1912.03986","Updated fundamental constant constraints from Planck 2018 data and   possible relations to the Hubble tension","  We present updated constraints on the variation of the fine structure constant, $\alpha_{\rm EM}$, and effective electron rest mass, $m_{\rm e}$, during the cosmological recombination era. These two fundamental constants directly affect the ionization history at redshift $z\simeq 1100$ and thus modify the temperature and polarisation anisotropies of the cosmic microwave background (CMB) measured precisely with {\it Planck }. The constraints on $\alpha_{\rm EM}$ tighten slightly due to improved {\it Planck} 2018 polarisation data but otherwise remain similar to previous CMB analysis. However, a comparison with the 2015 constraints reveals a mildly discordant behaviour for $m_{\rm e}$, which from CMB data alone is found below its local value. Adding baryon acoustic oscillation data brings $m_{\rm e}$ back to the fiducial value, $m_{\rm e}=(1.0078\pm0.0067) m_{\rm e,0}$, and also drives the Hubble parameter to $H_0=69.1\pm 1.2$ [in units of ${\rm km \, s^{-1} \, Mpc^{-1} }$]. Further adding supernova data yields $m_{\rm e}=(1.0190\pm0.0055) m_{\rm e,0}$ with $H_0=71.24\pm0.96$. We perform several comparative analyses using the latest cosmological recombination calculations to further understand the various effects. Our results indicate that a single-parameter extension allowing for a slightly increased value of $m_{\rm e}$ ($\simeq 3.5\sigma$ above $m_{\rm e,0}$) could play a role in the Hubble tension. ","astro-ph"
"1909.05424","VizSeq: A Visual Analysis Toolkit for Text Generation Tasks","  Automatic evaluation of text generation tasks (e.g. machine translation, text summarization, image captioning and video description) usually relies heavily on task-specific metrics, such as BLEU and ROUGE. They, however, are abstract numbers and are not perfectly aligned with human assessment. This suggests inspecting detailed examples as a complement to identify system error patterns. In this paper, we present VizSeq, a visual analysis toolkit for instance-level and corpus-level system evaluation on a wide variety of text generation tasks. It supports multimodal sources and multiple text references, providing visualization in Jupyter notebook or a web app interface. It can be used locally or deployed onto public servers for centralized data hosting and benchmarking. It covers most common n-gram based metrics accelerated with multiprocessing, and also provides latest embedding-based metrics such as BERTScore. ","cs"
"2007.13614","Fully Decentralized Federated Learning Based Beamforming Design for UAV   Communications","  To handle the data explosion in the era of internet of things (IoT), it is of interest to investigate the decentralized network, with the aim at relaxing the burden to central server along with keeping data privacy. In this work, we develop a fully decentralized federated learning (FL) framework with an inexact stochastic parallel random walk alternating direction method of multipliers (ISPW-ADMM). Performing more communication efficient and enhanced privacy preservation compared with the current state-of-the-art, the proposed ISPW-ADMM can be partially immune to the impacts from time-varying dynamic network and stochastic data collection, while still in fast convergence. Benefits from the stochastic gradients and biased first-order moment estimation, the proposed framework can be applied to any decentralized FL tasks over time-varying graphs. Thus to further demonstrate the practicability of such framework in providing fast convergence, high communication efficiency, and system robustness, we study the extreme learning machine(ELM)-based FL model for robust beamforming (BF) design in UAV communications, as verified by the numerical simulations. ","eess"
"1905.00398","Hydrodynamics of broken global symmetries in the bulk","  We consider holographic theories at finite temperature in which a continuous global symmetry in the bulk is spontaneously broken. We study the linear response of operators in a regime which is dual to time dependent, long wavelength deformations of solutions generated by the symmetry. By computing the boundary theory retarded Green's function we show the existence of a gapless mode with a diffusive dispersion relation. The diffusive character of the mode is compatible with the absence of a conserved charge from the field theory point of view. We give an analytic expression for the corresponding diffusion constant in terms of thermodynamic data and a new transport coefficient $\sigma_{b}$ which is fixed by the black hole horizon data. After adding a perturbative source on the boundary, we compute the resulting gap $\delta\omega_{g}$ as a simple function of $\sigma_{b}$ and of data of the thermal state. ","hep-th"
"1901.08223","Position of Effective Spins Induced by Dilution in Two-Dimensional   Spin-Peierls Systems","  The site- and bond-dilution effects of the nonmagnetic ground state of a two-dimensional $S=1/2$ antiferromagnetic Heisenberg model, coupled with the lattice distortions on a square lattice, are investigated by performing quantum Monte Carlo simulations. In the nondiluted system, a phase diagram parameterized by the interchain interaction and the elastic constant is obtained, and the values of the lattice distortions in the dimerized phase are evaluated precisely. In the diluted system, we compare two ground-state energies assuming two patterns of lattice distortions with magnetic moments (effective spins) induced near the diluted parts and induced at the midpoint between the diluted parts. As a result, we find that it is difficult to induce effective spins near diluted parts for large elastic constants, small interchain interactions, and large concentrations of dilution. ","cond-mat"
"2005.06675","Hall effect in ferromagnetic nanomagnets: magnetic field dependence as   an evidence of inverse spin Hall effect contribution","  We measure magnetic field dependence of the Hall angle in a metallic ferromagnetic nanomagnet with stable local magnetic moments where the adopted mechanisms of Hall effect predict linear plus a constant dependence on the external field originating from the ordinary and anomalous Hall effects, respectively. We suggest that the experimentally observed deviations from this dependence is caused by the inverse spin Hall effect (ISHE) and develop a phenomenological theory, which predicts a unique nonlinear dependence of the ISHE contribution on the external magnetic field. Perfect agreement between theory and experiment supports the considerable role of the ISHE in the Hall transport in ferromagnetic metals. ","cond-mat"
"1910.10102","Integrated Quantile RAnk Test (iQRAT) for gene-level associations in   sequencing studies","  Testing gene-based associations is the fundamental approach to identify genetic associations in sequencing studies. The best-known approaches include Burden and Sequence Kernel Association Tests (SKAT). The gene-traits associations are often complex due to population heterogeneity, gene-environmental interactions, and various other reasons. The mean-based tests, including Burden and SKAT, may miss or underestimate some high-order associations that could be scientifically interesting.   In this paper, we propose a new family of gene-level association tests, which integrate quantile rank score processes while combining multiple weighting schemes to accommodate complex associations. The resulting test statistics have multiple advantages. They are as efficient as the mean-based SKAT and Burden test when the associations are homogeneous across quantile levels and have improved efficiency for complex and heterogeneous associations. The test statistics are distribution-free, and could hence accommodate a wide range of distributions. They are also computationally feasible. We established the asymptotic properties of the proposed tests under the null and alternative hypothesis and conducted large scale simulation studies to investigate its finite sample performance. We applied the proposed tests to Metabochip data to identify genetic associations with lipid traits and compared the results with those of the the Burden and SKAT tests. ","stat"
"2001.06718","Ultrasound in Locomotion Research -- The Quest for Wider Views","  In a systematic review, we investigate current applications of ultrasound in locomotion research. Shortcomings in the range of view of ultrasound systems affect the direct validation of musculoskeletal simulations as inverse approaches have to be applied. We present currently used methods to estimate muscle and tendon length in human plantarflexors. ","q-bio"
"1812.01315","Supersymmetric Wilson loops in two dimensions and duality","  We classify bosonic $\mathcal{N}=(2,2)$ supersymmetric Wilson loops on arbitrary backgrounds with vector-like R-symmetry. These can be defined on any smooth contour and come in two forms which are universal across all backgrounds. We show that these Wilson loops, thanks to their cohomological properties, are all invariant under smooth deformations of their contour. At genus zero they can always be mapped to local operators and computed exactly with supersymmetric localisation. Finally, we find the precise map, under two-dimensional Seiberg-like dualities, of correlators of supersymmetric Wilson loops. ","hep-th"
"1905.06878","Probing Qubit Memory Errors at the Part-per-Million Level","  Robust qubit memory is essential for quantum computing, both for near-term devices operating without error correction, and for the long-term goal of a fault-tolerant processor. We directly measure the memory error $\epsilon_m$ for a $^{43}$Ca$^+$ trapped-ion qubit in the small-error regime and find $\epsilon_m<10^{-4}$ for storage times $t\lesssim50\,\mbox{ms}$. This exceeds gate or measurement times by three orders of magnitude. Using randomized benchmarking, at $t=1\,\mbox{ms}$ we measure $\epsilon_m=1.2(7)\times10^{-6}$, around ten times smaller than that extrapolated from the $T_{2}^{\ast}$ time, and limited by instability of the atomic clock reference used to benchmark the qubit. ","quant-ph"
"1910.08861","A Novel Scheme of Digital Instantaneous Automatic Gain Control (DIAGC)   for Pulse Radars","  Several schemes for gain control are used for preventing saturation of receiver, and overloading of data processor, tracker or display in pulse radars. The use of digital processing techniques open the door to a variety of digital automatic gain control schemes for analyzing digitized return signals and controlling receiver gain only at saturating clutter zones without affecting the detection at other zones. In this paper, we present a novel scheme of Digital Instantaneous Automatic Gain Control (DIAGC) which is based on storing digitally the dwell based clutter returns and deriving the gain control. The returns corresponding to the first two PRTs in a dwell are used to analyze the presence of saturating clutter zones and the depth of saturation. Third PRT onwards proper gain control is applied at the IF stage to prevent saturation of the following stages. FPGA based scheme is used for digital data processing, storing, threshold calculation and gain control generation. The effect of DIAGC on pulse compression is also addressed in this paper. ","eess"
"1902.04827","Bayesian inference using synthetic likelihood: asymptotics and   adjustments","  Implementing Bayesian inference is often computationally challenging in applications involving complex models, and sometimes calculating the likelihood itself is difficult. Synthetic likelihood is one approach for carrying out inference when the likelihood is intractable, but it is straightforward to simulate from the model. The method constructs an approximate likelihood by taking a vector summary statistic as being multivariate normal, with the unknown mean and covariance matrix estimated by simulation for any given parameter value. Our article makes three contributions. The first shows that if the summary statistic satisfies a central limit theorem, then the synthetic likelihood posterior is asymptotically normal and yields credible sets with the correct level of frequentist coverage. This result is similar to that obtained by approximate Bayesian computation. The second contribution compares the computational efficiency of Bayesian synthetic likelihood and approximate Bayesian computation using the acceptance probability for rejection and importance sampling algorithms with a ""good"" proposal distribution. We show that Bayesian synthetic likelihood is computationally more efficient than approximate Bayesian computation, and behaves similarly to regression-adjusted approximate Bayesian computation. Based on the asymptotic results, the third contribution proposes using adjusted inference methods when a possibly misspecified form is assumed for the covariance matrix of the synthetic likelihood, such as diagonal or a factor model, to speed up the computation. The methodology is illustrated with some simulated and real examples. ","stat"
"1903.10470","Measurement and feedback for cooling heavy levitated particles in low   frequency traps","  We consider a possible route to ground state cooling of a levitated nanoparticle, magnetically trapped by a strong permanent magnet, using a combination of measurement and feedback. The trap frequency of this system is much lower than those involving trapped ions or nano-mechanical resonators. Minimisation of environmental heating is therefore challenging as it requires control of the system on a timescale comparable to the inverse of the trap frequency. We show that these traps are an excellent platform for performing optimal feedback control via real-time state estimation, for the preparation of motional states with measurable quantum properties. ","quant-ph"
"1811.01180","Dark matter and LHC phenomenology of a scale invariant scotogenic model","  We study the phenomenology of a model that addresses the neutrino mass, dark matter, and generation of the electroweak scale in a single framework. Electroweak symmetry breaking is realized via the Coleman-Weinberg mechanism in a classically scale invariant theory, while the neutrino mass is generated radiatively through interactions with dark matter in a typically scotogenic manner. The model introduces a scalar triplet and singlet and a vector-like fermion doublet that carry an odd parity of $Z_2$, and an even parity scalar singlet that helps preserve classical scale invariance. We sample over the parameter space by taking into account various experimental constraints from the dark matter relic density and direct detection, direct scalar searches, neutrino mass, and charged lepton flavor violating decays. We then examine by detailed simulations possible signatures at the LHC to find some benchmark points of the free parameters. We find that the future high-luminosity LHC will have a significant potential in detecting new physics signals in the dilepton channel. ","hep-ph"
"1508.01240","A Bayesian framework for functional calibration of expensive   computational models through non-isometric matching","  We study statistical calibration, i.e., adjusting features of a computational model that are not observable or controllable in its associated physical system. We focus on functional calibration, which arises in many manufacturing processes where the unobservable features, called calibration variables, are a function of the input variables. A major challenge in many applications is that computational models are expensive and can only be evaluated a limited number of times. Furthermore, without making strong assumptions, the calibration variables are not identifiable. We propose Bayesian non-isometric matching calibration (BNMC) that allows calibration of expensive computational models with only a limited number of samples taken from a computational model and its associated physical system. BNMC replaces the computational model with a dynamic Gaussian process (GP) whose parameters are trained in the calibration procedure. To resolve the identifiability issue, we present the calibration problem from a geometric perspective of non-isometric curve to surface matching, which enables us to take advantage of combinatorial optimization techniques to extract necessary information for constructing prior distributions. Our numerical experiments demonstrate that in terms of prediction accuracy BNMC outperforms, or is comparable to, other existing calibration frameworks. ","stat"
"1908.06453","The Jones-Krushkal polynomial and minimal diagrams of surface links","  We prove a Kauffman-Murasugi-Thistlethwaite theorem for alternating links in thickened surfaces. It states that any reduced alternating diagram of a link in a thickened surface has minimal crossing number, and any two reduced alternating diagrams of the same link have the same writhe. This result is proved more generally for link diagrams that are adequate, and the proof involves a two-variable generalization of the Jones polynomial for surface links defined by Krushkal. The main result is used to establish the first and second Tait conjectures for links in thickened surfaces and for virtual links. ","math"
"1801.06297","Difference between quantum annealing by imaginary-time and real-time   Schr\""{o}dinger equation of Grover's search","  We confirmed the annealing time of Grover's search which is required to obtain desired success probability for quantum annealing by the imaginary-time and the real-time Schr\""{o}dinger equation with two kinds of schedulings; one linearly decreases the quantum fluctuation and the other tunes the evolution rate of the Hamiltonian based on the adiabatic condition. With linear scheduling, the required annealing time for quantum annealing by the imaginary-time Schr\""{o}dinger equation is of order $\log N$, which is very different from $O(N)$ required for the quantum annealing by the real-time Schr\""{o}dinger equation. With the scheduling based on the adiabatic condition, the required annealing time is of order $\sqrt{N}$, which is identical to the annealing time for quantum annealing by the real-time Schr\""{o}dinger equation. Although the scheduling based on the adiabatic condition is optimal for the quantum annealing by the real-time Schr\""{o}dinger equation, it is inefficient for the quantum annealing by the imaginary-time Schr\""{o}dinger equation. This result implies that the optimal scheduling for the quantum annealing by the imaginary-time and the real-time Schr\""{o}dinger equation is very different, and the efficient scheduling considered with the quantum Monte Carlo methods, which is based on imaginary-time Schr\""{o}dinger equation, is not necessarily effective to improve the performance of quantum annealing by the real-time Schr\""{o}dinger equation. We discuss the efficient scheduling for quantum annealing by the imaginary-time Schr\""{o}dinger equation with respect to the exponential decay of excited states. ","quant-ph"
"1503.07865","Estimating the Coherence of Noise","  Noise mechanisms in quantum systems can be broadly characterized as either coherent (i.e., unitary) or incoherent. For a given fixed average error rate, coherent noise mechanisms will generally lead to a larger worst-case error than incoherent noise. We show that the coherence of a noise source can be quantified by the unitarity, which we relate to the average change in purity averaged over input pure states. We then show that the unitarity can be efficiently estimated using a protocol based on randomized benchmarking that is efficient and robust to state-preparation and measurement errors. We also show that the unitarity provides a lower bound on the optimal achievable gate infidelity under a given noisy process. ","quant-ph"
"1910.09141","Low-rank mmWave MIMO channel estimation in one-bit receivers","  Receivers with one-bit analog-to-digital converters (ADCs) are promising for high bandwidth millimeter wave (mmWave) systems as they consume less power than their full resolution counterparts. The extreme quantization in one-bit receivers and the use of large antenna arrays at mmWave make channel estimation challenging. In this paper, we develop channel estimation algorithms that exploit the low-rank property of mmWave channels. We also propose a novel training solution that results in a low complexity implementation of our algorithms. Simulation results indicate that the proposed methods achieve better channel reconstruction than compressed sensing-based techniques that exploit sparsity of mmWave channels. ","eess"
"1910.08075","Nonequilibrium thermodynamics with thermodynamic parameter of lifetime   of system. II. Possibilities of increase lifetime","  The thermodynamics is studied with the thermodynamic parameter of the lifetime, first-passage time, generalizing the equilibrium thermodynamics. Various ways of describing several stationary nonequilibrium states in the system are considered. The possibilities of increasing the lifetime of the system under external influences on it are investigated. ","cond-mat"
"1907.04603","Colliding Pomerons","  We recall the main properties of inclusive particle distributions expected for Pomeron-proton and Pomeron-Pomeron interactions. Due to the small size of the Pomeron we expect larger transverse momenta of secondaries and a smaller probability of Multiple Interactions, that is a narrower multiplicity distribution. We propose to compare the spectra of secondaries produced in the Pomeron and the proton interactions in terms of the Feynman $x_F$ variable. The main difference should be observed for a relatively large $x_F$, that is near the edge of rapidity gaps. Such data offer the opportunity to illuminate the properties of the `soft' or `Regge' Pomeron, which drives the minimum-bias type of events in high energy $pp$ interactions. Besides this, there should be a good opportunity to observe a glueball in the Pomeron fragmentation region. ","hep-ph"
"1902.08290","Manifold valued data analysis of samples of networks, with applications   in corpus linguistics","  Networks can be used in many applications, such as in the analysis of text documents, social interactions and brain activity. We develop a general framework for extrinsic statistical analysis of samples of networks, motivated by networks representing text documents in corpus linguistics. We identify networks with their graph Laplacian matrices, for which we define metrics, embeddings, tangent spaces, and a projection from Euclidean space to the space of graph Laplacians. This framework provides a way of computing means, performing principal component analysis and regression, and carrying out hypothesis tests, such as for testing for equality of means between two samples of networks. We apply the methodology to the set of novels by Jane Austen and Charles Dickens. ","stat"
"1907.12529","Primes with Beatty and Chebotarev conditions","  We study the prime numbers that lie in Beatty sequences of the form $\lfloor \alpha n + \beta \rfloor$ and have prescribed algebraic splitting conditions. We prove that the density of primes in both a fixed Beatty sequence and a Chebotarev class of some Galois extension is precisely the product of the densities $\alpha^{-1}\cdot\frac{|C|}{|G|}$. Moreover, we show that the primes in the intersection of these sets satisfy a Bombieri--Vinogradov type theorem. This allows us to prove the existence of bounded gaps for such primes. As a final application, we prove a common generalization of the aforementioned bounded gaps result and the Green--Tao theorem. ","math"
"1907.10762","Fitting motion models to contextual player behavior","  The objective of this study was to incorporate contextual information into the modelling of player movements. This was achieved by combining the distributions of forthcoming passing contests that players committed to and those they did not. The resultant array measures the probability a player would commit to forthcoming contests in their vicinity. Commitment-based motion models were fit on 46220 samples of player behavior in the Australian Football League. It was found that the shape of commitment-based models differed greatly to displacement-based models for Australian footballers. Player commitment arrays were used to measure the spatial occupancy and dominance of the attacking team. The spatial characteristics of pass receivers were extracted for 2934 passes. Positional trends in passing were identified. Furthermore, passes were clustered into three components using Gaussian mixture models. Passes in the AFL are most commonly to one-on-one contests or unmarked players. Furthermore, passes were rarely greater than 25 m. ","stat"
"1903.12445","On asymptotic behaviour of Dirichlet inverse","  Let $f(n)$ be an arithmetic function with $f(1)\neq0$ and let $f^{-1}(n)$ be its reciprocal with respect to the Dirichlet convolution. We study the asymptotic behaviour of $|f^{-1}(n)|$ with regard to the asymptotic behaviour of $|f(n)|$ assuming that the latter one grows or decays with at most polynomial or exponential speed. As a by-product, we obtain simple but constructive upper bounds for the number of ordered factorizations of $n$ into $k$ factors. ","math"
"1912.05323","Potential Antimicrobial Activity of Marine Sponge Neopetrosia exigua","  Neopetrosia exigua has received great attention in natural product chemistry. The diversity of N. exigua constituents has been demonstrated by the continued discovery of novel bioactive metabolites such as antimicrobial metabolites. In this study, in order to localise the active component of N. exigua biomass according to the polarity, a sequential gradient partition with different solvents (nhexane, carbon tetrachloride, dichloromethane, n-butanol, and water) was performed to obtain fractions containing metabolites distributed according to their polarity. The antimicrobial activities of N. exigua fractions were then evaluated using disc diffusion and microdilution methods (influence on the growth curve, Minimum Inhibitory Concentration (MIC) and Minimum Bactericidal Concentration (MBC)). The results showed that the active metabolites were present in n-hexane, CH2Cl2, nBuOH, and water fractions. n-hexane, CH2Cl2, and n-BuOH fractions were the most effective fractions. Among microbes tested, Staphylococcus aureus was the most susceptible microbe evaluated. The obtained results are considered sufficient for further study to isolate the compounds represent the antimicrobial activity. ","q-bio"
"1908.07758","Signal denoising based on the Schr\""odinger operator's eigenspectrum and   a curvature constraint","  Recently, a new Signal processing method, named Semi-Classical Signal Analysis (SCSA), has been proposed for denoising Magnetic Resonance Spectroscopy (MRS) signals. It is based on the Schr\""odinger Operator's eigenspectrum. It allows an efficient noise reduction while preserving MRS signal's peaks. In this paper, we propose to extend this approach to different signals, in particular pulse shaped signals, by including an optimization that considers curvature constraints. The performance of the method is measured by analyzing noisy signal data and comparing with other denoising methods. Results indicate that the proposed method not only produces good denoising performance but also guarantees the peaks are well preserved in the denoising process. ","eess"
"1906.01716","High-resolution estimates of the foreign-born population and   international migration for the United States","  Detailed estimates of migration stocks and flows provides evidence for understanding population dynamics, and the impact of economic and political changes that influence migration. Using data from the 2000 decennial census and 2001-2016 American Community Survey (ACS), this study derives highly-disaggregated estimates of the foreign-born population residing in the United States for the period 2000-2018, and annual foreign-born entries to the ACS population as a measure of immigration volume. These estimates are derived from an evidence synthesis combining pooled survey data with auxiliary data on potential biases in raw survey estimates and other trends affecting the foreign-born population. For an individual population stratum (defined by current age, entry year, country of origin, and calendar year) direct estimates using survey data can have substantial sampling uncertainty. By imposing logical and probabilistic constraints, data are pooled across survey years to produce more precise estimates. Corrections are implemented for respondent misreporting of demographic information, and undercount of the foreign-born population in the ACS. This paper describes the statistical approach used to model population change, demonstrates the validity of the approach via in- and out-of-sample predictive performance, provides the population estimates, and highlights potential applications. ","stat"
"2001.03614","Paradoxical Results of Long-Term Potentiation explained by Voltage-based   Plasticity Rule","  Experiments have shown that the same stimulation pattern that causes Long-Term Potentiation in proximal synapses, will induce Long-Term Depression in distal ones. In order to understand these, and other, surprising observations we use a phenomenological model of Hebbian plasticity at the location of the synapse. Our computational model describes the Hebbian condition of joint activity of pre- and post-synaptic neuron in a compact form as the interaction of the glutamate trace left by a presynaptic spike with the time course of the postsynaptic voltage. We test the model using experimentally recorded dendritic voltage traces in hippocampus and neocortex. We find that the time course of the voltage in the neighborhood of a stimulated synapse is a reliable predictor of whether a stimulated synapse undergoes potentiation, depression, or no change. Our model can explain the existence of different -- at first glance seemingly paradoxical -- outcomes of synaptic potentiation and depression experiments depending on the dendritic location of the synapse and the frequency or timing of the stimulation. ","q-bio"
"1806.10568","Tunable spin-orbit coupling and magnetic superstripe phase in a BEC","  Superstripe phases in Bose-Einstein condensates (BECs), possessing both crystalline structure and superfluidity, opens a new avenue for exploring exotic quantum matters---supersolids. However, conclusive detection and further exploration of a superstripe is still challenging in experiments because of its short period, low visibility, fragility against magnetic field fluctuation or short lifetime. Here we propose a scheme in a spin-orbit coupled BEC which overcomes these obstacles and generates a robust magnetic superstripe phase, with only spin (no total) density modulation due to the magnetic translational symmetry, ready for direct real-space observation. In the scheme, two hyperfine spin states are individually Raman coupled with a largely-detuned third state, which induce a momentum-space separation between two lower band dispersions, yielding an effective spin-1/2 system with tunable spin-orbit coupling and Zeeman fields. Without effective Zeeman fields, spin-dependent interaction dominates, yielding a magnetic superstripe phase with a long tunable period and high visibility. Our scheme provides a platform for observing and exploring exotic properties of superstripe phases as well as novel physics with tunable spin-orbit coupling. ","cond-mat"
"2007.14786","Quickest Real-Time Detection of a Brownian Coordinate Drift","  Consider the motion of a Brownian particle in two or more dimensions, whose coordinate processes are standard Brownian motions with zero drift initially, and then at some random/unobservable time, one of the coordinate processes gets a (known) non-zero drift permanently. Given that the position of the Brownian particle is being observed in real time, the problem is to detect the time at which a coordinate process gets the drift as accurately as possible. We solve this problem in the most uncertain scenario when the random/unobservable time is (i) exponentially distributed and (ii) independent from the initial motion without drift. The solution is expressed in terms of a stopping time that minimises the probability of a false early detection and the expected delay of a missed late detection. To our knowledge this is the first time that such a problem has been solved exactly in the literature. ","math"
"2002.05199","Directed graphs and interferometry","  The observed output of an interferometer is the result of interference among the parts of the input light beam traveling along each possible optical path. In complex systems, writing down all these possible optical paths and computing their cumulative effect can become a difficult task. We present an intuitive graph-based method for solving this problem and calculating electric fields within an interferometric setup, classical and quantum. We show how to associate a weighted directed graph to an interferometer and define rules to simplify these associated graphs. Successive application of the rules results in a final graph containing information on the desired field amplitudes. The method is applied to a number of examples in cavity optomechanics and cavity-enhanced interferometers. ","quant-ph"
"2006.15584","A Polynomial Kernel for Line Graph Deletion","  The line graph of a graph $G$ is the graph $L(G)$ whose vertex set is the edge set of $G$ and there is an edge between $e,f\in E(G)$ if $e$ and $f$ share an endpoint in $G$. A graph is called line graph if it is a line graph of some graph. We study the Line-Graph-Edge Deletion problem, which asks whether we can delete at most $k$ edges from the input graph $G$ such that the resulting graph is a line graph. More precisely, we give a polynomial kernel for Line-Graph-Edge Deletion with $\mathcal{O}(k^{5})$ vertices. This answers an open question posed by Falk H\""{u}ffner at Workshop on Kernels (WorKer) in 2013. ","cs"
"1911.11790","Global Bounds on the Type-III Seesaw","  We derive general bounds on the Type-III Seesaw parameters from a global fit to flavor and electroweak precision data. We explore and compare three Type-III Seesaw realizations: a general scenario, where an arbitrary number of heavy triplets is integrated out without any further assumption, and the more constrained cases in which only 3 or 2 (minimal scenario) additional heavy states are included. The latter assumption implies rather non-trivial correlations in the Yukawa flavor structure of the model so as to reproduce the neutrino masses and mixings as measured in neutrino oscillations experiments and thus qualitative differences can be found with the more general scenario. In particular, we find that, while the bounds on most elements of the dimension 6 operator coefficients are of order $10^{-4}$ for the general and 3-triplet cases, the 2-triplet scenario is more strongly constrained with bounds between $10^{-5}$ and $10^{-7}$ for the different flavours. We also discuss how these correlations affect the present CMS constraints on the Type-III Seesaw in the minimal 2-triplet scenario. ","hep-ph"
"1904.04431","Stability-Preserving, Time-Efficient Mechanisms for School Choice in Two   Rounds","  We address the following dynamic version of the school choice question: a city, named City, admits students in two temporally-separated rounds, denoted $\mathcal{R}_1$ and $\mathcal{R}_2$. In round $\mathcal{R}_1$, the capacity of each school is fixed and mechanism $\mathcal{M}_1$ finds a student optimal stable matching. In round $\mathcal{R}_2$, certain parameters change, e.g., new students move into the City or the City is happy to allocate extra seats to specific schools. We study a number of Settings of this kind and give polynomial time algorithms for obtaining a stable matching for the new situations.   It is well established that switching the school of a student midway, unsynchronized with her classmates, can cause traumatic effects. This fact guides us to two types of results, the first simply disallows any re-allocations in round $\mathcal{R}_2$, and the second asks for a stable matching that minimizes the number of re-allocations. For the latter, we prove that the stable matchings which minimize the number of re-allocations form a sublattice of the lattice of stable matchings. Observations about incentive compatibility are woven into these results. We also give a third type of results, namely proofs of NP-hardness for a mechanism for round $\mathcal{R}_2$ under certain settings. ","cs"
"1812.05358","Fiber coupled EPR-state generation using a single temporally multiplexed   squeezed light source","  A prerequisite for universal quantum computation and other large-scale quantum information processors is the careful preparation of quantum states in massive numbers or of massive dimension. For continuous variable approaches to quantum information processing (QIP), squeezed states are the natural quantum resources, but most demonstrations have been based on a limited number of squeezed states due to the experimental complexity in up-scaling. The number of physical resources can however be significantly reduced by employing the technique of temporal multiplexing. Here, we demonstrate an application to continuous variable QIP of temporal multiplexing in fiber: Using just a single source of squeezed states in combination with active optical switching and a 200 m fiber delay line, we generate fiber-coupled Einstein-Podolsky-Rosen entangled quantum states. Our demonstration is a critical enabler for the construction of an in-fiber, all-purpose quantum information processor based on a single or few squeezed state quantum resources. ","quant-ph"
"1905.02065","Propensity Process: a Balancing Functional","  In observational clinic registries, time to treatment is often of interest, but treatment can be given at any time during follow-up and there is no structure or intervention to ensure regular clinic visits for data collection. To address these challenges, we introduce the time-dependent propensity process as a generalization of the propensity score. We show that the propensity process balances the entire time-varying covariate history which cannot be achieved by existing propensity score methods and that treatment assignment is strongly ignorable conditional on the propensity process. We develop methods for estimating the propensity process using observed data and for matching based on the propensity process. We illustrate the propensity process method using the Emory Amyotrophic Lateral Sclerosis (ALS) Registry data. ","stat"
"1809.00669","Geometric goodness of fit measure to detect patterns in data point   clouds","  The curse of dimensionality is a commonly encountered problem in statistics and data analysis. Variable sensitivity analysis methods are a well studied and established set of tools designed to overcome these sorts of problems. However, as this work shows, these methods fail to capture relevant features and patterns hidden within the geometry of the enveloping manifold projected onto a variable. Here we propose an index that captures, reflects and correlates the relevance of distinct variables within a model by focusing on the geometry of their projections. We construct the 2-simplices of a Vietoris-Rips complex and then estimate the area of those objects from a data-set cloud. The analysis was made with an original R-package called TopSA, short for Topological Sensitivity Analysis. The TopSA R-package is available at the site https://github.com/maikol-solis/TopSA. ","stat"
"1812.11725","Total Variation with Overlapping Group Sparsity and Lp Quasinorm for   Infrared Image Deblurring under Salt-and-Pepper Noise","  Because of the limitations of the infrared imaging principle and the properties of infrared imaging systems, infrared images have some drawbacks, including a lack of details, indistinct edges, and a large amount of salt-andpepper noise. To improve the sparse characteristics of the image while maintaining the image edges and weakening staircase artifacts, this paper proposes a method that uses the Lp quasinorm instead of the L1 norm and for infrared image deblurring with an overlapping group sparse total variation method. The Lp quasinorm introduces another degree of freedom, better describes image sparsity characteristics, and improves image restoration. Furthermore, we adopt the accelerated alternating direction method of multipliers and fast Fourier transform theory in the proposed method to improve the efficiency and robustness of our algorithm. Experiments show that under different conditions for blur and salt-and-pepper noise, the proposed method leads to excellent performance in terms of objective evaluation and subjective visual results. ","cs"
"1705.01829","Concentration on submanifolds of positively curved homogeneous spaces","  A classical result of Milman roughly states that every Lipschitz function on $\mathbb{S}^n$ is almost constant on a sufficiently high-dimensional sphere $\mathbb{S}^m\subset \mathbb{S}^n$. In this paper we extend the result by proving that any Lipschitz function on a positively curved homogeneous space is almost constant on a high dimensional submanifold. ","math"
"1911.10794","Finite $N$ corrections to the superconformal index of toric quiver gauge   theories","  The superconformal index of quiver gauge theories realized on D3-branes in toric Calabi-Yau cones is investigated. We use the AdS/CFT correspondence and study D3-branes wrapped on supersymmetric cycles. We focus on brane configurations in which a single D3-brane is wrapped on a cycle, and we do not take account of branes with multiple wrapping. We propose a formula that gives finite $N$ corrections to the index caused by such brane configurations. We compare the predictions of the formula for several examples with the results on the gauge theory side obtained by using localization for small size of gauge groups, and confirm that the formula correctly reproduces the finite $N$ corrections up to expected order. ","hep-th"
"1911.01590","Classification of topological phases in one dimensional interacting   non-Hermitian systems and emergent unitarity","  Topological phases in non-Hermitian systems have become a fascinating subject recently. In this paper, we attempt to classify topological phases in 1D interacting non-Hermitian systems. We begin with the non-Hermitian generalization of Su-Schrieffer-Heeger(SSH) model and discuss its many body topological Berry phase, which is well defined for any interacting quasi-Hermitian systems(non-Hermitian systems that have real energy spectrum). We then demonstrate that the classifications of topological phases for quasi-Hermitian systems are exactly the same as their Hermitian counterparts. Moreover, we find that unitarity can even emerge for fixed point partition function describing topological phases in 1D non-Hermitian systems with local interactions. Thus we conjecture that for generic 1D interacting non-Hermitian systems, the classification of topological phases are exactly the same as Hermitian systems. ","cond-mat"
"2004.04372","Low-requirement fast gates enable quantum computation in long ion chains","  We present a model for implementing fast entangling gates (${\sim}1\mu$s) with ultra-fast pulses in arbitrarily long ion chains, that requires low numbers of pulses and can be implemented with laser repetition rates well within experimental capability. We demonstrate that we are able to optimise pulse sequences that have theoretical fidelities above $99.99\%$ in arbitrarily long ion-chains, for laser repetition rates on the order of $100-300$~MHz. Notably, we find higher repetition rates are not required for gates in longer ion chains, which is in contrast to scaling analyses with other gate schemes. When pulse imperfections are considered in our calculations, we find that achievable gate fidelity is independent of the number of ions in the chain. We also show that pulse control requirements do not scale up with the number of ions. We find that population transfer efficiencies of above $99.9\%$ from individual ultra-fast pulses is the threshold for realising high-fidelity gates, which may be achievable in near-future experiments. ","quant-ph"
"1904.12630","Entanglement sudden death and birth effects in two qubits maximally   entangled mixed states under quantum channels","  In the present article, the robustness of entanglement in two qubits maximally entangled mixed states (MEME) have been studied under quantum decoherence channels. Here we consider bit flip, phase flip, bit-phase-flip, amplitude damping, phase damping and depolarization channels. To quantify the entanglement, the concurrence has been used as an entanglement measure. During this study interesting results have been found for sudden death and birth of entanglement under bit flip and bit-phase-flip channels. While amplitude damping channel produces entanglement sudden death and does not allow re-birth of entanglement. On the other hand, two qubits MEMS exhibit the robust character against the phase flip, phase damping and depolarization channels. The elegant behavior of all the quantum channels have been investigated with varying parameter of quantum state MEMS in different cases. ","quant-ph"
"1905.10470","On the calculation of covariant expressions for Dirac bilinears","  In this article, an approach to calculate covariant expressions for the bilinears of Dirac spinors will be presented. For this purpose, algebraic equations defining Dirac spinors will be discussed. Following that, a covariant approach for spacetime parameterization will be presented and the equations defining Dirac spinors will be written fully in terms of Lorentz scalars. Finally, explicitly covariant expressions for Dirac bilinears will be calculated. ","hep-th"
"1507.03556","$C^{r}-$prevalence of stable ergodicity for a class of partially   hyperbolic systems","  We prove that for $r \in \mathbb{N}_{\geq 2} \cup \{\infty\}$, for any dynamically coherent, center bunched and strongly pinched volume preserving $C^r$ partially hyperbolic diffeomorphism $f \colon X \to X$, if either (1) its center foliation is uniformly compact, or (2) its center-stable and center-unstable foliations are of class $C^1$, then there exists a $C^1$-open neighbourhood of $f$ in ${\rm Diff}^r(X,\mathrm{Vol})$, in which stable ergodicity is $C^r$-prevalent in Kolmogorov's sense. In particular, we verify Pugh-Shub's stable ergodicity conjecture in this region. This also provides the first result that verifies the prevalence of stable ergodicity in the measure-theoretical sense. Our theorem applies to a large class of algebraic systems. As applications, we give affirmative answers in the strongly pinched region to: 1. an open question of Pugh-Shub in \cite{PS}; 2. a generic version of an open question of Hirsch-Pugh-Shub in \cite{HPS}; and 3. a generic version of an open question of Pugh-Shub in \cite{HPS}. ","math"
"2007.12667","Positivity Bounds and the Massless Spin-2 Pole","  The presence of a massless spin-2 field in an effective field theory results in a $t$-channel pole in the scattering amplitudes that precludes the application of standard positivity bounds. Despite this, recent arguments based on compactification to three dimensions have suggested that positivity bounds may be applied to the $t$-channel pole subtracted amplitude. If correct this would have deep implications for UV physics and the Weak Gravity Conjecture. Within the context of a simple renormalizable field theory coupled to gravity we find that applying these arguments would constrain the low-energy coupling constants in a way which is incompatible with their actual values. This contradiction persists on deforming the theory. Further enforcing the $t$-channel pole subtracted positivity bounds on such generic renormalizable effective theories coupled to gravity would imply new physics at a scale parametrically smaller than expected, with far reaching implications. This suggests that generically the positivity bounds are inapplicable with gravity and we highlight a number of issues with the compactification arguments. ","hep-th"
"1909.00752","Seesaw neutrinos with one right-handed singlet field and a second Higgs   doublet","  We study parameters of an extension of the Standard Model. The neutrino sector is enlarged by one right-handed singlet field, allowing for the seesaw mechanism type-I, and the Higgs sector contains one additional doublet, which contributes to light neutrino masses through one-loop radiative corrections. Employing an approximation for the effective light neutrino mass matrix we express the masses of the light neutrinos analytically, allowing us to parametrize the Yukawa couplings to neutrinos by the experimental measurements on the neutrino sector and only two free parameters. We focus on a CP-conserving Higgs potential for which we present the allowed ranges of the input parameters and a statistical overview over the possible values of the Yukawa couplings. ","hep-ph"
"1910.00052","Spectral density, Levinson's theorem, and the extra term in the second   virial coefficient for 1D delta-function potential","  In contrast with the 3D result, the Beth-Uhlenbeck (BU) formula in 1D contains an extra -1/2 term. The origin of this -1/2 term is explained using a spectral density approach. To be explicit, a delta-function potential is used to show that the correction term arises from a pole of the density of states at zero energy. The spectral density method shows that this term is actually an artifact of the non-normalizability of the scattering states and an infrared cutoff regularization scheme has to be used to get the correct result in 1D. The formal derivation of the BU formula would miss this term since it ignores the effects of the boundary terms. While the result is shown for the delta-function potential, the method and result are valid for more general potentials. Additionally, the 1D Levinson's theorem can be extracted from the spectral density method using the asymptotic form of general potentials. The importance of the result lies in the fact that all these correction terms in 1D have a universal source: a pole at zero energy. Similar calculations using quantum field theoretical approaches (without explicit infrared cutoff regularization schemes) also show the same subtleties with the correction term originating from the zero energy scattering states (appendix A). ","cond-mat"
"2007.07643","Multivariate white matter alterations are associated with epilepsy   duration","  Previous studies investigating associations between white matter alterations and duration of temporal lobe epilepsy (TLE) have shown differing results, and were typically limited to univariate analyses of tracts in isolation. In this study we apply a multivariate measure (the Mahalanobis distance), to capture the distinct ways white matter may differ in individual patients, and relate this to epilepsy duration.   Diffusion MRI, from a cohort of 94 subjects (28 healthy controls, 33 left-TLE and 33 right-TLE), was used to assess associations between tract fractional anisotropy (FA) and epilepsy duration. Using ten white matter tracts, we analysed associations using traditional univariate analyses (z-scores) and a complementary multivariate approach (Mahalanobis distance), incorporating multiple white matter tracts into a single unified analysis.   In patients with right-TLE, FA was not significantly associated with epilepsy duration for any tract studied in isolation. In patients with left-TLE, the FA of two limbic tracts (ipsilateral fornix, contralateral cingulum gyrus) was significantly negatively associated with epilepsy duration (Bonferonni corrected p<0.05). Using a multivariate approach we found significant ipsilateral positive associations with duration in both left, and right-TLE cohorts (left-TLE: Spearman's rho=0.487, right-TLE: Spearman's rho=0.422). Extrapolating our multivariate results to duration equals zero (i.e. at onset) we found no significant difference between patients and controls. Associations using the multivariate approach were more robust than univariate methods.   The multivariate distance measure provides non-overlapping and more robust results than traditional univariate analyses. Future studies should consider adopting both frameworks into their analysis in order to ascertain a more complete understanding of epilepsy progression, regardless of laterality. ","q-bio"
"1910.03357","Trigonometric Parallaxes Of High-Mass Star Forming Regions: Our View Of   The Milky Way","  We compile and analyze ~200 trigonometric parallaxes and proper motions of molecular masers associated with very young high-mass stars. These measurements strongly suggest that the Milky Way is a four-arm spiral. Fitting log-periodic spirals to the locations of the masers, allows us to significantly expand our view of the structure of the Milky Way. We present an updated model for its spiral structure and incorporate it into our previously published parallax-based distance-estimation program for sources associated with spiral arms. Modeling the three-dimensional space motions yields estimates of the distance to the Galactic center, Ro = 8.15 +/- 0.15 kpc, the circular rotation speed at the Sun's position, To = 236 +/- 7 km/s, and the nature of the rotation curve. Our data strongly constrain the full circular velocity of the Sun, To + Vsun = 247 +/- 4 km/s, and its angular velocity, (To + Vsun)/Ro = 30.32 +/- 0.27 km/s/kpc. Transforming the measured space motions to a Galactocentric frame which rotates with the Galaxy, we find non-circular velocity components typically about 10 km/s. However, near the Galactic bar and in a portion of the Perseus arm, we find significantly larger non-circular motions. Young high-mass stars within 7 kpc of the Galactic center have a scale height of only 19 pc and, thus, are well suited to define the Galactic plane. We find that the orientation of the plane is consistent with the IAU-defined plane to within +/-0.1 deg., and that the Sun is offset toward the north Galactic pole by Zsun = 5.5 +/- 5.8 pc. Accounting for this offset places the central supermassive black hole, Sgr A*, in the midplane of the Galaxy. Using our improved Galactic parameters, we predict the Hulse-Taylor binary pulsar to be at a distance of 6.54 +/- 0.24 kpc, assuming its orbital decay from gravitational radiation follows general relativity. ","astro-ph"
"1907.01334","Bit Error Probability Instead of Secrecy Rate Criterion to Enhance   Performance for Secure Wireless Communication Systems","  In this paper, we propose a new practical power allocation technique based on bit error probability (BEP) for physical layer security systems. It is shown that the secrecy rate that is the most commonly used in physical layer security systems, cannot be a suitable criterion lonely. Large positive values are suitable for the secrecy rate in physical layer security, but it does not consider the performance of the legitimate and adversary users. In this paper, we consider and analyze BEP for physical layer security systems because based on it, the performance of the legitimate and adversary users are guaranteed and it is needed to use lower power. BEP is calculated for the legitimate and adversary users and it is shown that BEP can be better criterion for performance evaluation of the physical layer security systems. Based on BEP, the optimum transmit power is obtained and a new definition for outage probability is proposed and obtained theoretically. Also, the proposed approach is applied for adversary users with unknown mode and the cooperative adversary users. Simulation results show that the proposed method needs more than 5dB lower power for different scenarios. ","eess"
"2003.12690","EEG Signal Classification using Variational Mode Decomposition","  Epilepsy affects about 1% of the population every year, and is characterized by abnormal and sudden hyper-synchronous excitation of the neurons in the brain. The electroencephalogram(EEG) is the most widely used method to record brain signals and diagnose epilepsy and seizure cases. In this paper we use the method of Variational Mode Decomposition (VMD) in our analysis to classify seizure/seizure free signals. This technique uses variational non recursive mode decomposition, in comparison to other methods like Empirical Mode (EMD) and Hilbert-Huang transform which recursively decompose the signals, making them more susceptible to noise and sampling rate. VMD decomposes a signal into its components which are called principal modes. In our analysis, 4 features of the decomposed signals namely Renyi Entropy, second order difference plot (SODP), fourth order difference plot(FODP) and average amplitude are investigated, both individually and using a ranking methodology considering all 4 features at the same time. The SODP of decomposed signal modes is an elliptical structure. The 95% confidence ellipse area measured from the SODP of the decomposed signal modes has been used as a feature in order to discriminate seizure-free EEG signals from the epileptic seizure EEG signal. For the classification, a Multilayer Perceptron(MLP) with back propagation algorithm as the training method was used. A high percentage of accuracy was obtained when the features were used individually for classification and an even higher degree of accuracy was obtained when the ranking methodology was used. ","eess"
"1812.09555","An attractive $\phi^4$ theory in light-front coordinates","  We study an attractive $\phi^4$ interaction using Tamm-Dancoff truncation with light-front coordinates in $3+1$ dimensions. The truncated theory requires a coupling constant renormalization, we compute its $\beta$ function non-perturbatively, show that the model is asymptotically free, and find the corresponding Callan-Symanzik equations. The model supports bound states, we find the wave function for the ground state of the two-particle sector. We also give a bound for the $N$-particle ground state energy within a mean field approximation, including the corresponding result for the case of $2+1$ dimensions where the model does not require renormalization. ","hep-th"
"2002.05851","Generalized Quantum Spring","  Recently, it was found that after imposing a helix boundary condition on a scalar field, the Casimir force coming from the quantum effect is linearly proportional to $r$, which is the ratio of the pitch to the circumference of the helix. This linear behavior of the Casimir force is just like that of the force obeying the Hooke's law on a spring. In this paper, inspiring by some complex structures that lives in the cells of human body like DNA, protein, collagen etc., we generalize the helix boundary condition to a more general one, in which the helix consists of a tiny helix structure, and makes up a hierarchy of helix. After imposing this kind of boundary condition on a massless and a massive scalar, we calculate the Casimir energy and force by using the so-called zeta function regularization method. We find that the Hooke's law with the generalized helix boundary condition is not exactly the same as usual one. In this case, the force is proportional to the cube of $r$ instead. So we regard it as a generalized Hooke's law, which is complied by a \emph{generalized quantum spring}. ","hep-th"
"1810.10963","Shaping the Internet: 10 Years of IXP Growth","  Over the past decade, IXPs have been playing a key role in enabling interdomain connectivity. Their traffic volumes have grown dramatically and their physical presence has spread throughout the world. While the relevance of IXPs is undeniable, their long-term contribution to the shaping of the current Internet is not fully understood yet.   In this paper, we look into the impact on Internet routes of the intense IXP growth over the last decade. We observe that while in general IXPs only have a small effect in path shortening, very large networks do enjoy a clear IXP-enabled path reduction. We also observe a diversion of the routes, away from the central Tier-1 ASes supported by IXPs. Interestingly, we also find that whereas IXP membership has grown, large and central ASes have steadily moved away from public IXP peerings, whereas smaller ones have embraced them. Despite all this changes, we find though that a clear hierarchy remains, with a small group of highly central networks ","cs"
"1907.06734","Mediation effects that emulate a target randomised trial:   Simulation-based evaluation of ill-defined interventions on multiple   mediators","  Many epidemiological questions concern potential interventions to alter the pathways presumed to mediate an association. For example, we consider a study that investigates the benefit of interventions in young adulthood for ameliorating the poorer mid-life psychosocial outcomes of adolescent self-harmers relative to their healthy peers. Two methodological challenges arise. Firstly, mediation methods have hitherto mostly focused on the elusive task of discovering pathways, rather than on the evaluation of mediator interventions. Secondly, the complexity of such questions is invariably such that there are no existing data on well-defined interventions (i.e. actual treatments, programs, etc.) capturing the populations, outcomes and time-spans of interest. Instead, researchers must rely on exposure (non-intervention) data to address these questions, such as self-reported substance use and employment. We address the resulting challenges by specifying a target trial addressing three policy-relevant questions, regarding the impacts of hypothetical (rather than actual) interventions that would shift the mediators' distributions (separately, jointly or sequentially) to user-specified distributions that can be emulated with the observed data. We then define novel interventional effects that map to this trial, emulating shifts by setting mediators to random draws from those distributions. We show that estimation using a g-computation method is possible under an expanded set of causal assumptions relative to inference with well-defined interventions. These expanded assumptions reflect the lower level of evidence that is inevitable with ill-defined interventions. Application to the self-harm example using data from the Victorian Adolescent Health Cohort Study illustrates the value of our proposal for informing the design and evaluation of actual interventions in the future. ","stat"
"1907.12127","Near-Field Radiation Exposure Control in Slot-Loaded Microstrip Antenna:   A Characteristic Mode Approach","  Microstip antenna topology is commonly loaded with a narrow slot to manipulate the resonance frequency or impedance bandwidth. However, the tuning of the resonance frequency or impedance bandwidth results in the variation of the current and field distributions. In this regard, this work adopts the concept of characteristic modes to gain an initial understanding of the perturbation mechanism of the rectangular patch when loaded with a slot. The performance of microstrip antennas with finite ground plane is then studied using full-wave simulation. It has been found that the distribution of the induced current density is highly dependent on the orientation of the slot The incorporation of a narrow slot suppresses the nearby orthogonal eigen mode and, as a consequence, the radiation behavior is affected. Specifically, in the presence of biological tissues in the near-field region, both antenna input impedance properties and the realized gain are dependent on the slot orientation. Different examples are included for understanding the impact of slot loading on the energy absorption by biological tissues, by calculating the the specific absorption rate (SAR). The proposed analysis facilitates the design of miniaturized antenna geometries for biomedical applications via systematic loading of narrow slots. ","eess"
"1902.09672","Limited processivity of single motors improves overall transport flux of   self-assembled motor-cargo complexes","  Single kinesin molecular motors can processively move along a microtubule (MT) a few micrometers on average before dissociating. However, cellular length scales over which transport occurs are several hundred microns and more. Why seemingly unreliable motors are used to transport cellular cargo remains poorly understood. We propose a new theory for how low processivity, the average length of a single bout of directed motion, can enhance cellular transport when motors and cargoes must first diffusively self assemble into complexes. We employ stochastic modeling to determine the effect of processivity on overall cargo transport flux. We show that, under a wide range of physiologically relevant conditions, possessing ""infinite"" processivity does not maximize flux along MTs. Rather, we find that low processivity i.e., weak binding of motors to MTs, is optimal. These results shed light on the relationship between processivity and transport efficiency and offer a new theory for the physiological benefits of low motor processivity. ","q-bio"
"1910.09601","Incoherence and Fibering of Many Free-by-Freegroups","  We show that free-by-free groups satisfying a particular homological criterion are incoherent. This class is large in nature, including many examples of hyperbolic and non-hyperbolic free-by-free groups. We apply this criterion to finite index subgroups of $F_2\rtimes F_n$ to show incoherence of all such groups, and to other similar classes of groups. Furthermore, we show that a large class of groups, including all these groups, virtually algebraically fiber. ","math"
"2006.13964","Seven-Point Conformal Blocks in the Extended Snowflake Channel and   Beyond","  Seven-point functions have two inequivalent topologies or channels. The comb channel has been computed previously and here we compute scalar conformal blocks in the extended snowflake channel in $d$ dimensions. Our computation relies on the known action of the differential operator that sets up the operator product expansion in embedding space. The scalar conformal blocks in the extended snowflake channel are obtained as a power series expansion in the conformal cross-ratios whose coefficients are a triple sum of the hypergeometric type. This triple sum factorizes into a single sum and a double sum. The single sum can be seen as originating from the comb channel and is given in terms of a ${}_3F_2$-hypergeometric function, while the double sum originates from the snowflake channel which corresponds to a Kamp\'e de F\'eriet function. We verify that our results satisfy the symmetry properties of the extended snowflake topology. Moreover, we check that the behavior of the extended snowflake conformal blocks under several limits is consistent with known results. Finally, we conjecture rules leading to a partial construction of scalar $M$-point conformal blocks in arbitrary topologies. ","hep-th"
"2006.08526","Ferromagnetically shifting the power of pausing","  We study the interplay between quantum annealing parameters in embedded problems, providing both deeper insights into the physics of these devices and pragmatic recommendations to improve performance on optimization problems. We choose as our test case the class of degree-bounded minimum spanning tree problems. Through runs on a D-Wave quantum annealer, we demonstrate that pausing in a specific time window in the anneal provides improvement in the probability of success and in the time-to-solution for these problems. The time window is consistent across problem instances, and its location is within the region suggested by prior theory and seen in previous results on native problems. An approach to enable gauge transformations for problems with the qubit coupling strength $J$ in an asymmetric range is presented and shown to significantly improve performance. We also confirm that the optimal pause location exhibits a shift with the magnitude of the ferromagnetic coupling, $|J_F|$, between physical qubits representing the same logical one. We extend the theoretical picture for pausing and thermalization in quantum annealing to the embedded case. This picture, along with perturbation theory analysis, and exact numerical results on small problems, confirms that the effective pause region moves earlier in the anneal as $|J_F|$ increases. It also suggests why pausing, while still providing significant benefit, has a less pronounced effect on embedded problems. ","quant-ph"
"2005.00394","Bacterial pathways for the biosynthesis of ubiquinone","  Ubiquinone is an important component of the electron transfer chains in proteobacteria and eukaryotes. The biosynthesis of ubiquinone requires multiple steps, most of which are common to bacteria and eukaryotes. Whereas the enzymes of the mitochondrial pathway that produces ubiquinone are highly similar across eukaryotes, recent results point to a rather high diversity of pathways in bacteria. This review focuses on ubiquinone in bacteria, highlighting newly discovered functions and detailing the proteins that are known to participate to its biosynthetic pathways. Novel results showing that ubiquinone can be produced by a pathway independent of dioxygen suggest that ubiquinone may participate to anaerobiosis, in addition to its well established role for aerobiosis. We also discuss the supramolecular organization of ubiquinone biosynthesis proteins and we summarize the current understanding of the evolution of the ubiquinone pathways relative to those of other isoprenoid quinones like menaquinone and plastoquinone. ","q-bio"
"1907.12745","Unusually stronger quantum fluctuation with larger spins: Novel   phenomena revealed by emergent magnetism in pressurized high-temperature   superconductor FeSe","  A counter-intuitive enhancement of quantum fluctuation with larger spins, together with a few novel physical phenomena, is discovered in studying the recently observed emergent magnetism in high-temperature superconductor FeSe under pressure. Starting with experimental crystalline structure from our high-pressure X-ray refinement, we analyze theoretically the stability of the magnetically ordered state with a realistic spin-fermion model. We find surprisingly that in comparison with the magnetically ordered Fe-pnictides, the larger spins in FeSe suffer even stronger long-range quantum fluctuation that diminishes their ordering at ambient pressure. This ""fail-to-order"" quantum spin liquid state then develops into an ordered state above 1GPa due to weakened fluctuation accompanying the reduction of anion height and carrier density. The ordering further benefits from the ferro-orbital order and shows the observed enhancement around 1GPa. We further clarify the controversial nature of magnetism and its interplay with nematicity in FeSe in the same unified picture for all Fe-based superconductors. In addition, the versatile itinerant carriers produce interesting correlated metal behavior in a large region of phase space. Our study establishes a generic exceptional paradigm of stronger quantum fluctuation with larger spins that complements the standard knowledge of insulating magnetism. ","cond-mat"
"2007.08515","Multiple phases in a generalized Gross-Witten-Wadia matrix model","  We study a unitary matrix model of the Gross-Witten-Wadia type, extended with the addition of characteristic polynomial insertions. The model interpolates between solvable unitary matrix models and is the unitary counterpart of a deformed Cauchy ensemble. Exact formulas for the partition function and Wilson loops are given in terms of Toeplitz determinants and minors and large $N$ results are obtained by using Szeg\""o theorem with a Fisher-Hartwig singularity. In the large $N$ (planar) limit with two scaled couplings, the theory exhibits a surprisingly intricate phase structure in the two-dimensional parameter space. ","hep-th"
"2006.11101","Origin of large meteoritic SiC stardust grains in metal-rich AGB stars","  Stardust grains that originated in ancient stars and supernovae are recovered from meteorites and carry the detailed composition of their astronomical sites of origin. We present evidence that the majority of large ($\mu$m-sized) meteoritic silicon carbide (SiC) grains formed in C-rich asymptotic giant branch (AGB) stars that were more metal-rich than the Sun. In the framework of the slow neutron-captures (the s process) that occurs in AGB stars the lower-than-solar 88Sr/86Sr isotopic ratios measured in the large SiC grains can only be accompanied by Ce/Y elemental ratios that are also lower than solar, and predominately observed in metal-rich barium stars - the binary companions of AGB stars. Such an origin suggests that these large grains represent the material from high-metallicity AGB stars needed to explain the s-process nucleosynthesis variations observed in bulk meteorites (Ek et al. 2020). In the outflows of metal-rich, C-rich AGB stars SiC grains are predicted to be small ($\simeq$ 0.2 $\mu$m-sized); large ($\simeq$ $\mu$m-sized) SiC grains can grow if the number of dust seeds is two to three orders of magnitude lower than the standard value of $10^{-13}$ times the number of H atoms. We therefore predict that with increasing metallicity the number of dust seeds might decrease, resulting in the production of larger SiC grains. ","astro-ph"
"1610.02425","Quantum Cellular Automata Models for General Dirac Equation","  The goal of this study is to provide an exact unitary quantum cellular automata that, under discrete time steps, converges towards the Generalized Dirac Equation (GDE) in the continuum limit. The evolutionary rules for such a single particle walk are discussed in this paper, and it is shown that this quantum celluar automata will maintain similar properties to the GDE. ","quant-ph"
"2006.08988","A joint bayesian space-time model to integrate spatially misaligned air   pollution data in R-INLA","  In air pollution studies, dispersion models provide estimates of concentration at grid level covering the entire spatial domain, and are then calibrated against measurements from monitoring stations. However, these different data sources are misaligned in space and time. If misalignment is not considered, it can bias the predictions. We aim at demonstrating how the combination of multiple data sources, such as dispersion model outputs, ground observations and covariates, leads to more accurate predictions of air pollution at grid level. We consider nitrogen dioxide (NO2) concentration in Greater London and surroundings for the years 2007-2011, and combine two different dispersion models. Different sets of spatial and temporal effects are included in order to obtain the best predictive capability. Our proposed model is framed in between calibration and Bayesian melding techniques for data fusion red. Unlike other examples, we jointly model the response (concentration level at monitoring stations) and the dispersion model outputs on different scales, accounting for the different sources of uncertainty. Our spatio-temporal model allows us to reconstruct the latent fields of each model component, and to predict daily pollution concentrations. We compare the predictive capability of our proposed model with other established methods to account for misalignment (e.g. bilinear interpolation), showing that in our case study the joint model is a better alternative. ","stat"
"1902.05097","Knowledge-aided Two-dimensional Autofocus for Spotlight SAR Filtered   Backprojection Imagery","  Filtered backprojection (FBP) algorithm is a popular choice for complicated trajectory SAR image formation processing due to its inherent nonlinear motion compensation capability. However, how to efficiently autofocus the defocused FBP imagery when the motion measurement is not accurate enough is still a challenging problem. In this paper, a new interpretation of the FBP derivation is presented from the Fourier transform point of view. Based on this new viewpoint, the property of the residual 2-D phase error in FBP imagery is analyzed in detail. Then, by incorporating the derived a priori knowledge on the 2-D phase error, an accurate and efficient 2-D autofocus approach is proposed. The new approach performs the parameter estimation in a dimension-reduced parameter subspace by exploiting the a priori analytical structure of the 2-D phase error, therefore possesses much higher accuracy and efficiency than conventional blind methods. Finally, experimental results clearly demonstrate the effectiveness and robustness of the proposed method. ","eess"
"2006.03724","Competing Antiferromagnetic-Ferromagnetic States in $\it{d^7}$ Kitaev   Honeycomb Magnet","  The Kitaev model is a rare example of an analytically solvable and physically instantiable Hamiltonian yielding a topological quantum spin liquid ground state. Here we report signatures of Kitaev spin liquid physics in the honeycomb magnet $Li_3Co_2SbO_6$, built of high-spin $\it{d^7}$ ($Co^{2+}$) ions, in contrast to the more typical low-spin $\it{d^5}$ electron configurations in the presence of large spin-orbit coupling. Neutron powder diffraction measurements, heat capacity, and magnetization studies support the development of a long-range antiferromagnetic order space group of $\it{C_C}2/\it{m}$, below $\it{T_N}$ = 11 K at $\it{\mu_0H}$ = 0 T. The magnetic entropy recovered between $\it{T}$ = 2 K and 50 K is estimated to be 0.6Rln2, in good agreement with the value expected for systems close to a Kitaev quantum spin liquid state. The temperature-dependent magnetic order parameter demonstrates a $\beta$ value of 0.19(3), consistent with XY anisotropy and in-plane ordering, with Ising-like interactions between layers. Further, we observe a spin-flop driven crossover to ferromagnetic order with space group of $\it{C}2/\it{m}$ under an applied magnetic field of $\it{\mu_0H}$ $\approx$ 0.7 T at $\it{T}$ = 2 K. Magnetic structure analysis demonstrates these magnetic states are competing at finite applied magnetic fields even below the spin-flop transition. Both the $\it{d^7}$ compass model, a quantitative comparison of the specific heat of $Li_3Co_2SbO_6$, and related honeycomb cobaltates to the anisotropic Kitaev model further support proximity to a Kitaev spin liquid state. This material demonstrates the rich playground of high-spin $\it{d^7}$ systems for spin liquid candidates, and complements known $\it{d^5}$ Ir- and Ru-based materials. ","cond-mat"
"1905.01093","Embedding Principal Component Analysis for Data Reductionin Structural   Health Monitoring on Low-Cost IoT Gateways","  Principal component analysis (PCA) is a powerful data reductionmethod for Structural Health Monitoring. However, its computa-tional cost and data memory footprint pose a significant challengewhen PCA has to run on limited capability embedded platformsin low-cost IoT gateways. This paper presents a memory-efficientparallel implementation of the streaming History PCA algorithm.On our dataset, it achieves 10x compression factor and 59x memoryreduction with less than 0.15 dB degradation in the reconstructedsignal-to-noise ratio (RSNR) compared to standard PCA. More-over, the algorithm benefits from parallelization on multiple cores,achieving a maximum speedup of 4.8x on Samsung ARTIK 710. ","eess"
"2007.14221","The Ionised- and Cool-Gas Content of The BR1202-0725 System as seen by   MUSE and ALMA","  We present MUSE observations of the gas-rich major-merger BR1202-0725 at z~4.7, which constitutes one of the most overdense fields known in the early Universe. We utilise these data in conjunction with existing ALMA observations to compare and contrast the spatially resolved ionised- and cool-gas content of this system which hosts a quasar (QSO), a sub-millimeter galaxy (SMG), the two known optical companions (""LAE1"", ""LAE2""), and an additional companion discovered in this work ""LAE3"" just 5 arcsec to the North of the QSO. We find that QSO BR1202-0725 exhibits a large Ly$\alpha$ halo, covering $\approx55$ pkpc on-sky at surface brightness levels of SB$\geq$1E-17 erg/s/cm$^2$/arcsec$^2$. In contrast, the SMG, of similar far-infrared luminosity and star formation rate (SFR), does not exhibit such a Ly$\alpha$ halo. The QSO's halo exhibits high velocity widths ($\sim1000$ km/s) but the gas motion is to some extent kinematically coupled with the previously observed [CII] bridge between the QSO and the SMG. We note that the object known in the literature as LAE2 shows no local peak of Ly$\alpha$ emission, rather, its profile is more consistent with being part of the QSO's extended Ly$\alpha$ halo. The properties of LAE3 are typical of high-redshift LAEs; we measure F$_{\rm{Ly\alpha}}$(LAE3) = $0.24\pm$0.03E-16 erg/s/cm$^2$, corresponding to SFR$_{\rm{Ly\alpha}}\approx\ $5.0$\pm$0.5 M${_\odot}$/yr. The velocity width is $\Delta v$(LAE3) $\approx 400$ km/s, and equivalent width EW$_0$(Ly$\alpha_{\,5\sigma}^{\,lim})\geq 34.05$ $\\A$, consistent with star formation being the primary driver of Ly$\alpha$ emission. We also note a coherent absorption feature at $\sim -400$km/s in spectra from at least three objects; the QSO, LAE1 and ""LAE2"" which could imply the presence of an expanding neutral gas shell with an extent of at least $24$ pkpc. ","astro-ph"
"1808.04344","Prismatic Large $N$ Models for Bosonic Tensors","  We study the $O(N)^3$ symmetric quantum field theory of a bosonic tensor $\phi^{abc}$ with sextic interactions. Its large $N$ limit is dominated by a positive-definite operator, whose index structure has the topology of a prism. We present a large $N$ solution of the model using Schwinger-Dyson equations to sum the leading diagrams, finding that for $2.81 < d < 3$ and for $d<1.68$ the spectrum of bilinear operators has no complex scaling dimensions. We also develop perturbation theory in $3-\epsilon$ dimensions including eight $O(N)^3$ invariant operators necessary for the renormalizability. For sufficiently large $N$, we find a ""prismatic"" fixed point of the renormalization group, where all eight coupling constants are real. The large $N$ limit of the resulting $\epsilon$ expansions of various operator dimensions agrees with the Schwinger-Dyson equations. Furthermore, the $\epsilon$ expansion allows us to calculate the $1/N$ corrections to operator dimensions. The prismatic fixed point in $3-\epsilon$ dimensions survives down to $N\approx 53.65$, where it merges with another fixed point and becomes complex. We also discuss the $d=1$ model where our approach gives a slightly negative scaling dimension for $\phi$, while the spectrum of bilinear operators is free of complex dimensions. ","hep-th"
"1901.09896","Quadratic torsion subgroups of modular Jacobian varieties","  Let $D$ be an odd square-free positive integer and $C$ a divisor of $D$. For any quadratic character $\chi$ modulo $C$, we prove that the $\chi$-part of the group $J_0(DC)_\text{tor}$ of torsion points of $J_0(DC)$ coincides with the $\chi$-part of its cuspidal subgroup, away from those primes of bad reduction or where possible congruences between oldforms and newforms occur. ","math"
"1905.11750","Properties of excited $B_c$ states in QCD","  The mass and leptonic decay constants of recently observed two new excited $B_c$ states at LHC are studied within the QCD sum rules. Considering the contributions of the ground and radially excited states, the mass and residues of the excited states of pseudoscalar and vector mesons are calculated in the framework of two different approaches of the QCD sum rules, namely, linear combinations of the corresponding sum rules and its derivatives as well as QCD sum rules with the incorporation of the least square fitting method. The obtained results on mass $m_{B_c^+}(2S) = 6.88 \pm 0.03~\rm{GeV} $ and $m_{B_c^{*+}}(2S) = 6.94 \pm 0.03~\rm{GeV} $ are in good agreement with the experimental data. Our predictions for the decay constants of these states are: $f_{B_c^+}(2S) = 0.42 \pm 0.02~\rm{GeV} $ and $f_{B_c^{*+}}(2S) = 0.46 \pm 0.01~\rm{GeV}$, which can be checked at future experiments to be conducted at the LHC. Comparison of our results with the predictions of the other approaches on mass and residues is also presented. ","hep-ph"
"2003.07256","Behavior of principal curvatures of frontals near non-front singular   points and their application","  We investigate behavior of principal curvatures and principal vectors near a non-degenerate singular point of the first kind of frontals. As an application, we extend the notion of Ribaucour transformations to frontals with singular points. ","math"
"1908.00425","Tetrahedrality dictates dynamics in hard spheres","  Glasses are ubiquitous amorphous solids that remain one of the big mysteries in condensed matter. Despite the vast body of literature on glasses, a unifying approach to link the structure and dynamics of glasses is still missing. A growing set of evidence, however, indicates the microscopic local geometry as a key ingredient. This originated from the seminal work of Frank, who conjectured that glasses may be the result of the local tendency of liquids to form icosahedral structures, which are not capable of globally filling space regularly. Here, we show that, for a fundamental glass model, dynamics can be fully understood by simply counting the number of tetrahedra. Both globally and locally, these local structures directly predict dynamical slowdown. After more than 60 years of Frank's Conjecture, it might not be the icosahedra that matter for glasses, but rather the tetrahedra inside them. ","cond-mat"
"1904.05551","The set of numerical semigroups of a given multiplicity and Frobenius   number","  We study the structure of the family of numerical semigroups with fixed multiplicity and Frobenius number. We give an algorithmic method to compute all the semigroups in this family. As an application we compute the set of all numerical semigroups with given multiplicity and genus. ","math"
"1807.09930","Scaled Simplex Representation for Subspace Clustering","  The self-expressive property of data points, i.e., each data point can be linearly represented by the other data points in the same subspace, has proven effective in leading subspace clustering methods. Most self-expressive methods usually construct a feasible affinity matrix from a coefficient matrix, obtained by solving an optimization problem. However, the negative entries in the coefficient matrix are forced to be positive when constructing the affinity matrix via exponentiation, absolute symmetrization, or squaring operations. This consequently damages the inherent correlations among the data. Besides, the affine constraint used in these methods is not flexible enough for practical applications. To overcome these problems, in this paper, we introduce a scaled simplex representation (SSR) for subspace clustering problem. Specifically, the non-negative constraint is used to make the coefficient matrix physically meaningful, and the coefficient vector is constrained to be summed up to a scalar s<1 to make it more discriminative. The proposed SSR based subspace clustering (SSRSC) model is reformulated as a linear equality-constrained problem, which is solved efficiently under the alternating direction method of multipliers framework. Experiments on benchmark datasets demonstrate that the proposed SSRSC algorithm is very efficient and outperforms state-of-the-art subspace clustering methods on accuracy. The code can be found at https://github.com/csjunxu/SSRSC. ","cs"
"2007.06765","Patch-wise Attack for Fooling Deep Neural Network","  By adding human-imperceptible noise to clean images, the resultant adversarial examples can fool other unknown models. Features of a pixel extracted by deep neural networks (DNNs) are influenced by its surrounding regions, and different DNNs generally focus on different discriminative regions in recognition. Motivated by this, we propose a patch-wise iterative algorithm -- a black-box attack towards mainstream normally trained and defense models, which differs from the existing attack methods manipulating pixel-wise noise. In this way, without sacrificing the performance of white-box attack, our adversarial examples can have strong transferability. Specifically, we introduce an amplification factor to the step size in each iteration, and one pixel's overall gradient overflowing the $\epsilon$-constraint is properly assigned to its surrounding regions by a project kernel. Our method can be generally integrated to any gradient-based attack methods. Compared with the current state-of-the-art attacks, we significantly improve the success rate by 9.2\% for defense models and 3.7\% for normally trained models on average. Our code is available at \url{https://github.com/qilong-zhang/Patch-wise-iterative-attack} ","cs"
"1907.07957","Application of Cox Model to predict the survival of patients with   Chronic Heart Failure: A latent class regression approach","  Most prediction models that are used in medical research fail to accurately predict health outcomes due to methodological limitations. Using routinely collected patient data, we explore the use of a Cox proportional hazard (PH) model within a latent class framework to model survival of patients with chronic heart failure (CHF). We identify subgroups of patients based on their risk with the aid of available covariates. We allow each subgroup to have its own risk model.We choose an optimum number of classes based on the reported Bayesian information criteria (BIC). We assess the discriminative ability of the chosen model using an area under the receiver operating characteristic curve (AUC) for all the cross-validated and bootstrapped samples.We conduct a simulation study to compare the predictive performance of our models. Our proposed latent class model outperforms the standard one class Cox PH model. ","stat"
"2004.00258","Packing fraction related distortion of Mn$_6$C octahedra and its effect   on the first order magnetic transition in Mn based antiperovskites","  In this paper, we attempt to understand the cause of magnetostructural transformation in Mn-based antiperovskites by calculating EXAFS at the K edges of constituent metal atoms in three antiperovskite compounds, Mn$_3$GaC, Mn$_3$SnC and Mn$_3$InC. These three compounds have very different magnetic ground states despite the similar cubic structure. Our calculations show that the distortions of Mn$_6$C octahedra, which are responsible for the first-order magnetic transition to antiferromagnetic state, depends on the packing fraction of the lattice. ","cond-mat"
"1907.06299","Universal Non-Intrusive Load Monitoring (UNILM) Using Filter Pipelines,   Probabilistic Knapsack, and Labelled Partition Maps","  Being able to track appliances energy usage without the need of sensors can help occupants reduce their energy consumption to help save the environment all while saving money. Non-intrusive load monitoring (NILM) tries to do just that. One of the hardest problems NILM faces is the ability to run unsupervised -- discovering appliances without prior knowledge -- and to run independent of the differences in appliance mixes and operational characteristics found in various countries and regions. We propose a solution that can do this with the use of an advanced filter pipeline to preprocess the data, a Gaussian appliance model with a probabilistic knapsack algorithm to disaggregate the aggregate smart meter signal, and partition maps to label which appliances were found and how much energy they use no matter the country/region. Experimental results show that relatively complex appliance signals can be tracked accounting for 93.7% of the total aggregate energy consumed. ","eess"
"1909.09940","Pseudo-invariant approach for a particle in a complex time-dependent   linear potential","  The Lewis and Riesenfeld method has been investigated, by Ramos et al in Ref.[1], for quantum systems governed by time-dependent PT symmetric Hamiltonians and particularly where the quantum system is a particle submitted to action of a complex time-dependent linear potential. We discuss the method they used and propose an alternative one which leads to physically acceptable uncertainty product and to complex x and p expectation values but describe the classical motion. We used, for this situation, a linear pseudo hermitian invariant operator which allow us to solve analytically the time-dependent Schr\""odinger equation for this problem and to construct a Gaussian wave packet solution. The normalization condition for the invariant eigenfunctions with the Dirac delta function is correctly obtained, contrary to what is stated in Ref.[1]. ","quant-ph"
"1907.03764","How to GAN LHC Events","  Event generation for the LHC can be supplemented by generative adversarial networks, which generate physical events and avoid highly inefficient event unweighting. For top pair production we show how such a network describes intermediate on-shell particles, phase space boundaries, and tails of distributions. In particular, we introduce the maximum mean discrepancy to resolve sharp local features. It can be extended in a straightforward manner to include for instance off-shell contributions, higher orders, or approximate detector effects. ","hep-ph"
"1906.03848","Evolutionary Theory in Pacific Island Archaeology","  Evolution is the principal theoretical framework in Pacific Island archaeology. Progressive cultural evolutionary stages, particularly the chiefdom, provided the earliest framework. These ideas were increasingly linked to islands as relatively isolated laboratories of cultural evolution and diversification, albeit their populations phylogenetically linked in a series of ancestral and descendant societies. With more sophisticated environmental data, much research has investigated cultural adaptations and their homologous or analogous origins. Most recently, Darwinian mechanisms of transmission, selection, and drift comprise an important approach. The history of evolution in Pacific archaeology suggests it will continue as a useful theoretical framework, perhaps more so than in other world regions. ","q-bio"
"2003.13732","Certifiable Relative Pose Estimation","  In this paper we present the first fast optimality certifier for the non-minimal version of the Relative Pose problem for calibrated cameras from epipolar constraints. The proposed certifier is based on Lagrangian duality and relies on a novel closed-form expression for dual points. We also leverage an efficient solver that performs local optimization on the manifold of the original problem's non-convex domain. The optimality of the solution is then checked via our novel fast certifier. The extensive conducted experiments demonstrate that, despite its simplicity, this certifiable solver performs excellently on synthetic data, repeatedly attaining the (certified \textit{a posteriori}) optimal solution and shows a satisfactory performance on real data. ","cs"
"2004.04991","Liverpool-Maidanak monitoring of the Einstein Cross in 2006$-$2019. I.   Light curves in the $gVrRI$ optical bands and microlensing signatures","  Quasar microlensing offers a unique opportunity to resolve tiny sources in distant active galactic nuclei and study compact object populations in lensing galaxies. We therefore searched for microlensing-induced variability of the gravitationally lensed quasar QSO 2237+0305 (Einstein Cross) using 4374 optical frames taken with the 2.0 m Liverpool Telescope and the 1.5 m Maidanak Telescope. These $gVrRI$ frames over the 2006$-$2019 period were homogeneously processed to generate accurate long-term multi-band light curves of the four quasar images A-D. Through difference light curves, we found strong microlensing signatures. We then focused on the analytical modelling of two putative caustic-crossing events in image C, finding compelling evidence that this image experienced a double caustic crossing. Additionally, our overall results indicate that a standard accretion disc accounts reasonably well for the brightness profile of UV continuum emission sources and for the growth in source radius when the emission wavelength increases: $R_{\lambda} \propto \lambda^{\alpha}$, $\alpha$ = 1.33 $\pm$ 0.09. However, we caution that numerical microlensing simulations are required before firm conclusions can be reached on the UV emission scenario because the $VRI$-band monitoring during the first caustic crossing and one of our two $\alpha$ indicators lead to a few good solutions with $\alpha \approx$ 1. ","astro-ph"
"1907.02440","Supersymmetric Tensor Model at Large $N$ and Small $\epsilon$","  We study the $O(N)^3$ supersymmetric quantum field theory of a scalar superfield $\Phi_{abc}$ with a tetrahedral interaction. In the large $N$ limit the theory is dominated by the melonic diagrams. We solve the corresponding Dyson-Schwinger equations in continuous dimensions below $3$. For sufficiently large $N$ we find an IR stable fixed point and computed the $3-\epsilon$ expansion up to the second order of perturbation theory, which is in agreement with the solution of DS equations. We also describe the $1+\epsilon$ expansion of the model and discuss the possiblity of adding the Chern-Simons action to gauge the supersymmetric model. ","hep-th"
"1806.09963","LeMoNADe: Learned Motif and Neuronal Assembly Detection in calcium   imaging videos","  Neuronal assemblies, loosely defined as subsets of neurons with reoccurring spatio-temporally coordinated activation patterns, or ""motifs"", are thought to be building blocks of neural representations and information processing. We here propose LeMoNADe, a new exploratory data analysis method that facilitates hunting for motifs in calcium imaging videos, the dominant microscopic functional imaging modality in neurophysiology. Our nonparametric method extracts motifs directly from videos, bypassing the difficult intermediate step of spike extraction. Our technique augments variational autoencoders with a discrete stochastic node, and we show in detail how a differentiable reparametrization and relaxation can be used. An evaluation on simulated data, with available ground truth, reveals excellent quantitative performance. In real video data acquired from brain slices, with no ground truth available, LeMoNADe uncovers nontrivial candidate motifs that can help generate hypotheses for more focused biological investigations. ","q-bio"
"2001.08924","Radiomics and artificial intelligence analysis of CT data for the   identification of prognostic features in multiple myeloma","  Multiple Myeloma (MM) is a blood cancer implying bone marrow involvement, renal damages and osteolytic lesions. The skeleton involvement of MM is at the core of the present paper, exploiting radiomics and artificial intelligence to identify image-based biomarkers for MM. Preliminary results show that MM is associated to an extension of the intrabone volume for the whole body and that machine learning can identify CT image features mostly correlating with the disease evolution. This computational approach allows an automatic stratification of MM patients relying of these biomarkers and the formulation of a prognostic procedure for determining the disease follow-up. ","q-bio"
"1905.01313","Optical excitation of magnons in an easy-plane antiferromagnet:   Application to Sr$_2$IrO$_4$","  We study the interaction of a (classical) light field with the magnetic degrees of freedom in the two-dimensional antiferromagnet Sr$_2$IrO$_4$. The reduced space group symmetry of the crystal allows for several channels for spin-operator bilinears to couple to the electric field. Integrating out high-energy degrees of freedom in a Keldysh framework, we derive induced effective fields which enter the equations of motion of the low-energy mode of in-plane rotations which couple to the out-of-plane magnetization. Considering a pump-probe protocol, these induced fields excite magnetization oscillations which can subsequently probed, e.g. using Kerr rotation. We discuss how the induced fields depend on polarization and frequency of the driving light, and our study applies to both resonant and non-resonant regimes. Crucially, the induced fields depend on the two-magnon density of states, thus allowing for further insight into properties of the magnetic excitation spectrum. Furthermore, these effects rely upon (weak) magnon-interactions, and so are beyond a ""Floquet magnon"" description. ","cond-mat"
"1710.07158","$\mu_{n}$-actions on K3 surfaces in positive characteristic","  In characteristic $0$, symplectic automorphisms of K3 surfaces (i.e.\ automorphisms preserving the global $2$-form) and non-symplectic ones behave differently. In this paper we consider the actions of the group schemes $\mu_{n}$ on K3 surfaces (possibly with rational double point singularities) in characteristic $p$, where $n$ may be divisible by $p$. We introduce the notion of symplecticness of such actions, and we show that symplectic $\mu_{n}$-actions have similar properties, such as possible orders, fixed loci, and quotients, to symplectic automorphisms of order $n$ in characteristic $0$. We also study local $\mu_n$-actions on rational double points. ","math"
"2003.04365","A Simple System For Coleman-De Luccia Transitions","  This paper presents a simple framework that organizes thin-wall Coleman-De Luccia instantons based on the Euclidean geometries of their original and tunneled vacuum patches. We consider all a priori allowed vacuum pairs (de Sitter or Anti-de Sitter for either patch, Minkowski can be obtained as a limit of either), and $O(4)$-symmetric thin-wall geometries connecting them. For each candidate bounce geometry, either a condition under which a solution to the $O(4)$-invariant equations of motion exists is derived, or the would-be vacuum transition is ruled out. For the parameter regimes in which a solution exists, we determine whether expansion/contraction of the bounce supplies a negative mode in the second variation of the Euclidean action. All results follow from the monotonicity of a single function. ","hep-th"
"2006.06413","The Consequences of Switching Strategies in a Two-Player Iterated   Survival Game","  We consider two-player iterated survival games in which players may switch from a more cooperative behavior to a less cooperative one at some step of the game. Payoffs are survival probabilities and lone individuals have to finish the game on their own. We explore the potential of these games to support cooperation, focusing on the case in which each single step is a Prisoner's Dilemma. We find that incentives for or against cooperation depend on the number of defections at the end of the game, as opposed to the number of steps in the game. Broadly, cooperation is supported when the survival prospects of lone individuals are relatively bleak. Specifically, we find three critical values or cutoffs for the loner survival probability which, in concert with other survival parameters, determine the incentives for or against cooperation. One cutoff determines the existence of an optimal number of defections against a fully cooperative partner, one determines whether additional defections eventually become disfavored as the number of defections by the partner increases, and one determines whether additional cooperations eventually become favored as the number of defections by the partner increases. We obtain expressions for these switch-points and for optimal numbers of defections against partners with various strategies. These typically involve small numbers of defections even in very long games. We show that potentially long stretches of equilibria may exist, in which there is no incentive to defect more or cooperate more. We describe how individuals find equilibria in best-response walks among strategies, and establish that evolutionary stability requires there be just one such equilibrium. Otherwise, equilibria are not protected against invasion by strategies with fewer defections. ","q-bio"
"1903.00877","Hadronization from color interactions","  A quark coalescence model is presented based on semi-relativistic molecular dynamics with color interactions among quarks taken into account and applied to $pp$ collisions to study the effects of this model. A phenomenological potential with two tunable parameters is introduced to describe the color interactions between quarks and antiquarks. The interactions drive the process of hadronization and finally make them form different color neutral clusters, which can be identified as hadrons based on some criteria. A Monte Carlo generator, PYTHIA is used to generate the quarks in the initial state of hadronization, and different values of tunable parameters are used to study their effects on the final state distributions and correlations. Baryon to meson ratios, transverse momentum spectra, pseudorapidity distributions and forward-backward multiplicity correlations of hadrons produced in the hadronization process from this model with different parameters are compared with those from PYTHIA. ","hep-ph"
"1910.03181","Feedback Ansatz for Adaptive-Feedback Quantum Metrology Training with   Machine Learning","  It is challenging to construct metrology schemes which harness quantum features such as entanglement and coherence to surpass the standard quantum limit. We propose an ansatz for devising adaptive-feedback quantum metrology (AFQM) strategy which reduces greatly the searching space. Combined with the Markovian feedback assumption, the computational complexity for designing AFQM would decrease from $N^7$ to $N^4$ , for N probing systems. The feedback scheme devising via machine learning such as particle-swarm optimization and derivative evolution would thus requires much less time and produces equally well imprecision scaling. We have thus devised an AFQM for 207-partite system. The imprecision scaling would persist steadily for N > 207 when the parameter settings for 207-partite system is employed without further training. Our ansatz indicates an built-in resilience of the feedback strategy against qubit loss. The feedback strategies designed for the noiseless scenarios have been tested against the qubit loss noise and the phase fluctuation noise. Our numerical result confirms great resilience of the feedback strategies against the two kinds of noise. ","quant-ph"
"1904.00362","Non-Abelian T-duality as a Transformation in Double Field Theory","  Non-Abelian T-duality (NATD) is a solution generating transformation for supergravity backgrounds with non-Abelian isometries. We show that NATD can be described as a coordinate dependent O(d,d) transformation, where the dependence on the coordinates is determined by the structure constants of the Lie algebra associated with the isometry group. Besides making calculations significantly easier, this approach gives a natural embedding of NATD in Double Field Theory (DFT), a framework which provides an O(d,d) covariant formulation for effective string actions. As a result of this embedding, it becomes easy to prove that the NATD transformed backgrounds solve supergravity equations, when the isometry algebra is unimodular. If the isometry algebra is non-unimodular, the generalized dilaton field is forced to have a linear dependence on the dual coordinates, which implies that the resulting background solves generalized supergravity equations. ","hep-th"
"1908.05086","Improved Hodgkin & Huxley-type model for action potentials in squid","  By extending the crude Goldman-Hodgkin-Katz electrodiffusion model for resting-state membrane potentials in perfused giant axons of squid, we reformulate the Hodgkin-Huxley (HH) phenomenological quantitative model to create a new model which is simpler and based more fundamentally on electrodiffusion principles. Our dynamical system, like that of HH, behaves as a 4-dimensional resonator exhibiting subthreshold oscillations. The predicted speed of propagating action potentials at 20 degrees Celsius is in good agreement with the HH experimental value at 18.5 degrees Celsius. After the external concentration of calcium ions is reduced, the generation of repetitive rebound action potentials is predicted by our model, in agreement with experiment, when the membrane is stimulated by a brief (0.1 ms) depolarizing current. Unlike the HH model, our model predicts, in agreement with experiment, that prolonged constant-current stimulation does not generate spike trains in perfused axons. Our resonator model predicts rebound spiking following prolonged hyperpolarizing stimulation, observed at 18.5 degrees Celsius by HH but not predicted at this temperature by their quantitative model. Spiking promoted by brief hyperpolarization is also predicted, at room temperature, by our electrodiffusion model, but only at much lower temperatures (ca. 6 degrees Celsius) by the HH model. We discuss qualitatively, more completely than do HH, temperature dependences of the various physical effects which determine resting and action potentials. ","q-bio"
"1909.00341","A Unified Statistical Model for Atmospheric Turbulence-Induced Fading in   Orbital Angular Momentum Multiplexed FSO Systems","  This paper proposes a unified statistical channel model to characterize the atmospheric turbulence induced distortions faced by orbital angular momentum (OAM) in free space optical (FSO) communication systems. In this channel model, the self-channel irradiance of OAM modes as well as crosstalk irradiances between different OAM modes are characterized by a Generalized Gamma distribution (GGD). The latter distribution is shown to provide an excellent match with simulated data for all regimes of atmospheric turbulence. Therefore, it can be used to overcome the computationally complex numerical simulations to model the propagation of OAM modes through atmospheric turbulent FSO channels. The GGD allows obtaining very simple tractable closed-form expressions for a variety of performance metrics. Indeed, the average capacity, the bit-error rate, and the outage probability are derived for FSO systems using single OAM mode transmission with direct detection. Furthermore, we extend our study to FSO systems using OAM mode diversity to improve the performance. By using a maximum ratio combining (MRC) at the receiver, the GGD is also shown to fit the simulated combined received optical powers. Finally, space-time (ST) coding is proposed to provide diversity and multiplexing gains, and the error probability is theoretically derived under the newly proposed generic model. ","eess"
"1902.07531","Stellar masses from granulation and oscillations of 23 bright red giants   observed by BRITE - Constellation","  Context: The study of stellar structure and evolution depends crucially on accurate stellar parameters. The photometry from space telescopes has provided superb data that allowed asteroseismic characterisation of thousands of stars. However, typical targets of space telescopes are rather faint and complementary measurements are difficult to obtain. On the other hand, the brightest, otherwise well-studied stars, are lacking seismic characterization. Aims: Our goal is to use the granulation and/or oscillation time scales measured from photometric time series of bright red giants (1.6$\leq$Vmag$\leq$5.3) observed with BRITE to determine stellar surface gravities and masses. Methods: We use probabilistic methods to characterize the granulation and/or oscillation signal in the power density spectra and the autocorrelation function of the BRITE time series. Results: We detect a clear granulation and/or oscillation signal in 23 red giant stars and extract the corresponding time scales from the power density spectra as well as the autocorrelation function of the BRITE time series. To account for the recently discovered non-linearity of the classical seismic scaling relations, we use parameters from a large sample of Kepler stars to re-calibrate the scalings of the high- and low-frequency components of the granulation signal. We develop a method to identify which component is measured if only one granulation component is statistically significant in the data. We then use the new scalings to determine the surface gravity of our sample stars, finding them to be consistent with those determined from the autocorrelation signal of the time series. We further use radius estimates from the literature to determine the stellar masses of our sample stars from the measured surface gravities. We also define a statistical measure for the evolutionary stage of the stars. ","astro-ph"
"1907.05511","A nonunitary interpretation for a single vector leptoquark combined   explanation to the $B$-decay anomalies","  In order to simultaneously account for both $R_{D^{(\ast)}}$ and $R_{K^{(\ast)}}$ anomalies in $B$-decays, we consider an extension of the Standard Model by a single vector leptoquark field, and study how one can achieve the required lepton flavour non-universality, starting from a priori universal gauge couplings. While the unitary quark-lepton mixing induced by $SU(2)_L$ breaking is insufficient, we find that effectively nonunitary mixings hold the key to simultaneously address the $R_{K^{(\ast)}}$ and $R_{D^{(\ast)}}$ anomalies. As an intermediate step towards various UV-complete models, we show that the mixings of charged leptons with additional vector-like heavy leptons successfully provide a nonunitary framework to explain $R_{K^{(\ast)}}$ and $R_{D^{(\ast)}}$. These realisations have a strong impact for electroweak precision observables and for flavour violating ones: isosinglet heavy lepton realisations are already excluded due to excessive contributions to lepton flavour violating $Z$-decays. Furthermore, in the near future, the expected progress in the sensitivity of charged lepton flavour violation experiments should allow to fully probe this class of vector leptoquark models. ","hep-ph"
"1912.01857","Adjusting Decision Boundary for Class Imbalanced Learning","  Training of deep neural networks heavily depends on the data distribution. In particular, the networks easily suffer from class imbalance. The trained networks would recognize the frequent classes better than the infrequent classes. To resolve this problem, existing approaches typically propose novel loss functions to obtain better feature embedding. In this paper, we argue that drawing a better decision boundary is as important as learning better features. Inspired by observations, we investigate how the class imbalance affects the decision boundary and deteriorates the performance. We also investigate the feature distributional discrepancy between training and test time. As a result, we propose a novel, yet simple method for class imbalanced learning. Despite its simplicity, our method shows outstanding performance. In particular, the experimental results show that we can significantly improve the network by scaling the weight vectors, even without additional training process. ","cs"
"2001.03119","Bone tools, ornaments and other unusual objects during the Middle to   Upper Palaeolithic transition in Italy","  The arrival of Modern Humans (MHs) in Europe between 50 ka and 36 ka coincides with significant changes in human behaviour, regarding the production of tools, the exploitation of resources and the systematic use of ornaments and colouring substances. The emergence of the so-called modern behaviours is usually associated with MHs, although in these last decades findings relating to symbolic thinking of pre-Sapiens groups have been claimed. In this paper we present a synthesis of the Italian evidence concerning bone manufacturing and the use of ornaments and pigments in the time span encompassing the demise of Neandertals and their replacement by MHs. Current data show that Mousterian bone tools are mostly obtained from bone fragments used as is. Conversely an organized production of fine shaped bone tools is characteristic of the Uluzzian and the Protoaurignacian, when the complexity inherent in the manufacturing processes suggests that bone artefacts are not to be considered as expedient resources. Some traces of symbolic activities are associated to Neandertals in Northern Italy. Ornaments (mostly tusk shells) and pigments used for decorative purposes are well recorded during the Uluzzian. Their features and distribution witness to an intriguing cultural homogeneity within this technocomplex. The Protoaurignacian is characterized by a wider archaeological evidence, consisting of personal ornaments (mostly pierced gastropods), pigments and artistic items. ","q-bio"
"1902.06281","Approximate leave-future-out cross-validation for Bayesian time series   models","  One of the common goals of time series analysis is to use the observed series to inform predictions for future observations. In the absence of any actual new data to predict, cross-validation can be used to estimate a model's future predictive accuracy, for instance, for the purpose of model comparison or selection. Exact cross-validation for Bayesian models is often computationally expensive, but approximate cross-validation methods have been developed, most notably methods for leave-one-out cross-validation (LOO-CV). If the actual prediction task is to predict the future given the past, LOO-CV provides an overly optimistic estimate because the information from future observations is available to influence predictions of the past. To properly account for the time series structure, we can use leave-future-out cross-validation (LFO-CV). Like exact LOO-CV, exact LFO-CV requires refitting the model many times to different subsets of the data. Using Pareto smoothed importance sampling, we propose a method for approximating exact LFO-CV that drastically reduces the computational costs while also providing informative diagnostics about the quality of the approximation. ","stat"
"1804.04359","On Scalable Particle Markov Chain Monte Carlo","  Particle Markov Chain Monte Carlo (PMCMC) is a general approach to carry out Bayesian inference in non-linear and non-Gaussian state space models. Our article shows how to scale up PMCMC in terms of the number of observations and parameters by expressing the target density of the PMCMC in terms of the basic uniform or standard normal random numbers, instead of the particles, used in the sequential Monte Carlo algorithm. Parameters that can be drawn efficiently conditional on the particles are generated by particle Gibbs. All the other parameters are drawn by conditioning on the basic uniform or standard normal random variables; e.g. parameters that are highly correlated with the states, or parameters whose generation is expensive when conditioning on the states. The performance of this hybrid sampler is investigated empirically by applying it to univariate and multivariate stochastic volatility models having both a large number of parameters and a large number of latent states and shows that it is much more efficient than competing PMCMC methods. We also show that the proposed hybrid sampler is ergodic. ","stat"
"1904.08940","Shaping Asteroids with Genetic Evolution (SAGE)","  In this work we present SAGE (Shaping Asteroid models using Genetic Evolution) asteroid modelling algorithm based solely on photometric lightcurve data. It produces non-convex shapes, rotation axes orientati and rotational periods of asteroids. The main concept behind a genetic evolution algorithm is to produce random populations of shapes and spin orientations by mutating a seed shape and iterating the process until it converges to a stable global minimum. To test SAGE we have performed tes on five artificial shapes. We have also modelled (433) Eros and (9) Meti asteroids, as ground truth observations for them exist, allowing us to validate the models. We have compared derived Eros shape with NEAR Shoem model and Metis shape with adaptive optics and stellar occultation observations as with other available Metis models from various inversion methods. ","astro-ph"
"1903.12126","Neutrino mass via linear seesaw, 331-model and Froggatt-Nielsen   mechanism","  In this paper, we introduce an extension of the Standard Model, based on SU(3)$_\mathrm{C}\times $SU(3)$_\mathrm{L}\times $U(1)$_X$ gauge symmetry (331-model). The 331-models traditionally explain the number of fermion familes in nature. In our model the Froggatt-Nielsen mechanism is incorporated into the 331-setting in a particularly economical fashion. The model utilizes the both the Froggatt-Nielsen and linear seesaw mechanisms to explain the observed fermion mass hierarchies and lightness of neutrinos. In our numerical analysis we found that a $\sim$ 50 TeV new physics scale is able to reproduce correctly all the fermion masses and mixing matrices, including neutrino masses, mass squared differences and mixing matrix. ","hep-ph"
"1907.07997","Electric bias-controlled switching of magnetization of ferrimagnetically   coupled Mn delta-layers in a GaAs-AlGaAs quantum well","  We suggest a model of synthetic ferrimagnetic semiconductor structure based on GaAs-AlGaAs quantum well doped by two Mn delta-layers. The coupling between the delta-layers is mediated by extra holes, and can be switched between ferro- and antiferromagnetic one by gating the structure. A proper choice of Mn concentrations in the delta-layers and of local degree of disorder enables fabrication of a ferrimagnetic structure supporting ultrafast switching of magnetization by short pulses of electric bias without an external magnetic field. The switching mechanism in the structure relies on kinetic spin exchange between the two delta-layers which is mediated by exchange scattering of electric-pulse heated holes by magnetic ions within the layers. Owing to specific interplay between characteristics of the exchange scattering, spin decay times, and the heat withdraw in the suggested synthetic ferrimagnetic semiconductor, the necessary parameters of electric-bias pulse are within the technologically accessible range, and do not contradict typical thermal kinetics of semiconductor structures. ","cond-mat"
"1905.08382","The Proximity Effect in a Superconductor-Quasicrystal Hybrid Ring","  We compute the real-space profile of the superconducting order parameter (OP) in a hybrid ring that consists of a 1D superconductor connected to a Fibonacci chain using a self-consistent approach. In our study, the strength of the penetration, as measured by the order parameter at the center of the quasicrystal, depends on the structural parameter $\phi$, or phason angle, that characterizes different realizations of the Fibonacci chains of a given length. We show that the penetration strength dependence on $\phi$ reflects properties of the topological edge states of the Fibonacci chain. We show that the induced superconducting order parameter averaged over all chains has a power law decay as a function of distance from the S-N interface. More interestingly, we show that there are large OP fluctuations for individual chains and that the penetration strength in a finite Fibonacci chain can be significantly $larger$ than in a normal periodic conductor for special values of $\phi$. ","cond-mat"
"1907.01087","On simple $Z_2$-invariant and corner function germs","  V.I.Arnold has classified simple (i.e. having no modules for the classification) singularities (function germs), and also simple boundary singularities (function germs invariant with respect to the action $\sigma(x_1; y_1, \ldots, y_n)=(-x_1; y_1, \ldots, y_n)$ of the group $Z_2$. In particular, it was shown that a function germ (respectively a boundary singularity germ) is simple if and only if the intersection form (respectively the restriction of the intersection form to the subspace to anti-invariant cycles) of a germ in $3+4s$ variables stable equivalent to the one under consideration is negative definite and if and only if the (equivariant) monodromy group on the corresponding subspace is finite. We formulate and prove analogues of these statements for function germs invariant with respect to an arbitrary action of the group $Z_2$ and also for corner singularities. ","math"
"1908.03636","Star-convex Polyhedra for 3D Object Detection and Segmentation in   Microscopy","  Accurate detection and segmentation of cell nuclei in volumetric (3D) fluorescence microscopy datasets is an important step in many biomedical research projects. Although many automated methods for these tasks exist, they often struggle for images with low signal-to-noise ratios and/or dense packing of nuclei. It was recently shown for 2D microscopy images that these issues can be alleviated by training a neural network to directly predict a suitable shape representation (star-convex polygon) for cell nuclei. In this paper, we adopt and extend this approach to 3D volumes by using star-convex polyhedra to represent cell nuclei and similar shapes. To that end, we overcome the challenges of 1) finding parameter-efficient star-convex polyhedra representations that can faithfully describe cell nuclei shapes, 2) adapting to anisotropic voxel sizes often found in fluorescence microscopy datasets, and 3) efficiently computing intersections between pairs of star-convex polyhedra (required for non-maximum suppression). Although our approach is quite general, since star-convex polyhedra include common shapes like bounding boxes and spheres as special cases, our focus is on accurate detection and segmentation of cell nuclei. Finally, we demonstrate on two challenging datasets that our approach (StarDist-3D) leads to superior results when compared to classical and deep learning based methods. ","cs"
"1812.07684","Type-4 spinors: transmuting from Elko to single-helicity spinors","  In this communication we briefly report an unexpected theoretical discovery which emerge from the mapping of Elko mass-dimension-one spinors into single helicity spinors. Such procedure unveils a class of spinor which is classified as type-4 spinor field within Lounesto classification. In this paper we explore the underlying physical and mathematical contents of the type-4 spinor. ","hep-th"
"1903.11911","$\Lambda_b$ decays into $\Lambda_c^*\ell\bar{\nu}_\ell$ and   $\Lambda_c^*\pi^-$ $[\Lambda_c^*=\Lambda_c(2595)$ \& $\Lambda_c(2625)]$ and   heavy quark spin symmetry","  We study the implications for $\Lambda_b \to \Lambda_c^*\ell\bar{\nu}_\ell$ and $\Lambda_b \to \Lambda_c^*\pi^-$ $[\Lambda_c^*=\Lambda_c(2595)$ and $\Lambda_c(2625)]$ decays that can be deduced from heavy quark spin symmetry (HQSS). Identifying the odd parity $\Lambda_c(2595)$ and $\Lambda_c(2625)$ resonances as HQSS partners, with total angular momentum--parity $j_q^P=1^-$ for the light degrees of freedom, we find that the ratios $\Gamma(\Lambda_b\rightarrow\Lambda_c(2595)\pi^-)/\Gamma(\Lambda_b\rightarrow\Lambda_c(2625)\pi^-)$ and $\Gamma(\Lambda_b\rightarrow \Lambda_c(2595) \ell \bar{\nu}_\ell)/ \Gamma(\Lambda_b\rightarrow\Lambda_c(2625) \ell \bar{\nu}_\ell)$ agree, within errors, with the experimental values given in the Review of Particle Physics. We discuss how future, and more precise, measurements of the above branching fractions could be used to shed light into the inner HQSS structure of the narrow $\Lambda_c(2595)$ odd-parity resonance. Namely, we show that such studies would constrain the existence of a sizable $j^P_q=0^-$ component in its wave-function, and/or of a two-pole pattern, in analogy to the case of the similar $\Lambda(1405)$ resonance in the strange sector, as suggested by most of the approaches that describe the $\Lambda_c(2595)$ as a hadron molecule. We also investigate the lepton flavor universality ratios $R[\Lambda_c^*] = {\cal B}(\Lambda_b \to \Lambda_c^* \tau\,\bar\nu_\tau)/{\cal B}(\Lambda_b \to \Lambda_c^* \mu\,\bar\nu_\mu)$, and discuss how $R[\Lambda_c(2595)]$ may be affected by a new source of potentially large systematic errors if there are two $\Lambda_c(2595)$ poles. ","hep-ph"
"1912.00784","Thermodynamics of Inhomogeneously Mass-deformed ABJM Model and Pressure   Anisotropy","  In this paper we study the thermodynamics of black branes with a modulated complex scalar in the context of bulk and boundary theories. The modulation induces inhomogeneity to the dual field theory, anisotropic pressure, and brane charge to the bulk geometry. The first law of thermodynamics and the Smarr relation are obtained using the off-shell ADT and the reduced action formalisms. We discuss the prescription for the mass of black branes, which relies on relevant and marginal deformations in the dual field theory. One of the cases is the gravity dual to a ABJM model with a sinusoidal mass function depending on a spatial coordinate. This is the first study of the deformed ABJM model at finite temperature including bulk thermodynamics. ","hep-th"
"2008.07395","Fatigue and retention in the growth window of ferroelectric Hf0.5Zr0.5O2   thin films","  The growth window of epitaxial Hf0.5Zr0.5O2 is established taking into account the main ferroelectric properties that films have to present simultaneously: high remanent polarization, low fatigue and long retention. Defects in the film and imprint field depend on deposition temperature and oxygen pressure, with an impact on fatigue and retention, respectively. Fatigue increases with substrate temperature and pressure, and retention is short if low temperature is used. The growth window of epitaxial stabilization of ferroelectric Hf0.5Zr0.5O2 is narrower when all major ferroelectric properties (remanence, endurance and retention) are considered, but deposition temperature and pressure ranges are still sufficiently wide. ","cond-mat"
"2006.05760","Determination of generalized parton distributions through a simultaneous   analysis of axial form factor and wide-angle Compton scattering data","  In this work, we present a new set of unpolarized ($ H $) and polarized ($\widetilde{H}$) generalized parton distributions (GPDs) that have been determined using a simultaneous $ \chi^2 $ analysis of the nucleon axial form factor (AFF) and wide-angle Compton scattering (WACS) experimental data at the next-to-leading order (NLO) accuracy in QCD. We explore various Ansatzes presented in the literature for GPDs, which use forward parton distributions as input, and choose the ones most suited to our analysis. The experimental data included in our analysis cover a wide range of the squared transverse momentum, which is $ 0.025 < -t < 6.46 $ GeV$ ^2 $. We show that the WACS data affect significantly the large $-t$ behavior of $\widetilde{H}$. The polarized GPDs obtained from the simultaneous analysis of AFF and WACS data differ considerably from the corresponding ones obtained by analyzing AFF and WACS separately, and have less uncertainties. We show that the theoretical predictions obtained using our GPDs are in good agreement with the analyzed AFF and WACS data for the entire range of $ -t $ studied. Finally, we obtain the impact parameter dependent parton distributions, both in an unpolarized and in a transversely polarized proton, and present them as tomography plots. ","hep-ph"
"1608.07180","Bayesian Inference for Sequential Treatments under Latent Sequential   Ignorability","  We focus on causal inference for longitudinal treatments, where units are assigned to treatments at multiple time points, aiming to assess the effect of different treatment sequences on an outcome observed at a final point. A common assumption in similar studies is Sequential Ignorability (SI): treatment assignment at each time point is assumed independent of future potential outcomes given past observed outcomes and covariates. SI is questionable when treatment participation depends on individual choices, and treatment assignment may depend on unobservable quantities associated with future outcomes. We rely on Principal Stratification to formulate a relaxed version of SI: Latent Sequential Ignorability (LSI) assumes that treatment assignment is conditionally independent on future potential outcomes given past treatments, covariates and principal stratum membership, a latent variable defined by the joint value of observed and missing intermediate outcomes. We evaluate SI and LSI, using theoretical arguments and simulation studies to investigate the performance of the two assumptions when one holds and inference is conducted under both. Simulations show that when SI does not hold, inference performed under SI leads to misleading conclusions. Conversely, LSI generally leads to correct posterior distributions, irrespective of which assumption holds. ","stat"
"1809.06256","Sensor Transfer: Learning Optimal Sensor Effect Image Augmentation for   Sim-to-Real Domain Adaptation","  Performance on benchmark datasets has drastically improved with advances in deep learning. Still, cross-dataset generalization performance remains relatively low due to the domain shift that can occur between two different datasets. This domain shift is especially exaggerated between synthetic and real datasets. Significant research has been done to reduce this gap, specifically via modeling variation in the spatial layout of a scene, such as occlusions, and scene environmental factors, such as time of day and weather effects. However, few works have addressed modeling the variation in the sensor domain as a means of reducing the synthetic to real domain gap. The camera or sensor used to capture a dataset introduces artifacts into the image data that are unique to the sensor model, suggesting that sensor effects may also contribute to domain shift. To address this, we propose a learned augmentation network composed of physically-based augmentation functions. Our proposed augmentation pipeline transfers specific effects of the sensor model -- chromatic aberration, blur, exposure, noise, and color temperature -- from a real dataset to a synthetic dataset. We provide experiments that demonstrate that augmenting synthetic training datasets with the proposed learned augmentation framework reduces the domain gap between synthetic and real domains for object detection in urban driving scenes. ","cs"
"1910.07543","Modeling magnetic evolution and exchange hardening in disordered   magnets: The example of Mn$_{1-x}$Fe$_x$Ru$_2$Sn Heusler alloys","  We demonstrate how exchange hardening can arise in a chemically-disordered solid solution from a first-principles statistical mechanics approach. A general mixed-basis chemical and magnetic cluster expansion has been developed, and applied to the Mn$_{1-x}$Fe$_x$Ru$_2$Sn Heusler alloy system; single-phase solid solutions between antiferromagnetic \ch{MnRu2Sn} and ferromagnetic \ch{FeRu2Sn} with disorder on the Mn/Fe sublattice that exhibit unexpected exchange hardening. Monte Carlo simulations applied to the cluster expansion are able to reproduce the experimentally measured magnetic transition temperatures and the bulk magnetization as a function of composition. The magnetic ordering around a site is shown to be dependent not only on bulk composition, but also on the identity of the site and the local composition around that site. The simulations predict that local antiferromagnetic orderings form inside a bulk ferromagnetic region at intermediate compositions that drives the exchange hardening. Furthermore, the antiferromagnetic regions disorder at a lower temperature than the ferromagnetic regions, providing an atomistic explanation for the experimentally-observed decrease in exchange hardening with increasing temperature. These effects occur on a length scale too small to be resolved with previously-used characterization techniques. ","cond-mat"
"1907.10808","Approximate calculation of the binding energy between   17$\beta$-estradiol and human estrogen receptor alpha","  Estrogen receptors (ERs) are a group of proteins activated by 17$\beta$-estradiol. The endocrine-disrupting chemicals (EDCs) mimic estrogen action by bind directly to the ligand binding domain of ER. From this perspective, ER represent a good model for identifying and assessing the health risk of potential EDCs. This ability is best reflected by the ligand-ER binding energy. Multilayer fragment molecular orbital (MFMO) calculations were performed which allowed us to obtain the binding energy using a calculation scheme that considers the molecular interactions that occur on the following model systems: the bound and free receptor, 17$\beta$-estradiol and a water cluster. The bound and free receptor and 17$\beta$-estradiol were surrounded by a water shell containing the same number of molecules as the water cluster. The structures required for MFMO calculations were obtained from molecular dynamics simulations and cluster analysis. Attractive dispersion interactions were observed between 17$\beta$-estradiol and the binding site hydrophobic residues. In addition, strong electrostatic interactions were found between 17$\beta$-estradiol and the following charged/polarized residues: Glu 353, His 524 and Arg 394. The FMO2-RHF/STO-3G:MP2/6-31G(d) weighted binding energy was of -67.2 kcal/mol. We hope that the model developed in this study can be useful for identifying and assessing the health risk of potential EDCs. ","q-bio"
"1811.00022","Roll of the Dice: A Stochastically Sampled IMF Alters the Stellar   Content of Simulated Dwarf Galaxies","  Cosmological simulations are reaching the resolution necessary to study ultra-faint dwarf galaxies. Observations indicate that in small populations, the stellar initial mass function (IMF) is not fully populated; rather, stars are sampled in a way that can be approximated as coming from an underlying probability density function. To ensure the accuracy of cosmological simulations in the ultra-faint regime, we present an improved treatment of the IMF. We implement a self-consistent, stochastically populated IMF in cosmological hydrodynamic simulations. We test our method using high-resolution simulations of a Milky Way halo, run to $z=6$, yielding a sample of nearly 100 galaxies. We also use an isolated dwarf galaxy to investigate the resulting systematic differences in galaxy properties. We find that a stochastic IMF in simulations makes feedback burstier, strengthening feedback, and quenching star formation earlier in small dwarf galaxies. For galaxies in halos with mass $\lesssim10^{8.5}$ M$_\odot$, a stochastic IMF typically leads to lower stellar mass compared to a continuous IMF, sometimes by more than an order of magnitude. We show that existing methods of ensuring discrete supernovae incorrectly determine the mass of the star particle and its associated feedback. This leads to overcooling of surrounding gas, with at least ${\sim}$10 per cent higher star formation and ${\sim}$30 per cent higher cold gas content. Going forward, to accurately model dwarf galaxies and compare to observations, it will be necessary to incorporate a stochastically populated IMF that samples the full spectrum of stellar masses. ","astro-ph"
"1911.12846","Small-Instanton Transitions in F-theory","  We study the phase transition between G-instantons and D3-branes. A G-instanton is a classical solution to the self-dual equation of the M/F-theory four-form field strength G in the complex fourfold. This phase transition is dual to that between small instantons and 5-branes in the heterotic string. Using G as a background gauge flux, we may dynamically control the gauge symmetry breaking, connect between different vacua of F-theory and understand D3-branes in terms of group-theoretical quantities. We also discuss the resulting chirality change and preservation of anomaly freedom. ","hep-th"
"1902.02014","Detection of virulence factors and beta-lactamase encoding genes among   the clinical isolates of Pseudomonas aeruginosa","  Background: Pseudomonas aeruginosa has emerged as a significant opportunistic bacterial pathogen that causes nosocomial infections in healthcare settings resulting in treatment failure throughout the world. This study was carried out to compare the relatedness between virulence characteristics and \b{eta}-lactamase encoding genes producing Pseudomonas aeruginosa. Methods: A total of 120 P. aeruginosa isolates were obtained from both paediatric and adult patients of Selayang Hospital, Kuala Lumpur, Malaysia. Phenotypic methods were used to detect various virulence factors (Phospholipase, Hemolysin, Gelatinase, DNAse, and Biofilm). All the isolates were evaluated for production of extended spectrum beta-lactamase (ESBL) as well as metallo \b{eta}-lactamase (MBL) by Double-disk synergy test (DDST) and E-test while AmpC \b{eta}-lactamase production was detected by disk antagonism test. Results: In this study, 120 Pseudomonas aeruginosa isolates (20 each from blood, wounds, respiratory secretions, stools, urine, and sputum samples) were studied. Among Pseudomonas aeruginosa isolates, the distribution of virulence factors was positive for hemolysin (48.33%), DNAse (43.33%), phospholipase (40.83%), gelatinase (31.66%) production and biofilm formation (34%) respectively. The prevalence of multiple \b{eta}-lactamase in P. aeruginosa showed 19.16% ESBL, 7.5% MBL and 10.83% AmpC production respectively. Conclusion: A regular surveillance is required to reduce public healt ","q-bio"
"2002.12568","Reconstruction of weak bialgebra maps and its applications","  In this note we give a precise statement and a detailed proof for reconstruction problem of weak bialgebra maps. As an application we characterize indecomposability of weak algebras in categorical setting. ","math"
"2004.09774","Student-at-risk detection by current learning performance indicators   using Bayesian networks","  The present article is focused on the problem of prediction of student failures with the purpose of their possible prevention by timely introducing supportive measures. We propose a concept for building a predictive model based on Bayesian networks for an academic course or module taught in a blended learning format. Our empirical studies confirm that the proposed approach is perspective for the development of an early warning system for various stakeholders of the educational process. ","stat"
"1908.11787","Answering Conversational Questions on Structured Data without Logical   Forms","  We present a novel approach to answering sequential questions based on structured objects such as knowledge bases or tables without using a logical form as an intermediate representation. We encode tables as graphs using a graph neural network model based on the Transformer architecture. The answers are then selected from the encoded graph using a pointer network. This model is appropriate for processing conversations around structured data, where the attention mechanism that selects the answers to a question can also be used to resolve conversational references. We demonstrate the validity of this approach with competitive results on the Sequential Question Answering (SQA) task (Iyyer et al., 2017). ","cs"
"2006.09125","A small molecule drug candidate targeting SARS-CoV-2 main protease","  A new coronavirus identified as SARS-CoV-2 virus has brought the world to a state of crisis, causing a major pandemic, claiming more than 433,000 lives and instigating major financial damage to the global economy. Despite current efforts, developing safe and effective treatments remains a major challenge. Moreover, new strains of the virus are likely to emerge in the future. To prevent future pandemics, several drugs with various mechanisms of action are required. Drug discovery efforts against the virus fall into two main categories: (a) monoclonal antibodies targeting the spike protein of the virus and blocking it from entry; (b) small molecule inhibitors targeting key proteins of the virus, interfering with replication and translation of the virus. In this study, we are presenting a computational investigation of a potential drug candidate that targets SARS-CoV-2 protease, a viral protein critical for replication and translation of the virus. ","q-bio"
"1909.00696","The Price of Tiny Kinetic Mixing","  We consider both ""bottom-up"" and ""top-down"" approaches to the origin of gauge kinetic mixing. We focus on the possibilities for obtaining kinetic mixings $\epsilon$ which are consistent with experimental constraints and are much smaller than the naive estimates ($\epsilon \sim 10^{-2} - 10^{-1}$) at the one-loop level. In the bottom-up approach, we consider the possible suppression from multi-loop processes. Indeed we argue that kinetic mixing through gravity alone, requires at least six loops and could be as large as $\sim 10^{-13}$. In the top-down approach we consider embedding the Standard Model and a $U(1)_X$ in a single grand-unified gauge group as well as the mixing between Abelian and non-Abelian gauge sectors. ","hep-ph"
"2007.02299","Penrose limit for holographic duals of $ J\bar{T} $ deformations","  We explore bosonic string sigma models on warped $ BTZ\times S^3 $ both in the plane wave as well as beyond plane wave limit. Using the light cone gauge, we obtain the corresponding Hamiltonian and therefore the spectrum associated with the pp wave strings. Our analysis reveals a constant shift in the spectrum arising as a result of TsT transformations along the isometries of the target space manifold. Imposing the energy positivity constraint on the CFT$ _2 $ spectrum, we estimate an upper bound on the shift. We also estimate corrections as we go beyond the plane wave limit. Finally, we perform calculations using conformal gauge which reveals identical spectrum for the pp wave strings and thereby shows the equivalence between the two approaches. ","hep-th"
"2004.06522","Prospects and limits of SIR-type Mathematical Models to Capture the   COVID-19 Pandemic","  For the description of a pandemic mathematical models could be interesting. Both for physicians and politicians as a base for decisions to treat the disease. The responsible estimation of parameters is a main issue of mathematical pandemic models. Especially a good choice of $\beta$ as the number of others that one infected person encounters per unit time (per day) influences the adequateness of the results of the model. For the actual COVID-19 pandemic some aspects of the parameter choice will be discussed. Because of the incompatibility of the data of the Johns-Hopkins-University to the data of the German Robert-Koch-Institut we use the COVID-19 data of the European Centre for Disease Prevention and Control (ECDC) as a base for the parameter estimation. Two different mathematical methods for the data analysis will be discussed in this paper and possible sources of trouble will be shown. As example of the parameter choice serve the data of the USA and the UK. The resulting parameters will be used estimated and used in W.\,O. Kermack and A.\,G. McKendrick's SIR model. Strategies for the commencing and ending of social and economic shutdown measures are discussed. The numerical solution of the ordinary differential equation system of the modified SIR model is being done with a Runge-Kutta integration method of fourth order. At the end the applicability of the SIR model could be shown essentially. Suggestions about appropriate points in time at which to commence with lockdown measures based on the acceleration rate of infections conclude the paper. ","q-bio"
"1907.10188","Galaxy Structural Analysis with the Curvature of the Brightness Profile","  In this work we introduce the curvature of a galaxy brightness profile to identify its structural subcomponents in a non-parametrically fashion. Bulges, bars, disks, lens, rings and spiral arms are key to understand the formation and evolution path the galaxy undertook. Identifying them is also crucial for morphological classification of galaxies. We measure and analyse in detail the curvature of $14$ galaxies with varied morphology. High (low) steepness profiles show high (low) curvature measures. Transitions between components are identified as local peaks oscillations in the values of the curvature. We identify patterns that characterise bulges (pseudo or classic), disks, bars and rings. This method can be automated to identify galaxy components in large datasets or to provide a reliable starting point for traditional multicomponent modelling of galaxy light distribution. ","astro-ph"
"1904.04972","Decorrelated Adversarial Learning for Age-Invariant Face Recognition","  There has been an increasing research interest in age-invariant face recognition. However, matching faces with big age gaps remains a challenging problem, primarily due to the significant discrepancy of face appearances caused by aging. To reduce such a discrepancy, in this paper we propose a novel algorithm to remove age-related components from features mixed with both identity and age information. Specifically, we factorize a mixed face feature into two uncorrelated components: identity-dependent component and age-dependent component, where the identity-dependent component includes information that is useful for face recognition. To implement this idea, we propose the Decorrelated Adversarial Learning (DAL) algorithm, where a Canonical Mapping Module (CMM) is introduced to find the maximum correlation between the paired features generated by a backbone network, while the backbone network and the factorization module are trained to generate features reducing the correlation. Thus, the proposed model learns the decomposed features of age and identity whose correlation is significantly reduced. Simultaneously, the identity-dependent feature and the age-dependent feature are respectively supervised by ID and age preserving signals to ensure that they both contain the correct information. Extensive experiments are conducted on popular public-domain face aging datasets (FG-NET, MORPH Album 2, and CACD-VS) to demonstrate the effectiveness of the proposed approach. ","cs"
"1911.08418","Fast Convergence of Fictitious Play for Diagonal Payoff Matrices","  Fictitious Play (FP) is a simple and natural dynamic for repeated play in zero-sum games. Proposed by Brown in 1949, FP was shown to converge to a Nash Equilibrium by Robinson in 1951, albeit at a slow rate that may depend on the dimension of the problem. In 1959, Karlin conjectured that FP converges at the more natural rate of $O(1/\sqrt{t})$. However, Daskalakis and Pan disproved a version of this conjecture in 2014, showing that a slow rate can occur, although their result relies on adversarial tie-breaking. In this paper, we show that Karlin's conjecture is indeed correct for the class of diagonal payoff matrices, as long as ties are broken lexicographically. Specifically, we show that FP converges at a $O(1/\sqrt{t})$ rate in the case when the payoff matrix is diagonal. We also prove this bound is tight by showing a matching lower bound in the identity payoff case under the lexicographic tie-breaking assumption. ","cs"
"2008.04766","Channel Estimation for Intelligent Reflecting Surface Assisted MIMO   Systems: A Tensor Modeling Approach","  Intelligent reflecting surface (IRS) is an emerging technology for future wireless communications including 5G and especially 6G. It consists of a large 2D array of (semi-)passive scattering elements that control the electromagnetic properties of radio-frequency waves so that the reflected signals add coherently at the intended receiver or destructively to reduce co-channel interference. The promised gains of IRS-assisted communications depend on the accuracy of the channel state information. In this paper, we address the receiver design for an IRS-assisted multiple-input multiple-output (MIMO) communication system via a tensor modeling approach aiming at the channel estimation problem using supervised (pilot-assisted) methods. Considering a structured time-domain pattern of pilots and IRS phase shifts, we present two channel estimation methods that rely on a parallel factor (PARAFAC) tensor modeling of the received signals. The first one has a closed-form solution by solving rank-1 matrix approximation problems, while the second one is based on an alternating estimation scheme. Uniqueness issues are discussed and design requirements that guide the choice of the system parameters as well as the structures of the pilot signals and IRS phase shifts are discussed. A performance analysis is also carried out by means of the Cram\'er-Rao lower bound. Numerical results show the effectiveness of the proposed receivers and highlight the involved tradeoffs, while corroborating their superior performance compared to competing solutions. ","eess"
"1705.05295","Constructing a Consensus Phylogeny from a Leaf-Removal Distance","  Understanding the evolution of a set of genes or species is a fundamental problem in evolutionary biology. The problem we study here takes as input a set of trees describing {possibly discordant} evolutionary scenarios for a given set of genes or species, and aims at finding a single tree that minimizes the leaf-removal distance to the input trees. This problem is a specific instance of the general consensus/supertree problem, widely used to combine or summarize discordant evolutionary trees. The problem we introduce is specifically tailored to address the case of discrepancies between the input trees due to the misplacement of individual taxa. Most supertree or consensus tree problems are computationally intractable, and we show that the problem we introduce is also NP-hard. We provide tractability results in form of a 2-approximation algorithm. We also introduce a variant that minimizes the maximum number $d$ of leaves that are removed from any input tree, and provide a parameterized algorithm for this problem with parameter $d$. ","cs"
"1812.08179","Almost Inert Higgs Bosons at the LHC","  Non-minimal Higgs sectors are strongly constrained by the agreement of the measured couplings of the 125 GeV Higgs with Standard Model predictions. This agreement can be explained by an approximate $\mathbb{Z}_2$ symmetry under which the additional Higgs bosons are odd. This allows the additional Higgs bosons to be approximately inert, meaning that they have suppressed VEVs and suppressed mixing with the Standard Model Higgs. In this case, single production of the new Higgs bosons is suppressed, but electroweak pair production is unsuppressed. We study the phenomenology of a minimal 2 Higgs doublet model that realizes this scenario. In a wide range of parameters, the phenomenology of the model is essentially fixed by the masses of the exotic Higgs bosons, and can therefore be explored systematically. We study a number of different plausible signals in this model, and show that several LHC searches can constrain or discover additional Higgs bosons in this parameter space. We find that the reach is significantly extended at the high luminosity LHC. ","hep-ph"
"1903.06531","High Frame Rate Video Reconstruction based on an Event Camera","  Event-based cameras measure intensity changes (called events) with microsecond accuracy under high-speed motion and challenging lighting conditions. With the active pixel sensor (APS), event cameras allow simultaneous output of intensity frames. However, the output images are captured at a relatively low frame rate and often suffer from motion blur. A blurred image can be regarded as the integral of a sequence of latent images, while events indicate changes between the latent images. Thus, we are able to model the blur-generation process by associating event data to a latent sharp image. Based on the abundant event data alongside low frame rate, easily blurred images, we propose a simple yet effective approach to reconstruct high-quality and high frame rate sharp videos. Starting with a single blurred frame and its event data, we propose the Event-based Double Integral (EDI) model and solve it by adding regularization terms. Then, we extend it to multiple Event-based Double Integral (mEDI) model to get more smooth results based on multiple images and their events. Furthermore, we provide a new and more efficient solver to minimize the proposed energy model. By optimizing the energy function, we achieve significant improvements in removing blur and the reconstruction of a high temporal resolution video. The video generation is based on solving a simple non-convex optimization problem in a single scalar variable. Experimental results on both synthetic and real sequences demonstrate the superiority of our mEDI model and optimization method compared to the state of the art. ","cs"
"2001.04649","Synchrotron Gamma-Ray Emission Model of the Giant Outburst of Quasar 3C   279 in 2015 June: Fast Reconnection or Stochastic Acceleration with   Electromagnetic Cascade?","  We test the synchrotron emission scenario for the very bright gamma-ray flare of blazar 3C 279 observed in 2015 June using time-dependent numerical simulations. A bulk Lorentz factor as high as 100 can bring the synchrotron maximum energy above the GeV energy range. We find two possible solutions for the X-ray to gamma-ray spectrum. One is a prompt electron injection model with a hard power-law index as magnetic reconnection models suggest. A too strong magnetic field yields a too bright synchrotron X-ray flux due to secondary electron--positron pairs. Even in the prompt electron injection model, the Poynting flux luminosity is at most comparable to the gamma-ray or electron luminosity. Another model is the stochastic acceleration model, which leads to a very unique picture accompanying the electromagnetic cascade and re-acceleration of the secondary electron--positron pairs. In this model, the energy budget of the magnetic field is very low compared to gamma rays and electrons. ","astro-ph"
"1810.09161","Mathematical Modelling of Auxin Transport in Plant Tissues: Flux meets   Signalling and Growth","  Plant hormone auxin has critical roles in plant growth, dependent on its heterogeneous distribution in plant tissues. Exactly how auxin transport and developmental processes such as growth coordinate to achieve the precise patterns of auxin observed experimentally is not well understood. Here we use mathematical modelling to examine the interplay between auxin dynamics and growth and their contribution to formation of patterns in auxin distribution in plant tissues. Mathematical models describing the auxin-related signalling pathway, PIN and AUX1 dynamics, auxin transport, and cell growth in plant tissues are derived. A key assumption of our models is the regulation of PIN proteins by the auxin-responsive ARF-Aux/IAA signalling pathway, with upregulation of PIN biosynthesis by ARFs. Models are analysed and solved numerically to examine the long-time behaviour and auxin distribution. Changes in auxin-related signalling processes are shown to be able to trigger transition between passage and spot type patterns in auxin distribution. The model was also shown to be able to generate isolated cells with oscillatory dynamics in levels of components of the auxin signalling pathway which could explain oscillations in levels of ARF targets that have been observed experimentally. Cell growth was shown to have influence on PIN polarisation and determination of auxin distribution patterns. Numerical simulation results indicate that auxin-related signalling processes can explain the different patterns in auxin distributions observed in plant tissues, whereas the interplay between auxin transport and growth can explain the `reverse-fountain' pattern in auxin distribution observed at plant root tips. ","q-bio"
"1907.10879","Synaptic Time-Dependent Plasticity Leads to Efficient Coding of   Predictions","  Latency reduction of postsynaptic spikes is a well-known effect of Synaptic Time-Dependent Plasticity. We expand this notion for long postsynaptic spike trains, showing that, for a fixed input spike train, STDP reduces the number of postsynaptic spikes and concentrates the remaining ones. Then we study the consequences of this phenomena in terms of coding, finding that this mechanism improves the neural code by increasing the signal-to-noise ratio and lowering the metabolic costs of frequent stimuli. Finally, we illustrate that the reduction of postsynaptic latencies can lead to the emergence of predictions. ","q-bio"
"1912.03289","Constrained fit of the valence transversity distributions from dihadron   production","  We present a constrained analysis of the valence transversity Parton Distribution Functions from dihadron production in semi-inclusive DIS. While usual extractions of the transversity distributions rely explicitly on the fulfilment of the Soffer bounds, the present analysis releases that implicit restriction to implement further explicit constraints through the Lagrange multipliers method. The results are quantitatively comparable to previous analyses in the kinematical range of data ; the qualitative impact of the chosen fitting strategy translates into an increased flexibility in the functional form. ","hep-ph"
"2006.07786","Spin-orbit torque generated by amorphous Fe$_{x}$Si$_{1-x}$","  While tremendous work has gone into spin-orbit torque and spin current generation, charge-to-spin conversion efficiency remains weak in silicon to date, generally stemming from the low spin-orbit coupling (low atomic number, Z) and lack of bulk lattice inversion symmetry breaking. Here we report the observation of spin-orbit torque in an amorphous, non-ferromagnetic Fe$_{x}$Si$_{1-x}$ / cobalt bilayer at room temperature, using spin torque ferromagnetic resonance and harmonic Hall measurements. Both techniques provide a minimum spin torque efficiency of about 3 %, comparable to prototypical heavy metals such as Pt or Ta. According to the conventional theory of the spin Hall effect, a spin current in an amorphous material is not expected to have any substantial contribution from the electronic bandstructure. This, combined with the fact that Fe$_{x}$Si$_{1-x}$ does not contain any high-Z element, paves a new avenue for understanding the underlying physics of spin-orbit interaction and opens up a new class of material systems - silicides - that is directly compatible with complementary metal-oxide-semiconductor (CMOS) processes for integrated spintronics applications. ","cond-mat"
"2004.03142","Human Motion Transfer from Poses in the Wild","  In this paper, we tackle the problem of human motion transfer, where we synthesize novel motion video for a target person that imitates the movement from a reference video. It is a video-to-video translation task in which the estimated poses are used to bridge two domains. Despite substantial progress on the topic, there exist several problems with the previous methods. First, there is a domain gap between training and testing pose sequences--the model is tested on poses it has not seen during training, such as difficult dancing moves. Furthermore, pose detection errors are inevitable, making the job of the generator harder. Finally, generating realistic pixels from sparse poses is challenging in a single step. To address these challenges, we introduce a novel pose-to-video translation framework for generating high-quality videos that are temporally coherent even for in-the-wild pose sequences unseen during training. We propose a pose augmentation method to minimize the training-test gap, a unified paired and unpaired learning strategy to improve the robustness to detection errors, and two-stage network architecture to achieve superior texture quality. To further boost research on the topic, we build two human motion datasets. Finally, we show the superiority of our approach over the state-of-the-art studies through extensive experiments and evaluations on different datasets. ","cs"
"2002.03290","The studies on $Z \to \Upsilon(1S)+g+g$ at the next-to-leading-order QCD   accuracy","  In this paper, we carry out the next-to-leading-order (NLO) studies on $Z \to \Upsilon(1S)+g+g$ via the color-singlet (CS) $b\bar{b}$ state. We find the newly calculated NLO QCD corrections to this process can significantly influence its leading-order (LO) results, and greatly improve the dependence on the renormalization scale. By including the considerable feeddown contributions, the branching ratio $\mathcal{B}_{Z \to \Upsilon(1S)+g+g}$ is predicted to be $(0.56 \sim 0.95)\times 10^{-6}$, which can reach up to $19\% \sim 31\%$ of the LO predictions given by the CS dominant process $Z \to \Upsilon(1S)+b+\bar{b}$. Moreover, $Z \to \Upsilon(1S)+g+g$ also seriously affect the CS predictions on the $\Upsilon(1S)$ energy distributions, especially when $z$ is relatively small. In summary, for the inclusive $\Upsilon(1S)$ productions in $Z$ decay, besides $Z \to \Upsilon(1S)+b+\bar{b}$, the gluon radiation process $Z \to \Upsilon(1S)+g+g$ can provide indispensable contributions as well. ","hep-ph"
"2002.05109","Towards Energy Positive Sensing using Kinetic Energy Harvesters","  Conventional systems for motion context detection rely on batteries to provide the energy required for sampling a motion sensor. Batteries, however, have limited capacity and, once depleted, have to be replaced or recharged. Kinetic Energy Harvesting (KEH) allows to convert ambient motion and vibration into usable electricity and can enable batteryless, maintenance free operation of motion sensors. The signal from a KEH transducer correlates with the underlying motion and may thus directly be used for context detection, saving space, cost and energy by omitting the accelerometer. Previous work uses the open circuit or the capacitor voltage for sensing without using the harvested energy to power a load. In this paper, we propose to use other sensing points in the KEH circuit that offer information rich sensing signals while the energy from the harvester is used to power a load. We systematically analyse multiple sensing signals available in different KEH architectures and compare their performance in a transport mode detection case study. To this end, we develop four hardware prototypes, conduct an extensive measurement campaign and use the data to train and evaluate different classifiers. We show that sensing the harvesting current signal from a transducer can be energy positive, delivering up to ten times as much power as it consumes for signal acquisition, while offering comparable detection accuracy to the accelerometer signal for most of the considered transport modes. ","eess"
"2008.06994","ADL-MVDR: All deep learning MVDR beamformer for target speech separation","  Speech separation algorithms are often used to separate the target speech from other interfering sources. However, purely neural network based speech separation systems often cause nonlinear distortion that is harmful for ASR systems. The conventional mask-based minimum variance distortionless response (MVDR) beamformer can be used to minimize the distortion, but comes with high level of residual noise. Furthermore, the matrix inversion and eigenvalue decomposition processes involved in the conventional MVDR solution are not stable when jointly trained with neural networks. In this paper, we propose a novel all deep learning MVDR framework, where the matrix inversion and eigenvalue decomposition are replaced by two recurrent neural networks (RNNs), to resolve both issues at the same time. The proposed method can greatly reduce the residual noise while keeping the target speech undistorted by leveraging on the RNN-predicted frame-wise beamforming weights. The system is evaluated on a Mandarin audio-visual corpus and compared against several state-of-the-art (SOTA) speech separation systems. Experimental results demonstrate the superiority of the proposed method across several objective metrics and ASR accuracy. ","eess"
"1910.13719","Tree-Structured Scale Effects in Binary and Ordinal Regression","  In binary and ordinal regression one can distinguish between a location component and a scaling component. While the former determines the location within the range of the response categories, the scaling indicates variance heterogeneity. In particular since it has been demonstrated that misleading effects can occur if one ignores the presence of a scaling component it is important to account for potential scaling effects in the regression model, which is not possible in available recursive partitioning methods. The proposed recursive partitioning method yields two trees, one for the location and one for the scaling. They show in a simple interpretable way how variables interact to determine the binary or ordinal response. The developed algorithm controls for the global significance level and automatically selects the variables that have an impact on the response. The modelling approach is illustrated by several real-world applications. ","stat"
"1905.05642","Scratchy: A Lightweight Modular Autonomous Robot for Robotic   Competitions","  We present Scratchy---a modular, lightweight robot built for low budget competition attendances. Its base is mainly built with standard 4040 aluminium profiles and the robot is driven by four mecanum wheels on brushless DC motors. In combination with a laser range finder we use estimated odometry -- which is calculated by encoders -- for creating maps using a particle filter. A RGB-D camera is utilized for object detection and pose estimation. Additionally, there is the option to use a 6-DOF arm to grip objects from an estimated pose or generally for manipulation tasks. The robot can be assembled in less than one hour and fits into two pieces of hand luggage or one bigger suitcase. Therefore, it provides a huge advantage for student teams that participate in robot competitions like the European Robotics League or RoboCup. Thus, this keeps the funding required for participation, which is often a big hurdle for student teams to overcome, low. The software and additional hardware descriptions are available under: https://github.com/homer-robotics/scratchy. ","cs"
"1907.03475","Estimating Return on Investment for GUI Test Automation Tools","  Automated graphical user interface (GUI) tests can reduce manual testing activities and increase test frequency. This motivates the conversion of manual test cases into automated GUI tests. However, it is not clear whether such automation is cost-effective given that GUI automation scripts add to the code base and demand maintenance as a system evolves. In this paper, we introduce a method for estimating maintenance cost and Return on Investment (ROI) for Automated GUI Testing (AGT). The method utilizes the existing source code change history and can be used for evaluation also of other testing or quality assurance automation technologies. We evaluate the method for a real-world, industrial software system and compare two fundamentally different AGT tools, namely Selenium and EyeAutomate, to estimate and compare their ROI. We also report on their defect-finding capabilities and usability. The quantitative data is complemented by interviews with employees at the case company. The method was successfully applied and estimated maintenance cost and ROI for both tools are reported. Overall, the study supports earlier results showing that implementation time is the leading cost for introducing AGT. The findings further suggest that while EyeAutomate tests are significantly faster to implement, Selenium tests require more of a programming background but less maintenance. ","cs"
"1907.10187","High-dimensional inference using the extremal skew-$t$ process","  Max-stable processes are a popular tool for the study of environmental extremes, and the extremal skew-$t$ process is a general model that allows for a flexible extremal dependence structure. For inference on max-stable processes with high-dimensional data, exact likelihood-based estimation is computationally intractable. Composite likelihoods, using lower dimensional components, and Stephenson-Tawn likelihoods, using occurrence times of maxima, are both attractive methods to circumvent this issue for moderate dimensions. In this article we establish the theoretical formulae for simulations of and inference for the extremal skew-$t$ process. We also incorporate the Stephenson-Tawn concept into the composite likelihood framework, giving greater statistical and computational efficiency for higher-order composite likelihoods. We compare 2-way (pairwise), 3-way (triplewise), 4-way, 5-way and 10-way composite likelihoods for models of up to 100 dimensions. Furthermore, we propose cdf approximations for the Stephenson-Tawn likelihood function, leading to large computational gains, and enabling accurate fitting of models in large dimensions in only a few minutes. We illustrate our methodology with an application to a 90-dimensional temperature dataset from Melbourne, Australia. ","stat"
"1905.10233","Heavy Higgs Bosons at the LHC Upgrade","  We evaluate the discovery potential for the heavy Higgs bosons at the LHC energy upgrade with $\sqrt{s}=27$ TeV. We take degenerate mass spectrum and assume near the alignment limit in the Type-II Two Higgs Doublet Model for illustration. We explore the observability of the heavy neutral Higgs bosons by examining the leading decay channel $H^0/A^0\to \tau^+\tau^-$ and the clean signals from $H^0\to W^+W^-, ZZ$ via gluon-gluon fusion production. The associated production of a top quark and a charged Higgs boson via $gb\to t H^\pm$ is adopted to predict the discovery potential of heavy charged Higgses. We also emphasize the potential importance of the electroweak production of Higgs boson pairs, i.e. $pp\to W^\ast \to H^\pm A^0$ and $pp\to Z^\ast/\gamma^\ast \to H^+ H^-$. They are only governed by pure electroweak gauge couplings and can provide complementary information to the conventional signals in the determination of the nature of the Higgs sector. ","hep-ph"
"2001.10549","General Prescription for Global U(1)'s in 6D SCFTs","  We present a general prescription for determining the global U(1) symmetries of six-dimensional superconformal field theories (6D SCFTs). We use the quiver-like gauge theory description of the tensor branch to identify candidate U(1) symmetries which can act on generalized matter. The condition that these candidate U(1)'s are free of Adler-Bell-Jackiw (ABJ) anomalies provides bottom-up constraints for U(1)'s. This agrees with the answer obtained from symmetry breaking patterns induced by Higgs branch flows. We provide numerous examples illustrating the details of this proposal. In the F-theory realization of these theories, some of these symmetries originate from deformations of non-abelian flavor symmetries localized on a component of the discriminant, while others come from an additional generator of the Mordell-Weil group. We also provide evidence that some of these global U(1)'s do not arise from gauge symmetries, as would happen in taking a decoupling limit of a model coupled to six-dimensional supergravity. ","hep-th"
"2001.05369","Estimating the extent of glioblastoma invasion","  Glioblastoma Multiforme is a malignant brain tumor with poor prognosis. There have been numerous attempts to model the invasion of tumorous glioma cells via partial differential equations in the form of advection-diffusion-reaction equations. The patient-wise parametrisation of these models, and their validation via experimental data has been found to be difficult, as time sequence measurements are generally missing. Also the clinical interest lies in the actual (invisible) tumor extent for a particular MRI/DTI scan and not in a predictive estimate. Therefore we propose a stationalised approach to estimate the extent of glioblastoma (GBM) invasion at the time of a given MRI/DTI scan. The underlying dynamics can be derived from an instationary GBM model, falling into the wide class of advection-diffusion-reaction equations. The stationalisation is introduced via an analytical solution of the Fisher-KPP equation, the simplest model in the considered model class. We investigate the applicability in 1D and 2D, in the presence of inhomogeneous diffusion coefficients and on a real 3D DTI-dataset. ","q-bio"
"2005.08608","A note on 'Collider bias undermines our understanding of COVID-19   disease risk and severity' and how causal Bayesian networks both expose and   resolve the problem","  An important recent preprint by Griffith et al highlights how 'collider bias' in studies of COVID19 undermines our understanding of the disease risk and severity. This is typically caused by the data being restricted to people who have undergone COVID19 testing, among whom healthcare workers are overrepresented. For example, collider bias caused by smokers being underrepresented in the dataset may (at least partly) explain empirical results that suggest smoking reduces the risk of COVID19. We extend the work of Griffith et al making more explicit use of graphical causal models to interpret observed data. We show that their smoking example can be clarified and improved using Bayesian network models with realistic data and assumptions. We show that there is an even more fundamental problem for risk factors like 'stress' which, unlike smoking, is more rather than less prevalent among healthcare workers; in this case, because of a combination of collider bias from the biased dataset and the fact that 'healthcare worker' is a confounding variable, it is likely that studies will wrongly conclude that stress reduces rather than increases the risk of COVID19. Indeed, ""being in close contact with COVID19 people"" reduces the risk of COVID19. To avoid such potentially erroneous conclusions, any analysis of observational data must take account of the underlying causal structure including colliders and confounders. If analysts fail to do this explicitly then any conclusions they make about the effect of specific risk factors on COVID19 are likely to be flawed. ","stat"
"1901.11502","FSK-based Simultaneous Wireless Information and Power Transfer in   Inductively Coupled Resonant Circuits Exploiting Frequency Splitting","  Inductively coupled resonant circuits are affected by the so-called frequency splitting phenomenon at short distances. In the area of power electronics, tracking of one of the peak frequencies is state-of-the-art. In the data transmission community, however, the frequency splitting effect is often ignored. Particularly, modulation schemes have not yet been adapted to the bifurcation phenomenon. We argue that binary frequency shift keying (2-ary FSK) is a low-cost modulation scheme which well matches the double-peak voltage transfer function $H(s)$, particularly when the quality factor $Q$ is large, whereas most other modulation schemes suffer from the small bandwidths of the peaks. Additionally we show that a rectified version of 2-ary FSK, coined rectified FSK (RFSK), is even more attractive from output power and implementation points of view. Analytical and numerical contributions include the efficiency factor, the impulse response, and the bit error performance. A low-cost incoherent receiver is proposed. Theoretical examinations are supported by an experimental prototype. ","eess"
"2006.09435","Splittings of global Mackey functors and regularity of equivariant Euler   classes","  We establish natural splittings for the values of global Mackey functors at orthogonal, unitary and symplectic groups. In particular, the restriction homomorphisms between the orthogonal, unitary and symplectic groups of adjacent dimensions are naturally split epimorphisms. The interest in the splitting comes from equivariant stable homotopy theory. The equivariant stable homotopy groups of every global spectrum form a global Mackey functor, so the splittings imply that certain long exact homotopy group sequences separate into short exact sequences. For the real and complex global Thom spectra $\mathbf{MO}$ and $\mathbf{MU}$, the splittings imply the regularity of various Euler classes related to the tautological representations of $O(n)$ and $U(n)$. ","math"
"1803.10574","Non-Interlaced SAT is in P","  We investigate the NP-Complete problem SAT and the geometry of its instances. For a particular type that we call {\it non-interlaced formulas}, we propose a polynomial time algorithm for their resolution using graphs and matrices. ","cs"
"2008.03094","Uncertainty Relations of Variances in View of the Weak Value","  The Schr{\""o}dinger inequality is known to underlie the Kennard-Robertson inequality, which is the standard expression of quantum uncertainty for the product of variances of two observables $A$ and $B$, in the sense that the latter is derived from the former. In this paper we point out that, albeit more subtle, there is yet another inequality which underlies the Schr{\""o}dinger inequality in the same sense. The key component of this observation is the use of the weak-value operator $A_{\rm w}(B)$ introduced in our previous works (named after Aharonov's weak value), which was shown to act as the proxy operator for $A$ when $B$ is measured. The lower bound of our novel inequality supplements that of the Schr{\""o}dinger inequality by a term representing the discord between $A_{\rm w}(B)$ and $A$. In addition, the decomposition of the Schr{\""o}dinger inequality, which was also obtained in our previous works by making use the weak-value operator, is examined more closely to analyze its structure and the minimal uncertainty states. Our results are exemplified with some elementary spin 1 and 3/2 models as well as the familiar case of $A$ and $B$ being the position and momentum of a particle. ","quant-ph"
"2004.07580","If deep learning is the answer, then what is the question?","  Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence (AI) research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This perspective has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterise computations or neural codes, or who wish to understand perception, attention, memory, and executive functions? In this Perspective, our goal is to offer a roadmap for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics, and neural representation in artificial and biological systems. We highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning. ","q-bio"
"1905.07064","The Need for Laboratory Measurements and Ab Initio Studies to Aid   Understanding of Exoplanetary Atmospheres","  We are now on a clear trajectory for improvements in exoplanet observations that will revolutionize our ability to characterize their atmospheric structure, composition, and circulation, from gas giants to rocky planets. However, exoplanet atmospheric models capable of interpreting the upcoming observations are often limited by insufficiencies in the laboratory and theoretical data that serve as critical inputs to atmospheric physical and chemical tools. Here we provide an up-to-date and condensed description of areas where laboratory and/or ab initio investigations could fill critical gaps in our ability to model exoplanet atmospheric opacities, clouds, and chemistry, building off a larger 2016 white paper, and endorsed by the NAS Exoplanet Science Strategy report. Now is the ideal time for progress in these areas, but this progress requires better access to, understanding of, and training in the production of spectroscopic data as well as a better insight into chemical reaction kinetics both thermal and radiation-induced at a broad range of temperatures. Given that most published efforts have emphasized relatively Earth-like conditions, we can expect significant and enlightening discoveries as emphasis moves to the exotic atmospheres of exoplanets. ","astro-ph"
"1906.03126","Manipulation of exciton and trion quasiparticles in monolayer WS2 via   charge transfer","  Charge doping in transition metal dichalcogenide is currently a subject of high importance for future electronic and optoelectronic applications. Here we demonstrate chemical doping in CVD grown monolayer (1L) of WS2 by a few commonly used laboratory solvents by investigating the room temperature photoluminescence (PL). The appearance of distinct trionic emission in the PL spectra and quenched PL intensities suggest n-type doping in WS2. The temperature-dependent PL spectra of the doped 1L-WS2 reveal significant enhancement of trion emission intensity over the excitonic emission at low temperature indicating the stability of trion at low temperature. The temperature dependent exciton-trion population dynamic has been modeled using the law of mass action of trion formation. These results shed light on the solution-based chemical doping in 1L WS2 and its profound effect on the photoluminescence which is essential for the control of optical and electrical properties for optoelectronics applications. ","cond-mat"
"2007.12700","PyR@TE 3","  We present a new version of PyR@TE, a Python tool for the computation of renormalization group equations for general, non-supersymmetric gauge theories. Its new core relies on a recent paper by Poole & Thomsen (arXiv:1906.04625) to compute the $\beta$-functions. In this framework, gauge kinetic mixing is naturally implemented, and the Weyl consistency relations between gauge, quartic and Yukawa couplings are automatically satisfied. One of the main new features is the possibility for the user to compute the gauge coupling $\beta$-functions up to the three-loop order. Large parts of the PyR@TE code have been rewritten and improved, including the group theory module PyLie. As a results, the overall performance in terms of computation speed was drastically improved and the model file is more flexible and user-friendly. ","hep-ph"
"2001.05405","Heterogeneous accretion of Earth inferred from Mo-Ru isotope systematics","  The Mo and Ru isotopic compositions of meteorites and the bulk silicate Earth (BSE) hold important clues about the provenance of Earth's building material. Prior studies have argued that non-carbonaceous (NC) and carbonaceous (CC) meteorite groups together define a Mo-Ru 'cosmic' correlation, and that the BSE plots on the extension of this correlation. These observations were taken as evidence that the final 10-15% of Earth's accreted material derived from a homogeneous inner disk reservoir with an enstatite chondrite-like isotopic composition. Here, using new Mo and Ru isotopic data for previously uninvestigated meteorite groups, we show that the Mo-Ru correlation only exists for NC meteorites, and that both the BSE and CC meteorites fall off this Mo-Ru correlation. These observations indicate that the final stages of Earth's accretion were heterogeneous and consisted of a mixture of NC and CC materials. The Mo-Ru isotope systematics are best accounted for by either an NC heritage of the late veneer combined with a CC heritage of the Moon-forming giant impactor, or by mixed NC-CC compositions for both components. The involvement of CC bodies in the late-stage accretionary assemblage of Earth is consistent with chemical models for core-mantle differentiation, which argue for the addition of more oxidized and volatile-rich material toward the end of Earth's formation. As such, this study resolves the inconsistencies between homogeneous accretion models based on prior interpretations of the Mo-Ru systematics of meteorites and the chemical evidence for heterogeneous accretion of Earth. ","astro-ph"
"2002.06563","Epidemic analysis of COVID-19 in China by dynamical modeling","  The outbreak of novel coronavirus-caused pneumonia (COVID-19) in Wuhan has attracted worldwide attention. Here, we propose a generalized SEIR model to analyze this epidemic. Based on the public data of National Health Commission of China from Jan. 20th to Feb. 9th, 2020, we reliably estimate key epidemic parameters and make predictions on the inflection point and possible ending time for 5 different regions. According to optimistic estimation, the epidemics in Beijing and Shanghai will end soon within two weeks, while for most part of China, including the majority of cities in Hubei province, the success of anti-epidemic will be no later than the middle of March. The situation in Wuhan is still very severe, at least based on public data until Feb. 15th. We expect it will end up at the beginning of April. Moreover, by inverse inference, we find the outbreak of COVID-19 in Mainland, Hubei province and Wuhan all can be dated back to the end of December 2019, and the doubling time is around two days at the early stage. ","q-bio"
"1811.10973","Optimal Designs for Second-Order Interactions in Paired Comparison   Experiments with Binary Attributes","  In paired comparison experiments respondents usually evaluate pairs of competing options. For this situation we introduce an appropriate model and derive optimal designs in the presence of second-order interactions when all attributes are dichotomous. ","stat"
"2005.13030","Vortex-antivortex physics in shell-shaped Bose-Einstein condensates","  Shell-shaped hollow Bose-Einstein condensates (BECs) exhibit behavior distinct from their filled counterparts and have recently attracted attention due to their potential realization in microgravity settings. Here we study distinct features of these hollow structures stemming from vortex physics and the presence of rotation. We focus on a vortex-antivortex pair as the simplest configuration allowed by the constraints on superfluid flow imposed by the closed-surface topology. In the two-dimensional limit of an infinitesimally thin shell BEC, we characterize the long-range attraction between the vortex-antivortex pair and find the critical rotation speed that stabilizes the pair against self-annihilation. In the three-dimensional case, we contrast the bounds on vortex stability with those in the two-dimensional limit and the filled sphere BECs, and evaluate the critical rotation speed as a function of shell thickness. We thus demonstrate that analyzing vortex nucleation provides a non-destructive means of characterizing a hollow sphere BEC and distinguishing it from its filled counterpart. ","cond-mat"
"2005.13208","A connection between bacterial chemotactic network and optimal filtering","  The chemotactic network of Escherichia coli has been studied extensively both biophysically and information-theoretically. Nevertheless, the connection between these two aspects is still elusive. In this work, we report such a connection by showing that a standard biochemical model of the chemotactic network is mathematically equivalent to an information-theoretically optimal filtering dynamics. Moreover, we demonstrate that an experimentally observed nonlinear response relation can be reproduced from the optimal dynamics. These results suggest that the biochemical network of E. coli chemotaxis is designed to optimally extract gradient information in a noisy condition. ","q-bio"
"1911.09337","Multiple Spin-Orbit Excitons and the Electronic Structure of   $\alpha$-RuCl$_3$","  The honeycomb compound $\alpha$-RuCl$_3$ is widely discussed as a proximate Kitaev spin-liquid material. This scenario builds on spin-orbit entangled $j = 1/2$ moments arising for a $t_{2g}^5$ electron configuration with strong spin-orbit coupling $\lambda$ and a large cubic crystal field. The low-energy electronic structure of $\alpha$-RuCl$_3$, however, is still puzzling. In particular infrared absorption features at 0.30 eV, 0.53 eV, and 0.75 eV seem to be at odds with theory. Also the energy of the spin-orbit exciton, the excitation from $j = 1/2$ to 3/2, and thus the value of $\lambda$ are controversial. Combining infrared and Raman data, we show that the infrared features can be attributed to single, double, and triple spin-orbit excitons. We find $\lambda$ = 0.16 eV and $\Delta$ =42(4) meV for the observed non-cubic crystal-field splitting, supporting the validity of the $j= 1/2$ picture for $\alpha$-RuCl$_3$. The unusual strength of the double excitation is related to the underlying hopping interactions which form the basis for dominant Kitaev exchange. ","cond-mat"
"1905.12147","Submillimeter continuum variability in Planck Galactic cold clumps","  In the early stages of star formation, a protostar is deeply embedded in an optically thick envelope such that it is not directly observable. Variations in the protostellar accretion rate, however, will cause luminosity changes that are reprocessed by the surrounding envelope and are observable at submillimeter wavelengths. We searched for submillimeter flux variability toward 12 Planck Galactic Cold Clumps detected by the James Clerk Maxwell Telescope (JCMT)-SCUBA-2 Continuum Observations of Pre-protostellar Evolution (SCOPE) survey. These observations were conducted at 850 um using the JCMT/SCUBA-2. Each field was observed three times over about 14 months between 2016 April and 2017 June. We applied a relative flux calibration and achieved a calibration uncertainty of ~ 3.6% on average. We identified 136 clumps across 12 fields and detected four sources with flux variations of ~ 30%. For three of these sources, the variations appear to be primarily due to large-scale contamination, leaving one plausible candidate. The flux change of the candidate may be associated with low- or intermediate-mass star formation assuming a distance of 1.5 kpc, although we cannot completely rule out the possibility that it is a random deviation. Further studies with dedicated monitoring would provide a better understanding of the detailed relationship between submillimeter flux and accretion rate variabilities while enhancing the search for variability in star-forming clumps farther away than the Gould Belt. ","astro-ph"
"2005.04023","Neutrino Mixing by modifying the Yukawa coupling structure of   constrained sequential dominance","  In the constrained sequential dominance (CSD), tri-bimaximal mixing (TBM) pattern in the neutrino sector has been explained, by proposing a certain Yukawa coupling structure for the right-handed neutrinos of the model. Since the current nomenological model where we consider Yukawa couplings which are modified that of CSD. Essentially, we add small complex parameters to the Yukawa couplings of CSD. using these modified Yukawa couplings, we demonstrate that neutrino mixing angles can deviate from their TBM values. We also construct a model, based on flavour symmetries, in order to justify the modified form of Yukawa couplings of our work. ","hep-ph"
"2005.02490","Adaptive Conditional Distribution Estimation with Bayesian Decision Tree   Ensembles","  We present a Bayesian nonparametric model for conditional distribution estimation using Bayesian additive regression trees (BART). The generative model we use is based on rejection sampling from a base model. Typical of BART models, our model is flexible, has a default prior specification, and is computationally convenient. To address the distinguished role of the response in the BART model we propose, we further introduce an approach to targeted smoothing which is possibly of independent interest for BART models. We study the proposed model theoretically and provide sufficient conditions for the posterior distribution to concentrate at close to the minimax optimal rate adaptively over smoothness classes in the high-dimensional regime in which many predictors are irrelevant. To fit our model we propose a data augmentation algorithm which allows for existing BART samplers to be extended with minimal effort. We illustrate the performance of our methodology on simulated data and use it to study the relationship between education and body mass index using data from the medical expenditure panel survey (MEPS). ","stat"
"1905.00351","Complete energy conversion between light beams carrying orbital angular   momentum using coherent population trapping for a coherently driven   double-\Lambda atom-light coupling","  We propose a procedure to achieve a complete energy conversion between laser pulses carrying orbital angular momentum (OAM) in a cloud of cold atoms characterized by a double-\Lambda atom-light coupling scheme. A pair of resonant spatially dependent control fields prepare atoms in a position-dependent coherent population trapping state, while a pair of much weaker vortex probe beams propagate in the coherently driven atomic medium. Using the adiabatic approximation we derive the propagation equations for the probe beams. We consider a situation where the second control field is absent at the entrance to the atomic cloud and the first control field goes to zero at the end of the atomic medium. In that case the incident vortex probe beam can transfer its OAM to a generated probe beam. We show that the efficiency of such an energy conversion approaches the unity under the adiabatic condition. On the other hand, by using spatially independent profiles of the control fields, the maximum conversion efficiency is only 1/2. ","quant-ph"
"1904.01782","Conditional Adversarial Generative Flow for Controllable Image Synthesis","  Flow-based generative models show great potential in image synthesis due to its reversible pipeline and exact log-likelihood target, yet it suffers from weak ability for conditional image synthesis, especially for multi-label or unaware conditions. This is because the potential distribution of image conditions is hard to measure precisely from its latent variable $z$. In this paper, based on modeling a joint probabilistic density of an image and its conditions, we propose a novel flow-based generative model named conditional adversarial generative flow (CAGlow). Instead of disentangling attributes from latent space, we blaze a new trail for learning an encoder to estimate the mapping from condition space to latent space in an adversarial manner. Given a specific condition $c$, CAGlow can encode it to a sampled $z$, and then enable robust conditional image synthesis in complex situations like combining person identity with multiple attributes. The proposed CAGlow can be implemented in both supervised and unsupervised manners, thus can synthesize images with conditional information like categories, attributes, and even some unknown properties. Extensive experiments show that CAGlow ensures the independence of different conditions and outperforms regular Glow to a significant extent. ","cs"
"1905.01993","Cooperative Evaluation of the Cause of Urban Traffic Congestion via   Connected Vehicles","  We developed a distributed data mining system to elaborate a decision concerning the cause of urban traffic congestion via emerging connected vehicle (CV) technology. We observe this complex phenomena through the interactions between vehicles exchanging messages via Vehicle to Vehicle (V2V) communication. Results are based on real-time simulation generated scenarios extended from the real-world traffic Travel and Activity PAtterns Simulation (TAPAS) Cologne scenario. We evaluate a Voting Procedure (VP) useful for obtaining deeper insights using cooperation between vehicles, Belief Functions (BF) aim at improving representation of information and a Data Association Technique (DAT) aiming at data mining and extracting the association rules from the messages exchanged. Methods are tested and compared using a microscopic urban mobility simulator, SUMO and a network simulator, ns-2, for the simulation of communication between CVs. Compared to the Back-Propagation algorithm (BP) extensively used in the past literature, our performance evaluation shows that the proposed methods enhance the estimation of the cause of congestion by 48\% for the proposed VP, 58\% for the BF, 71\% for the DAT and 70\% for \textbeta-DAT. The methods also enhance detection time from 7.09\% to 10.3\%, and \textbeta-DAT outperforms BP by approximately 1.25\% less false alarms triggered by the network, which can be significant in the context of real-time decision making. We show that a market penetration rate between 63\% and 75\% is enough to ensure satisfactory performance. ","eess"
"1903.06501","Liouville Quantum Gravity","  We define a three-dimensional quantum theory of gravity as the holographic dual of the Liouville conformal field theory. The theory is consistent and unitary by definition. The corresponding theory of gravity with negative cosmological constant has peculiar properties. The quantum theory has no normalisable AdS3 vacuum. The model contains primary black holes with zero spin. All states can be interpreted as black holes dressed with boundary gravitons. There is a unique universal interaction between these states consistent with unitarity and the conformal symmetry of the model. This theory of gravity, though conceptually isolated from other models of quantum gravity, is worth scrutinising. ","hep-th"
"2008.10397","Extended Self-similar Solution for Circumstellar Material-Supernova   Ejecta Interaction","  In this note, we present a detailed self-similar solution to the interaction of a uniformly expanding gas and a stationary ambient medium, with an application to supernovae interacting with preexisting circumstellar media (Type IIn SNe). We implement the generalized solution into the Modular Open Source Fitter for Transients (MOSFiT), an open-source Python package for fitting extragalactic transient light curves. ","astro-ph"
"1908.01040","Nonperturbative Dynamics of Hadronic Collisions","  In the last couple of years, the LHC has released precise measurements of elastic proton-proton scattering which has become an important guide in the search for selecting phenomenological models and theoretical approaches to understand, in a deeper level, the theory of strong interactions. In this thesis, through the formulation of two models compatible with analyticity and unitarity constraints, we study some aspects concerning the Physics behind hadronic interactions. In particular, we investigate the proton-proton and the antiproton-proton elastic scattering at high energies using a Regge theory-based model, where the increase of the total cross section is attributed to the exchange of a colorless state having the quantum numbers of the vacuum, and using a model based on the Quantum-Chromodynamics-improved parton model, where the increase of the total cross section is in turn associated with semihard scatterings of partons in the hadrons. ","hep-ph"
"1506.07383","Einstein-Podolsky-Rosen (EPR) Correlations and Superluminal Interactions","  The possible connection between EPR correlations and superluminal interactions, as suggested by Bell and Bohm, is discussed using simple and palpable arguments: (a) It is shown how an experiment based on time-like events can allow us to answer the question ""Can a measurement performed on one of the photons of an entangled pair change the state of the other?"" (b) The theorem on superluminal finite-speed causal influences and superluminal signaling, introduced by Scarani and Gisin, is reexamined. (c) It is shown how faster-than-light interactions and Lorentz transformations might peacefully coexist. ","quant-ph"
"1811.10313","Heavy Majorana Neutrino Production at Future $ep$ Colliders","  The heavy singlet Majorana neutrinos are introduced to generate the neutrino mass in the so-called phenomenological type-I seesaw mechanism. The phenomena induced by the heavy Majorana neutrinos are important to search for new physics. In this paper, we explore the heavy Majorana neutrino production and decay at future $e^{-}p$ colliders. The corresponding cross sections via $W$ and photon fusion are predicted for different collider energies. Combined with the results of the heavy Majorana neutrino production via single $W$ exchange, this work can provide helpful information to search for heavy Majorana neutrinos at future $e^{-}p$ colliders. ","hep-ph"
"1907.13258","Incremental causal effects","  Causal evidence is needed to act and it is often enough for the evidence to point towards a direction of the effect of an action. For example, policymakers might be interested in estimating the effect of slightly increasing taxes on private spending across the whole population. We study identifiability and estimation of causal effects, where a continuous treatment is slightly shifted across the whole population (termed average partial effect or incremental causal effect). We show that incremental effects are identified under local ignorability and local overlap assumptions, where exchangeability and positivity only hold in a neighborhood of units. Average treatment effects are not identified under these assumptions. In this case, and under a smoothness condition, the incremental effect can be estimated via the average derivative. Moreover, we prove that in certain finite-sample observational settings, estimating the incremental effect is easier than estimating the average treatment effect in terms of asymptotic variance. For high-dimensional settings, we develop a simple feature transformation that allows for doubly-robust estimation and inference of incremental causal effects. Finally, we compare the behaviour of estimators of the incremental treatment effect and average treatment effect in experiments including data-inspired simulations. ","stat"
"1802.02426","The linearization problem of a binary quadratic problem and its   applications","  We provide several applications of the linearization problem of a binary quadratic problem. We propose a new lower bounding strategy, called the linearization-based scheme, that is based on a simple certificate for a quadratic function to be non-negative on the feasible set. Each linearization-based bound requires a set of linearizable matrices as an input. We prove that the Generalized Gilmore-Lawler bounding scheme for binary quadratic problems provides linearization-based bounds. Moreover, we show that the bound obtained from the first level reformulation linearization technique is also a type of linearization-based bound, which enables us to provide a comparison among mentioned bounds. However, the strongest linearization-based bound is the one that uses the full characterization of the set of linearizable matrices. Finally, we present a polynomial-time algorithm for the linearization problem of the quadratic shortest path problem on directed acyclic graphs. Our algorithm gives a complete characterization of the set of linearizable matrices for the quadratic shortest path problem. ","math"
"1907.11953","Automated Mammogram Analysis with a Deep Learning Pipeline","  Current deep learning based detection models tackle detection and segmentation tasks by casting them to pixel or patch-wise classification. To automate the initial mass lesion detection and segmentation on the whole mammographic images and avoid the computational redundancy of patch-based and sliding window approaches, the conditional generative adversarial network (cGAN) was used in this study. Subsequently, feeding the detected regions to the trained densely connected network (DenseNet), the binary classification of benign versus malignant was predicted. We used a combination of publicly available mammographic data repositories to train the pipeline, while evaluating the model's robustness toward our clinically collected repository, which was unseen to the pipeline. ","eess"
"1907.09392","Spin-lattice and electron-phonon coupling in 3$d$/5$d$ hybrid   Sr$_3$NiIrO$_6$","  While 3$d$-containing materials display strong electron correlations, narrow band widths, and robust magnetism, 5$d$ systems are recognized for strong spin-orbit coupling, increased hybridization, and more diffuse orbitals. Combining these properties leads to novel behavior. Sr$_3$NiIrO$_6$, for example, displays complex magnetism and ultra-high coercive fields - up to an incredible 55~T. Here, we combine infrared and optical spectroscopies with high-field magnetization and first principles calculations to explore the fundamental excitations of the lattice and related coupling processes including spin-lattice and electron-phonon mechanisms. Magneto-infrared spectroscopy reveals spin-lattice coupling of three phonons that modulate the Ir environment to reduce the energy required to modify the spin arrangement. While these modes primarily affect exchange within the chains, analysis also uncovers important inter-chain motion. This provides a mechanism by which inter-chain interactions can occur in the developing model for ultra-high coercivity. At the same time, analysis of the on-site Ir$^{4+}$ excitations reveals vibronic coupling and extremely large crystal field parameters that lead to a t$_{2g}$-derived low-spin state for Ir. These findings highlight the spin-charge-lattice entanglement in Sr$_3$NiIrO$_6$ and suggest that similar interactions may take place in other 3$d$/5$d$ hybrids. ","cond-mat"
"1812.05678","Split regression modeling","  In this note we study the benefits of splitting variables variables for reducing the variance of linear functions of the regression coefficient estimate. We show that splitting combined with shrinkage can result in estimators with smaller mean squared error compared to popular shrinkage estimators such as Lasso, ridge regression and garrote. ","stat"
"1810.13290","A descent criterion for equivalences between equivariant derived   categories","  We investigate equivalences between the categories of perfects complexes of the quotients of two smooth projective schemes by the action of a finite group. As a result we give a necessary and sufficient condition for an equivalence between the equivariant derived categories to descend to the categories of perfect complexes. ","math"
"1707.02043","Weakly distance-regular digraphs whose attached association schemes are   regular","  In this paper, we study commutative weakly distance-regular digraphs whose attached association schemes are regular, and give a characterization of mixed arcs. As an application, we classify such digraphs of diameter 2. ","math"
"2006.11140","Clarity: Machine Learning Challenges to Revolutionise Hearing Device   Processing","  In the Clarity project, we will run a series of machine learning challenges to revolutionise speech processing for hearing devices. Over five years, there will be three paired challenges. Each pair will consist of a competition focussed on hearing-device processing (""enhancement"") and another focussed on speech perception modelling (""prediction""). The enhancement challenges will deliver new and improved approaches for hearing device signal processing for speech. The parallel prediction challenges will develop and improve methods for predicting speech intelligibility and quality for hearing impaired listeners. This Engineering and Physical Sciences Research Council (EPSRC) funded project involves researchers from the Universities of Sheffield, Salford, Nottingham and Cardiff in conjunction with the Hearing Industry Research Consortium, Action on Hearing Loss, Amazon, and Honda. To register interest in the challenges, go to www.claritychallenge.org. ","eess"
"2006.00258","Experimental reconstruction of the few-photon nonlinear scattering   matrix from a single quantum dot in a nanophotonic waveguide","  Coherent photon-emitter interfaces offer a way to mediate effcient nonlinear photon-photon interactions, much needed for quantum-information processing. Here we experimentally study the case of a two-level emitter, a quantum dot, coupled to a single optical mode in a nanophotonic waveguide. We carry out few-photon transport experiments and record the statistics of the light to reconstruct the scattering matrix elements of 1- and 2-photon components. This provides direct insight to the complex nonlinear photon interaction that contains rich many-body physics. ","quant-ph"
"1807.10014","Topological Gravity with Non-Compact Matter","  We couple twisted non-compact N=(2,2) supersymmetric models to topological gravity in two dimensions. We propose expressions for the genus zero correlation functions based on a Kadomtsev-Petviashvili integrable hierarchy. Moreover, we prove recursion relations satisfied by the topological gravity amplitudes at all genera and compute characteristic critical exponents. We discuss the extent to which moving beyond the N=2 central charge barrier opens a window on two-dimensional gravity with central charge larger than one. ","hep-th"
"1310.0736","Toward a Theory of Creative Inklings","  It is perhaps not so baffling that we have the ability to develop, refine, and manifest a creative idea, once it has been conceived. But what sort of a system could spawn the initial seed of creativity from which an idea grows? This paper looks at how the mind is structured in such a way that we can experience a glimmer of insight or inkling of artistic inspiration. ","q-bio"
"2003.05662","Bloch electrons on honeycomb lattice and toric Calabi-Yau geometry","  We find a new relation between the spectral problem for Bloch electrons on a two-dimensional honeycomb lattice in a uniform magnetic field and that for quantum geometry of a toric Calabi-Yau threefold. We show that a difference equation for the Bloch electron is identical to a quantum mirror curve of the Calabi-Yau threefold. As an application, we show that bandwidths of the electron spectra in the weak magnetic flux regime are systematically calculated by the topological string free energies at conifold singular points in the Nekrasov-Shatashvili limit. ","hep-th"
"1911.10054","The existence and stability of spike solutions for a chemotaxis system   modeling crime pattern formation","  This paper is a continuation of the paper Berestycki, Wei and Winter \cite{Berestycki2014}. In \cite{Berestycki2014}, the existence of multiple symmetric and asymmetric spike solutions of a chemotaxis system modeling crime pattern formation, suggested by Short, Bertozzi, and Brantingham \cite{Short2010}, has been proved in the one-dimensional case. The problem of stability of these spike solutions has been left open. In this paper, we establish the existence of a single radial symmetric spike solution for the system in the one and two-dimensional cases. The main difficulty is to deal with quasilinear elliptic problems whose diffusion coefficients vary largely near the core. We also study the linear stability of the spike solutions in both one-dimensional and two-dimensional cases which show complete different behaviors. In the one-dimensional case, we show that when the reaction time ratio $\tau>0$ is small enough, or large enough, the spike solution is linearly stable. In the two-dimensional case, when $\tau$ is small enough, the spike solution is linearly stable; while when $\tau$ is large enough, the spike solution is linearly unstable and Hopf bifurcation occurs from the spike solution at some $\tau=\tau_h$. ","math"
"1904.07786","A Pattern-Hierarchy Classifier for Reduced Teaching","  This paper uses a branching classifier mechanism in an unsupervised scenario, to enable it to self-organise data into unknown categories. A teaching phase is then able to help the classifier to learn the true category for each input row, using a reduced number of training steps. The pattern ensembles are learned in an unsupervsised manner that use a closest-distance clustering. This is done without knowing what the actual output category is and leads to each actual category having several clusters associated with it. One measure of success is then that each of these sub-clusters is coherent, which means that every data row in the cluster belongs to the same category. The total number of clusters is also important and a teaching phase can then teach the classifier what the correct actual category is. During this phase, any classifier can also learn or infer correct classifications from some other classifier's knowledge, thereby reducing the required number of presentations. As the information is added, cross-referencing between the two structures allows it to be used more widely. With this process, a unique structure can build up that would not be possible by either method separately. The lower level is a nested ensemble of patterns created by self-organisation. The upper level is a hierarchical tree, where each end node represents a single category only, so there is a transition from mixed ensemble masses to specific categories. The structure also has relations to brain-like modelling. ","cs"
"1903.11427","Halo Substructure Boosts to the Signatures of Dark Matter Annihilation","  The presence of dark matter substructure will boost the signatures of dark matter annihilation. We review recent progress on estimates of this subhalo boost factor---a ratio of the luminosity from annihilation in the subhalos to that originating the smooth component---based on both numerical $N$-body simulations and semi-analytic modelings. Since subhalos of all the scales, ranging from the Earth mass (as expected, e.g., the supersymmetric neutralino, a prime candidate for cold dark matter) to galaxies or larger, give substantial contribution to the annihilation rate, it is essential to understand subhalo properties over a large dynamic range of more than twenty orders of magnitude in masses. Even though numerical simulations give the most accurate assessment in resolved regimes, extrapolating the subhalo properties down in sub-grid scales comes with great uncertainties---a straightforward extrapolation yields a very large amount of the subhalo boost factor of $\gtrsim$100 for galaxy-size halos. Physically motivated theoretical models based on analytic prescriptions such as the extended Press-Schechter formalism and tidal stripping modeling, which are well tested against the simulation results, predict a more modest boost of order unity for the galaxy-size halos. Giving an accurate assessment of the boost factor is essential for indirect dark matter searches and thus, having models calibrated at large ranges of host masses and redshifts, is strongly urged upon. ","astro-ph"
"2006.06908","Chiral photocurrent in parity-violating magnet and enhanced response in   topological antiferromagnet","  Rectified electric current induced by irradiating light, so-called photocurrent, is an established phenomenon in optoelectronic physics. In this paper, we present a comprehensive classification of the photocurrent response arising from the parity violation in bulk systems. We clarify the contrasting role of $\mathcal{T}$- and $\mathcal{PT}$-symmetries and consequently find a new type of photocurrent phenomena characteristic of parity-violating magnets, magnetic rectification current and gyration current. Especially, the gyration current is induced by the circularly-polarized light and it is the counterpart of the shift current caused by the linearly-polarized light. This photocurrent adds a new functionality of materials studied in various fields of condensed matter physics such as multiferroics and spintronics. A list of materials is provided. Furthermore, we show that the gyration current is strongly enhanced by topologically nontrivial band dispersion. On the basis of the microscopic analysis of Dirac models, we demonstrate the divergent photocurrent response and elucidate the importance of tilting of Dirac cones. ","cond-mat"
"1912.08162","Optimality of Observed Information Adaptive Designs in Linear Models","  This work considers experimental design in linear models with additive errors. A traditional objective in design is to minimize the variance of the estimates of the model parameters. The optimal design, which is found by minimizing a convex function of the expected Fisher information, accomplishes this objective, approximately. The inverse of expected Fisher information is asymptotically equivalent to the variance of the maximum likelihood estimate. It is often remarked that observed Fisher information is a better measure of the variance of the maximum likelihood estimate than the expected Fisher information [Efron and Hinkley (1978)]. However, unlike expected Fisher information, observed Fisher information depends on the observed data and cannot be used to design an experiment in advance of data collection. In a sequential experiment the observed Fisher information from past observations is available to incorporate into the design of the current observation. In this work an adaptive design that incorporates observed Fisher information is proposed. It is shown that this proposed design is optimal, at the limit, with respect to inference and conditional mean square error. In a simulation study the proposed adaptive design performs nearly uniformly better than the optimal design. ","stat"
"1912.07135","Nonlocal Generalized Quantum Measurements of Spin Products Without   Maximal Entanglement","  Measuring a nonlocal observable on a space-like separated quantum system is a resource-hungry and experimentally challenging task. Several theoretical measurement schemes have already been proposed to increase its feasibility, using a shared maximally-entangled ancilla. We present a new approach to this problem, using the language of generalized quantum measurements, to show that it is actually possible to measure a nonlocal spin product observable without necessarily requiring a maximally-entangled ancilla. This approach opens the door to more economical arbitrary-strength nonlocal measurements, with applications ranging from nonlocal weak values to possible new tests of Bell inequalities. The relation between measurement strength and the amount of ancillary entanglement needed is made explicit, bringing a new perspective on the links that tie quantum nonlocality, entanglement and information transmission together. ","quant-ph"
"1905.01264","Distinguishing Dirac and Majorana neutrinos by their gravi-majoron   decays","  Neutrinos may acquire small Dirac or Majorana masses by new low-energy physics in terms of the chiral gravitational anomaly, as proposed by Dvali and Funcke (2016). This model predicts fast neutrino decays, $\nu_i\to\nu_j+\phi$ and $\nu_i\to\bar{\nu}_j+\phi$, where the gravi-majorons $\phi$ are pseudoscalar Nambu-Goldstone bosons. The final-state neutrino and antineutrino distributions differ depending on the Dirac or Majorana mass of the initial state. This opens a channel for distinguishing these cases, for example in the spectrum of high-energy astrophysical neutrinos. In particular, we put bounds on the neutrino lifetimes in the Majorana case, ${\tau_2}/{m_2}> 1.1\times 10^{-3}(6.7\times 10^{-4})~{\rm s/eV}$ and ${\tau_3}/{m_3}> 2.2\times 10^{-5}(1.3\times 10^{-4})~{\rm s/eV}$ at 90% CL for hierarchical (degenerate) masses, using data from experiments searching for antineutrino appearance from the Sun. ","hep-ph"
"1904.06712","Bilateral symmetry strengthens the perceptual salience of figure against   ground","  Although symmetry has been discussed in terms of a major law of perceptual organization since the early conceptual efforts of the Gestalt school (Wertheimer, Metzger, Koffka and others), the first quantitative measurements testing for effects of symmetry on processes of Gestalt formation have seen the day only recently. In this study, a psychophysical rating study and a ""foreground"" versus ""background"" choice response time experiment were run with human observers to test for effects of bilateral symmetry on the perceived strength of figure against ground in triangular Kanizsa configurations. Displays with and without bilateral symmetry, identical physically specified to total contour ratio and constant local contrast intensity within and across conditions, but variable local contrast polarity and variable orientation in the plane were presented in a random order to human observers. Configurations with bilateral symmetry produced significantly stronger figure against ground percepts reflected by greater subjective magnitudes and consistently higher percentages of ""foreground"" judgments accompanied by significantly shorter response times. These effects of symmetry depend neither on the orientation of the axis of symmetry, nor on the contrast polarity of the physical inducers. It is concluded that bilateral symmetry, irrespective of orientation, significantly contributes to the, largely sign invariant, visual mechanisms of shape segregation that determine the salience of figure against ground in perceptually ambiguous image configurations. ","q-bio"
"1907.11446","Experimental investigation of superdiffusion via coherent disordered   Quantum Walks","  Many disordered systems show a superdiffusive dynamics, intermediate between the diffusive one, typical of a classical stochastic process, and the so called ballistic behaviour, which is generally expected for the spreading in a quantum process. We have experimentally investigated the superdiffusive behaviour of a quantum walk (QW), whose dynamics can be related to energy transport phenomena, with a resolution which is high enough to clearly distinguish between different disorder regimes. By our experimental setup, the region between ballistic and diffusive spreading can be effectively scanned by suitably setting few degrees of freedom and without applying any decoherence to the QW evolution. ","quant-ph"
"1906.05174","UAV Swarms as Amplify-and-Forward MIMO Relays","  Unmanned aerial vehicles provide new opportunities for performance improvements in future wireless communications systems. For example, they can act as relays that extend the range of a communication link and improve the capacity. Unlike conventional relays that are deployed at fixed locations, UAVs can change their positions to optimize the capacity or range on demand. In this paper, we consider using a swarm of UAVs as amplify-and-forward MIMO relays to provide connectivity between an obstructed multi-antenna equipped source and destination. We start by optimizing UAV placement for the single antenna case, and analyze its dependence on the noise introduced by the relay, its gain, and transmit power constraint. We extend our analysis for an arbitrary UAV swarm and show how the MIMO link capacity can be optimized by changing the distance of the swarm to the source and the destination. Then, we consider the effect of optimizing the positions of the UAVs within the swarm and derive an upper bound for the capacity at any given placement of the swarm. We also propose a simple near optimal approach to find the positions that optimize the capacity for the end-to-end link given that the source and the destination have uniform rectangular arrays. ","eess"
"1907.00090","A computational proof of the linear Arithmetic Fundamental Lemma of   GL$_4$","  Let $K/F$ be an unramified quadratic extension of non-Archimedian local fields with residue character not equals to 2. We prove the linear Arithmetic Fundamental Lemma for GL$_4$ with the unit element in the spherical Hecke Algebra. In this article, all measures are normalized by its hyperspecial subgroup. ","math"
"2004.03123","Efficient quantum memory for single photon polarization qubits","  A quantum memory, for storing and retrieving flying photonic quantum states, is a key interface for realizing long-distance quantum communication and large-scale quantum computation. While many experimental schemes of high storage-retrieval efficiency have been performed with weak coherent light pulses, all quantum memories for true single photons achieved so far have efficiencies far below 50%, a threshold value for practical applications. Here, we report the demonstration of a quantum memory for single-photon polarization qubits with an efficiency of >85% and a fidelity of >99 %, basing on balanced two-channel electromagnetically induced transparency in laser-cooled rubidium atoms. For the single-channel quantum memory, the optimized efficiency for storing and retrieving single-photon temporal waveforms can be as high as 90.6 %. Our result pushes the photonic quantum memory closer to its practical applications in quantum information processing. ","quant-ph"
"1908.08657","Transverse momentum dependent parton distributions of pion in the   light-front holographic model","  Using the light-front holographic model, we study the transverse momentum dependent parton distributions (TMDs) for the case of pion. At leading twist, the unpolarized parton distribution function $ f_{1\pi}(x,\bfk^{2}) $ and the Boer-Mulders function $ h_{1\pi}^{\bot}(x,\bfk^{2}) $ are obtained for pion. We calculate both the functions using the light-front holographic model with spin improved wave function and compare the predicted results with available results of other models. In order to provide inputs in predicting future experimental data, a LO evolution is performed from model scale to experimental scale for the case of unpolarized parton distribution function $ f_{1\pi}(x,\bfk^{2}) $. ","hep-ph"
"1901.07969","Flavor changing in the flipped trinification","  The flipped trinification, a framework for unifying the 3-3-1 and left-right symmetries, has recently been proposed in order to solve profound questions, the weak parity violation and the number of families, besides the implication for neutrino mass generation and dark matter stability. In this work, we argue that this gauge-completion naturally provides flavor-changing neutral currents in both quark and lepton sectors. The quark flavor changing happens at the tree-level due to the nonuniversal couplings of $Z'_{L,R}$, while the lepton flavor changing $l\rightarrow l'\gamma$ starts from the one loop level contributed significantly by the new charged currents of $Y_{L,R}$, which couple ordinary to exotic leptons. These effects disappear in the minimal left-right model, but are present in the framework characterizing a flipped trinification symmetry. ","hep-ph"
"2004.07857","Ultimate limit on time signal generation","  The generation of time signals is a fundamental task in science. Here we study the relation between the quality of a time signal and the physics of the system that generates it. According to quantum theory, any time signal can be decomposed into individual quanta that lead to single detection events. Our main result is a bound on how sharply peaked in time these events can be, which depends on the dimension of the signal generator. This result promises applications in various directions, including information theory, quantum clocks, and process simulation. ","quant-ph"
"1903.10730","Error-Disturbance Trade-off in Sequential Quantum Measurements","  We derive a state dependent error-disturbance trade-off based on a statistical distance in the sequential measurements of a pair of noncommutative observables and experimentally verify the relation with a photonic qubit system. We anticipate that this Letter may further stimulate the study on the quantum uncertainty principle and related applications in quantum measurements. ","quant-ph"
"1804.02669","On the local factors of irreducible representations of quaternionic   unitary groups","  In this paper, we give a precise definition of the analytic $\gamma$-factors of irreducible representations of quaternionic unitary groups, which extends a work of Lapid-Rallis. ","math"
"1904.04929","Equivalent Circuit Programming for Estimating the State of a Power   System","  An Equivalent Circuit Programming (ECP) approach that expresses the optimality conditions of an optimization problem in terms of an equivalent circuit model and uses circuit simulation techniques to solve for an optimal solution, is applied to the state estimation problem for power systems. The benefits of using an equivalent circuit formulation for incorporating both Phasor Measurement Units (PMU) and Remote Terminal Units (RTU), as well as for reducing the nonlinearities of the state estimation problem was previously demonstrated. In this paper we further exploit the circuit nature of the state estimation problem to formulate not only the model but also the optimality conditions as an ECP problem. The efficiency and accuracy of our approach are demonstrated by estimating the states of large-scale power grids (80k+ buses). ","eess"
"2005.14718","Kilohertz electron paramagnetic resonance spectroscopy of single   nitrogen centers at zero magnetic field","  Electron paramagnetic resonance spectroscopy (EPR) is among the most important analytical tools in physics, chemistry, and biology. The emergence of nitrogen-vacancy (NV) centers in diamond, serving as an atomic-sized magnetometer, has promoted this technique to single-spin level, even under ambient conditions. Despite the enormous progress in spatial resolution, the current megahertz spectral resolution is still insufficient to resolve key heterogeneous molecular information. A major challenge is the short coherence times of the sample electron spins. Here, we address this challenge by employing a magnetic noise-insensitive transition between states of different symmetry. We demonstrate a 27-fold narrower spectrum of single substitutional nitrogen (P1) centers in diamond with linewidth of several kilohertz, and then some weak couplings can be resolved. Those results show both spatial and spectral advances of NV center-based EPR, and provide a route towards analytical (EPR) spectroscopy at single-molecule level. ","quant-ph"
"2005.11877","Optimal Measurement Configuration in Computational Diffractive Imaging","  Diffractive lenses have recently been applied to the domain of multispectral imaging in the X-ray and UV regimes where they can achieve very high resolution as compared to reflective and refractive optics. Conventionally, spectral components are reconstructed by taking measurements at the focal planes. However, the reconstruction quality can be improved by optimizing the measurement configuration. In this work, we adapt a sequential backward selection algorithm to search for a configuration which minimizes expected reconstruction error. By approximating the forward system as a circular convolution and making assumptions on the source and noise, we greatly reduce the complexity of the algorithm. Numerical results show that the configuration found by the algorithm significantly improves the reconstruction performance compared to a standard configuration. ","eess"
"2008.03870","Entanglement enhanced and one-way steering in PT -symmetric cavity   magnomechanics","  We study creation of entanglement and quantum steering in a parity-time- (PT -) symmetric cavity magnomechanical system. There is magnetic dipole interaction between the cavity and photon-magnon, and there is also magnetostrictive interaction which is induced by the phononmagnon coupling in this system. By introducing blue-detuned driving microwave field to the system, the bipartite entanglement of the system with PT -symmetry is significantly enhanced versus the case in the conventional cavity magnomechanical systems (loss-loss systems). Moreover, the one-way quantum steering between magnon-phonon and photon-phonon modes can be obtained in the unbroken-PT -symmetric regime. The boundary of stability is demonstrated and this show that the steady-state solutions are more stable in the gain and loss systems. This work opens up a route to explore the characteristics of quantum entanglement and steering in magnomechanical systems, which might have potential applications in quantum state engineering and quantum information. ","quant-ph"
"1912.12565","Transformation formulas of finite sums into continued fractions","  We state and prove three general formulas allowing to transform formal finite sums into formal continued fractions and apply them to generalize certain expansions in continued fractions given by Hone and Varona. ","math"
"2008.02639","Exploring reionisation and high-z galaxy observables with recent   multi-redshift MWA upper limits on the 21-cm signal","  We use the latest multi-redshift ($z=6.5-8.7$) upper limits on the 21-cm signal from the Murchison Widefield Array (MWA) to explore astrophysical models which are inconsistent with the data. These upper limits are achieved using 298 h of carefully excised data over four observing seasons. To explore these upper limits in the context of reionisation astrophysics, we use 21CMMC. We then connect the disfavoured regions of parameter space to existing observational constraints on reionisation such as high-$z$ galaxy ultra-violet (UV) luminosity functions, background UV photoionisation rate, intergalactic medium (IGM) neutral fraction, the electron scattering optical depth and the soft-band X-ray emissivity. We find the vast majority of models disfavoured by the MWA limits are already inconsistent with existing observational constraints. These inconsistent models arise from two classes of models: (i) `cold' reionisation and (ii) pure matter density fluctuations (i.e. no reionisation). However, a small subsample of models are consistent implying the existing MWA limits provide unique information in disfavouring models of reionisation, albeit extremely weakly. We also provide the first limits on the soft-band X-ray emissivity from galaxies at high redshifts, finding $1\sigma$ lower limits of $\epsilon_{{\rm X},0.5-2~{\rm keV}}\gtrsim10^{34.5}$ erg s$^{-1}$ Mpc$^{-3}$. Finally, we recover 95 per cent disfavoured limits on the IGM spin temperature of $\bar{T}_{\rm S}\lesssim$ 1.3, 1.4, 1.5, 1.8, 2.1, 2.4 K at $z=6.5, 6.8, 7.1, 7.8, 8.2, 8.7$. With this we infer the IGM must have undergone, at the very least, a small amount of X-ray heating. Note, the limits on $\epsilon_{{\rm X},0.5-2~{\rm keV}}$ and $\bar{T}_{\rm S}$ are conditional on the IGM neutral fraction. ","astro-ph"
"1812.06088","Reconstructing Quantum Mechanics Without Foundational Problems","  I present a reconstruction of general Hamiltonian action mechanics that eliminates all foundational problems of quantum mechanics. The key advance is the completion of Hamiltonian mechanics to the universal mechanics of particles based on action-waves, consistent with the inclusive validity of the principle of stationary action. It is found that irreducible indeterminism is intrinsic and universal at all scales of dynamics. The new action-wave equation is the complete description of single dynamical histories, dissolving the classical-quantum divide. The statistical theory of quantum mechanics emerges as the ensemble average of modified action dynamics. The ensemble average of the new action mechanics leads to a hybrid function consisting of the action-waves and the probability density of the ensemble. This hybrid wavefunction obeys the Schr\""odinger equation, which is not a single particle dynamical equation. The reconstructed mechanics without matter waves is free of the cardinal problem known as the collapse of the wavefunction and with that, the vexing issue of quantum measurement is resolved. Another significant advance is the correct decoding of quantum entanglement and purging of nonseparability and nonlocality in quantum correlations. The action-waves do not carry the burden of divergent zero-point energy. The reconstructed mechanics is in complete agreement with all empirical requirements and in harmony with credible physical ontology. ","quant-ph"
"1907.10945","Indirect evidence of significant grain growth in young protostellar   envelopes from polarized dust emission","  How and when in the star formation sequence do dust grains start to grow into pebbles is a cornerstone question to both star and planet formation. We compute the polarized radiative transfer from a model solar-type protostellar core, using the POLARIS code, aligning the dust grains with the local magnetic field, following the radiative torques (RATs) theory. We test the dependency of the resulting dust polarized emission with the maximum grain size of the dust size distribution at the envelope scale, from amax = 1 micron to 50 micron. Our work shows that, in the framework of RAT alignment, large dust grains are required to produce polarized dust emission at levels similar to those currently observed in solar-type protostellar envelopes at millimeter wavelengths. Considering the current theoretical dificulties to align a large fraction of small ISM-like grains in the conditions typical of protostellar envelopes, our results suggest that grain growth (typically > 10 micron) might have already significantly progressed at scales 100-1000 au in the youngest objects, observed less than 10^5 years after the onset of collapse. Observations of dust polarized emission might open a new avenue to explore dust pristine properties and describe, for example, the initial conditions for the formation of planetesimals. ","astro-ph"
"1803.02332","The Frankel property for self-shrinkers from the viewpoint of elliptic   PDE's","  We show that two properly embedded self-shrinkers in Euclidean space that are sufficiently separated at infinity must intersect at a finite point. The proof is based on a localized version of the Reilly formula applied to a suitable f-harmonic function with controlled gradient. In the immersed case, a new direct proof of the generalized half-space property is also presented. ","math"
"1903.04729","Gemini IFU, VLA, and HST observation of the OH Megamaser Galaxy   IRAS17526+3253","  We present a multiwavelength study of the OH megamaser galaxy (OHMG) IRAS17526+3253, based on new Gemini Multi-Object Spectrograph Integral Field Unit (GMOS/IFU) observations, Hubble Space Telescope F814W and H$\alpha$+[N{\sc ii}] images, and archival 2MASS and 1.49GHz VLA data. The HST images clearly reveal a mid-to-advanced stage major merger whose northwestern and southeastern nuclei have a projected separation of $\sim$8.5kpc. Our HST/H$\alpha$+[N{\sc ii}] image shows regions of ongoing star-formation across the envelope on $\sim$10kpc scales, which are aligned with radio features, supporting the interpretation that the radio emission originates from star-forming regions. The measured H$\alpha$ luminosities imply that the unobscured star-formation rate is $\sim$10-30\,M$_{\odot}$yr$^{-1}$. The GMOS/IFU data reveal two structures in northwestern separated by 850\,pc and by a discontinuity in the velocity field of $\sim$~200~km~s$^{-1}$. We associate the blue-shifted and red-shifted components with, respectively, the distorted disk of northwestern and tidal debris, possibly a tail originating in southeastern. Star-formation is the main ionization source in both components, which have SFRs of $\sim$2.6-7.9\,M$_{\odot}$yr$^{-1}$ and $\sim$1.5-4.5\,M$_{\odot}$yr$^{-1}$, respectively. Fainter line emission bordering these main components is consistent with shock ionization at a velocity $\sim$200~km~s$^{-1}$ and may be the result of an interaction between the tidal tail and the northwestern galaxy's disk. IRAS17526+3253 is one of only a few systems known to host both luminous OH and H$_{2}$O masers. The velocities of the OH and H$_{2}$O maser lines suggest that they are associated with the northwestern and southeastern galaxies, respectively. ","astro-ph"
"1812.11843","Exploring the prominent channel: Charged Higgs pair production in   supersymmetric Two-parameter Non-Universal Higgs Model","  In this study, the charged Higgs pair production is calculated in the context of the supersymmetry at a $\gamma\gamma$-collider. The channel is explored in Two-parameter Non-Universal Higgs Model where the model provides relatively light neutral and charged Higgs bosons. The computation is extended to one loop-level, and the divergence arising in the loop-diagrams are cured with the radiative photon correction. The production rate of the charged Higgs pair reaches up to $\hat{\sigma}_\text{UU}^\text{LO+NLO}=121\text{ fb}$ at $\sqrt{\hat{s}}=635\text{ GeV}$. The analysis of the cross-section is also given varying the parameters $m_A$ and $\tan\beta$. The total convoluted cross-section with the photon luminosity in an $e^+e^-$ machine is calculated as a function of the center-of-mass energy up to $1\text{ TeV}$, and it gets up to $42\text{ fb}$ at $\sqrt{s}=900 \text{ GeV}$ depending on the polarization of the initial electron and laser photon. ","hep-ph"
"1902.01779","Constraints on the low frequency spectrum of FRB 121102","  While repeating fast radio bursts (FRBs) remain scarce in number, they provide a unique opportunity for follow-up observations that enhance our knowledge of their sources and potentially of the FRB population as a whole. Attaining more burst spectra could lead to a better understanding of the origin of these bright, millisecond-duration radio pulses. We therefore performed $\sim$20 hr of simultaneous observations on FRB 121102 with the Effelsberg 100-m radio telescope and the Low Frequency Array (LOFAR) to constrain the spectral behaviour of bursts from FRB 121102 at 1.4 GHz and 150 MHz. This campaign resulted in the detection of nine new bursts at 1.4 GHz but no simultaneous detections with LOFAR. Assuming that the ratio of the fluence at two frequencies scales as a power law, we placed a lower limit of $\alpha$ > -1.2 $\pm$ 0.4 on the spectral index for the fluence of the instantaneous broad band emission of FRB 121102. For the derivation of this limit, a realistic fluence detection threshold for LOFAR was determined empirically assuming a burst would be scattered as predicted by the NE2001 model. A significant variation was observed in the burst repeat rate R at L-band. During observations in September 2016, nine bursts were detected, giving R = 1.1 $\pm$ 0.4 hr$^{-1}$, while in November no bursts were detected, yielding R < 0.3 hr$^{-1}$ (95% confidence limit). This variation is consistent with earlier seen episodic emission of FRB 121102. In a blind and targeted search, no bursts were found with LOFAR at 150 MHz, resulting in a repeat rate limit of R < 0.16 hr$^{-1}$ (95% confidence limit). Burst repeat rate ratios of FRB 121102 at 3, 2, 1.4, and 0.15 GHz are consistent within the uncertainties with a flattening of its spectrum below 1 GHz. ","astro-ph"
"2007.12126","The degeneracy between primordial non-Gaussianity and foregrounds in   21cm intensity mapping experiments","  Potential evidence for primordial non-Gaussianity (PNG) is expected to lie in the largest scales mapped by cosmological surveys. Forthcoming 21cm intensity mapping experiments will aim to probe these scales by surveying neutral hydrogen (HI) within galaxies. However, foreground signals dominate the faint 21cm emission, meaning foreground cleaning is required to recover the cosmological signal. The effect this has is to damp the HI power spectrum on the largest scales, especially along the line-of-sight. Whilst there is agreement that this contamination is potentially problematic for probing PNG, it is yet to be fully explored and quantified. In this work we carry out the first forecasts on $f_\text{NL}$ that incorporate simulated foreground maps that are removed using techniques employed in real data. Using an MCMC analysis, we demonstrate that foreground cleaned data recovers hugely biased values ($f_\text{NL} = -102.1_{-7.96}^{+8.39}$ [68% CL]) on our $f_\text{NL}=0$ fiducial input. Introducing a model with fixed parameters for the foreground contamination allows us to recover unbiased results ($f_\text{NL} = -2.94_{-11.9}^{+11.4}$). However, it is not clear that we will have sufficient understanding of foreground contamination to allow for such rigid models. Treating the main parameter $k_\parallel^\text{FG}$ in our foreground model as a nuisance parameter and marginalizing over it, still recovers unbiased results but at the expense of much larger errors ($f_\text{NL} = 0.75^{+40.2}_{-44.5}$), that can only be reduced by imposing the Planck 2018 prior. Our results show that significant progress on understanding and controlling foreground removal effects is necessary in order to study PNG with HI intensity mapping. ","astro-ph"
"2003.14126","Weak gravity (and other conjectures) with broken supersymmetry","  We study the weak gravity conjecture in non-supersymmetric string theory setups. Precisely, those are type I string theory with supersymmetry broken \`a la Scherk-Schwarz and open strings on D branes wrapped around magnetized tori in type II string theory. We compute long-range interactions between identical branes at one-loop and compare them to the weak gravity conjecture for higher-degree forms. In our examples, SUSY breaking generates interactions between branes, which are not anymore BPS, in such a way that the weak gravity conjecture is verified. In type I with the Scherk-Schwarz mechanism, the tension of the branes is reduced by one-loop quantum effects, so that there are long-range repulsive forces. The correlation of the non-vanishing brane potential with the presence of a running modulus and of possible D branes bound states nicely connects to other swampland conjectures. For magnetized branes in type II strings, we check that non-BPS branes experience a long-range repulsion whenever the open string spectrum is tachyon-free. Ultimately, the role of stringy objects in the discussion makes it compelling to further understand swampland conjectures in strings with broken SUSY, let alone their phenomenological relevance. ","hep-th"
"1904.09006","Performance of the Gemini Planet Imager Non-Redundant Mask and   spectroscopy of two close-separation binaries HR 2690 and HD 142527","  The Gemini Planet Imager (GPI) contains a 10-hole non-redundant mask (NRM), enabling interferometric resolution in complement to its coronagraphic capabilities. The NRM operates both in spectroscopic (integral field spectrograph, henceforth IFS) and polarimetric configurations. NRM observations were taken between 2013 and 2016 to characterize its performance. Most observations were taken in spectroscopic mode with the goal of obtaining precise astrometry and spectroscopy of faint companions to bright stars. We find a clear correlation between residual wavefront error measured by the AO system and the contrast sensitivity by comparing phase errors in observations of the same source, taken on different dates. We find a typical 5-$\sigma$ contrast sensitivity of $2-3~\times~10^{-3}$ at $\sim\lambda/D$. We explore the accuracy of spectral extraction of secondary components of binary systems by recovering the signal from a simulated source injected into several datasets. We outline data reduction procedures unique to GPI's IFS and describe a newly public data pipeline used for the presented analyses. We demonstrate recovery of astrometry and spectroscopy of two known companions to HR 2690 and HD 142527. NRM+polarimetry observations achieve differential visibility precision of $\sigma\sim0.4\%$ in the best case. We discuss its limitations on Gemini-S/GPI for resolving inner regions of protoplanetary disks and prospects for future upgrades. We summarize lessons learned in observing with NRM in spectroscopic and polarimetric modes. ","astro-ph"
"2005.02724","Skyrmion crystal phases in antiferromagnetic itinerant triangular   magnets","  Very often the skyrmions form a triangular crystal in chiral magnets. Here we study the effect of itinerant electrons on the structure of skyrmion crystal (SkX) on triangular lattice using Kondo lattice model in the large coupling limit and treating the localized spins as classical vectors. To simulate the system, we employ hybrid Markov Chain Monte Carlo method (hMCMC) which includes electron diagonalization in each MCMC update for classical spins. We present the low temperature results for $12\times 12$ system at electron density $n=1/3$ which show a sudden jump in skyrmion number when we increase the hopping strength of the itinerant electrons. We find that this high skyrmion number SkX phase is stabilized by combined effects: lowering of density of states at electron filling $n=1/3$ and also pushing the bottom energy states further down. We show that these results hold for larger system using travelling cluster variation of hMCMC. We expect that itinerant triangular magnets might exhibit the possible transition between low density to high density SkX phases by applying external pressure. ","cond-mat"
"1905.01441","Compactness of first-order fuzzy logics","  One of the nice properties of the first-order logic is the compactness of satisfiability. It state that a finitely satisfiable theory is satisfiable. However, different degrees of satisfiability in many-valued logics, poses various kind of the compactness in these logics. One of this issues is the compactness of $K$-satisfiability. Here, after an overview on the results around the compactness of satisfiability and compactness of $K$-satisfiability in many-valued logic based on continuous t-norms (basic logic), we extend the results around this topic. To this end, we consider a reverse semantical meaning for basic logic. Then we introduce a topology on $[0,1]$ and $[0,1]^2$ that the interpretation of all logical connectives are continuous with respect to these topologies. Finally using this fact we extend the results around the compactness of satisfiability in basic ogic. ","math"
"2006.13713","Coconut: a scalable bottom-up approach for building data series indexes","  Many modern applications produce massive amounts of data series that need to be analyzed, requiring efficient similarity search operations. However, the state-of-the-art data series indexes that are used for this purpose do not scale well for massive datasets in terms of performance, or storage costs. We pinpoint the problem to the fact that existing summarizations of data series used for indexing cannot be sorted while keeping similar data series close to each other in the sorted order. This leads to two design problems. First, traditional bulk-loading algorithms based on sorting cannot be used. Instead, index construction takes place through slow top-down insertions, which create a non-contiguous index that results in many random I/Os. Second, data series cannot be sorted and split across nodes evenly based on their median value; thus, most leaf nodes are in practice nearly empty. This further slows down query speed and amplifies storage costs. To address these problems, we present Coconut. The first innovation in Coconut is an inverted, sortable data series summarization that organizes data series based on a z-order curve, keeping similar series close to each other in the sorted order. As a result, Coconut is able to use bulk-loading techniques that rely on sorting to quickly build a contiguous index using large sequential disk I/Os. We then explore prefix-based and median-based splitting policies for bottom-up bulk-loading, showing that median-based splitting outperforms the state of the art, ensuring that all nodes are densely populated. Overall, we show analytically and empirically that Coconut dominates the state-of-the-art data series indexes in terms of construction speed, query speed, and storage costs. ","cs"
"1805.05533","Discovering Transforms: A Tutorial on Circulant Matrices, Circular   Convolution, and the Discrete Fourier Transform","  How could the Fourier and other transforms be naturally discovered if one didn't know how to postulate them? In the case of the Discrete Fourier Transform (DFT), we show how it arises naturally out of analysis of circulant matrices. In particular, the DFT can be derived as the change of basis that simultaneously diagonalizes all circulant matrices. In this way, the DFT arises naturally from a linear algebra question about a set of matrices. Rather than thinking of the DFT as a signal transform, it is more natural to think of it as a single change of basis that renders an entire set of mutually-commuting matrices into simple, diagonal forms. The DFT can then be ``discovered'' by solving the eigenvalue/eigenvector problem for a special element in that set. A brief outline is given of how this line of thinking can be generalized to families of linear operators, leading to the discovery of the other common Fourier-type transforms, as well as its connections with group representations theory. ","eess"
"2005.14602","A New Susceptible-Infectious (SI) Model With Endemic Equilibrium","  The focus of this article is on the dynamics of a new susceptible-infected model which consists of a susceptible group ($S$) and two different infectious groups ($I_1$ and $I_2$). Once infected, an individual becomes a member of one of these infectious groups which have different clinical forms of infection. In addition, during the progress of the illness, an infected individual in group $I_1$ may pass to the infectious group $I_2$ which has a higher mortality rate. In this study, positiveness of the solutions for the model is proved. Stability analysis of species extinction, $I_1$-free equilibrium and endemic equilibrium as well as disease-free equilibrium is studied. Relation between the basic reproduction number of the disease and the basic reproduction number of each infectious stage is examined. The model is investigated under a specific condition and its exact solution is obtained. ","q-bio"
"2003.13015","Statistics of Quenched Defects Containing Semi-Flexible Polymer Chain:   Exact Results (II)","  We describe method to discuss thermodynamics of a defected semi-flexible homo-polymer chain in the two and three dimensions using fully directed self-avoiding walk lattice model. The defects are located along a line and these defects are not in the thermal equilibrium with the monomers of the semi-flexible polymer chain; i. e. we consider the case of defected semi-flexible polymer chain in the present manuscript for the case of quenched defects. There are m defects on the conformations of the N monomers long semi-flexible polymer chain and we exactly count the number of Q realizations of the defected conformations of N-monomers long self-avoiding semi-flexible polymer chain; and thus we derive the exact expression of the free energy of the defected semi-flexible polymer chain for the finite length (i. e. using the fixed particle ensemble method); and we also derive exact expression of the partition function for the defected self-avoiding semi-flexible polymer chain in the thermodynamic limit using the grand canonical ensemble theory. The method described in this manuscript may be easily extended to another case of the defected polymer chain for isotropic/directed walk lattice models. ","cond-mat"
"2008.06132","Effects of applied mechanical strain on vacancy clustering in FCC Ni","  Irradiation-induced vacancy evolution in face-centered cubic (FCC) Ni under mechanical strains was studied using molecular dynamics simulations. Applied hydrostatic strain led to different stable forms of vacancy clusters, i.e., voids under strain >= +2% and stacking fault tetrahedras (SFTs) under strain <= 0. Direct transitions between SFT and void revealed that increasing strain magnitude facilitated the thermodynamic stability and dynamical evolution. The estimated free energy difference could well validate the dynamical simulations results by accounting for entropic contribution, which was revealed to play an important role in the thermodynamic stability of vacancy clusters in FCC Ni. ","cond-mat"
"1902.11194","Clocks and Rods in Jackiw-Teitelboim Quantum Gravity","  We specify bulk coordinates in Jackiw-Teitelboim (JT) gravity using a boundary-intrinsic radar definition. This allows us to study and calculate exactly diff-invariant bulk correlation functions of matter-coupled JT gravity, which are found to satisfy microcausality. We observe that quantum gravity effects dominate near-horizon matter correlation functions. This shows that quantum matter in classical curved spacetime is not a sensible model for near-horizon matter-coupled JT gravity. This is how JT gravity, given our choice of bulk frame, evades an information paradox. This echoes into the quantum expectation value of the near-horizon metric, whose analysis is extended from the disk model to the recently proposed topological completion of JT gravity. Due to quantum effects, at distances of order the Planck length to the horizon, a dramatic breakdown of Rindler geometry is observed. ","hep-th"
"1910.07854","Quantum locally linear embedding for nonlinear dimensionality reduction","  Reducing the dimension of nonlinear data is crucial in data processing and visualization. The locally linear embedding algorithm (LLE) is specifically a representative nonlinear dimensionality reduction method with well maintaining the original manifold structure. In this paper, we present two implementations of the quantum locally linear embedding algorithm (QLLE) to perform the nonlinear dimensionality reduction on quantum devices. One implementation, the linear-algebra-based QLLE algorithm, utilizes quantum linear algebra subroutines to reduce the dimension of the given data. The other implementation, the variational quantum locally linear embedding algorithm (VQLLE) utilizes a variational hybrid quantum-classical procedure to acquire the low-dimensional data. The classical LLE algorithm requires polynomial time complexity of $N$, where $N$ is the global number of the original high-dimensional data. Compared with the classical LLE, the linear-algebra-based QLLE achieves quadratic speedup in the number and dimension of the given data. The VQLLE can be implemented on the near term quantum devices in two different designs. In addition, the numerical experiments are presented to demonstrate that the two implementations in our work can achieve the procedure of locally linear embedding. ","quant-ph"
"2006.07139","Attribute analysis with synthetic dataset for person re-identification","  Person re-identification (re-ID) plays an important role in applications such as public security and video surveillance. Recently, learning from synthetic data, which benefits from the popularity of synthetic data engine, have achieved remarkable performance. However, existing synthetic datasets are in small size and lack of diversity, which hinders the development of person re-ID in real-world scenarios. To address this problem, firstly, we develop a large-scale synthetic data engine, the salient characteristic of this engine is controllable. Based on it, we build a large-scale synthetic dataset, which are diversified and customized from different attributes, such as illumination and viewpoint. Secondly, we quantitatively analyze the influence of dataset attributes on re-ID system. To our best knowledge, this is the first attempt to explicitly dissect person re-ID from the aspect of attribute on synthetic dataset. Comprehensive experiments help us have a deeper understanding of the fundamental problems in person re-ID. Our research also provides useful insights for dataset building and future practical usage. ","cs"
"1903.07036","Time Synchronization Attack and Countermeasure for Multi-System   Scheduling in Remote Estimation","  We consider time synchronization attack against multi-system scheduling in a remote state estimation scenario where a number of sensors monitor different linear dynamical processes and schedule their transmissions through a shared collision channel. We show that by randomly injecting relative time offsets on the sensors, the malicious attacker is able to make the expected estimation error covariance of the overall system diverge without any system knowledge. For the case that the attacker has full system information, we propose an efficient algorithm to calculate the optimal attack, which spoofs the least number of sensors and leads to unbounded average estimation error covariance. To mitigate the attack consequence, we further propose a countermeasure by constructing shift invariant transmission policies and characterize the lower and upper bounds for system estimation performance. Simulation examples are provided to illustrate the obtained results. ","cs"
"1612.00469","Electron and hole transport in disordered monolayer MoS2: atomic   vacancy-induced short-range and Coulomb disorder scattering","  Atomic disorder is a common limiting factor for the low-temperature mobility in monolayer transition-metal dichalcogenides (TMDs; MX2). Here, we study the effect of often occurring atomic vacancies on carrier scattering and transport in p- and n-type monolayer MoS2. Due to charge trapping in vacancy-induced in-gap states, both neutral and charged vacancies resembling, respectively, short-range and combined short-range and long-range Coulomb scatterers, must be considered. Using the T-matrix formalism, we demonstrate a strong renormalization of the Born description of short-range scattering, manifested in a pronounced reduction and a characteristic energy dependence of the scattering rate. As a consequence, carrier scattering in TMDs with charged vacancies is dominated by the long-range Coulomb-disorder scattering, giving rise to a strong screening-induced temperature and density dependence of the low-temperature carrier mobility. For TMDs with neutral vacancies, the absence of intrinsic Coulomb disorder results in significantly higher mobilities as well as an unusual density dependence of the mobility which decreases with the carrier density. Our work illuminates the transport-limiting effects of atomic-vacancy scattering relevant for high-mobility TMD devices. ","cond-mat"
"1911.03492","Dimer description of the SU(4) antiferromagnet on the triangular lattice","  In systems with many local degrees of freedom, high-symmetry points in the phase diagram can provide an important starting point for the investigation of their properties throughout the phase diagram. In systems with both spin and orbital (or valley) degrees of freedom such a starting point gives rise to SU(4)-symmetric models. Here we consider SU(4)-symmetric ""spin"" models, corresponding to Mott phases at half-filling, i.e. the six-dimensional representation of SU(4). This may be relevant to twisted multilayer graphene. In particular, we study the SU(4) antiferromagnetic ""Heisenberg"" model on the triangular lattice, both in the classical limit and in the quantum regime. Carrying out a numerical study using the density matrix renormalization group (DMRG), we argue that the ground state is non-magnetic. We then derive a dimer expansion of the SU(4) spin model. An exact diagonalization (ED) study of the effective dimer model suggests that the ground state breaks translation invariance, forming a valence bond solid (VBS) with a 12-site unit cell. Finally, we consider the effect of SU(4)-symmetry breaking interactions due to Hund's coupling, and argue for a possible phase transition between a VBS and a magnetically ordered state. ","cond-mat"
"1812.03860","Lepton-flavor violation and two loop electroweak corrections to   $(g-2)_\mu$ in the B-L symmetry SSM","  Charged lepton flavor violating processes are forbidden in the standard model (SM), hence the observation of charged lepton flavor transitions would represent a clear signal of new physics beyond the standard Model. In this work, we investigate some lepton flavor violating processes in the minimal supersymmetric extension of the SM with local $B-L$ gauge symmetry (B-LSSM). And including the corrections from some two loop diagrams to the anomalous dipole moments (MDM) of muon, we discuss the corresponding constraint on the relevant parameter space of the model. Considering the constraints from updated experimental data, the numerical results show that, new contributions in the B-LSSM enhance the MSSM predictions on the rates of $l_j-l_i$ transitions about one order of magnitude, and also enhance the MSSM prediction on the muon MDM. In addition, two loop electroweak corrections can make important contributions to the muon MDM in the B-LSSM. ","hep-ph"
"1903.12573","Primordial Gravitational Waves in the Cosmic Bubble Chamber","  We explore the effect of relic gravitational waves on the primordial phase change from the quark-gluon plasma into the low density hadron gas that occurred approximately $10^{-5}$s after the beginning. We show that the gravitational wave, through doing work on the fluid, modulates the local volumes, causing a pressure modulation which either suppresses or boosts the bubble cavitation rate. The boosted rate is significant, implying that the phase transition could have occurred earlier than if this interaction is not considered. ","astro-ph"
"2004.02355","Deep Multilayer Perceptrons for Dimensional Speech Emotion Recognition","  Modern deep learning architectures are ordinarily performed on high-performance computing facilities due to the large size of the input features and complexity of its model. This paper proposes traditional multilayer perceptrons (MLP) with deep layers and small input size to tackle that computation requirement limitation. The result shows that our proposed deep MLP outperformed modern deep learning architectures, i.e., LSTM and CNN, on the same number of layers and value of parameters. The deep MLP exhibited the highest performance on both speaker-dependent and speaker-independent scenarios on IEMOCAP and MSP-IMPROV corpus. ","eess"
"1909.00793","Gamma-rays and positrons from Colliding Wind Binaries","  The $\eta$ Carinae binary system is the first $\gamma$-ray binary ever observed which does not contain a compact object. The dense wind of the primary star shocks against the fast light wind coming from the companion star, creating the conditions to accelerate particles up to relativistic energies via Fermi mechanisms. These relativistic particles subsequently dissipates non-thermal radiation. Fermi-LAT and H.E.S.S. detection of $\eta$ Carinae confirm such hypotheses. Hydrodynamic simulations provide a convincing match to the observations if a few percent of the wind mechanical energy dissipated in the shock goes into particle acceleration. The intrinsic $\pi^0$ decay spectrum is a complex convolution of the maximum energy, luminosity, particle drift and obscuration. Accelerated particles cool down mainly via inverse-Compton, synchrotron radiation, and photo-pion production. High-energy $\gamma$-rays interact also with the pool of anisotropic UV photons emitted by both luminous stars, creating $e^\pm$ pairs and strongly modifying the observed spectrum. Quick variations of the optical depth are expected along the orbit, due to changes in shape, position, and gas density of the shocked region. Various CTA simulations confirm that flux variabilities down to few days timescale could be detected above 30 GeV. These variations will disentangle the intrinsic particle spectral cut off from that related to $\gamma$-$\gamma$ opacity and determine the flux of relativistic protons and positrons injected in the interstellar medium, the geometry of the colliding wind region and the magnetic field configuration, as well as the geometrical orientation of the binary system. CTA will also enlighten the nature of the high-energy component, the mechanisms and the percentage of kinetic energy channelled into particle acceleration. ","astro-ph"
"2006.08860","Note on Quantum Periods and a TBA System","  There is an interesting relation between the quantum periods on a certain limit of local $\mathbb{P}^1\times \mathbb{P}^1$ Calabi-Yau space and a TBA (Thermodynamic Bethe Ansatz) system appeared in the studies of ABJM (Aharony-Bergman-Jafferis-Maldacena) theory. We propose a one-parameter generalization of the relation. Furthermore, we derive the differential operators for quantum periods and the TBA system in various limits of the generalized relation. ","hep-th"
"2002.00362","Optimal local unitary encoding circuits for the surface code","  The surface code is a leading candidate quantum error correcting code, owing to its high threshold, and compatibility with existing experimental architectures. Bravyi et al. (2006) showed that encoding a state in the surface code using local unitary operations requires time at least linear in the lattice size $L$, however the most efficient known method for encoding an unknown state, introduced by Dennis et al. (2002), has $O(L^2)$ time complexity. Here, we present an optimal local unitary encoding circuit for the planar surface code that uses exactly $2L$ time steps to encode an unknown state in a distance $L$ planar code. We further show how an $O(L)$ complexity local unitary encoder for the toric code can be found by enforcing locality in the $O(\log L)$-depth non-local renormalisation encoder. We relate these techniques by providing an $O(L)$ local unitary circuit to convert between a toric code and a planar code, and also provide optimal encoders for the rectangular, rotated and 3D surface codes. Furthermore, using known mappings from surface codes, our circuits also imply optimal encoders for any 2D translationally invariant topological code, some 2D subsystem codes, as well as the 2D color code with and without boundaries. Our results therefore provide a tight upper bound on the time complexity of encoding an unknown state in the surface code using local unitary operations, and may enable earlier experimental demonstrations of topological quantum order. ","quant-ph"
"2006.01881","Atmosphere loss in planet-planet collisions","  Many of the planets discovered by the Kepler satellite are close orbiting Super-Earths or Mini-Neptunes. Such objects exhibit a wide spread of densities for similar masses. One possible explanation for this density spread is giant collisions stripping planets of their atmospheres. In this paper we present the results from a series of smoothed particle hydrodynamics (SPH) simulations of head-on collisions of planets with significant atmospheres and bare projectiles without atmospheres. Collisions between planets can have sufficient energy to remove substantial fractions of the mass from the target planet. We find the fraction of mass lost splits into two regimes -- at low impact energies only the outer layers are ejected corresponding to atmosphere dominated loss, at higher energies material deeper in the potential is excavated resulting in significant core and mantle loss. Mass removal is less efficient in the atmosphere loss dominated regime compared to the core and mantle loss regime, due to the higher compressibility of atmosphere relative to core and mantle. We find roughly twenty per cent atmosphere remains at the transition between the two regimes. We find that the specific energy of this transition scales linearly with the ratio of projectile to target mass for all projectile-target mass ratios measured. The fraction of atmosphere lost is well approximated by a quadratic in terms of the ratio of specific energy and transition energy. We provide algorithms for the incorporation of our scaling law into future numerical studies. ","astro-ph"
"2004.08630","Efficient implementation of median bias reduction","  In numerous regular statistical models, median bias reduction (Kenne Pagui et al., 2017) has proven to be a noteworthy improvement over maximum likelihood, alternative to mean bias reduction. The estimator is obtained as solution to a modified score ensuring smaller asymptotic median bias than the maximum likelihood estimator. This paper provides a simplified algebraic form of the adjustment term. With the new formula, the estimation procedure benefits from a considerable computational gain by avoiding multiple summations and thus allows an efficient implementation for general parametric models. More importantly, the new formulation allows to highlight how the median bias reduction adjustment can be obtained by adding an extra term to the mean bias reduction adjustment. Illustrations are provided through new applications of median bias reduction to extended beta regression and beta-binomial regression. Mean bias reduction is also provided here for the latter model. Simulation studies show remarkable componentwise median centering of the median bias reduced estimator, while dispersion and coverage of related confidence intervals are comparable with those of its main competitors. Moreover, for the beta-binomial model the method is successful in solving the boundary estimate problem. ","stat"
"1911.00529","On the logarithmic coefficient of the entanglement entropy of a Maxwell   field","  We elucidate the mismatch between the $A$-anomaly coefficient and the coefficient of the logarithmic term in the entanglement entropy of a Maxwell field. In contrast to the usual assumptions about the protection of renormalization group charges at the infrared, the logarithmic term is different for a free Maxwell field and a Maxwell field interacting with heavy charges. This is possible because of the presence of superselection sectors in the IR theory. However, the correction due to the coupling with charged vacuum fluctuations, that restores the anomaly coefficient, is independent of the precise UV dynamics. The problem is invariant under electromagnetic duality, and the solution requires both the existence of electric charges and magnetic monopoles. We use a real-time operator approach but we also show how the results for the free and interacting fields are translated into an effective correction to the four-sphere partition function. ","hep-th"
"2005.12822","Bayesian joint models for longitudinal and survival data","  This paper takes a quick look at Bayesian joint models (BJM) for longitudinal and survival data. A general formulation for BJM is examined in terms of the sampling distribution of the longitudinal and survival processes, the conditional distribution of the random effects and the prior distribution. Next a basic BJM defined in terms of a mixed linear model and a Cox survival regression models is discussed and some extensions and other Bayesian topics are briefly outlined. ","stat"
"1910.09617","Spectral Perturbations of the Line Graph Laplacian","  The graph Laplacian is an important tool in Graph Signal Processing (GSP) as its eigenvalue decomposition acts as an analogue to the Fourier transform and is known as the Graph Fourier Transform (GFT). The line graph has a GFT that is a direct analogue to the Discrete Cosine Transform Type II (DCT-II). Leveraging Fourier transform properties, one can then define processing operations on this graph structure that is loosely analogous to processing operations encountered in Digital Signal Processing (DSP) theory. This raises the question of whether well defined DSP-like operations can be derived from the GFT for more complex graph structures. One potential approach to this problem is to perturb simple graph structures and study the perturbation's impact on the graph Laplacian. This paper explores this idea by examining the eigenvalue decomposition of the Laplacian of undirected line graphs that undergo a single edge weight perturbation. This single perturbation can perturb either an existing edge weight or create new edge between distant unconnected vertices. The eigenvalue bounds are expressed in closed form and agree with simulated examples. The theory can be extended to include multiple perturbations such that the GFT can be defined for a more general graph structure. ","eess"
"1903.06235","Learning Automata Based Q-learning for Content Placement in Cooperative   Caching","  An optimization problem of content placement in cooperative caching is formulated, with the aim of maximizing sum mean opinion score (MOS) of mobile users. Firstly, a supervised feed-forward back-propagation connectionist model based neural network (SFBC-NN) is invoked for user mobility and content popularity prediction. More particularly, practical data collected from GPS-tracker app on smartphones is tackled to test the accuracy of mobility prediction. Then, a learning automata-based Q-learning (LAQL) algorithm for cooperative caching is proposed, in which learning automata (LA) is invoked for Q-learning to obtain an optimal action selection in a random and stationary environment. It is proven that the LA-based action selection scheme is capable of enabling every state to select the optimal action with arbitrarily high probability if Q-learning is able to converge to the optimal Q value eventually. To characterize the performance of the proposed algorithms, the sum MOS of users is applied to define the reward function. Extensive simulations reveal that: 1) The prediction error of SFBC-NN lessen with the increase of iterations and nodes; 2) the proposed LAQL achieves significant performance improvement against traditional Q-learning; 3) the cooperative caching scheme is capable of outperforming non-cooperative caching and random caching of 3% and 4%. ","eess"
"2005.01042","Transcriptional landscape of SARS-CoV-2 infection dismantles pathogenic   pathways activated by the virus, proposes unique sex-specific differences and   predicts tailored therapeutic strategies","  The emergence of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) disease (COVID-19) has posed a serious threat to global health. As no specific therapeutics are yet available to control disease evolution, more in-depth understanding of the pathogenic mechanisms induced by SARS-CoV-2 will help to characterize new targets for the management of COVID-19. The present study identified a specific set of biological pathways altered in primary human lung epithelium upon SARS-CoV-2 infection, and a comparison with SARS-CoV from the 2003 pandemic was studied. The transcriptomic profiles were also exploited as possible novel therapeutic targets, and anti-signature perturbation analysis predicted potential drugs to control disease progression. Among them, Mitogen-activated protein kinase kinase (MEK), serine-threonine kinase (AKT), mammalian target of rapamycin (mTOR) and I kappa B Kinase (IKK) inhibitors emerged as candidate drugs. Finally, sex-specific differences that may underlie the higher COVID-19 mortality in men are proposed. ","q-bio"
"1911.01001","Enhanced Secure Wireless Information and Power Transfer via Intelligent   Reflecting Surface","  In this paper, secure wireless information and power transfer with intelligent reflecting surface (IRS) is proposed for a multiple-input single-output (MISO) system. Under the secrecy rate (SR) and the reflecting phase shifts of IRS constraints, the secure transmit beamforming at access point (AP) and phase shifts at IRS are jointly optimized to maximize the harvested power of energy harvesting receiver (EHR). Due to the non-convexity of optimization problem and coupled optimization variables, firstly, we convert the optimization problem into a semidefinite relaxation (SDR) problem and a sub-optimal solution is achieved. To reduce the high-complexity of the proposed SDR method, a low-complexity successive convex approximation (SCA) technique is proposed. Simulation results show the power harvested by the proposed SDR and SCA methods approximately double that of the existing method without IRS given the same SR. In particular, the proposed SCA achieves almost the same performance as the proposed SDR but with a much lower complexity. ","eess"
"1909.00892","Reading tea leaves? Polygenic scores and differences in traits among   groups","  In the past decade, Genome-Wide Association Studies (GWAS) have delivered an increasingly broad view of the genetic basis of human phenotypic variation. One of the major developments from GWAS is polygenic scores, a genetic predictor of an individual's genetic predisposition towards a trait constructed from GWAS. The success of GWAS and polygenic scores seems to suggest that we will soon be able to settle debates about whether phenotypic differences among groups are driven in part by genetics. However, answering these questions is more complicated than it seems at first glance and touches on many old issues about the interpretation of human genetic variation. In this perspective piece, I outline the ways in which issues of causality, stratification, gene-by-environment interactions, and divergence among groups all complicate the interpretation of among-population polygenic score differences. ","q-bio"
"1903.09468","Quantum Ising model in a period-2 modulated transverse field","  We study a finite spin-$\frac{1}{2}$ Ising chain with a spatially alternating transverse field of period 2. By means of a Jordan-Wigner transformation for even and odd sites, we are able to map it into a one-dimensional model of free fermions. We determine the ground-state energies in the positive- and negative-parity subspaces (subspaces with an even or odd total number of down spins, respectively) and compare them in order to establish the ground-state energy for the entire Hamiltonian. We derive closed-form expressions for this energy gap between the different parity subspaces and analyze its behavior and dependence on the system size in the various regimes of the applied field. Finally, we suggest an expression for the correlation length of such a model that is consistent with the various values found in the literature for its behavior in the vicinity of critical points. ","quant-ph"
"1509.06679","Mental Wormholes and the Inner Workings of Creative Thought","  Most creative outputs are readily classified as belonging to a particular domain such as art, music, or technology. But does that mean the creative thinking that goes into creative projects respects these conventional domain boundaries? This question provides the departure point for this chapter. It is an important question because the answer has implications for how the creative process works, as well as for computational models of creativity, and thus it provides the departure point for this chapter. Next we look at how the creator sifts out from its vast contents those items to incorporate into a creative project, and converts these raw materials into a form that ""gels"" with the project. We then explore the hypothesis that the creative mind forges ""mental wormholes"" that connect concepts and percepts, often from seemingly disparate domains. Finally, we take a brief look at the strangely non-compositional interactions that take place in these mental wormholes, and techniques being advanced to model and understand these interactions. ","q-bio"
"2004.14042","The local and global properties of different types of supernova host   galaxies","  By using Data Analysis Pipeline (DAP) products of Mapping Nearby Galaxies at Apache Point Observatory (MaNGA), which are publicly available from the SDSS Data Release 15, we analyze the local properties at the SN explosion sites and global properties of different types of SN host galaxies to explore the explosion environments of different types of SNe. In our sample, there are 67 SN host galaxies in the field of view of MaNGA, including 32 Type Ia, 29 CCSNe, 1 super-luminous SN (SLSN), 1 Type I and 4 unclassified type of SNe, with which we can perform the K-S test for analysis and derive statistically robust results. Due to the limited sample size, we couldn't remove the mass dependence in this work, which is likely the true driver of the trends for the properties presented in this work. The global star formation rate (SFR) and EW(H$\alpha$) for SN Ia hosts is slightly lower than that for CCSN hosts on average. SN Ia host galaxies are $\sim$ 0.3 dex more massive than CCSN hosts, which implies that the number ratio of CCSNe to Type Ia SNe will decrease with the increasing of stellar mass of host galaxies. The stellar population age of SN Ia host galaxies is older than that of CCSN hosts on average. There is no significant difference between different types of SN hosts for some properties, including local SFR density ($\Sigma \rm SFR$), local and global gas-phase oxygen abundance. For most galaxies in our sample, the global gas-phase oxygen abundance estimated from the integrated spectra of SN hosts can represent the local gas-phase oxygen abundance at the SN explosion sites with small bias. ","astro-ph"
"1910.11194","Analytical Theory for Sequence-Specific Binary Fuzzy Complexes of   Charged Intrinsically Disordered Proteins","  Intrinsically disordered proteins (IDPs) are important for biological functions. In contrast to folded proteins, molecular recognition among certain IDPs is ""fuzzy"" in that their binding and/or phase separation are stochastically governed by the interacting IDPs' amino acid sequences while their assembled conformations remain largely disordered. To help elucidate a basic aspect of this fascinating yet poorly understood phenomenon, the binding of a homo- or hetero-dimeric pair of polyampholytic IDPs is modeled statistical mechanically using cluster expansion. We find that the binding affinities of binary fuzzy complexes in the model correlate strongly with a newly derived simple ""jSCD"" parameter readily calculable from the pair of IDPs' sequence charge patterns. Predictions by our analytical theory are in essential agreement with coarse-grained explicit-chain simulations. This computationally efficient theoretical framework is expected to be broadly applicable to rationalizing and predicting sequence-specific IDP-IDP polyelectrostatic interactions. ","q-bio"
"1909.04209","Comments on ""Three regimes of QCD"" by L.Glozman","  There are no ""three regimes of QCD"", as speculated in that paper. There are only two, separated by already well known $T_c\sim 155\, MeV$. Above it electric interactions are screened rather then confined. Magnetic ones remain confined all the way to $T\rightarrow \infty$. Spectrum of ""mesonic screening masses"" is there, but they do not represent real masses. At high $T$ they correspond to ""heavy quarkonia"" of 2+1 d gauge theory, which is well known to be a confining theory. There is no reason to expect any transition unbinding them, at $T\sim 1\, GeV$ as claimed. I make calculation of correction to screening masses in 2+1d at high temperature including spatial screening tension and find results in agreement with recent lattice data. ","hep-ph"
"1902.09360","CoHSI V: Identical multiple scale-independent systems within genomes and   computer software","  A mechanism-free and symbol-agnostic conservation principle, the Conservation of Hartley-Shannon Information (CoHSI) is predicted to constrain the structure of discrete systems regardless of their origin or function. Despite their distinct provenance, genomes and computer software share a simple structural property; they are linear symbol-based discrete systems, and thus they present an opportunity to test in a comparative context the predictions of CoHSI. Here, without any consideration of, or relevance to, their role in specifying function, we identify that 10 representative genomes (from microbes to human) and a large collection of software contain identically structured nested subsystems. In the case of base sequences in genomes, CoHSI predicts that if we split the genome into n-tuples (a 2-tuple is a pair of consecutive bases; a 3-tuple is a trio and so on), without regard for whether or not a region is coding, then each collection of n-tuples will constitute a homogeneous discrete system and will obey a power-law in frequency of occurrence of the n-tuples. We consider 1-, 2-, 3-, 4-, 5-, 6-, 7- and 8-tuples of ten species and demonstrate that the predicted power-law behavior is emphatically present, and furthermore as predicted, is insensitive to the start window for the tuple extraction i.e. the reading frame is irrelevant.   We go on to provide a proof of Chargaff's second parity rule and on the basis of this proof, predict higher order tuple parity rules which we then identify in the genome data.   CoHSI predicts precisely the same behavior in computer software. This prediction was tested and confirmed using 2-, 3- and 4-tuples of the hexadecimal representation of machine code in multiple computer programs, underlining the fundamental role played by CoHSI in defining the landscape in which discrete symbol-based systems must operate. ","q-bio"
"2007.12191","Positive Geometries for One-Loop Chiral Octagons","  Inspired by the topological sign-flip definition of the Amplituhedron, we introduce similar, but distinct, positive geometries relevant for one-loop scattering amplitudes in planar $\mathcal{N}=4$ super Yang-Mills theory. The simplest geometries are those with the maximal number of sign flips, and turn out to be associated with chiral octagons previously studied in the context of infrared (IR) finite, pure and dual conformal invariant local integrals. Our result bridges two different themes of the modern amplitudes program: positive geometry and Feynman integrals. ","hep-th"
"1808.08984","Minimax quantum state estimation under Bregman divergence","  We investigate minimax estimators for quantum state tomography under general Bregman divergences. First, generalizing the work of Komaki et al. $\href{http://dx.doi.org/10.3390/e19110618}{\textrm{[Entropy 19, 618 (2017)]}}$ for relative entropy, we find that given any estimator for a quantum state, there always exists a sequence of Bayes estimators that asymptotically perform at least as well as the given estimator, on any state. Second, we show that there always exists a sequence of priors for which the corresponding sequence of Bayes estimators is asymptotically minimax (i.e. it minimizes the worst-case risk). Third, by re-formulating Holevo's theorem for the covariant state estimation problem in terms of estimators, we find that any covariant measurement is, in fact, minimax (i.e. it minimizes the worst-case risk). Moreover, we find that a measurement is minimax if it is only covariant under a unitary 2-design. Lastly, in an attempt to understand the problem of finding minimax measurements for general state estimation, we study the qubit case in detail and find that every spherical 2-design is a minimax measurement. ","quant-ph"
"1901.01896","Hodge theory of degenerations, (I): Consequences of the decomposition   theorem","  We use the Decomposition Theorem to derive several generalizations of the Clemens-Schmid sequence, relating asymptotic Hodge theory of a degeneration to the mixed Hodge theory of its singular fiber(s). ","math"
"2004.12877","Perturbative unitarity bounds for fermions composite models","  Perturbative unitarity is a powerful tool for inferring the range of validity of a given effective field theory. Here, we study such a bound in the parameter space of dimension-5 and dimension-6 effective operators that arise in a scenario of fermion compositeness. These operators are routinely used in experimental searches at the LHC to constraint contact and gauge interactions between ordinary Standard Model fermions and excited states of mass $M$. We derive the unitarity bound for the production process of an excited neutrino, then we implement such bound and compare it with the recent experimental exclusion curves for Run 2, the High-Luminosity and High-Energy configurations of the LHC. The results also apply to the searches where a generic single excited state is produced via dimension-6 contact interactions. The unitarity bound, so far overlooked in these effective models, is quite compelling and can serve as a guide for exploring the parameter space ($M,\Lambda$) in addition to the standard request $M \le \Lambda$. ","hep-ph"
"1903.03005","K-group identification of supergravity solutions","  The problem with Bekenstein-Hawking entropy of black hole can be resolved with quantum gravity theory with Dp-branes as supergravity solutions of type IIB string theory. Dp-brane solutions of type IIB are a direct analog of the Schwarzschild charged hole, so called black p-branes. The coincidence of the black p-brane metrics and ten-dimensional metrics of N-parallel D3-branes was used from the viewpoint of the Azumaya structure on D-branes connected with deformation of the classical moduli space. Applying Rosenberg theorem we can classify Hilbert spaces of N coinciding Dp-branes as vector bundles through K-functor. ","hep-th"
"1909.10425","The ASKAP-EMU Early Science Project:Radio Continuum Survey of the Small   Magellanic Cloud","  We present two new radio continuum images from the Australian Square Kilometre Array Pathfinder (ASKAP) survey in the direction of the Small Magellanic Cloud (SMC). These images are part of the Evolutionary Map of the Universe (EMU) Early Science Project (ESP) survey of the Small and Large Magellanic Clouds. The two new source lists produced from these images contain radio continuum sources observed at 960 MHz (4489 sources) and 1320 MHz (5954 sources) with a bandwidth of 192 MHz and beam sizes of 30.0""x30.0"" and 16.3""x15.1"", respectively. The median Root Mean Squared (RMS) noise values are 186$\mu$Jy beam$^{-1}$ (960 MHz) and 165$\mu$Jy beam$^{-1}$ (1320 MHz). To create point source catalogues, we use these two source lists, together with the previously published Molonglo Observatory Synthesis Telescope (MOST) and the Australia Telescope Compact Array (ATCA) point source catalogues to estimate spectral indices for the whole population of radio point sources found in the survey region. Combining our ASKAP catalogues with these radio continuum surveys, we found 7736 point-like sources in common over an area of 30 deg$^2$. In addition, we report the detection of two new, low surface brightness supernova remnant candidates in the SMC. The high sensitivity of the new ASKAP ESP survey also enabled us to detect the bright end of the SMC planetary nebula sample, with 22 out of 102 optically known planetary nebulae showing point-like radio continuum emission. Lastly, we present several morphologically interesting background radio galaxies. ","astro-ph"
"2006.00906","Center-of-Mass-based Robust Grasp Planning for Unknown Objects Using   Tactile-Visual Sensors","  An unstable grasp pose can lead to slip, thus an unstable grasp pose can be predicted by slip detection. A regrasp is required afterwards to correct the grasp pose in order to finish the task. In this work, we propose a novel regrasp planner with multi-sensor modules to plan grasp adjustments with the feedback from a slip detector. Then a regrasp planner is trained to estimate the location of center of mass, which helps robots find an optimal grasp pose. The dataset in this work consists of 1 025 slip experiments and 1 347 regrasps collected by one pair of tactile sensors, an RGB-D camera and one Franka Emika robot arm equipped with joint force/torque sensors. We show that our algorithm can successfully detect and classify the slip for 5 unknown test objects with an accuracy of 76.88% and a regrasp planner increases the grasp success rate by 31.0% compared to the state-of-the-art vision-based grasping algorithm. ","cs"
"1911.09468","Phase covariant qubit dynamics and divisibility","  Phase covariant qubit dynamics describes an evolution of a two-level system under simultaneous action of pure dephasing, energy dissipation, and energy gain with time-dependent rates $\gamma_z(t)$, $\gamma_-(t)$, and $\gamma_+(t)$, respectively. Non-negative rates correspond to completely positive divisible dynamics, which can still exhibit such peculiarities as non-monotonicity of populations for any initial state. We find a set of quantum channels attainable in the completely positive divisible phase covariant dynamics and show that this set coincides with the set of channels attainable in semigroup phase covariant dynamics. We also construct new examples of eternally indivisible dynamics with $\gamma_z(t) < 0$ for all $t > 0$ that is neither unital nor commutative. Using the quantum Sinkhorn theorem, we for the first time derive a restriction on the decoherence rates under which the dynamics is positive divisible, namely, $\gamma_{\pm}(t) \geq 0$, $\sqrt{\gamma_+(t) \gamma_-(t)} + 2 \gamma_z(t) > 0$. Finally, we consider phase covariant convolution master equations and find a class of admissible memory kernels that guarantee complete positivity of the dynamical map. ","quant-ph"
"1906.02165","Heterotic/type II Duality and Non-Geometric Compactifications","  We present a new class of dualities relating non-geometric Calabi-Yau compactifications of type II string theory to T-fold compactifications of the heterotic string, both preserving four-dimensional $\mathcal{N}=2$ supersymmetry. The non-geometric Calabi-Yau space is a $K3$ fibration over $T^2$ with non-geometric monodromies in the duality group $O(\Gamma_{4,20})$; this is dual to a heterotic reduction on a $T^4$ fibration over $T^2$ with the $O(\Gamma_{4,20})$ monodromies now viewed as heterotic T-dualities. At a point in moduli space which is a minimum of the scalar potential, the type II compactification becomes an asymmetric Gepner model and the monodromies become automorphisms involving mirror symmetries, while the heterotic dual is an asymmetric toroidal orbifold. We generalise previous constructions to ones in which the automorphisms are not of prime order. The type II construction is perturbatively consistent, but the naive heterotic dual is not modular invariant. Modular invariance on the heterotic side is achieved by including twists in the circles dual to the winding numbers round the $T^2$, and this in turn introduces non-perturbative phases depending on NS5-brane charge in the type II construction. ","hep-th"
"1905.02013","Energetic and entropic effects of bath-induced coherences","  The unavoidable interaction of a quantum system with its surrounding (bath) is not always detrimental for quantum properties. For instance, under some specific conditions (that we identify as indistinguishability), a many-body system can gain internal coherences thanks to the interaction with its bath. The most famous consequence of this phenomenon is superradiance. Beyond that, the thermodynamic effects on the system of these bath-induced coherences have been mostly unexplored. We show here, for a simple and common system (a pair of two-level systems), that the energetic and entropic impacts can indeed be dramatic and diverse, including amplification of the action of the bath but also its mitigation. Our results can be tested experimentally. They suggest that bath-induced coherences can be harnessed to enhance thermodynamic tasks, opening up interesting perspectives for thermal machines, quantum battery charging, natural or artificial energy harvesting systems, and state preparation and protection. ","quant-ph"
"1910.10674","Generalized Planar Feynman Diagrams: Collections","  Tree-level Feynman diagrams in a cubic scalar theory can be given a metric such that each edge has a length. The space of metric trees is made out of orthants joined where a tree degenerates. Here we restrict to planar trees since each degeneration of a tree leads to a single planar neighbor. Amplitudes are computed as an integral over the space of metrics where edge lengths are Schwinger parameters. In this work we propose that a natural generalization of Feynman diagrams is provided by what are known as metric tree arrangements. These are collections of metric trees subject to a compatibility condition on the metrics. We introduce the notion of planar collections of Feynman diagrams and argue that using planarity one can generate all planar collections starting from any one. Moreover, we identify a canonical initial collection for all $n$. Generalized $k=3$ biadjoint amplitudes, introduced by Early, Guevara, Mizera, and one of the authors, are easily computed as an integral over the space of metrics of planar collections of Feynman diagrams. ","hep-th"
"1706.09813","Gene expression rearrangements denoting changes in the biological state","  In many situations, the gene expression signature is a unique marker of the biological state. We study the modification of the gene expression distribution function when the biological state of a system experiences a change. This change may be the result of a selective pressure, as in the Long Term Evolution Experiment with E. Coli populations, or the progression to Alzheimer disease in aged brains, or the progression from a normal tissue to the cancer state. The first two cases seem to belong to a class of transitions, where the initial and final states are relatively close to each other, and the distribution function for the differential expressions is short ranged, with a tail of only a few dozens of strongly varying genes. In the latter case, cancer, the initial and final states are far apart and separated by a low-fitness barrier. The distribution function shows a very heavy tail, with thousands of silenced and over-expressed genes. We characterize the biological states by means of their principal component representations, and the expression distribution functions by their maximal and minimal differential expression values and the exponents of the Pareto laws describing the tails. ","q-bio"
"1812.01146","Wigner function and pair production in parallel electric and magnetic   fields","  We derive analytical formulas for the equal-time Wigner function in an electromagnetic field of arbitrary strength. While the magnetic field is assumed to be constant, the electric field is assumed to be space-independent and oriented parallel to the magnetic field. The Wigner function is first decomposed in terms of the so-called Dirac-Heisenberg-Wigner (DHW) functions and then the transverse-momentum dependence is separated using a new set of basis functions which depend on the quantum number $n$ of the Landau levels. Equations for the coefficients are derived and then solved for the case of a constant electric field. The pair-production rate for each Landau level is calculated. In the case of finite temperature and chemical potential, the pair-production rate is suppressed by Pauli's exclusion principle. ","hep-ph"
"2003.12814","Investigating linear relationships between non constant variances of   economic variables","  In this paper we aim to assess linear relationships between the non constant variances of economic variables. The proposed methodology is based on a bootstrap cumulative sum (CUSUM) test. Simulations suggest a good behavior of the test for sample sizes commonly encountered in practice. The tool we provide is intended to highlight relations or draw common patterns between economic variables through their non constant variances. The outputs of this paper is illustrated considering U.S. regional data. ","stat"
"2004.10527","The Effect of Population Size for Pathogen Transmission on Prediction of   COVID-19 Pandemic Spread","  Extreme public health interventions play a critical role in mitigating the local and global prevalence and pandemic potential of COVID-19. Here, we use population size for pathogen transmission to measure the intensity of public health interventions, which is a key characteristic variable for nowcasting and forecasting of the epidemic. By formulating a hidden Markov dynamic system and using nonlinear filtering theory, we have developed a stochastic epidemic dynamic model under public health interventions. The model parameters and states are estimated in time from internationally available public data by combining an unscented filter and an interacting multiple model filter. Moreover, we consider the computability of the population size and provide its selection criterion. We estimate the mean of the basic reproductive number of China and the rest of the globe except China (GEC) to be 2.46 (95% CI: 2.41-2.51) and 3.64 (95% CI: (3.55-3.72), respectively. We infer that the number of latent infections of GEC is about 7.47*10^5 (95% CI: 7.32*10^5-7.62*10^5) as of April 2, 2020. We predict that the peak of infections in hospitals of GEC may reach 3.00*10^6 on the present trajectory, i.e., if the population size for pathogen transmission and epidemic parameters remains unchanged. If the control intensity is strengthened, e.g., 50% reduction or 75% reduction of the population size for pathogen transmission, the peak would decline to 1.84*10^6, 1.27*10^6, respectively. ","q-bio"
"1809.09061","Sparse-to-Continuous: Enhancing Monocular Depth Estimation using   Occupancy Maps","  This paper addresses the problem of single image depth estimation (SIDE), focusing on improving the quality of deep neural network predictions. In a supervised learning scenario, the quality of predictions is intrinsically related to the training labels, which guide the optimization process. For indoor scenes, structured-light-based depth sensors (e.g. Kinect) are able to provide dense, albeit short-range, depth maps. On the other hand, for outdoor scenes, LiDARs are considered the standard sensor, which comparatively provides much sparser measurements, especially in areas further away. Rather than modifying the neural network architecture to deal with sparse depth maps, this article introduces a novel densification method for depth maps, using the Hilbert Maps framework. A continuous occupancy map is produced based on 3D points from LiDAR scans, and the resulting reconstructed surface is projected into a 2D depth map with arbitrary resolution. Experiments conducted with various subsets of the KITTI dataset show a significant improvement produced by the proposed Sparse-to-Continuous technique, without the introduction of extra information into the training stage. ","cs"
"2006.08115","Minimax Dynamics of Optimally Balanced Spiking Networks of Excitatory   and Inhibitory Neurons","  Excitation-inhibition (E-I) balance is ubiquitously observed in the cortex. Recent studies suggest an intriguing link between balance on fast timescales, tight balance, and efficient information coding with spikes. We further this connection by taking a principled approach to optimal balanced networks of excitatory (E) and inhibitory (I) neurons. By deriving E-I spiking neural networks from greedy spike-based optimizations of constrained minimax objectives, we show that tight balance arises from correcting for deviations from the minimax optimum. We predict specific neuron firing rates in the network by solving the minimax problem, going beyond statistical theories of balanced networks. Finally, we design minimax objectives for reconstruction of an input signal, associative memory, and storage of manifold attractors, and derive from them E-I networks that perform the computation. Overall, we present a novel normative modeling approach for spiking E-I networks, going beyond the widely-used energy minimizing networks that violate Dale's law. Our networks can be used to model cortical circuits and computations. ","q-bio"
"1908.00496","Deep Generative Model Driven Protein Folding Simulation","  Significant progress in computer hardware and software have enabled molecular dynamics (MD) simulations to model complex biological phenomena such as protein folding. However, enabling MD simulations to access biologically relevant timescales (e.g., beyond milliseconds) still remains challenging. These limitations include (1) quantifying which set of states have already been (sufficiently) sampled in an ensemble of MD runs, and (2) identifying novel states from which simulations can be initiated to sample rare events (e.g., sampling folding events). With the recent success of deep learning and artificial intelligence techniques in analyzing large datasets, we posit that these techniques can also be used to adaptively guide MD simulations to model such complex biological phenomena. Leveraging our recently developed unsupervised deep learning technique to cluster protein folding trajectories into partially folded intermediates, we build an iterative workflow that enables our generative model to be coupled with all-atom MD simulations to fold small protein systems on emerging high performance computing platforms. We demonstrate our approach in folding Fs-peptide and the $\beta\beta\alpha$ (BBA) fold, FSD-EY. Our adaptive workflow enables us to achieve an overall root-mean squared deviation (RMSD) to the native state of 1.6$~\AA$ and 4.4~$\AA$ respectively for Fs-peptide and FSD-EY. We also highlight some emerging challenges in the context of designing scalable workflows when data intensive deep learning techniques are coupled to compute intensive MD simulations. ","q-bio"
"1910.06565","To Recurse or not to Recurse,a Low Dose CT Study","  Restoring high-quality CT images from low dose CT counterparts is an ill-posed, nonlinear problem to which Deep Learning approaches have been giving superior solutions compared to classical model-based approaches. In this article, a framework is presented wherein a Recurrent Neural Network (RNN) is utilized to remove the streaking artefacts from low projection number CT imaging. The results indicate similar image restoration performance for the RNN compared to the feedforward network in low noise cases while in high noise levels the RNN returns better results. The computational costs are also compared between RNN and feedforward networks. ","eess"
"1602.06366","Robust Estimation of Propensity Score Weights via Subclassification","  Weighting estimators based on propensity scores are widely used for causal estimation in a variety of contexts, such as observational studies, marginal structural models and interference. They enjoy appealing theoretical properties such as consistency and possible efficiency under correct model specification. However, this theoretical appeal may be diminished in practice by sensitivity to misspecification of the propensity score model. To improve on this, we borrow an idea from an alternative approach to causal effect estimation in observational studies, namely subclassification estimators. It is well known that compared to weighting estimators, subclassification methods are usually more robust to model misspecification. In this paper, we first discuss an intrinsic connection between the seemingly unrelated weighting and subclassification estimators, and then use this connection to construct robust propensity score weights via subclassification. We illustrate this idea by proposing so-called full-classification weights and accompanying estimators for causal effect estimation in observational studies. Our novel estimators are both consistent and robust to model misspecification, thereby combining the strengths of traditional weighting and subclassification estimators for causal effect estimation from observational studies. Numerical studies show that the proposed estimators perform favorably compared to existing methods. ","stat"
"1610.07949","Statistical Inference Based on a New Weighted Likelihood Approach","  We discuss a new weighted likelihood method for parametric estimation. The method is motivated by the need for generating a simple estimation strategy which provides a robust solution that is simultaneously fully efficient when the model is correctly specified. This is achieved by appropriately weighting the score function at each observation in the maximum likelihood score equation. The weight function determines the compatibility of each observation with the model in relation to the remaining observations and applies a downweighting only if it is necessary, rather than automatically downweighting a proportion of the observations all the time. This allows the estimators to retain full asymptotic efficiency at the model. We establish all the theoretical properties of the proposed estimators and substantiate the theory developed through simulation and real data examples. Our approach provides an alternative to the weighted likelihood method of Markatou et al. (1997, 1998). ","stat"
"1901.02677","Short life and abrupt death of PicSat, a small 3U CubeSat dreaming of   exoplanet detection","  PicSat was a three unit CubeSat (measuring 30 cm x 10 cm x 10 cm) which was developed to monitor the beta Pictoris system. The main science objective was the detection of a possible transit of the giant planet beta Pictoris b's Hill sphere. Secondary objectives included studying the circumstellar disk, and detecting exocomets in the visible band. The mission also had a technical objective: demonstrate our ability to inject starlight in a single mode fiber, on a small satellite platform. To answer all those objectives, a dedicated opto-mechanical payload was built, and integrated in a commercial 3U platform, along with a commercial ADCS (Attitude Determination and Control System). The satellite successfully reached Low Earth Orbit on the PSLV-C40 rocket, on January, 12, 2018. Unfortunately, on March, 20, 2018, after 10 weeks of operations, the satellite fell silent, and the mission came to an early end. Furthermore, due to a failure of the ADCS, the satellite never actually pointed toward its target star during the 10 weeks of operations. In this paper, we report on the PicSat mission development process, and on the reasons why it did not deliver any useful astronomical data. ","astro-ph"
"2008.04706","Use of IT tools to search for a correlation between weather factors and   onset of pulmonary thromboembolism","  Pulmonary embolism (PE) and deep vein thrombosis (DVT) are gathered in venous thromboembolism (VTE) and represent the third cause of cardiovascular diseases. Recent studies suggest that meteorological parameters as atmospheric pressure, temperature, and humidity could affect PE incidence but, nowadays, the relationship between these two phenomena is debated and the evidence is not completely explained. The clinical experience of the Department of Emergency Medicine at AOUC Hospital suggests the possibility that a relationship effectively exists. We have collected data concerning the Emergency Medicine Unit admissions of PE patients to confirm our hypothesis. At the same time, atmospheric parameters are collected from the Lamma Consortium of Tuscany region. We have implemented new IT models and statistic tools by using semi-hourly records of weather time high resolution data to process the dataset. We have carried out tools from econometrics, like mobile means, and we have studied anomalies through the search for peaks and possible patterns. We have created a framework in Python to represent and study time series and to analyze data and plot graphs. The project has been uploaded on GitHub. Our analyses highlighted a strong correlation between the moving averages of atmospheric pressure and those of the hospitalizations number (R= -0.9468, p<0,001) although causality is still unknown. The existence of an increase in the number of hospitalizations in the days following short-to-medium periods of time characterized by a high number of half-hourly pressure changes is also detected. The spectrograms studies obtained by the Fourier transform requires to increase the dataset. The analyzed data (especially hospitalization data) were too few to carry out this kind of analyses. ","stat"
"1807.05455","Supersymmetric Localization in GLSMs for Supermanifolds","  In this paper we apply supersymmetric localization to study gauged linear sigma models (GLSMs) describing supermanifold target spaces. We use the localization method to show that A-twisted GLSM correlation functions for certain supermanifolds are equivalent to A-twisted GLSM correlation functions for hypersurfaces in ordinary spaces under certain conditions. We also argue that physical two-sphere partition functions are the same for these two types of target spaces. Therefore, we reproduce the claim of arXiv:hep-th/9404186, arXiv:hep-th/9506070. Furthermore, we explore elliptic genera and (0,2) deformations and find similar phenomena. ","hep-th"
"2001.10833","On quantum ensembles of quantum classifiers","  Quantum machine learning seeks to exploit the underlying nature of a quantum computer to enhance machine learning techniques. A particular framework uses the quantum property of superposition to store sets of parameters, thereby creating an ensemble of quantum classifiers that may be computed in parallel. The idea stems from classical ensemble methods where one attempts to build a stronger model by averaging the results from many different models. In this work, we demonstrate that a specific implementation of the quantum ensemble of quantum classifiers, called the accuracy-weighted quantum ensemble, can be fully dequantised. On the other hand, the general quantum ensemble framework is shown to contain the well-known Deutsch-Jozsa algorithm that notably provides a quantum speedup and creates the potential for a useful quantum ensemble to harness this computational advantage. ","quant-ph"
"2008.05126","Insights into the structural, electronic and optical properties of   X$_2$MgZ$_4$($X=$ Sc, Y; $Z=$ S, Se) spinel compounds: Materials for the   future optoelectronic applications","  Direct bandgap bulk materials are very important for the optical applications. It is therefore important to predict new materials with the desired properties. In the present work, density functional theory is applied to study different physical properties of X$_2$MgZ$_4$($X=$ Sc, Y; $Z=$ S, Se) spinel compounds. Generalized gradient approximation is used to analyze the structural and elastic parameters while modified Becke Johnson exchange potential is applied to calculate electric band profiles and optical properties. All the studied compounds are stable in the cubic structure. Also the energy bandgap is of direct nature. Therefore these compounds can find useful applications in the optoelectrics devices. Optical properties of the compounds are studied in terms of dielectric function, refractive index, extinction coefficient, optical conductivity and reflectivity. The transport parameters like electrical conductivity, Seebeck coefficient, and thermal conductivity are also evaluated. ","cond-mat"
"2001.03716","Self-similar Blast Wave for A Two-component Fluid with Variable   Adiabatic Index","  We propose a self-similar (SS) solution to hydrodynamic non-relativistic flow behind a spherical strong blast wave (BW) passing through a homogeneous plasma with efficient relativistic particle acceleration at the shock front. The flow is described by an ideal two-fluid model with a relativistic component so that the post-shock gas has an effective SS adiabatic index $ \gamma $ varying from $ 5/3 $ to $ 4/3 $. This solution is calculated numerically and compared with the standard Sedov solution. We find that the BW center in our solution is dominated by the relativistic component with $ \gamma =4/3 $ for the divergence of expansion there, and the relativistic component dominates the interior for a moderate acceleration efficiency at the shock front. The overall efficiency of relativistic particle acceleration can be enhanced by a factor of $ 2 $ due to the slower adiabatic energy loss rate of the relativistic component during expansion. Tendency of the dominance by the relativistic component may be common in expanding astrophysical two-fluid systems such as supernova remnants, lobes of radio galaxies. ","astro-ph"
"1805.09579","Model-based inference of conditional extreme value distributions with   hydrological applications","  Multivariate extreme value models are used to estimate joint risk in a number of applications, with a particular focus on environmental fields ranging from climatology and hydrology to oceanography and seismic hazards. The semi-parametric conditional extreme value model of Heffernan and Tawn (2004) involving a multivariate regression provides the most suitable of current statistical models in terms of its flexibility to handle a range of extremal dependence classes. However, the standard inference for the joint distribution of the residuals of this model suffers from the curse of dimensionality since in a $d$-dimensional application it involves a $d-1$-dimensional non-parametric density estimator, which requires, for accuracy, a number points and commensurate effort that is exponential in $d$. Furthermore, it does not allow for any partially missing observations to be included and a previous proposal to address this is extremely computationally intensive, making its use prohibitive if the proportion of missing data is non-trivial. We propose to replace the $d-1$-dimensional non-parametric density estimator with a model-based copula with univariate marginal densities estimated using kernel methods. This approach provides statistically and computationally efficient estimates whatever the dimension, $d$ or the degree of missing data. Evidence is presented to show that the benefits of this approach substantially outweigh potential mis-specification errors. The methods are illustrated through the analysis of UK river flow data at a network of 46 sites and assessing the rarity of the 2015 floods in north west England. ","stat"
"1810.11199","Optimal Task Offloading and Resource Allocation in Mobile-Edge Computing   with Inter-user Task Dependency","  Mobile-edge computing (MEC) has recently emerged as a cost-effective paradigm to enhance the computing capability of hardware-constrained wireless devices (WDs). In this paper, we first consider a two-user MEC network, where each WD has a sequence of tasks to execute. In particular, we consider task dependency between the two WDs, where the input of a task at one WD requires the final task output at the other WD. Under the considered task-dependency model, we study the optimal task offloading policy and resource allocation (e.g., on offloading transmit power and local CPU frequencies) that minimize the weighted sum of the WDs' energy consumption and task execution time. The problem is challenging due to the combinatorial nature of the offloading decisions among all tasks and the strong coupling with resource allocation. To tackle this problem, we first assume that the offloading decisions are given and derive the closed-form expressions of the optimal offloading transmit power and local CPU frequencies. Then, an efficient bi-section search method is proposed to obtain the optimal solutions. Furthermore, we prove that the optimal offloading decisions follow an one-climb policy, based on which a reduced-complexity Gibbs Sampling algorithm is proposed to obtain the optimal offloading decisions. We then extend the investigation to a general multi-user scenario, where the input of a task at one WD requires the final task outputs from multiple other WDs. Numerical results show that the proposed method can significantly outperform the other representative benchmarks and efficiently achieve low complexity with respect to the call graph size. ","cs"
"2004.14009","Joint Likelihood-based Principal Components Regression","  We propose a method for estimating principal components regressions by maximizing a multivariate normal joint likelihood for responses and predictors. In contrast to classical principal components regression, our method uses information in both responses and predictors to select useful linear combinations of the predictors. We show our estimators are consistent when responses and predictors have sub-Gaussian distributions and the number of observations tends to infinity faster than the number of predictors. Simulations indicate our method is substantially more accurate than classical principal components regression in estimation and prediction, and that it often compares favorably to competing methods such as partial least squares and predictor envelopes. We corroborate the simulation results and illustrate the practical usefulness of our method with a data example with cross-sectional prediction of stock returns. ","stat"
"1905.05080","Periodic twists of $GL_3$-automorphic forms","  We prove that sums of length about $q^{3/2}$ of Hecke eigenvalues of automorphic forms on $SL_3(\Zz)$ do not correlate with $q$-periodic functions with bounded Fourier transform. This generalizes the earlier results of Munshi and Holowinsky--Nelson, corresponding to multiplicative Dirichlet characters, and applies in particular to trace functions of small conductor modulo primes. ","math"
"2002.09035","Rapid Quantification of White Matter Disconnection in the Human Brain","  With an estimated five million new stroke survivors every year and a rapidly aging population suffering from hyperintensities and diseases of presumed vascular origin that affect white matter and contribute to cognitive decline, it is critical that we understand the impact of white matter damage on brain structure and behavior. Current techniques for assessing the impact of lesions consider only location, type, and extent, while ignoring how the affected region was connected to the rest of the brain. Regional brain function is a product of both local structure and its connectivity. Therefore, obtaining a map of white matter disconnection is a crucial step that could help us predict the behavioral deficits that patients exhibit. In the present work, we introduce a new practical method for computing lesion-based white matter disconnection maps that require only moderate computational resources. We achieve this by creating diffusion tractography models of the brains of healthy adults and assessing the connectivity between small regions. We then interrupt these connectivity models by projecting patients' lesions into them to compute predicted white matter disconnection. A quantified disconnection map can be computed for an individual patient in approximately 35 seconds using a single core CPU-based computation. In comparison, a similar quantification performed with other tools provided by MRtrix3 takes 5.47 minutes. ","q-bio"
"2007.02006","Cluster Prediction for Opinion Dynamics from Partial Observations","  We present a Bayesian approach to predict the clustering of opinions for a system of interacting agents from partial observations. The Bayesian formulation overcomes the unobservability of the system and quantifies the uncertainty in the prediction. We characterize the clustering by the posterior of the clusters' sizes and centers, and we represent the posterior by samples. To overcome the challenge in sampling the high-dimensional posterior, we introduce an auxiliary implicit sampling (AIS) algorithm using two-step observations. Numerical results show that the AIS algorithm leads to accurate predictions of the sizes and centers for the leading clusters, in both cases of noiseless and noisy observations. In particular, the centers are predicted with high success rates, but the sizes exhibit a considerable uncertainty that is sensitive to observation noise and the observation ratio. ","stat"
"2002.10932","Theoretical Performance Bound of Uplink Channel Estimation Accuracy in   Massive MIMO","  In this paper, we present a new performance bound for uplink channel estimation (CE) accuracy in the Massive Multiple Input Multiple Output (MIMO) system. The proposed approach is based on noise power prediction after the CE unit. Our method outperforms the accuracy of a well-known Cramer-Rao lower bound (CRLB) due to considering more statistics since performance strongly depends on a number of channel taps and power ratio between them. Simulation results are presented for the non-line of sight (NLOS) 3D-UMa model of 5G QuaDRiGa 2.0 channel and compared with CRLB and state-of-the-art CE algorithms. ","eess"
"2007.13886","Perpetual Motion: Generating Unbounded Human Motion","  The modeling of human motion using machine learning methods has been widely studied. In essence it is a time-series modeling problem involving predicting how a person will move in the future given how they moved in the past. Existing methods, however, typically have a short time horizon, predicting a only few frames to a few seconds of human motion. Here we focus on long-term prediction; that is, generating long sequences (potentially infinite) of human motion that is plausible. Furthermore, we do not rely on a long sequence of input motion for conditioning, but rather, can predict how someone will move from as little as a single pose. Such a model has many uses in graphics (video games and crowd animation) and vision (as a prior for human motion estimation or for dataset creation). To address this problem, we propose a model to generate non-deterministic, \textit{ever-changing}, perpetual human motion, in which the global trajectory and the body pose are cross-conditioned. We introduce a novel KL-divergence term with an implicit, unknown, prior. We train this using a heavy-tailed function of the KL divergence of a white-noise Gaussian process, allowing latent sequence temporal dependency. We perform systematic experiments to verify its effectiveness and find that it is superior to baseline methods. ","cs"
"1811.05798","Dynamical freezing of relaxation to equilibrium","  We provide evidence of an extremely slow thermalization occurring in the Discrete NonLinear Schr\""odinger (DNLS) model. At variance with many similar processes encountered in statistical mechanics - typically ascribed to the presence of (free) energy barriers - here the slowness has a purely dynamical origin: it is due to the presence of an adiabatic invariant, which freezes the dynamics of a tall breather. Consequently, relaxation proceeds via rare events, where energy is suddenly released towards the background. We conjecture that this exponentially slow relaxation is a key ingredient contributing to the non-ergodic behavior recently observed in the negative temperature region of the DNLS equation. ","cond-mat"
"1909.06575","Quantum Dot Arrays in Silicon and Germanium","  Electrons and holes confined in quantum dots define an excellent building block for quantum emergence, simulation, and computation. In order for quantum electronics to become practical, large numbers of quantum dots will be required, necessitating the fabrication of scaled structures such as linear and 2D arrays. Group IV semiconductors contain stable isotopes with zero nuclear spin and can thereby serve as excellent host for spins with long quantum coherence. Here we demonstrate group IV quantum dot arrays in silicon metal-oxide-semiconductor (SiMOS), strained silicon (Si/SiGe) and strained germanium (Ge/SiGe). We fabricate using a multi-layer technique to achieve tightly confined quantum dots and compare integration processes. While SiMOS can benefit from a larger temperature budget and Ge/SiGe can make ohmic contact to metals, the overlapping gate structure to define the quantum dots can be based on a nearly identical integration. We realize charge sensing in each platform, for the first time in Ge/SiGe, and demonstrate fully functional linear and two-dimensional arrays where all quantum dots can be depleted to the last charge state. In Si/SiGe, we tune a quintuple quantum dot using the N+1 method to simultaneously reach the few electron regime for each quantum dot. We compare capacitive cross talk and find it to be the smallest in SiMOS, relevant for the tuning of quantum dot arrays. These results constitute an excellent base for quantum computation with quantum dots and provide opportunities for each platform to be integrated with standard semiconductor manufacturing. ","cond-mat"
"1812.09643","Few-electrode design for silicon MOS quantum dots","  Silicon metal-oxide-semiconductor (MOS) spin qubits have become a promising platform for quantum information processing, with recent demonstrations of high-fidelity single and two-qubit gates. To move beyond a few qubits, however, more scalable designs that reduce the fabrication complexity and electrode density are needed. Here, we introduce a two-metal-layer MOS quantum dot device in which tunnel barriers are naturally formed by gaps between electrodes and controlled by adjacent accumulation gates. The accumulation gates define the electron reservoirs and provide tunability of the tunnel rate of nearly 8.5 decades/V, determined by a combination of charge sensor electron counting measurements and by direct transport. The valley splitting in the few-electron regime is probed by magneto-spectroscopy up to a field of 6 T, providing an estimate for the ground-state gap of 290 $\mu$eV. We show preliminary characterization of a double quantum dot, demonstrating that this design can be extended to linear dot arrays that should be useful in applications like electron shuttling. These results motivate further innovations in MOS quantum dot design that can improve the scalability prospects for spin qubits. ","cond-mat"
"1910.05526","Enhanced electron-phonon coupling for charge-density-wave formation in   La$_{1.8-x}$Eu$_{0.2}$Sr$_{x}$CuO$_{4+\delta}$","  Charge density wave (CDW) correlations are prevalent in all copper-oxide superconductors. While CDWs in conventional metals are driven by coupling between lattice vibrations and electrons, the role of the electron-phonon coupling (EPC) in cuprate CDWs is strongly debated. Using Cu $L_3$ edge resonant inelastic x-ray scattering (RIXS), we study the CDW and Cu-O bond-stretching phonons in the stripe-ordered cuprate La$_{1.8-x}$Eu$_{0.2}$Sr$_{x}$CuO$_{4+\delta}$. We investigate the interplay between charge order and EPC as a function of doping and temperature, and find that the EPC is enhanced in a narrow momentum region around the CDW wave vector. By detuning the incident photon energy from the absorption resonance, we extract an EPC matrix element at the CDW wave vector of $M\simeq$ 0.36 eV, which decreases to $M\simeq$ 0.30 eV at high temperature in the absence of the CDW. Our results suggest a feedback mechanism in which the CDW enhances the EPC which, in turn, further stabilizes the CDW. ","cond-mat"
"2004.09661","The $\mathbf{AdS_5 \times S^5}$ Superstring","  The duality between the type IIB superstring theory in an $AdS_5 \times S^5$ background with $N$ units of five-form flux and ${\cal N} =4$ super Yang--Mills theory with a $U(N)$ gauge group has been studied extensively. My version of the construction of the superstring world-sheet action is reviewed here. This paper is dedicated to Michael Duff on the occasion of his 70th birthday. ","hep-th"
"0705.2562","Anthropic prediction in a large toy landscape","  The successful anthropic prediction of the cosmological constant depends crucially on the assumption of a flat prior distribution. However, previous calculations in simplified landscape models showed that the prior distribution is staggered, suggesting a conflict with anthropic predictions. Here we analytically calculate the full distribution, including the prior and anthropic selection effects, in a toy landscape model with a realistic number of vacua, $N \sim 10^{500}$. We show that it is possible for the fractal prior distribution we find to behave as an effectively flat distribution in a wide class of landscapes, depending on the regime of parameter space. Whether or not this possibility is realized depends on presently unknown details of the landscape. ","hep-th"
"1907.03269","The homology of moduli stacks of complexes","  We compute the rational homology of the moduli stack $\mathcal{M}$ of objects in the derived category of certain smooth complex projective varieties $X$ including toric varieties, flag varieties, curves, surfaces, and some 3- and 4-folds. We identify Joyce's vertex algebra construction on $H_\ast(\mathcal{M},\mathbb{Q})$ with a generalized super-lattice vertex algebra associated to $K^0_{\rm top}(X^{\rm an}) \oplus K^1_{\rm top}(X^{\rm an})$. ","math"
"2002.00509","A Machine Consciousness architecture based on Deep Learning and Gaussian   Processes","  Recent developments in machine learning have pushed the tasks that machines can do outside the boundaries of what was thought to be possible years ago. Methodologies such as deep learning or generative models have achieved complex tasks such as generating art pictures or literature automatically. On the other hand, symbolic resources have also been developed further and behave well in problems such as the ones proposed by common sense reasoning. Machine Consciousness is a field that has been deeply studied and several theories based in the functionalism philosophical theory like the global workspace theory or information integration have been proposed that try to explain the ariseness of consciousness in machines. In this work, we propose an architecture that may arise consciousness in a machine based in the global workspace theory and in the assumption that consciousness appear in machines that has cognitive processes and exhibit conscious behaviour. This architecture is based in processes that use the recent developments in artificial intelligence models which output are these correlated activities. For every one of the modules of this architecture, we provide detailed explanations of the models involved and how they communicate with each other to create the cognitive architecture. ","cs"
"1902.02107","Unsupervised landmark analysis for jump detection in molecular dynamics   simulations","  Molecular dynamics is a versatile and powerful method to study diffusion in solid-state ionic conductors, requiring minimal prior knowledge of equilibrium or transition states of the system's free energy surface. However, the analysis of trajectories for relevant but rare events, such as a jump of the diffusing mobile ion, is still rather cumbersome, requiring prior knowledge of the diffusive process in order to get meaningful results. In this work, we present a novel approach to detect the relevant events in a diffusive system without assuming prior information regarding the underlying process. We start from a projection of the atomic coordinates into a landmark basis to identify the dominant features in a mobile ion's environment. Subsequent clustering in landmark space enables a discretization of any trajectory into a sequence of distinct states. As a final step, the use of the smooth overlap of atomic positions descriptor allows distinguishing between different environments in a straightforward way. We apply this algorithm to ten Li-ionic systems and conduct in-depth analyses of cubic Li$_{7}$La$_{3}$Zr$_{2}$O$_{12}$, tetragonal Li$_{10}$GeP$_{2}$S$_{12}$, and the $\beta$-eucryptite LiAlSiO$_{4}$. We compare our results to existing methods, underscoring strong points, weaknesses, and insights into the diffusive behavior of the ionic conduction in the materials investigated. ","cond-mat"
"1812.02130","On High Dimensional Covariate Adjustment for Estimating Causal Effects   in Randomized Trials with Survival Outcomes","  We study the estimation of the average causal effect (ACE) on the survival scale where right-censoring exists and high-dimensional covariate information is available. We propose new estimators using regularized survival regression and survival random forests (SRF) to make adjustment with high dimensional covariates to improve efficiency. We study the behavior of general adjusted estimator when the adjustments are `risk consistent' and `jackknife compatible'. The theoretical results provided guarantee that the estimators we proposed are more efficient than the unadjusted one asymptotically when using SRF for adjustment. The finite sample behavior of our methods are studied by simulation, and the results are in agreement with our theoretical results. We also illustrated our methods via analyzing the real data from transplant research to identify the relative effectiveness of identical sibling donors compared to unrelated donors with the adjustment of cytogenetic abnormalities. ","stat"
"1904.10845","How self-regulation, the storage effect and their interaction contribute   to coexistence in stochastic and seasonal environments","  Explaining coexistence in species-rich communities of primary producers remains a challenge for ecologists because of their likely competition for shared resources. Following Hutchinson's seminal suggestion, many theoreticians have tried to create diversity through a fluctuating environment, which impairs or slows down competitive exclusion. However, fluctuating-environment models often only produce a dozen of coexisting species at best. Here, we investigate how to create richer communities in fluctuating environments, using an empirically parameterized model. Building on the forced Lotka-Volterra model of Scranton and Vasseur (Theor Ecol 9(3):353-363, 2016), inspired by phytoplankton communities, we have investigated the effect of two coexistence mechanisms, namely the storage effect and higher intra- than interspecific competition strengths (i.e., strong self-regulation). We tuned the intra/inter competition ratio based on empirical analyses, in which self-regulation dominates interspecific interactions. Although a strong self-regulation maintained more species (50%) than the storage effect (25%), we show that none of the two coexistence mechanisms considered could ensure the coexistence of all species alone. Realistic seasonal environments only aggravated that picture, as they decreased persistence relative to a random environment. However, strong self-regulation and the storage effect combined superadditively so that all species could persist with both mechanisms at work. Our results suggest that combining different coexistence mechanisms into community models might be more fruitful than trying to find which mechanism best explains diversity. We additionally highlight that while biomass-trait distributions provide some clues regarding coexistence mechanisms, they cannot indicate unequivocally which mechanisms are at play. ","q-bio"
"2004.05925","Optimizing the allocation of trials to sub-regions in multi-environment   crop variety testing","  New crop varieties are extensively tested in multi-environment trials in order to obtain a solid empirical basis for recommendations to farmers. When the target population of environments is large and heterogeneous, a division into sub-regions is often advantageous. When designing such trials, the question arises how to allocate trials to the different subregions. We consider a solution to this problem assuming a linear mixed model. We propose an analytical approach for computation of optimal designs for best linear unbiased prediction of genotype effects and pairwise linear contrasts and illustrate the obtained results by a real data example from Indian nation-wide maize variety trials. It is shown that, except in simple cases such as a compound symmetry model, the optimal allocation depends on the variance-covariance structure for genotypic effects nested within sub-regions. ","stat"
"1908.09310","Time dependence of complexity for Lovelock black holes","  We study the general time dependence of complexity for holographic states dual to Lovelock black holes using the ""Complexity=Action"" (CA) proposal. We observe that at early times, the critical time at which the complexity begins to increase is a decreasing function of the higher order coupling constants, which implies that the complexity evolves faster than that of Schwarzschild black holes. At late times, the rate of change of complexity is essentially determined by the generalised Gibbons-Hawking-York boundary term evaluated at the future singularity. In particular, its ratio to black hole mass is a characteristic constant, independent of the higher order couplings. Thus, in the vanishing coupling limit, the result in general does not reduce to that of Schwarzschild black holes, in spite of that the metric reduces to the latter as well as the gravitational action. In fact, the two differ by a constant during the whole time evolution. Including the next-to-leading order term around late times, we find that as the Einstein case, the late time limit is always approached from above, thus violating any conjectured upper bound given by the late time result. For charged Lovelock black holes, we find that with sufficient charge, the complexity roughly behaves the same as the Einstein case. However, for smaller charges, the two have some significant differences. In particular, unlike the Einstein case, in the uncharged limit the complexity growth rate does not match with the neutral case, differing by a constant in the whole time evolution. ","hep-th"
"2007.02117","Transfer learning of regression models from a sequence of datasets by   penalized estimation","  Transfer learning refers to the promising idea of initializing model fits based on pre-training on other data. We particularly consider regression modeling settings where parameter estimates from previous data can be used as anchoring points, yet may not be available for all parameters, thus covariance information cannot be reused. A procedure that updates through targeted penalized estimation, which shrinks the estimator towards a nonzero value, is presented. The parameter estimate from the previous data serves as this nonzero value when an update is sought from novel data. This naturally extends to a sequence of data sets with the same response, but potentially only partial overlap in covariates. The iteratively updated regression parameter estimator is shown to be asymptotically unbiased and consistent. The penalty parameter is chosen through constrained cross-validated loglikelihood optimization. The constraint bounds the amount of shrinkage of the updated estimator toward the current one from below. The bound aims to preserve the (updated) estimator's goodness-of-fit on all-but-the-novel data. The proposed approach is compared to other regression modeling procedures. Finally, it is illustrated on an epidemiological study where the data arrive in batches with different covariate-availability and the model is re-fitted with the availability of a novel batch. ","stat"
"1908.09125","When a Dollar Makes a BWT","  The Burrows-Wheeler-Transform (BWT) is a reversible string transformation which plays a central role in text compression and is fundamental in many modern bioinformatics applications. The BWT is a permutation of the characters, which is in general better compressible and allows to answer several different query types more efficiently than the original string.   It is easy to see that not every string is a BWT image, and exact characterizations of BWT images are known. We investigate a related combinatorial question. In many applications, a sentinel character dollar is added to mark the end of the string, and thus the BWT of a string ending with dollar contains exactly one dollar-character. Given a string w, we ask in which positions, if any, the dollar-character can be inserted to turn w into the BWT image of a word ending with dollar. We show that this depends only on the standard permutation of w and present a O(n log n)-time algorithm for identifying all such positions, improving on the naive quadratic time algorithm. We also give a combinatorial characterization of such positions and develop bounds on their number and value. ","cs"
"1907.12391","Nonlinear spectroscopy of a three level atom strongly interacting with a   quantized cavity mode","  We present numerical simulation of the previously unexplored multiphoton spectra of a realistic three level atom one of whose transitions is strongly coupled to a cavity mode while the other is driven by a classical light employing only standard dipole and rotating wave approximations. We show that, if the atom-cavity coupling constant is much larger than atomic and cavity dissipation rates, a relatively weak signal can excite multiphoton transitions. We also show that under resonant atom-cavity conditions, the dark state gets dressed by the cavity photons which leads to a Raman spectra with richly complex structure involving dark-state mediated discrete multiphoton transitions as well as direct Raman transitions. ","quant-ph"
"1812.00598","A Static Distributed-parameter Circuit Model Explains Electrical   Stimulation on the Neuromuscular System","  Finite Element Modeling (FEM) has been widely used to model the electric field distribution, to study the interaction between stimulation electrodes and neural tissue. However, due to the insufficient computational capability to represent neural tissue down to an atom-level, the existing FEM fails to model the real electric field that is perpendicular to neuron membrane to initiate an action potential. Thus, to reveal the real electrode-tissue interactions, we developed a circuit to model transmembrane voltage waveforms. Here, we show a distributed-parameter circuit model to systematically study how electrode-tissue interaction is affected by electrode position, input current waveform, and biological structures in the neuromuscular system. Our model explains and predicts various phenomena in neuromuscular stimulation, guides new stimulation electrode and method design, and more importantly, facilitates a fundamental understanding of the physical process during electrode-tissue interaction. In our model, myelin is assumed to be inductive. The voltage waveform resonance caused by this inductive myelin accounts for the much lower stimulation threshold to activate motoneurons than muscle fibers, which is observed with in vivo measurements. These findings confirmed the feasibility of studying electrode-tissue interaction using a proper distributed-parameter circuit. Our current application on the neuromuscular system also raises the possibility that this distributed-parameter circuit model could potentially be applied to study other neural tissues, including the Peripheral Nervous System (PNS) and the Central Nervous System (CNS). ","q-bio"
"1811.02589","Spatially Resolved Metal Loss from M31","  As galaxies evolve, they must enrich and exchange gas with the surrounding medium, but the timing of these processes and how much gas is involved remain poorly understood. In this work, we leverage metals as tracers of past gas flows to constrain the history of metal ejection and redistribution in M31. This roughly $L*$ galaxy is a unique case where spatially resolved measurements of the gas-phase and stellar metallicity, dust extinction, and neutral ISM gas content are all available, enabling a census of the present metal mass. We combine spatially resolved star formation histories from the Panchromatic Hubble Andromeda Treasury survey with a metal production model to calculate the history of metal production in M31. We find that $1.8\times10^9 \, M_\odot$ of metals, or 62\% of the metal mass formed within $r < 19 \,\mathrm{kpc}$, is missing from the disk in our fiducial model, implying that the M31 disk has experienced significant gaseous outflows over its lifetime. Under a conservative range of model assumptions, we find that between 3\% and 88\% of metals have been lost ($1.9\times10^7 - 6.4\times10^9 \, M_\odot$), so metals are missing even when all model parameters are chosen to favor metal retention. We show that the missing metal mass could be harbored in M31's CGM if the majority of the metals reside in a hot gas phase. Finally, we find that some metal mass produced in the past 1.5 Gyr in the central $\sim5 \,\mathrm{kpc}$ has likely been redistributed to larger radii within the disk. ","astro-ph"
"2003.01552","Human EMF Exposure in Wearable Networks for Internet of Battlefield   Things","  Numerous antenna design approaches for wearable applications have been investigated in the literature. As on-body wearable communications become more ingrained in our daily activities, the necessity to investigate the impacts of these networks burgeons as a major requirement. In this study, we investigate the human electromagnetic field (EMF) exposure effect from on-body wearable devices at 2.4 GHz and 60 GHz, and compare the results to illustrate how the technology evolution to higher frequencies from wearable communications can impact our health. Our results suggest the average specific absorption rate (SAR) at 60 GHz can exceed the regulatory guidelines within a certain separation distance between a wearable device and the human skin surface. To the best of authors' knowledge, this is the first work that explicitly compares the human EMF exposure at different operating frequencies for on-body wearable communications, which provides a direct roadmap in design of wearable devices to be deployed in the Internet of Battlefield Things (IoBT). ","eess"
"1911.12340","Elastoviscoplastic rheology and ageing in a simplified soft glassy   constitutive model","  Yield stress fluids display a rich rheological phenomenology. Beyond the defining existence of a yield stress in the steady state flow curve, this includes in many materials rather flat viscoelastic spectra over many decades of frequency in small amplitude oscillatory shear; slow stress relaxation following the sudden imposition of a small shear strain; stress overshoot in shear startup; logarithmic or sublinear power law creep following the imposition of a shear stress below the yield stress; creep followed by yielding after the imposition of a shear stress above the yield stress; richly featured Lissajous-Bowditch curves in large amplitude oscillatory shear; a Bauschinger effect, in which a material's effective yield strain is lowered under straining in one direction, following a preceding strain in the opposite direction; hysteresis in up-down shear rate sweeps; and (in some materials) thixotropy and/or rheological ageing. A key challenge is to develop a constitutive model that contains enough underlying mesoscopic physics to have meaningful predictive power for the full gamut of rheological behaviour just described, with only a small number of model parameters, and yet is simple enough for use in computational fluid dynamics to predict flows in complicated geometries, or complicated flows that arise due to spontaneous symmetry breaking instabilities even in simple geometries. Here we introduce such a model, motivated by the widely used soft glassy rheology model, and show that it captures all the above rheological features. ","cond-mat"
"2007.10518","Predicting the number of viable autocatalytic sets in systems that   combine catalysis and inhibition","  The emergence of self-sustaining autocatalytic networks in chemical reaction systems has been studied as a possible mechanism for modelling how living systems first arose. It has been known for several decades that such networks will form within systems of polymers (under cleavage and ligation reactions) under a simple process of random catalysis, and this process has since been mathematically analysed. In this paper, we provide an exact expression for the expected number of self-sustaining autocatalytic networks that will form in a general chemical reaction system, and the expected number of these networks that will also be uninhibited (by some molecule produced by the system). Using these equations, we are able to describe the patterns of catalysis and inhibition that maximise or minimise the expected number of such networks. We apply our results to derive a general theorem concerning the trade-off between catalysis and inhibition, and to provide some insight into the extent to which the expected number of self-sustaining autocatalytic networks coincides with the probability that at least one such system is present. ","q-bio"
"1908.05470","Subtracting non-critical fluctuations in higher cumulants of conserved   charges","  Using the sample produced by the AMPT default model, we construct a corresponding mixed sample by the method of mixed events. The mixed sample provides an effective estimation for non-critical fluctuations which are caused by global and systematic effects. The dynamical cumulants of conserved charges are defined as the cumulants of the original sample minus the cumulants of the mixed sample. It is demonstrated that dynamical cumulants are subtracted statistical fluctuations, and centrality bin width or detection efficiency independent, in consistent with formulae corrected cumulants. Therefore, dynamical cumulants are helpful in obtaining critical fluctuations at the RHIC BES. ","hep-ph"
"2008.09245","Anomaly Detection on Seasonal Metrics via Robust Time Series   Decomposition","  The stability and persistence of web services are important to Internet companies to improve user experience and business performances. To keep eyes on numerous metrics and report abnormal situations, time series anomaly detection methods are developed and applied by various departments in companies and institutions. In this paper, we proposed a robust anomaly detection algorithm (MEDIFF) to monitor online business metrics in real time. Specifically, a decomposition method using robust statistical metric--median--of the time series was applied to decouple the trend and seasonal components. With the effects of daylight saving time (DST) shift and holidays, corresponding components were decomposed from the time series. The residual after decomposition was tested by a generalized statistics method to detect outliers in the time series. We compared the proposed MEDIFF algorithm with two open source algorithms (SH-ESD and DONUT) by using our labeled internal business metrics. The results demonstrated the effectiveness of the proposed MEDIFF algorithm. ","stat"
"2005.02070","Asteroseismic signatures of the helium-core flash","  All evolved stars with masses $M_\star\lesssim 2M_\odot$ undergo a helium(He)-core flash at the end of their first stage as a giant star. Although theoretically predicted more than 50 years ago, this core-flash phase has yet to be observationally probed. We show here that gravity modes (g modes) stochastically excited by He-flash driven convection are able to reach the stellar surface, and induce periodic photometric variabilities in hot-subdwarf stars with amplitudes of the order of a few mmag. As such they can now be detected by space-based photometry with the Transiting Exoplanet Survey Satellite (TESS) in relatively bright stars (e.g. magnitudes $I_C\lesssim 13$). The range of predicted periods spans from a few thousand seconds to tens of thousand seconds, depending on the details of the excitation region. In addition, we find that stochastically excited pulsations reproduce the pulsations observed in a couple of He-rich hot subdwarf stars. These stars, and in particular the future TESS target Feige 46, are the most promising candidates to probe the He-core flash for the first time. ","astro-ph"
"2006.10451","Learning High-Resolution Domain-Specific Representations with a GAN   Generator","  In recent years generative models of visual data have made a great progress, and now they are able to produce images of high quality and diversity. In this work we study representations learnt by a GAN generator. First, we show that these representations can be easily projected onto semantic segmentation map using a lightweight decoder. We find that such semantic projection can be learnt from just a few annotated images. Based on this finding, we propose LayerMatch scheme for approximating the representation of a GAN generator that can be used for unsupervised domain-specific pretraining. We consider the semi-supervised learning scenario when a small amount of labeled data is available along with a large unlabeled dataset from the same domain. We find that the use of LayerMatch-pretrained backbone leads to superior accuracy compared to standard supervised pretraining on ImageNet. Moreover, this simple approach also outperforms recent semi-supervised semantic segmentation methods that use both labeled and unlabeled data during training. Source code for reproducing our experiments will be available at the time of publication. ","cs"
"1911.05102","Baryon-Number-Violating Nucleon and Dinucleon Decays in a Model with   Large Extra Dimensions","  It is known that limits on baryon-violating nucleon decays do not, in general, imply corresponding suppression of $n - \bar n$ transitions. In the context of a model with fermions propagating in higher dimensions, we investigate a related question, namely the implications of limits on $\Delta L=-1$ proton and bound neutron decays mediated by four-fermion operators for rates of nucleon decays mediated by $k$-fermion operators with $k =6$ and $k=8$. These include a variety of nucleon and dinucleon decays to dilepton and trilepton final states with $\Delta L=-3, \ -2, \ 1$, and $2$. We carry out a low-energy effective field theory analysis of relevant operators for these decays and show that, in this extra-dimensional model, the rates for these decays are strongly suppressed and hence are in accord with experimental limits. ","hep-ph"
"1903.00541","Some New Bounds on the Entropy Numbers of Diagonal Operators","  Entropy numbers are an important tool for quantifying the compactness of operators. Besides establishing new upper bounds on the entropy numbers of diagonal operators $D_\sigma$ from $\ell_p$ to $\ell_q$, where $p\not=q$, we investigate the optimality of these bounds. In case of $p<q$ optimality is proven for fast decaying diagonal sequences, which include exponentially decreasing sequences. In case of $p>q$ we show optimality under weaker assumption than previously used in the literature. In addition, we illustrate the benefit of our results with examples not covered in the literature so far. ","math"
"1802.09053","Estimation of the Evolutionary Spectra with Application to Stationarity   Test","  In this work, we propose a new inference procedure for understanding non-stationary processes, under the framework of evolutionary spectra developed by Priestley. Among various frameworks of modeling non-stationary processes, the distinguishing feature of the evolutionary spectra is its focus on the physical meaning of frequency. The classical estimate of the evolutionary spectral density is based on a double-window technique consisting of a short-time Fourier transform and a smoothing. However, smoothing is known to suffer from the so-called bias leakage problem. By incorporating Thomson's multitaper method that was originally designed for stationary processes, we propose an improved estimate of the evolutionary spectral density, and analyze its bias/variance/resolution tradeoff. As an application of the new estimate, we further propose a non-parametric rank-based stationarity test, and provide various experimental studies. ","stat"
"2003.03126","Metastability in the Potts model: exact results in the large q limit","  We study the metastable equilibrium properties of the Potts model with heat-bath transition rates using a novel expansion. The method is especially powerful for large number of state spin variables and it is notably accurate in a rather wide range of temperatures around the phase transition. ","cond-mat"
"1812.09483","Witnesses of non-classicality for simulated hybrid quantum systems","  The task of testing whether quantum theory applies to all physical systems and all scales requires considering situations where a quantum probe interacts with another system that need not obey quantum theory in full. Important examples include the cases where a quantum mass probes the gravitational field, for which a unique quantum theory of gravity does not yet exist, or a quantum field, such as light, interacts with a macroscopic system, such as a biological molecule, which may or may not obey unitary quantum theory. In this context a class of experiments has recently been proposed, where the non-classicality of a physical system that need not obey quantum theory (the gravitational field) can be tested indirectly by detecting whether or not the system is capable of entangling two quantum probes. Here we illustrate some of the subtleties of the argument, to do with the role of locality of interactions and of non-classicality, and perform proof-of-principle experiments illustrating the logic of the proposals, using a Nuclear Magnetic Resonance quantum computational platform with four qubits. ","quant-ph"
"1902.05325","Supersymmetric Dyonic Strings in 6-Dimensions from 3-Dimensions","  It was shown in arXiv:1410.7168 that compactifying $D=6$, $\mathcal{N}=(1,0)$ ungauged supergravity coupled to a single tensor multiplet on S$^3$ one gets a particular $D=3$, $\mathcal{N}=4$ gauged supergravity which is a consistent reduction. We construct two supersymmetric black string solutions in this 3-dimensional model with one and two active scalars respectively. Uplifting the first, one gets a dyonic string solution in $D=6$ that has been known for a long time. Whereas, uplifting the second solution, one finds a very interesting configuration where magnetic strings are located uniformly on a circle in a plane within the 4-dimensional flat transverse space and electric strings are distributed homogeneously inside this circle. Both solutions have $\mathrm{AdS}_3 \times$ S$^3$ limits. ","hep-th"
"2006.06168","Satellite-Terrestrial Channel Characterization in High-Speed Railway   Environment at 22.6 GHz","  The integration of satellite and terrestrial communication systems plays a vital role in the fifth-generation mobile communication system (5G) for the ubiquitous coverage, reliable service and flexible networking. Moreover, the millimeter wave (mmWave) communication with large bandwidth is a key enabler for 5G intelligent rail transportation. In this paper, the satellite-terrestrial channel at 22.6 GHz is characterized for a typical high-speed railway (HSR) environment. The three-dimensional model of the railway scenario is reconstructed and imported into the Cloud Ray-Tracing (CloudRT) simulation platform. Based on extensive ray-tracing simulations, the channel for the terrestrial HSR system and the satellite-terrestrial system with two weather conditions are characterized, and the interference between them are evaluated. The results of this paper can help for the design and evaluation for the satellite-terrestrial communication system enabling future intelligent rail transportation. ","eess"
"1902.06014","Ultraviolet Fabry-Perot cavity with stable finesse under ultrahigh   vacuum conditions","  We have constructed an apparatus containing a linear ion trap and a high-finesse optical cavity in the ultraviolet spectral range. In our construction, we have avoided all organic materials inside the ultrahigh vacuum chamber. We show that, unlike previously reported, the optical cavity does not degrade in performance over a time scale of 9 months. ","quant-ph"
"1308.6531","Geometric Waldspurger periods II","  In this paper we extend the calculation of the geometric Waldspurger periods from our paper math/0510110 to the case of ramified coverings. We give some applications to the study of Whittaker coefficients of the theta-lifting of automorphic sheaves from PGL_2 to the metaplectic group Mp_2, they agree with our conjectures from arXiv:1211.1596. In the process of the proof, we get some new automorphic sheaves for GL_2 in the ramified setting. We also formulate stronger conjectures about Waldspurger periods and geometric theta-lifting for the dual pair (SL_2, Mp_2). ","math"
"1906.11473","Little Strings, Long Strings, and Fuzzballs","  At high energy densities, fivebranes are populated by a Hagedorn phase of so-called ""little strings"", whose statistical mechanics underlies black fivebrane thermodynamics. A particular limit of this phase yields BTZ black holes in $AdS_3$, leading us to the idea that in this context fuzzballs and highly excited little strings are one and the same. We explore these ideas through an analysis of D-brane probes of fivebrane supertube backgrounds. String theory dynamics on these backgrounds is described by an exactly solvable null-gauged WZW model. We develop the formalism of null gauging on worldsheets with boundaries, and find that D-branes wrapping topology at the bottom of the supertube throat are avatars of the ""long string"" structure that dominates the thermodynamics of the black hole regime, appearing here as excitations of supertubes lying near but slightly outside the black hole regime. ","hep-th"
"1812.10754","Attribute Evaluation on Attack Trees with Incomplete Information","  Attack trees are considered a useful tool for security modelling because they support qualitative as well as quantitative analysis. The quantitative approach is based on values associated to each node in the tree, expressing, for instance, the minimal cost or probability of an attack. Current quantitative methods for attack trees allow the analyst to, based on an initial assignment of values to the leaf nodes, derive the values of the higher nodes in the tree. In practice, however, it shows to be very difficult to obtain reliable values for all leaf nodes. The main reasons are that data is only available for some of the nodes, that data is available for intermediate nodes rather than for the leaf nodes, or even that the available data is inconsistent. We address these problems by developing a generalisation of the standard bottom-up calculation method in three ways. First, we allow initial attributions of non-leaf nodes. Second, we admit additional relations between attack steps beyond those provided by the underlying attack tree semantics. Third, we support the calculation of an approximative solution in case of inconsistencies. We illustrate our method, which is based on constraint programming, by a comprehensive case study. ","cs"
"1910.02956","Hard X-ray Excess from the Magnificent Seven Neutron Stars","  We report significant hard X-ray excesses in the energy range 2-8 keV for two nearby isolated neutron stars RX J1856.6-3754 and RX J0420.0-5022. These neutron stars have previously been observed in soft X-rays to have nearly thermal spectra at temperatures ~100 eV, which are thought to arise from the warm neutron star surfaces. We find non-trivial hard X-ray spectra well above the thermal surface predictions with archival data from the XMM-Newton and Chandra X-ray telescopes. We analyze possible systematic effects that could generate such spurious signals, such as nearby X-ray point sources and pileup of soft X-rays, but we find that the hard X-ray excesses are robust to these systematics. We also investigate possible sources of hard X-ray emission from the neutron stars and find no satisfactory explanation with known mechanisms, suggesting that a novel source of X-ray emission is at play. We do not find high-significance hard X-ray excesses from the other five Magnificent Seven isolated neutron stars. ","astro-ph"
"2008.07876","Quantum chicken-egg dilemmas: Delayed-choice causal order and the   reality of causal non-separability","  Recent frameworks describing quantum mechanics in the absence of a global causal order admit the existence of causally indefinite processes, where it is impossible to ascribe causal order for events A and B. These frameworks even allow for processes that violate the so-called causal inequalities, which are analogous to Bell's inequalities. However, the physicality of these exotic processes is, in the general case, still under debate, bringing into question their foundational relevance. While it is known that causally indefinite processes can be probabilistically realised by means of a quantum circuit, along with an additional conditioning event C, evidence for their ontological status has heretofore been limited. Here, we show that causally indefinite processes are indeed elements of reality by demonstrating that they can be realised with schemes where C serves only as parity-flag. We then show that there are processes where any pure conditioning measurement of C leads to a causally indefinite process for A and B, thus establishing causal indefiniteness as an observer-independent quantity. Finally, we demonstrate that quantum mechanics allows for phenomena where C can deterministically decide whether A comes before B or vice versa, without signalling to either. This is akin to Wheeler's famous delayed-choice experiment establishing definite causal order in quantum mechanics as an observer-dependent property. ","quant-ph"
"2004.08711","Precise Critical Exponents of the O(N)-Symmetric Quantum field Model   using Hypergeometric-Meijer Resummation","  In this work, we show that one can select different types of Hypergeometric approximants for the resummation of divergent series with different large-order growth factors. Being of $n!$ growth factor, the divergent series for the $\varepsilon$-expansion of the critical exponents of the $O(N)$-symmetric model is approximated by the Hypergeometric functions $_{k+1}F_{k-1}$. The divergent $_{k+1}F_{k-1}$ functions are then resummed using their equivalent Meijer-G function representation. The convergence of the resummation results for the exponents $\nu$,\ $\eta$ and $\omega$ has been shown to improve systematically in going from low order to the highest known six-loops order. Our six-loops resummation results are very competitive to the recent six-loops Borel with conformal mapping predictions and to recent Monte Carlo simulation results. To show that precise results extend for high $N$ values, we listed the five-loops results for $\nu$ which are very accurate as well. The recent seven-loops order ($g$-series) for the renormalization group functions $\beta,\gamma_{\phi^2}$ and $\gamma_{m^2}$ have been resummed too. Accurate predictions for the critical coupling and the exponents $\nu$, $\eta$ and $\omega$ have been extracted from $\beta$,$\gamma_{\phi^2}$ and $\gamma_{m^2}$ approximants. ","hep-th"
"1902.00280","A generic frequency dependence for the atmospheric tidal torque of   terrestrial planets","  Thermal atmospheric tides have a strong impact on the rotation of terrestrial planets. They can lock these planets into an asynchronous rotation state of equilibrium. We aim at characterizing the dependence of the tidal torque resulting from the semidiurnal thermal tide on the tidal frequency, the planet orbital radius, and the atmospheric surface pressure. The tidal torque is computed from full 3D simulations of the atmospheric climate and mean flows using a generic version of the LMDZ general circulation model (GCM) in the case of a nitrogen-dominated atmosphere. Numerical results are discussed with the help of an updated linear analytical framework. Power scaling laws governing the evolution of the torque with the planet orbital radius and surface pressure are derived. The tidal torque exhibits i) a thermal peak in the vicinity of synchronization, ii) a resonant peak associated with the excitation of the Lamb mode in the high frequency range, and iii) well defined frequency slopes outside these resonances. These features are well explained by our linear theory. Whatever the star-planet distance and surface pressure, the torque frequency spectrum -- when rescaled with the relevant power laws -- always presents the same behaviour. This allows us to provide a single and easily usable empirical formula describing the atmospheric tidal torque over the whole parameter space. With such a formula, the effect of the atmospheric tidal torque can be implemented in evolutionary models of the rotational dynamics of a planet in a computationally efficient, and yet relatively accurate way. ","astro-ph"
"2005.03272","Generalized log-sum inequalities","  In information theory, the so-called log-sum inequality is fundamental and a kind of generalization of the non-nagativity for the relative entropy. In this paper, we show the generalized log-sum inequality for two functions defined for scalars. We also give a new result for commutative matrices. In addition, we demonstrate further results for general non-commutative positive semi-definite matrices. ","math"
"1912.10345","Design of van der Waals Interfaces for Broad-Spectrum Optoelectronics","  Van der Waals (vdW) materials offer new ways to assemble artificial electronic media with properties controlled at the design stage, by combining atomically defined layers into interfaces and heterostructures. Their potential for optoelectronics stems from the possibility to tailor the spectral response over a broad range by exploiting interlayer transitions between different compounds with an appropriate band-edge alignment. For the interlayer transitions to be radiative, however, a serious challenge comes from details of the materials --such as lattice mismatch or even a small misalignment of the constituent layers-- that can drastically suppress the electron-photon coupling. The problem was evidenced in recent studies of heterostructures of monolayer transition metal dichalcogenides, whose band edges are located at the K-point of reciprocal space. Here we demonstrate experimentally that the solution to the interlayer coupling problem is to engineer type-II interfaces by assembling atomically thin crystals that have the bottom of the conduction band and the top of the valence band at the $\Gamma$-point, thus avoiding any momentum mismatch. We find that this type of vdW interfaces exhibits radiative optical transition irrespective of lattice constant, rotational/translational alignment of the two layers, or whether the constituent materials are direct or indirect gap semiconductors. The result, which is robust and of general validity, drastically broadens the scope of future optoelectronics device applications based on 2D materials. ","cond-mat"
"2002.00740","Relative Equilibria of Magnetic Micro-Swimmers","  We revisit the dynamics of a permanent-magnetic rigid body submitted to a spatially-uniform steadily-rotating magnetic field in Stokes flow. We propose an analytical parameterisation of the full set of equilibria depending on two key experimental parameters, and show how it brings further understanding that helps to optimise magnetisation and operating parameters. The system is often bistable when it reaches its optimal swimming velocity. A handling strategy is proposed that guarantees that the correct equilibrium is reached. ","math"
"2004.02266","Determining the three-dimensional atomic structure of an amorphous solid","  Amorphous solids such as glass are ubiquitous in our daily life and have found broad applications ranging from window glass and solar cells to telecommunications and transformer cores. However, due to the lack of long-range order, the three-dimensional (3D) atomic structure of amorphous solids have thus far defied any direct experimental determination. Here, using a multi-component metallic glass as a model, we advance atomic electron tomography to determine its 3D atomic positions and chemical species with a precision of 21 picometer. We quantify the short-range order (SRO) and medium-range order (MRO) of the 3D atomic arrangement. We find that although the 3D atomic packing of the SRO is geometrically disordered, some SROs connect with each other to form crystal-like networks and give rise to MROs, which exhibit translational but no orientational order. We identify four crystal-like MROs - face-centred cubic, hexagonal close-packed, body-centered cubic and simple cubic - coexisting in the sample, which significantly deviate from the ideal crystal structures. We quantify the size, shape, volume, and structural distortion of these MROs with unprecedented detail. Looking forward, we anticipate this experiment will open the door to determining the 3D atomic coordinates of various amorphous solids, whose impact on non-crystalline solids may be comparable to the first 3D crystal structure solved by x-ray crystallography over a century ago. ","cond-mat"
"1904.07898","The Discovery of QSOs Behind M31 and M33","  We report the discovery of 11 newly found quasars behind the stellar disks of the spiral galaxies M31 and M33 in the fields covered by the Local Group Galaxy Survey. Their redshifts range from 0.37 to 2.15. Most are X-ray, UV, and IR sources. We also report the discovery of 5 normal background galaxies. Most of these objects were observed owing to their anomalous colors, as part of a program (reported elsewhere) to confirm spectroscopically candidate red supergiant plus B star binaries; others were discovered as part of our identification of early-type massive stars based upon their optical colors. There are 15 previously known quasars in the same fields, for a grand total of 26, 15 behind M31 and 11 behind M33. Of these, only eight were discovered as part of surveys for quasars; the rest were found accidentally. The quasars are well distributed in the M31 and M33 fields, except for the inner regions, and have the potential for being good probes of the interstellar medium in these stellar disks, as well as serving as zero-point calibrators for Gaia parallaxes. ","astro-ph"
"1902.06247","A pharmacokinetic model of lead absorption and calcium competitive   dynamics","  Lead is a naturally-occurring element. It has been known to man for a long time, and it is one of the longest established poisons. The current consensus is that no level of lead exposure should be deemed ""safe."" New evidence regarding the blood levels at which morbidities occur has prompted the CDC to reduce the screening guideline of 10 $\mu$g/dl to 2 $\mu$g/dl. Measurable cognitive decline (reduced IQ, academic deficits) have been found to occur at levels below 10mg/dl.   Knowledge of lead pharmacology allows us to better understand its absorption and metabolization, mechanisms that produce its medical consequences. Based upon an original and very simplified compartmental model of Rabinowitz (1973) with only three major compartments (blood, bone and soft tissue), extensive biophysical models sprouted over the following two decades. However, none of these models have been specifically designed to use new knowledge of lead molecular dynamics to understand its deleterious effects on the brain. We build and analyze a compartmental model of lead pharmacokinetics, focused specifically on addressing neurotoxicity. We use traditional phase space methods, parameter sensitivity analysis and bifurcation theory to study the transitions in the system's behavior in response to various physiological parameters.   We conclude that modeling the complex interaction of lead and calcium along their dynamic trajectory may successfully explain counter-intuitive effects on systemic function and neural behavior which could not be addressed by existing linear models. Our results encourage further efforts towards using nonlinear phenomenology in conjunction with empirically driven system parameters, to obtain a biophysical model able to provide clinical assessments and predictions. ","q-bio"
"2003.06349","Dynamics of Strategy Distribution in a One-Dimensional Continuous Trait   Space with a Bi-linear and Quadratic Payoff Functions","  Evolution of distribution of strategies in game theory is an interesting question that has been studied only for specific cases. Here I develop a general method to extend analysis of the evolution of continuous strategy distributions given bi-linear and quadratic payoff functions for any initial distribution to answer the following question: given the initial distribution of strategies in a game, how will it evolve over time? I look at several specific examples, including normal distribution on the entire line, normal truncated distribution, as well as exponential, uniform and Gamma distributions. I show that the class of exponential distributions is invariant with respect to replicator dynamics in games with bi-linear payoff functions. I show also that the class of normal distributions is invariant with respect to replicator dynamics in games with quadratic payoff functions. The developed method can now be applied to a broad class of questions pertaining to evolution of strategies in games with different payoff functions and different initial distributions. ","q-bio"
"1911.05296","Portfolio rebalancing experiments using the Quantum Alternating Operator   Ansatz","  This paper investigates the experimental performance of a discrete portfolio optimization problem relevant to the financial services industry on the gate-model of quantum computing. We implement and evaluate a portfolio rebalancing use case on an idealized simulator of a gate-model quantum computer. The characteristics of this exemplar application include trading in discrete lots, non-linear trading costs, and the investment constraint. We design a novel problem encoding and hard constraint mixers for the Quantum Alternating Operator Ansatz, and compare to its predecessor the Quantum Approximate Optimization Algorithm. Experimental analysis demonstrates the potential tractability of this application on Noisy Intermediate-Scale Quantum (NISQ) hardware, identifying portfolios within 5% of the optimal adjusted returns and with the optimal risk for a small eight-stock portfolio. ","quant-ph"
"1911.06923","Copper ion dynamics and phase segregation in Cu-rich tetrahedrite: an   NMR study","  $^{63}$Cu NMR measurements are reported for the Cu-rich phase of \ch{Cu_{12+x}Sb4S13} ($x \lesssim 2$) and compared to \ch{Cu12Sb4S13}. We identify the NMR signatures of the phase segregation into Cu-poor ($x \approx 0$) and Cu-rich ($x \lesssim 2$) phases, with the metal-insulator transition observed in \ch{Cu12Sb4S13} suppressed in the Cu-rich phase. Based on NMR $T_1$ and $T_2$ measurements, the results demonstrate Cu-ion hopping below room temperature with an activation energy of $\sim$150 meV for the Cu-rich phase, consistent with superionic behavior. The NMR results also demonstrate the effects of Cu-ion mobility in the \ch{Cu12Sb4S13} phase, but with a larger activation barrier. We identify a small difference in NMR Knight shift for the metallic phase of \ch{Cu12Sb4S13}, compared to the Cu-rich phase, and when compared to DFT calculations the results indicate a mix of hyperfine contributions to the metallic shift. ","cond-mat"
"2007.04877","Hawking Radiation Correlations of Evaporating Black Holes in JT Gravity","  We consider the Hawking radiation emitted by an evaporating black hole in JT gravity and compute the entropy of arbitrary subsets of the radiation in the slow evaporation limit, and find a zoo of possible island saddles. The Hawking radiation is shown to have long range correlations. We compute the mutual information between early and late modes and bound from below their squashed entanglement. A small subset of late modes are shown to be correlated with modes in a suitably large subset of the radiation previously emitted as well as later modes. We show how there is a breakdown of the semi-classical approximation in the form of a violation of the Araki-Lieb triangle entropy inequality, if the interior of the black hole and the radiation are considered to be separate systems. Finally, we consider how much of the radiation must be collected, and how early, to recover information thrown into the black hole as it evaporates. ","hep-th"
"1712.06337","Probing light top partners with CP violation","  We investigate CP-violating effects induced by light top partners in composite Higgs theories. We find that sizable contributions to the dipole moments of the light SM quarks and leptons are generically generated at the two-loop level through Barr-Zee-type diagrams. The present constraints on the electron and neutron electric dipole moments translate into bounds on top partner masses of order few TeV and are competitive with the reach of LHC direct searches. Interestingly, we find that CP-violation effects are sensitive to the same operators that control top partner single production. Near-future improvements in the determination of the electron dipole moment will extend the reach on top partner masses beyond the 5 - 10 TeV range. ","hep-ph"
"2008.03489","Craig Interpolation with Clausal First-Order Tableaux","  We develop foundations for computing Craig-Lyndon interpolants of two given formulas with first-order theorem provers that construct clausal tableaux. Provers that can be understood in this way include efficient machine-oriented systems based on calculi of two families: goal-oriented such as model elimination and the connection method, and bottom-up such as the hypertableau calculus. Similar to known resolution-based interpolation methods our method proceeds in two stages. The first stage is an induction on the tableau structure, which is sufficient to compute propositional interpolants. We show that this can linearly simulate different prominent propositional interpolation methods that operate by an induction on a resolution deduction tree. In the second stage, interpolant lifting, quantified variables that replace certain terms (constants and compound terms) by variables are introduced. Correctness of this second stage was apparently shown so far on the basis of resolution and paramodulation with an error concerning equality, on the basis of resolution with paramodulation and superposition for a special case, and on the basis of a natural deduction calculus without taking equality into special account. Here the correctness of interpolant lifting is justified abstractly on the basis of Herbrand's theorem and based on a different characterization of the formulas to be lifted than in the literature (without taking equality into special account). In addition, we discuss various subtle aspects that are relevant for the investigation and practical realization of first-order interpolation based on clausal tableaux. ","cs"
"1903.05076","An initialization strategy for addressing barren plateaus in   parametrized quantum circuits","  Parametrized quantum circuits initialized with random initial parameter values are characterized by barren plateaus where the gradient becomes exponentially small in the number of qubits. In this technical note we theoretically motivate and empirically validate an initialization strategy which can resolve the barren plateau problem for practical applications. The technique involves randomly selecting some of the initial parameter values, then choosing the remaining values so that the circuit is a sequence of shallow blocks that each evaluates to the identity. This initialization limits the effective depth of the circuits used to calculate the first parameter update so that they cannot be stuck in a barren plateau at the start of training. In turn, this makes some of the most compact ans\""atze usable in practice, which was not possible before even for rather basic problems. We show empirically that variational quantum eigensolvers and quantum neural networks initialized using this strategy can be trained using a gradient based method. ","quant-ph"
"1903.00279","Molecular understanding of charge storage and charging dynamics in   supercapacitors with MOF electrodes and ionic liquid electrolytes","  We present a computational microscopy analysis (targeted molecular dynamics simulations) of the structure and performance of conductive metal organic framework (MOF) electrodes in supercapacitors with room temperature ionic liquids. The molecular modeling predicts the characteristic shapes of the potential dependence of electrode capacitance, relying on the structure of MOF electrodes and particularly how ions transport and reside in MOFs under polarization. Transmission line model was adopted to characterize the charging dynamics process and build up a bridge to evaluate the capacitive performance of practical supercapacitor devices at macroscale from the simulation-obtained data at nanoscale. Such nanoscale-to-macroscale analysis demonstrates the potential of MOF supercapacitors for achieving unprecedentedly high volumetric energy and power densities. The investigation gives molecular insights into the preferred structures of MOF for achieving these results, which could provide a blueprint for future experimental characterization of these new systems. ","cond-mat"
"2001.07273","Galois groups arising from families with big orthogonal monodromy","  We study the Galois groups of polynomials arising from a compatible family of representations with big orthogonal monodromy. We show that the Galois groups are usually as large as possible given the constraints imposed on them by a functional equation and discriminant considerations. As an application, we consider the Frobenius polynomials arising from the middle \'etale cohomology of hypersurfaces in $\mathbb{P}_{\mathbb{F}_q}^{2n+1}$ of degree at least $3$. We also consider the $L$-functions of quadratic twists of fixed degree of an elliptic curve over a function field $\mathbb{F}_q(t)$. To determine the typical Galois group in the elliptic curve setting requires using some known cases of the Birch and Swinnerton-Dyer conjecture. This extends and generalizes work of Chavdarov, Katz and Jouve. ","math"
"1902.09181","A New Exact Worst-Case Linear Convergence Rate of the Proximal Gradient   Method","  In this note, we establish a new exact worst-case linear convergence rate of the proximal gradient method in terms of the proximal gradient norm, which complements the recent results in [1] and implies a refined descent lemma.descent lemma. Based on the new lemma, we improve the linear convergence rate of the objective function accuracy under the Polyak-Lojasiewicz inequality. ","math"
"1907.09179","A model for integrating the effects of multiple simultaneous stressors   on marine systems","  While much has been learnt about the impacts of specific stressors on individual marine organisms, considerable debate exists over the nature and impact of multiple simultaneous stressors on both individual species and marine ecosystems. We describe a modelling tool (OSIRIS) for integrating the effects of multiple simultaneous stressors. The model is relatively computationally light, and demonstrated using a coarse-grained, non-spatial and simplified representation of a temperate marine ecosystem. This version is capable of reproducing a wide range of dynamic responses.Results indicate the degree to which interactions are synergistic is crucial in determining sensitivity to forcing, particularly for the higher trophic levels, which can respond non-linearly to stronger forcing. Stronger synergistic interactions sensitize the system to variability in forcing, and combinations of stronger forcing, noise and synergies between effects are particularly potent. This work also underlines the significant potential risk incurred in treating stressors on ecosystems as individual and additive. ","q-bio"
"1904.10641","Detecting Machine-Translated Paragraphs by Matching Similar Words","  Machine-translated text plays an important role in modern life by smoothing communication from various communities using different languages. However, unnatural translation may lead to misunderstanding, a detector is thus needed to avoid the unfortunate mistakes. While a previous method measured the naturalness of continuous words using a N-gram language model, another method matched noncontinuous words across sentences but this method ignores such words in an individual sentence. We have developed a method matching similar words throughout the paragraph and estimating the paragraph-level coherence, that can identify machine-translated text. Experiment evaluates on 2000 English human-generated and 2000 English machine-translated paragraphs from German showing that the coherence-based method achieves high performance (accuracy = 87.0%; equal error rate = 13.0%). It is efficiently better than previous methods (best accuracy = 72.4%; equal error rate = 29.7%). Similar experiments on Dutch and Japanese obtain 89.2% and 97.9% accuracy, respectively. The results demonstrate the persistence of the proposed method in various languages with different resource levels. ","cs"
"1902.09611","Non-hexagonal lattices from a two species interacting system","  A two species interacting system motivated by the density functional theory for triblock copolymers contains long range interaction that affects the two species differently. In a two species periodic assembly of discs, the two species appear alternately on a lattice. A minimal two species periodic assembly is one with the least energy per lattice cell area. There is a parameter $b$ in $[0,1]$ and the type of the lattice associated with a minimal assembly varies depending on $b$. There are several thresholds defined by a number $B=0.1867...$ If $b \in [0, B)$, a minimal assembly is associated with a rectangular lattice whose ratio of the longer side and the shorter side is in $[\sqrt{3}, 1)$; if $b \in [B, 1-B]$, a minimal assembly is associated with a square lattice; if $b \in (1-B, 1]$, a minimal assembly is associated with a rhombic lattice with an acute angle in $[\frac{\pi}{3}, \frac{\pi}{2})$. Only when $b=1$, this rhombic lattice is a hexagonal lattice. None of the other values of $b$ yields a hexagonal lattice, a sharp contrast to the situation for one species interacting systems, where hexagonal lattices are ubiquitously observed. ","math"
"1902.08863","On a discrete scheme for time fractional fully nonlinear evolution   equations","  We introduce a discrete scheme for second order fully nonlinear parabolic PDEs with Caputo's time fractional derivatives. We prove the convergence of the scheme in the framework of the theory of viscosity solutions. The discrete scheme can be viewed as a resolvent-type approximation. ","math"
"2004.11742","ST$^2$: Small-data Text Style Transfer via Multi-task Meta-Learning","  Text style transfer aims to paraphrase a sentence in one style into another style while preserving content. Due to lack of parallel training data, state-of-art methods are unsupervised and rely on large datasets that share content. Furthermore, existing methods have been applied on very limited categories of styles such as positive/negative and formal/informal. In this work, we develop a meta-learning framework to transfer between any kind of text styles, including personal writing styles that are more fine-grained, share less content and have much smaller training data. While state-of-art models fail in the few-shot style transfer task, our framework effectively utilizes information from other styles to improve both language fluency and style transfer accuracy. ","cs"
"2006.00833","On the correctness of orbital solutions obtained from a small set of   points. Orbit of HIP 53731","  HIP 53731 is a binary consisting of stars of the spectral types K0 and K9. Orbit of this object was constructed previously by Cvetkovi'c et al. (2016) and improved by Tokovinin (2019). It should be noted that there is an 180 degree ambiguity in the position angles of some published measurements. Speckle interferometric observations were obtained in 2007-2020 (21 measurements) at the 6-m telescope of the SAO RAS (BTA) by the authors of this article. The analysis of new data together with previously published ones made it possible to construct the accurate orbit of HIP 53731 and to halve the already known values of the orbital period of the system. As a result of the study, the mass sum, the masses of each component and their spectral types were determined by two independent methods. According to the qualitative classification of orbits, the orbital solution has grade 2 - ""good"" (observations cover more than half of the orbital period and correspond to different phases). ","astro-ph"
"1910.12064","Multiquark-Adequate QCD Sum Rules: the Case of Flavour-Exotic   Tetraquarks","  Frequently, theoretical discussions of multiquark hadron states prove to be contaminated or even dominated by contributions of conventional hadrons. For the approach to QCD bound states in terms of QCD sum rules, we show how to get rid of all unwanted ordinary-hadron ballast by boiling down the traditional QCD sum-rule formalism to the nonconventional aspects in the focus of interest. ","hep-ph"
"1901.04035","Dimension Theory of some non-Markovian repellers Part I: A gentle   introduction","  Michael Barnsley introduced a family of fractals sets which are repellers of piecewise affine systems. The study of these fractals was motivated by certain problems that arose in fractal image compression but the results we obtained can be applied for the computation of the Hausdorff dimension of the graph of some functions, like generalized Takagi functions and fractal interpolation functions.   In this paper we introduce this class of fractals and present the tools in the one-dimensional dynamics and nonconformal fractal theory that are needed to investigate them. This is the first part in a series of two papers. In the continuation there will be more proofs and we apply the tools introduced here to study some fractal function graphs. ","math"
"2005.05834","Even-odd conductance effect in graphene nanoribbons induced by edge   functionalization with aromatic molecules: Basis for novel chemosensors","  We theoretically investigate the electron transport in armchair and zigzag graphene nanoribbons (GNRs) chemically functionalized with p-polyphenyl and polyacene groups of increasing length. Our nearest-neighbor tight-binding calculations indicate that, depending on whether the number of aromatic rings in the functional group is even or odd, the resulting conductance at energies matching the energy levels of the corresponding isolated molecule are either unaffected or reduced by exactly one quantum as compared to the pristine GNR, respectively. Such an even-odd effect is shown to originate from a subtle interplay between the electronic states of the guest molecule that are spatially localized on the binding sites and those of the host nanoribbon. We next generalize our findings by employing more accurate tight-binding Hamiltonians along with density-functional theory calculations, and critically discuss the robustness of the observed physical effects against the level of theory adopted. Our work offers a comprehensive understanding of the influence of aromatic molecules bound to the edge of graphene nanoribbons on their electronic transport properties, an issue which is instrumental to the prospective realization of graphene-based chemosensors. ","cond-mat"
"1812.06696","Rapid Acceleration of the Permutation Test via Slow Random Walks in the   Permutation Group","  The permutation test is an often used test procedure in brain imaging. Unfortunately, generating every possible permutation for large-scale brain image datasets such as HCP and ADNI with hundreds images is not practical. Many previous attempts at speeding up the permutation test rely on various approximation strategies such as estimating the tail distribution with known parametric distributions. In this study, we show how to rapidly accelerate the permutation test without any type of approximate strategies by exploiting the underlying algebraic structure of the permutation group. The method is applied to large number of MRIs in two applications: (1) localizing the male and female differences and (2) localizing the regions of high genetic heritability in the sulcal and gyral pattern of the human cortical brain. ","stat"
"2007.10809","Software Transactional Memory with Interactions","  Software Transactional memory (STM) is an emerging abstraction for concurrent programming alternative to lock-based synchronizations. Most STM models admit only isolated transactions, which are not adequate in multithreaded programming where transactions need to interact via shared data before committing. To overcome this limitation, in this paper we present Open Transactional Memory (OTM), a programming abstraction supporting safe, data-driven interactions between composable memory transactions. This is achieved by relaxing isolation between transactions, still ensuring atomicity. This model allows for loosely-coupled interactions since transaction merging is driven only by accesses to shared data, with no need to specify participants beforehand. ","cs"
"1901.10099","Asymptotic security of discrete-modulation protocols for   continuous-variable quantum key distribution","  We consider discrete-modulation protocols for continuous-variable quantum key distribution (CV-QKD) that employ a modulation constellation consisting of a finite number of coherent states and that use a homodyne-detection receiver. We establish a security proof for arbitrary collective attacks in the asymptotic regime, and we provide a formula for an achievable secret-key rate. Previous works established security proofs for Gaussian-modulation CV-QKD protocols or for discrete-modulation protocols with two or three coherent states. The main constituents of our approach include approximating a complex, isotropic Gaussian probability distribution by a finite-size Gauss-Hermite constellation, applying entropic continuity bounds, and leveraging previous security proofs for Gaussian-modulation protocols. As an application of our method, we calculate secret-key rates achievable over a pure-loss bosonic channel. Our results indicate that in the high-loss regime the achievable key rates scale optimally, i.e., proportional to the channel's transmissivity, and approach that achieved by a Gaussian-modulation protocol as the constellation size is increased. ","quant-ph"
"2006.00335","Probabilistic Forecasting of Patient Waiting Times in an Emergency   Department","  We study the estimation of the probability distribution of individual patient waiting times in an emergency department (ED). Our feature-rich modelling allows for dynamic updating and refinement of waiting time estimates as patient- and ED-specific information (e.g., patient condition, ED congestion levels) is revealed during the waiting process. Aspects relating to communicating forecast uncertainty to patients, and implementing this methodology in practice, are also discussed. ","stat"
"1811.00439","Exact parametric causal mediation analysis for a binary outcome with a   binary mediator","  A parametric expression for causal natural direct and indirect effects is derived for the setting of a binary outcome with a binary mediator. The proposed effect decomposition does not require the outcome to be rare and generalizes the existing ones, allowing for interactions between both the exposure and the mediator and confounding covariates. Further, it outlines the relationship between the causal effects and the correspondent pathway-specific logistic regression parameters, in parallel with results derived under the rare outcome assumption. Formulae for standard errors, obtained via the delta method, are also given. A simulation study is implemented which compares these estimators to a number of competing ones. An empirical application to data coming from a microfinance experiment performed in Bosnia and Herzegovina is illustrated as an example. ","stat"
"2004.06361","Modelling and docking of Indian SARS-CoV-2 spike protein 1 with ACE2:   implications for co-morbidity and therapeutic intervention","  Presently, India bears amongst the highest burden of non-communicable diseases such as diabetes mellitus (DM), hypertension (HT), and cardio vascular disease (CVD) and thus represents a vulnerable target to the SARS-CoV-2/COVID-19 pandemic. Involvement of the angiotensin converting enzyme 2 (ACE2) in susceptibility to infection and pathogenesis by SARS-CoV-2 is currently an actively pursued research area. An increased susceptibility to infection in individuals with DM, HT and CVD together with higher levels of circulating ACE2 in these settings presents a scenario where interaction with soluble ACE2 may result in disseminated virus-receptor complexes that could enhance virus acquisition and pathogenesis. Thus, understanding the SARS-CoV-2 receptor binding domain-ACE2 interaction, both membrane bound and in the cell free context may contribute to elucidating the role of co-morbidities in increased susceptibility to infection and pathogenesis. Both Azithromycin and Hydroxychloroquine (HCQ) have shown efficacy in mitigating viral carriage in infected individuals. Furthermore, each of these compounds generate active metabolites which in turn may also modulate virus-receptor interaction and thus influence clinical outcomes. In this study, we model the structural interaction of S1 with both full-length and soluble ACE2. Additionally, therapeutic drugs and their active metabolites were docked with soluble ACE2 protein. Our results show that S1 from either of the reported Indian sequences can bind both full-length and soluble ACE2, albeit with varying affinity that can be attributed to a reported substitution in the RBD. Furthermore, both Azythromycin and HCQ together with their active metabolites can allosterically affect, to a range of extents, binding of S1 to ACE2. ","q-bio"
"1907.09444","Common origin of inverse seesaw and baryon asymmetry","  In the inverse seesaw scenario, several fermion singlets have a small Majorana mass term. We show such Majorana masses can be suppressed by some heavy fermion and/or Higgs singlets after a global symmetry is spontaneously broken. These interactions can also accommodate a leptogenesis mechanism to explain the cosmic baryon asymmetry. ","hep-ph"
"2005.08683","Conceptual variables, quantum theory, and statistical inference theory","  A different approach towards quantum theory is proposed in this paper. The basis is taken to be conceptual variables, physical variables that may be accessible or inaccessible, i.e., it may be possible or impossible to assign numerical values to them. In an epistemic process, the accessible variables are just ideal observations as observed by an actor or by some communicating actors. Group actions are defined on these variables, and using group representation theory this is the basis for developing the Hilbert space formalism here. Operators corresponding to accessible conceptual variables are derived as a result of the formalism, and in the discrete case it is argued that the possible physical values are the eigenvalues of these operators. The Born formula is derived under specific assumptions. The whole discussion here is a supplement to the author's book [1]. The interpretation of quantum states (or eigenvector spaces) implied by this approach is as focused questions to nature together with sharp answers to those questions. Resolutions if the identity are then connected to the questions themselves; these may be complementary in the sense defined by Bohr. This interpretation may be called a general epistemic interpretation of quantum theory. It is similar to Zwirn's recent Convival Solipsism, and also to QBism, and more generally, can be seen as a concrete implementation of Rovelli's Relational Quantum Mechanics. The focus in the present paper is, however, as much on foundation as on interpretation. But the simple consequences of an epistemic interpretation for some so called quantum paradoxes are discussed. Connections to statistical inference theory are discussed in a preliminary way, both through an example and through a brief discussion of quantum measurement theory. ","quant-ph"
"2006.10009","Regularity of transition densities and ergodicity for affine   jump-diffusion processes","  In this paper we study the transition density and exponential ergodicity in total variation for an affine process on the canonical state space $\mathbb{R}_{\geq0}^{m}\times\mathbb{R}^{n}$. Under a H\""ormander-type condition for diffusion components as well as a boundary non-attainment assumption, we derive the existence and regularity of the transition density for the affine process and then prove the strong Feller property. Moreover, we also show that under these and the additional subcritical conditions the corresponding affine process on the canonical state space is exponentially ergodic in the total variation distance. To prove existence and regularity of the transition density we derive some precise estimates for the real part of the characteristic function of the process. Our ergodicity result is a consequence of a suitable application of a Harris-type theorem based on a local Dobrushin condition combined with the regularity of the transition densities. ","math"
"1903.05256","Cubic Planar Graphs that cannot be Drawn on few Lines","  For every integer $\ell$, we construct a cubic 3-vertex-connected planar bipartite graph $G$ with $O(\ell^3)$ vertices such that there is no planar straight-line drawing of $G$ whose vertices all lie on $\ell$ lines. This strengthens previous results on graphs that cannot be drawn on few lines, which constructed significantly larger maximal planar graphs. We also find apex-trees and cubic bipartite series-parallel graphs that cannot be drawn on a bounded number of lines. ","cs"
"1910.03837","Strong stationary times for features of random walks","  In [4], we examined the use of coupling to obtain bounds on the mixing time of statistics on Markov chains. In the present paper, we consider the same general problem, but using strong stationary times rather than coupling. We discuss various types of behaviour that may occur when this is attempted, and analyse a variety of examples. ","math"
"1906.02529","Uncertainty Principles For the continuous Gabor quaternion linear   canonical transform","  Gabor transform is one of the performed tools for time-frequency signal analysis. The principal aim of this paper is to generalize the Gabor Fourier transform to the quaternion linear canonical transform. Actually, this transform gives us more flexibility to studied nonstationary and local signals associated with the quaternion linear canonical transform. Some useful properties are derived, such as Plancherel and inversion formulas. And we prove some uncertainty principles: those including Heisenberg's, Lieb's and logarithmic inequalities. We finish by analogs of concentration and Benedick's type theorems. ","math"
"1803.01936","Variations of Hodge Structures of Rank Three k-Higgs Bundles","  There is an isomorphism between the moduli spaces of $\sigma$-stable holomorphic triples and some of the critical submanifolds of the moduli space of $k$-Higgs bundles of rank three, whose elements $(E,\varphi^k)$ correspond to variations of Hodge structure, VHS. There are special embeddings on the moduli spaces of $k$-Higgs bundles of rank three. The main objective here is to study the cohomology of the critical submanifolds of such moduli spaces, extending those embeddings to moduli spaces of holomorphic triples. ","math"
"2003.05811","Exploring the ground state spectrum of gamma-deformed N=4 SYM","  We study the gamma-deformation of the planar N=4 super Yang-Mills theory which breaks all supersymmetries but is expected to preserve integrability of the model. We focus on the operator Tr$(\phi_1\phi_1)$ built from two scalars, whose integrability description has been questioned before due to contributions from double-trace counterterms. We show that despite these subtle effects, the integrability-based Quantum Spectral Curve (QSC) framework works perfectly for this state and in particular reproduces the known 1-loop prediction. This resolves an earlier controversy concerning this operator and provides further evidence that the gamma-deformed model is an integrable CFT at least in the planar limit. We use the QSC to compute the first 5 weak coupling orders of the anomalous dimension analytically, matching known results in the fishnet limit, and also compute it numerically all the way from weak to strong coupling. We also utilize this data to extract a new coefficient of the beta function of the double-trace operator couplings. ","hep-th"
"1902.05506","One-dimensional edge contacts to a monolayer semiconductor","  Integration of electrical contacts into van der Waals (vdW) heterostructures is critical for realizing electronic and optoelectronic functionalities. However, to date no scalable methodology for gaining electrical access to buried monolayer two-dimensional (2D) semiconductors exists. Here we report viable edge contact formation to hexagonal boron nitride (hBN) encapsulated monolayer MoS$_2$. By combining reactive ion etching, in situ Ar$^+$ sputtering and annealing, we achieve a relatively low edge contact resistance, high mobility (up to ~30 cm$^2$/Vs) and high on-current density (>50 uA/um at V$_{\rm DS}$ = 3V), comparable to top contacts. Furthermore, the atomically smooth hBN environment also preserves the intrinsic MoS$_2$ channel quality during fabrication, leading to a steep subthreshold swing of 116 mV/dec with a negligible hysteresis. Hence, edge contacts are highly promising for large-scale practical implementation of encapsulated heterostructure devices, especially those involving air sensitive materials, and can be arbitrarily narrow, which opens the door to further shrinkage of 2D device footprint. ","cond-mat"
"1909.00406","Kodaikanal calcium images: Detection of plages, Fixing the heliographic   coordinates and Estimation of Area","  Kodaikanal Observatory is a veritable treasure trove of data, with the data repository covering almost 100 years of observations. For the years 1909-2007, we use calibrated Ca II K spectroheliograms from the Kodaikanal Observatory to detect the plages, fix their heliographic coordinates and also estimate the plage areas. We adopt the following procedure. After ensuring that, for all the years, Kodai calcium images have very negligible ellipcity, a circle is fitted and two central coordinates and radius of calcium images are determined uniquely. For each pixel of the calcium image, we then fix heliographic coordinates and extract plages along with their weighted average coordinates. The heliographic coordinates of these extracted plages are then compared with the heliographic coordinates of photospheric sunspots from the Greenwich sunspot database and chromospheric magnetic plages detected from the SOHO/MDI magnetograms. We find that the heliographic coordinates of calcium plages match very well with the heliographic coordinates of sunspots and magnetic plages authenticating our method of detection of plages and computation of positional coordinates. A code is developed in Python and all the nearly century scale plages data, with accurately estimated heliographic coordinates and areas, is available to the public. ","astro-ph"
"1911.03922","Un systeme de lemmatisation pour les applications de TALN","  This paper presents a method of stemming for the Arabian texts based on the linguistic techniques of the natural language processing. This method leans on the notion of scheme (one of the strong points of the morphology of the Arabian language). The advantage of this approach is that it doesn't use a dictionary of inflexions but a smart dynamic recognition of the different words of the language. ","cs"
"1910.00815","Modeling of Measurement-based Quantum Network Coding on IBM Q Experience   Devices","  Quantum network coding has been proposed to improve resource utilization to support distributed computation but has not yet been put in to practice. We investigate a particular implementation of quantum network coding using measurement-based quantum computation on IBM Q processors. We compare the performance of quantum network coding with entanglement swapping and entanglement distribution via linear cluster states. These protocols outperform quantum network coding in terms of the final Bell pair fidelities but are unsuitable for optimal resource utilization in complex networks with contention present. We demonstrate the suitability of noisy intermediate-scale quantum (NISQ) devices such as IBM Q for the study of quantum networks. We also identify the factors that limit the performance of quantum network coding on these processors and provide estimates or error rates required to boost the final Bell pair fidelities to a point where they can be used for generation of genuinely random cryptographic keys among other useful tasks. Surprisingly, the required error rates are only around a factor of 2 smaller than the current status and we expect they will be achieved in the near future. ","quant-ph"
"1909.10676","Review on Generalized Dynamics of Soft-Matter Quasicrystals and Its   Applications","  This article provides a detailed review on the generalized dynamics of soft-matter quasicrystals developed recent years. Comparing to solid quasicrystals consisted mainly with metallic alloys, soft-matter quasicrystals have been observed in liquid crystals, polymers, colloids, nanoparticles, and surfactants, which indicate quite different formation mechanism. Based on Landau-Anderson theory and group representation theory, we have studied the symmetry, symmetry breaking and elementary excitations for the observed and possible soft-matter quasicrystals. We further proposed one more elementary excitation: fluid phonon additional to the phonon and phason for solid quasicrystals, to quantitatively describe the dynamics of soft-matter quasicrystals. The general governing equations and the solutions of the dynamics evolution on the distribution, deformation and motion of the new phase are studied, which reveal quite distinguishing dynamic behavior with those of conventional fluids and solid quasicrystals. Some applications are introduced, which show this is an important field of new materials and materials science. ","cond-mat"
"1910.09331","The Nature of the Neutrino (Dirac/Majorana) and Double Beta Decay with   or without Neutrinos","  The history of research associated with the fundamental problem of the nature of massive neutrinos, which can be Dirac particles or Majorana fermions, and the related processes of neutrinoless double beta decay, $(A,Z)\rightarrow (A,Z+2) + e^- + e^-$, and two neutrino double beta decay, $(A,Z)\rightarrow (A,Z+2) + e^- + e^- + \bar{\nu_e} + \bar{\nu_e}$, is reviewed. ","hep-ph"
"1807.11917","Direct $CP$ violation from isospin symmetry breaking effects in PQCD","  We investigate the direct $CP$ violation for the decay process of $\bar{B}_{s}\rightarrow P(V)\pi^{0}$ (P,V refer to the pseudoscalar meson and vector meson, respectively) via isospin symmetry breaking effects from the $\pi^{0}-\eta-\eta'$ mixing mechanism in PQCD factorization approach. Isospin symmetry breaking arises from the electroweak interaction and the u-d quark mass difference by the strong interaction which are known to be tiny. However, we find that isospin symmetry breaking at the leading order shifts the $CP$ violation due to the new strong phases. ","hep-ph"
"2001.03658","Forecasting multiple functional time series in a group structure: an   application to mortality","  When modeling sub-national mortality rates, we should consider three features: (1) how to incorporate any possible correlation among sub-populations to potentially improve forecast accuracy through multi-population joint modeling; (2) how to reconcile sub-national mortality forecasts so that they aggregate adequately across various levels of a group structure; (3) among the forecast reconciliation methods, how to combine their forecasts to achieve improved forecast accuracy. To address these issues, we introduce an extension of grouped univariate functional time series method. We first consider a multivariate functional time series method to jointly forecast multiple related series. We then evaluate the impact and benefit of using forecast combinations among the forecast reconciliation methods. Using the Japanese regional age-specific mortality rates, we investigate one-step-ahead to 15-step-ahead point and interval forecast accuracies of our proposed extension and make recommendations. ","stat"
"1906.11741","Attentional Modulation of Visual Spatial Integration: Psychophysical   Evidence Supported by Population Coding Modeling","  Two prominent strategies that the human visual system uses to reduce incoming information are spatial integration and selective attention. Although spatial integration summarizes and combines information over the visual field, selective attention can single it out for scrutiny. The way in which these well-known mechanisms, with rather opposing effects, interact remains largely unknown. To address this, we had observers perform a gaze-contingent search task that nudged them to deploy either spatial or feature-based attention to maximize performance. We found that, depending on the type of attention employed, visual spatial integration strength changed either in a strong and localized or a more modest and global manner compared with a baseline condition. Population code modeling revealed that a single mechanism can account for both observations: Attention acts beyond the neuronal encoding stage to tune the spatial integration weights of neural populations. Our study shows how attention and integration interact to optimize the information flow through the brain. ","q-bio"
"1707.04928","The Multivariate Hawkes Process in High Dimensions: Beyond Mutual   Excitation","  The Hawkes process is a class of point processes whose future depends on their own history. Previous theoretical work on the Hawkes process is limited to a special case in which a past event can only increase the occurrence of future events, and the link function is linear. However, in neuronal networks and other real-world applications, inhibitory relationships may be present, and the link function may be non-linear. In this paper, we develop a new approach for investigating the properties of the Hawkes process without the restriction to mutual excitation or linear link functions. To this end, we employ a thinning process representation and a coupling construction to bound the dependence coefficient of the Hawkes process. Using recent developments on weakly dependent sequences, we establish a concentration inequality for second-order statistics of the Hawkes process. We apply this concentration inequality to cross-covariance analysis in the high-dimensional regime, and we verify the theoretical claims with simulation studies. ","stat"
"2005.07773","Deep Generative Modeling of Periodic Variable Stars Using Physical   Parameters","  The ability to generate physically plausible ensembles of variable sources is critical to the optimization of time-domain survey cadences and the training of classification models on datasets with few to no labels. Traditional data augmentation techniques expand training sets by reenvisioning observed exemplars, seeking to simulate observations of specific training sources under different (exogenous) conditions. Unlike fully theory-driven models, these approaches do not typically allow principled interpolation nor extrapolation. Moreover, the principal drawback of theory-driven models lies in the prohibitive computational cost of simulating source observables from {\it ab initio} parameters. In this work, we propose a computationally tractable machine learning approach to generate realistic light curves of periodic variables capable of integrating physical parameters and variability classes as inputs. Our deep generative model, inspired by the Transparent Latent Space Generative Adversarial Networks (TL-GANs), uses a Variational Autoencoder (VAE) architecture with Temporal Convolutional Network (TCN) layers, trained using the \hbox{OGLE-III} optical light curves and physical characteristics (e.g., effective temperature and absolute magnitude) from Gaia DR2. A test using the temperature-shape relationship of RR\,Lyrae demonstrates the efficacy of our generative ""Physics-Enhanced Latent Space VAE"" (PELS-VAE) model. Such deep generative models, serving as non-linear non-parametric emulators, present a novel tool for astronomers to create synthetic time series over arbitrary cadences. ","astro-ph"
"1810.07938","Impact of RGE-induced $ \mu-\tau $ Reflection Symmetry Breaking on the   Effective Majorana Neutrino Mass in $ 0\nu\beta \beta $ Decay","  We make an attempt to study the impact of renormalization-group equations (RGE) induced $\mu-\tau$ reflection symmetry breaking on the effective Majorana neutrino mass $ |\langle m\rangle_{ee} | $ in neutrinoless double beta ($ 0\nu\beta \beta $) decay. At present, the $ 0\nu\beta \beta $ decay serves as a unique process to address the Majorana nature of massive neutrinos. The rate of such decay process depends on $ |\langle m\rangle_{ee} | $. On the other hand, $\mu-\tau$ reflection symmetry predicts $ \theta_{23} = 45^\circ$ and $ \delta = \pm 90^\circ $ together with trivial values of the Majorana CP-phases ($ \rho, \sigma $). Moreover, based on the recent global best-fit values which prefer higher octant of $ \theta_{23} $ and third quadrant of $ \delta $, it is hard to believe the exactness of such symmetry. Also, any non-trivial values of $ \rho, \sigma $ may have some significant impact on $ |\langle m\rangle_{ee} | $. In this context, we study the spontaneous breaking of the symmetry via one-loop RGE-running from a superhigh energy scale ($\Lambda_{\mu \tau} $) down to the electroweak scale ($ \Lambda_{\rm EW} $). Given the broken symmetry, we perform some systematic analysis for $ |\langle m\rangle_{ee} | $ in substantial detail. Further, we also extend this analysis for other lepton-number violating effective Majorana masses. ","hep-ph"
"1812.09362","The case for emulating insect brains using anatomical ""wiring diagrams""   equipped with biophysical models of neuronal activity","  Developing whole-brain emulation (WBE) technology would provide immense benefits across neuroscience, biomedicine, artificial intelligence, and robotics. At this time, constructing a simulated human brain lacks feasibility due to limited experimental data and limited computational resources. However, I suggest that progress towards this goal might be accelerated by working towards an intermediate objective, namely insect brain emulation (IBE). More specifically, this would entail creating biologically realistic simulations of entire insect nervous systems along with more approximate simulations of non-neuronal insect physiology to make ""virtual insects."" I argue that this could be realistically achievable within the next 20 years. I propose that developing emulations of insect brains will galvanize the global community of scientists, businesspeople, and policymakers towards pursuing the loftier goal of emulating the human brain. By demonstrating that WBE is possible via IBE, simulating mammalian brains and eventually the human brain may no longer be viewed as too radically ambitious to deserve substantial funding and resources. Furthermore, IBE will facilitate dramatic advances in cognitive neuroscience, artificial intelligence, and robotics through studies performed using virtual insects. ","q-bio"
"2005.00827","Quasi-particle functional Renormalisation Group calculations in the   two-dimensional half-filled Hubbard model at finite temperatures","  We present a highly parallelisable scheme for treating functional Renormalisation Group equations which incorporates a quasi-particle-based feedback on the flow and provides direct access to real-frequency self-energy data. This allows to map out the boundaries of Fermi-liquid regimes and to study the effect of quasi-particle degradation near Fermi liquid instabilities. As a first application, selected results for the two-dimensional half-filled perfectly nested Hubbard model are shown. ","cond-mat"
"1909.04178","Translation Operator in Graph Signal Processing: A Generalized Approach","  The notion of translation (shift) is straightforward in classical signal processing, however, it is challenging on an irregular graph structure. In this work, we present an approach to characterize the translation operator in various signal domains. By a natural generalization from classical domains, one can characterize an abstract representation for the graph translation operator. Then we propose an isometric translation operator in joint time-vertex domain consistent with the abstract form of translation operators in other domains. We also demonstrate the connection between this notion and the Schr\""{o}dinger equation on a dynamic system which intriguingly describes the idea behind translation on graph. ","eess"
"2007.16086","Relative systoles in hyperelliptic translation surfaces","  In this paper we prove that the systole fonction on a connected component of area one translation surfaces admits a local maximum that is not a global maximum if and only if the connected component is not hyperelliptic. ","math"
"2004.02191","Using Cyclic Noise as the Source Signal for Neural Source-Filter-based   Speech Waveform Model","  Neural source-filter (NSF) waveform models generate speech waveforms by morphing sine-based source signals through dilated convolution in the time domain. Although the sine-based source signals help the NSF models to produce voiced sounds with specified pitch, the sine shape may constrain the generated waveform when the target voiced sounds are less periodic. In this paper, we propose a more flexible source signal called cyclic noise, a quasi-periodic noise sequence given by the convolution of a pulse train and a static random noise with a trainable decaying rate that controls the signal shape. We further propose a masked spectral loss to guide the NSF models to produce periodic voiced sounds from the cyclic noise-based source signal. Results from a large-scale listening test demonstrated the effectiveness of the cyclic noise and the masked spectral loss on speaker-independent NSF models in copy-synthesis experiments on the CMU ARCTIC database. ","eess"
"2006.07165","Entanglement for any definition of two subsystems","  The notion of entanglement of quantum states is usually defined with respect to a fixed bipartition. Indeed, a global basis change can always map an entangled state to a separable one. The situation is however different when considering a set of states. In this work we define the notion of an ""absolutely entangled set"" of quantum states: for any possible choice of global basis, at least one of the states in the set is entangled. Hence, for all bipartitions, i.e. any possible definition of the subsystems, the set features entanglement. We present a minimum example of this phenomenon, with a set of four states in $\mathbb{C}^4 = \mathbb{C}^2 \otimes \mathbb{C}^2$. Moreover, we propose a quantitative measure for absolute set entanglement. To lower-bound this quantity, we develop a method based on polynomial optimization to perform convex optimization over unitaries, which is of independent interest. ","quant-ph"
"2007.07737","How Retroactivity Affects the Behavior of Incoherent Feed-Forward Loops","  An incoherent feed-forward loop (IFFL) is a network motif known for its ability to accelerate responses and generate pulses. Though functions of IFFLs are well studied, most previous computational analysis of IFFLs used ordinary differential equation (ODE) models where retroactivity, the effect downstream binding sites exert on the dynamics of an upstream transcription factor (TF), was not considered. It remains an open question to understand the behavior of IFFLs in contexts with high levels of retroactivity, e.g., in cells transformed/transfected with high-copy plasmids, or in eukaryotic cells where a TF binds to numerous high-affinity binding sites in addition to one or more functional target sites. Here we study the behavior of IFFLs by simulating and comparing ODE models with different levels of retroactivity. We find that increasing retroactivity in an IFFL can increase, decrease, or keep the network's response time and pulse amplitude constant. This suggests that increasing retroactivity, traditionally considered as an impediment to designing robust synthetic systems, could be exploited to improve the performance of IFFLs. We compare the behaviors of IFFLs to negative autoregulatory loops, another sign-sensitive response-accelerating network motif, and find that increasing retroactivity in a negative autoregulated circuit can only slow the response. The inability of a negative autoregulatory loop to flexibly handle retroactivity may have contributed to its lower abundance in eukaryotic relative to bacterial regulatory networks, a sharp contrast to the significant abundance of IFFLs in both cell types. ","q-bio"
"1801.02946","Max-infinitely divisible models and inference for spatial extremes","  For many environmental processes, recent studies have shown that the dependence strength is decreasing when quantile levels increase. This implies that the popular max-stable models are inadequate to capture the rate of joint tail decay, and to estimate joint extremal probabilities beyond observed levels. We here develop a more flexible modeling framework based on the class of max-infinitely divisible processes, which extend max-stable processes while retaining dependence properties that are natural for maxima. We propose two parametric constructions for max-infinitely divisible models, which relax the max-stability property but remain close to some popular max-stable models obtained as special cases. The first model considers maxima over a finite, random number of independent observations, while the second model generalizes the spectral representation of max-stable processes. Inference is performed using a pairwise likelihood. We illustrate the benefits of our new modeling framework on Dutch wind gust maxima calculated over different time units. Results strongly suggest that our proposed models outperform other natural models, such as the Student-t copula process and its max-stable limit, even for large block sizes. ","stat"
"1906.05600","UBVRI-KC Photometry of NGC~2323 and NGC~2539 Open Clusters","  The open clusters NGC 2323 and NGC 2539 have been analysed using CCD UBV(RI)KC photometric data, observed at the San Pedro Martir Observatory. Cluster memberships have been determined with the proper motion and parallax measures from the GaiaDR2 astrometric data release. Photometric metal and heavy element abundances have been obtained as (M/H, Z) = (-0.10, 0.012) (NGC 2323) and (-0.31, 0.007) (NGC 2539), from the delta(U-B) technique in the two colour diagrams, which are used to select the appropriate PARSEC isochrones.   The estimated reddening of NGC 2323 is E(B-V) = 0.23+-0.04 using 11 early type stars. For NGC 2539, we find E(B-V)= 0.02+-0.06. For (B-V) colour, distance moduli and distances for NGC 2323 and NGC 2539 are derived as (V0-MV, d (pc)) = (10.00+-0.10, 1000+-50) and (V0-MV, d (pc)) = (10.00+-0.04,1000+-20), respectively.The median GaiaDR2 distance d=1000+-140 pc (plx=0.998+-0.136 mas) for the likely members of NGC 2323 is in concordance with its four colour photometric distances 910-1000 pc. For NGC 2539, its GaiaDR2 distance d=1330+-250 pc (plx=0.751+-0.139 mas) is close to its four colour photometric distances, 1000 pc.   Fitting the PARSEC isochrones to the colour magnitude diagrams (CMDs) gives an old age, 890+-110 Myr, for NGC 2539. Whereas NGC 2323 has an intermediate age, 200+-50 Myr. One Red Clump Red Giant candidate (BD 12 2380) in the CMDs of NGC 2539 has been confirmed as a member in terms of the distances dI = 950+-50 pc and dV =910+-90 pc of VI filters within the uncertainties, as compared to the distance, 1000+-20 pc of NGC 2539. This giant's GaiaDR2 distance (d=1200+-70 pc) is not close to these photometric distances. ","astro-ph"
"1904.00047","Pronounced drop of $^{17}$O NMR Knight shift in superconducting state of   Sr$_2$RuO$_4$","  The superconducting state in the quasi-two-dimensional and strongly correlated Sr$_2$RuO$_4$ is uniquely held up as a solid state analog to superfluid $^3$He-$A$, with an odd-parity order parameter that also breaks time reversal symmetry, and for which the vector order parameter has the same direction in spin space for all electron momenta. The recent discovery that uniaxial pressure causes a steep rise and maximum in transition temperature ($T_c$) in strained samples motivated the study of $^{17}$O nuclear magnetic resonance (NMR) that we describe in this article. A reduction of Knight shifts $K$ was observed for all strain values and temperatures $T<T_c$, consistent with a drop in spin polarization in the superconducting state. In unstrained samples, our results are in contradiction with a body of previous NMR work, and with the most prominent previous proposals for the order parameter of Sr$_2$RuO$_4$. Possible alternative scenarios are discussed. ","cond-mat"
"1809.07114","A Test for detecting Structural Breakdowns in Markets using Eigenvalue   Decompositions","  Correlations among stock returns during volatile markets differ substantially compared to those from quieter markets. During times of financial crisis, it has been observed that traditional dependency in global markets breaks down. However, such an upheaval in dependency structure happens over a span of several months, with the breakdown coinciding with a major bankruptcy or sovereign default. Even though risk managers generally agree that identifying these periods of breakdown is important, there are few statistical methods to test for significant breakdowns. The purpose of this paper is to propose a simple test to detect such structural changes in global markets. This test relies on the assumption that asset price follows a Geometric Brownian Motion. We test for a breakdown in correlation structure using eigenvalue decomposition. We derive the asymptotic distribution under the null hypothesis and apply the test to stock returns. We compute the power of our test and compare it with the power of other known tests. Our test is able to accurately identify the times of structural breakdown in real-world stock returns. Overall we argue, despite the parsimony and simplicity in the assumption of Geometric Brownian Motion, our test can perform well to identify the breakdown in dependency of global markets. ","stat"
"2003.09696","PyCARL: A PyNN Interface for Hardware-Software Co-Simulation of Spiking   Neural Network","  We present PyCARL, a PyNN-based common Python programming interface for hardware-software co-simulation of spiking neural network (SNN). Through PyCARL, we make the following two key contributions. First, we provide an interface of PyNN to CARLsim, a computationally-efficient, GPU-accelerated and biophysically-detailed SNN simulator. PyCARL facilitates joint development of machine learning models and code sharing between CARLsim and PyNN users, promoting an integrated and larger neuromorphic community. Second, we integrate cycle-accurate models of state-of-the-art neuromorphic hardware such as TrueNorth, Loihi, and DynapSE in PyCARL, to accurately model hardware latencies that delay spikes between communicating neurons and degrade performance. PyCARL allows users to analyze and optimize the performance difference between software-only simulation and hardware-software co-simulation of their machine learning models. We show that system designers can also use PyCARL to perform design-space exploration early in the product development stage, facilitating faster time-to-deployment of neuromorphic products. We evaluate the memory usage and simulation time of PyCARL using functionality tests, synthetic SNNs, and realistic applications. Our results demonstrate that for large SNNs, PyCARL does not lead to any significant overhead compared to CARLsim. We also use PyCARL to analyze these SNNs for a state-of-the-art neuromorphic hardware and demonstrate a significant performance deviation from software-only simulations. PyCARL allows to evaluate and minimize such differences early during model development. ","cs"
"1909.02340","Two-bridge knots admit no purely cosmetic surgeries","  We show that two-bridge knots and alternating fibered knots admit no purely cosmetic surgeries, i.e., no pair of distinct Dehn surgeries on such a knot produce 3-manifolds that are homeomorphic as oriented manifolds. Our argument, based on a recent result by Hanselman, uses several invariants of knots or 3-manifolds; for knots, we study the signature and some finite type invariants, and for 3-manifolds, we deploy the $SL(2,\mathbb{C})$ Casson invariant. ","math"
"1909.10090","Towards Explainability for a Civilian UAV Fleet Management using an   Agent-based Approach","  This paper presents an initial design concept and specification of a civilian Unmanned Aerial Vehicle (UAV) management simulation system that focuses on explainability for the human-in-the-loop control of semi-autonomous UAVs. The goal of the system is to facilitate the operator intervention in critical scenarios (e.g. avoid safety issues or financial risks). Explainability is supported via user-friendly abstractions on Belief-Desire-Intention agents. To evaluate the effectiveness of the system, a human-computer interaction study is proposed. ","cs"
"2005.08290","Longitudinal high-throughput TCR repertoire profiling reveals the   dynamics of T cell memory formation after mild COVID-19 infection","  COVID-19 is a global pandemic caused by the SARS-CoV-2 coronavirus. The T cell response is a critical part of both individual and herd immunity to SARS-CoV-2 and the efficacy of developed vaccines. However neither the dynamics and cross-reactivity of the SARS-CoV-2-specific T cell response nor the diversity of resulting immune memory are well understood. In this study we use longitudinal high-throughput T cell receptor sequencing to track changes in the T cell repertoire following two mild cases of COVID-19 infection. In both donors we identified SARS-CoV-2-responding CD4+ and CD8+ T cell clones. We describe characteristic motifs in TCR sequences of COVID-19-reactive clones, suggesting the existence of immunodominant epitopes. We show that in both donors the majority of infection-reactive clonotypes acquire memory phenotypes. Certain CD4+ clones were detected in the memory fraction at the pre-infection timepoint, suggesting participation of pre-existing cross-reactive memory T cells in the immune response to SARS-CoV-2. ","q-bio"
"1905.05151","Two-loop n-point anomalous amplitudes in N=4 supergravity","  We compute the anomalous two-loop four-point amplitudes in N=4 pure supergravity, using unitarity and the double-copy construction. We also present all terms determined by four-dimensional cuts in two all-multiplicity two-loop anomalous superamplitudes. This result provides the first two-loop n-point gravity amplitude, up to a class of undetermined rational terms, which are absent at four points. We show that a recently proposed finite counterterm cancels these amplitudes to this order. We argue that the counterterm does not spoil the three-loop finiteness of anomalous amplitudes in the N=4 theory. ","hep-th"
"1908.06628","A stochastic comparison result for the multitype contact process with   unequal death rates","  A stochastic comparison result that makes progress towards understanding the classical multitype contact process with unequal death rates is given. It has long been conjectured that the particle type with the largest birth to death rate ratio survives and the other dies out. A point process coupling result of Broman is used to give a sufficient condition for when the dominant particle type survives. ","math"
"1912.06646","Black Hole Growth and Feedback in Isolated Romulus25 Dwarf Galaxies","  We investigate the effects of massive black hole growth on the structural evolution of dwarf galaxies within the Romulus25 cosmological hydrodynamical simulation. We study a sample of 228 central, isolated dwarf galaxies with stellar masses $M_{star} < 10^{10} M_\odot$ and a central BH. We find that the local $M_{BH} - M_{star}$ relation exhibits a high degree of scatter below $M_{star} < 10^{10} M_\odot$, which we use to classify BHs as overmassive or undermassive relative to their host $M_{star}$. Overmassive BHs grow through a mixture of BH mergers and relatively high average accretion rates, while undermassive BHs grow slowly through accretion. We find that isolated dwarf galaxies that host overmassive BHs also follow different evolutionary tracks relative to their undermassive BH counterparts, building up their stars and dark matter earlier and experiencing star formation suppression starting around $z=2$. By $z=0.05$, overmassive BH hosts above $M_{star} > 10^{9} M_\odot$ are more likely to exhibit lower central stellar mass density, lower HI gas content, and lower star formation rates than their undermassive BH counterparts. Our results suggest that overmassive BHs in isolated galaxies above $M_{star} > 10^{9} M_\odot$ are capable of driving feedback, in many cases suppressing and even quenching star formation by late times. ","astro-ph"
"1909.06176","Modulation of the cardiomyocyte contraction inside a hydrostatic   pressure bioreactor: $\textit{in vitro}$ verification of the Frank-Starling   law","  We have studied beating mouse cardiac syncytia $\textit{in vitro}$ in order to assess the inotropic, ergotropic, and chronotropic effects of both increasing and decreasing hydrostatic pressures. In particular, we have performed an image processing analysis to evaluate the kinematics and the dynamics of those pressure-loaded beating syncytia starting from the video registration of their contraction movement. By this analysis, we have verified the Frank-Starling law of the heart in $\textit{in vitro}$ beating cardiac syncytia and we have obtained their geometrical-functional classification. ","q-bio"
"1806.10384","Analysis of the $\bar{D}\Sigma_c$, $\bar{D}\Sigma_c^*$,   $\bar{D}^{*}\Sigma_c$ and $\bar{D}^{*}\Sigma_c^*$ pentaquark molecular states   with QCD sum rules","  In this article, we study the $\bar{D}\Sigma_c$, $\bar{D}\Sigma_c^*$, $\bar{D}^{*}\Sigma_c$ and $\bar{D}^{*}\Sigma_c^*$ pentaquark molecular states with the QCD sum rules by carrying out the operator product expansion up to the vacuum condensates of dimension $13$ in a consistent way. The present calculations support assigning the $P_c(4312)$ to be the $\bar{D}\Sigma_c$ pentaquark molecular state with $J^P={\frac{1}{2}}^-$, assigning the $P_c(4380)$ to be the $\bar{D}\Sigma_c^*$ pentaquark molecular state with $J^P={\frac{3}{2}}^-$, assigning the $P_c(4440/4457)$ to be the $\bar{D}^{*}\Sigma_c$ pentaquark molecular state with $J^P={\frac{3}{2}}^-$ or the $\bar{D}^{*}\Sigma_c^*$ pentaquark molecular state with $J^P={\frac{5}{2}}^-$. Special attentions are payed to the operator product expansion. ","hep-ph"
"1910.14130","A Semiparametric Approach to Model-based Sensitivity Analysis in   Observational Studies","  When drawing causal inference from observational data, there is always concern about unmeasured confounding. One way to tackle this is to conduct a sensitivity analysis. One widely-used sensitivity analysis framework hypothesizes the existence of a scalar unmeasured confounder U and asks how the causal conclusion would change were U measured and included in the primary analysis. Works along this line often make various parametric assumptions on U, for the sake of mathematical and computational simplicity. In this article, we substantively further this line of research by developing a valid sensitivity analysis that leaves the distribution of U unrestricted. Our semiparametric estimator has three desirable features compared to many existing methods in the literature. First, our method allows for a larger and more flexible family of models, and mitigates observable implications (Franks et al., 2019). Second, our methods work seamlessly with any primary analysis that models the outcome regression parametrically. Third, our method is easy to use and interpret. We construct both pointwise confidence intervals and confidence bands that are uniformly valid over a given sensitivity parameter space, thus formally accounting for unknown sensitivity parameters. We apply our proposed method on an influential yet controversial study of the causal relationship between war experiences and political activeness using observational data from Uganda. ","stat"
"2004.08985","Experimental simulation of the Parity-Time-symmetric dynamics using   photonics qubits","  The concept of parity-time (PT) symmetry originates from the framework of quantum mechanics, where if the Hamiltonian operator satisfies the commutation relation with the parity and time operators, it shows all real eigen-energy spectrum. Recently, PT symmetry was introduced into optics, electronic circuits, acoustics, and so many other classical fields to further study the dynamics of the Hamiltonian and the energy of the system. Focusing on the dynamical evolution of the quantum state under the action of PT symmetric Hamiltonian, here we experimentally demonstrated the general dynamical evolution of a two-level system under the PT symmetric Hamiltonian using single-photon system. By enlarging the system using ancillary qubits and encoding the subsystem under the non-Hermitian Hamiltonian with post-selection, the evolution of the state can be observed with a high fidelity when the successfully parity-time symmetrically evolved subspace is solely considered. Owing to the effectively operation of the dilation method, our work provides a route for further exploiting the exotic properties of PT symmetric Hamiltonian for quantum simulation and quantum information processing. ","quant-ph"
"2005.09457","The Proper Motion of the Central Compact Object RX J0822-4300 in the   Supernova Remnant Puppis A, Revisited","  We present an improved proper motion measurement of the central compact object RX J0822-4300, located in the supernova remnant Puppis A. By employing a new data set taken in February 2019 by the High Resolution Camera aboard the Chandra X-ray Observatory, we approximately double the available temporal baseline for our analysis to slightly more than 19 years (7000 days). We correct for the astrometric inaccuracy of Chandra using calibrator stars with known optical positions that are detected in all observations. Thereby, we obtain absolute positions of RX J0822-4300 accurate to around $0.1^{\prime\prime}$ and from these a new best estimate for its total proper motion of $\mu_{\rm tot}= (80.4 \pm 7.7)\,\rm{mas\,yr}^{-1}$. For a remnant distance of 2 kpc, this corresponds to a projected kick velocity of $(763 \pm 73)\, \rm{km\,s}^{-1}$ at a position angle of $\phi_0 = (247.8 \pm 4.4)^{\circ}$. The proper motion measurement of RX J0822-4300 is used for discussing the kinematic age of Puppis A. ","astro-ph"
"1912.12038","Experimental Observation of Equilibrium and Dynamical Quantum Phase   Transitions via Out-of-Time-Ordered Correlators","  The out-of-time-ordered correlators (OTOC) have been established as a fundamental concept for quantifying quantum information scrambling and diagnosing quantum chaotic behavior. Recently, it was theoretically proposed that the OTOC can be used as an order parameter to dynamically detect both equilibrium quantum phase transitions (EQPTs) and dynamical quantum phase transitions (DQPTs) in one-dimensional many-body systems. Here we report the first experimental observation of EQPTs and DQPTs in a quantum spin chain via quench dynamics of OTOC on a nuclear magnetic resonance quantum simulator. We observe that the quench dynamics of both the order parameter and the two-body correlation function cannot detect the DQPTs, but the OTOC can unambiguously detect the DQPTs. Moreover, we demonstrate that the long-time average value of the OTOC in quantum quench signals the equilibrium quantum critical point and ordered quantum phases, thus one can measure the EQPTs from the non-equilibrium quantum quench dynamics. Our experiment paves a way for experimentally investigating DQPTs through OTOCs and for studying the EQPTs through the non-equilibrium quantum quench dynamics with quantum simulators. ","quant-ph"
"2005.11905","Neural Discriminant Analysis for Deep Speaker Embedding","  Probabilistic Linear Discriminant Analysis (PLDA) is a popular tool in open-set classification/verification tasks. However, the Gaussian assumption underlying PLDA prevents it from being applied to situations where the data is clearly non-Gaussian. In this paper, we present a novel nonlinear version of PLDA named as Neural Discriminant Analysis (NDA). This model employs an invertible deep neural network to transform a complex distribution to a simple Gaussian, so that the linear Gaussian model can be readily established in the transformed space. We tested this NDA model on a speaker recognition task where the deep speaker vectors (x-vectors) are presumably non-Gaussian. Experimental results on two datasets demonstrate that NDA consistently outperforms PLDA, by handling the non-Gaussian distributions of the x-vectors. ","eess"
"1910.08175","Tunable magnetic order in low-symmetry SeO$_3$ ligand linked   $TM_3$(SeO$_3$)$_3$H$_2$O ($TM$ = Mn, Co and Ni) compounds","  Generally, one has two strategies to achieve magnetic frustration: through geometric means or interactions with different length scales. As the former leads to much simpler theoretical treatments it is favored and so magnetic sublattices with geometric frustration are sought after. One approach to finding such lattices is to design them chemically by using non-magnetic linker ligands. Here we report on the magnetic properties of one such family of materials, the transition metal ($TM$) selenite hydrate compounds chemical formula $TM_3$(SeO$_3$)$_3$H$_2$O . These materials link highly distorted $TM$O$_6$ octahedra via non-magnetic [SeO$_3$]$^{2+}$ linkers. Using $TM$ = Mn, Co and Ni we report on the structural effects of changing the $TM$ site and how they may influence the magnetic structure. Using magnetic susceptibility and neutron powder diffraction we identify low temperature magnetic transitions for all three compounds characterized by the onset of long-range AFM order with moderate frustration indexes. Consideration of the magnetic structures reveal that the magnetic order is sensitive to the $TM$ site ion and is tunable as it is changed - especially from Mn to Co - with changes in both the moment direction and the ordering vector. Field dependent susceptibility and heat capacity measurements reveal metamagnetic transitions in both Mn$_3$(SeO$_3$)$_3$H$_2$O and Co$_3$(SeO$_3$)$_3$H$_2$O indicating nearby magnetic ground states accessible under relatively small applied fields. Density functional theory calculations broadly confirm these results, showing both a sensitivity of the magnetic structure to the $TM$ and its local environment. Although no spin liquid behavior is achieved, these results suggest the fruitfulness of such synthesis philosophies and encourage future work to engender higher frustration in these materials via doping, field, pressure or larger linker ligands. ","cond-mat"
"2002.06519","A principled distance-based prior for the shape of the Weibull model","  The use of flat or weakly informative priors is popular due to the objective a priori belief in the absence of strong prior information. In the case of the Weibull model the improper uniform, equal parameter gamma and joint Jeffrey's priors for the shape parameter are popular choices. The effects and behaviors of these priors have yet to be established from a modeling viewpoint, especially their ability to reduce to the simpler exponential model. In this work we propose a new principled prior for the shape parameter of the Weibull model, originating from a prior on the distance function, and advocate this new prior as a principled choice in the absence of strong prior information. This new prior can then be used in models with a Weibull modeling component, like competing risks, joint and spatial models, to mention a few. This prior is available in the R-INLA for use, and is applied in a joint longitudinal-survival model framework using the INLA method. ","stat"
"2002.08146","A censored mixture model for modeling risk taking","  Risk behavior can have substantial consequences for health, well-being, and functioning. Previous studies have shown an association between real-world risk behavior and risk behavior on experimental tasks, such as the Columbia Card Task, but their modeling is challenging for several reasons. First, many of the experimental risk tasks may end prematurely leading to censored observations. Second, certain outcome values can be more attractive than others. Third, a priori unknown groups of participants can react differently to certain risk-levels. Here, we propose the Censored Mixture Model (CMM), which models risk taking while handling censoring, experimental conditions, and attractiveness to certain outcomes. ","stat"
"1807.02421","Large-Scale Multiple Hypothesis Testing with the Normal-Beta Prime Prior","  We revisit the problem of simultaneously testing the means of $n$ independent normal observations under sparsity. We take a Bayesian approach to this problem by introducing a scale-mixture prior known as the normal-beta prime (NBP) prior. We first derive new concentration properties when the beta prime density is employed for a scale parameter in Bayesian hierarchical models. To detect signals in our data, we then propose a hypothesis test based on thresholding the posterior shrinkage weight under the NBP prior. Taking the loss function to be the expected number of misclassified tests, we show that our test procedure asymptotically attains the optimal Bayes risk when the signal proportion $p$ is known. When $p$ is unknown, we introduce an empirical Bayes variant of our test which also asymptotically attains the Bayes Oracle risk in the entire range of sparsity parameters $p \propto n^{-\epsilon}, \epsilon \in (0, 1)$. Finally, we also consider restricted marginal maximum likelihood (REML) and hierarchical Bayes approaches for estimating a key hyperparameter in the NBP prior and examine multiple testing under these frameworks. ","stat"
"2003.11437","A Dolbeault lemma for temperate currents","  We consider a bounded open Stein subset $\Omega$ of a complex Stein manifold $X$ of dimension $n$. We prove that if $f$ is a current on $X$ of bidegree $(p,q+1)$, $\bar\partial$-closed on $\Omega$, we can find a current $u$ on $X$ of bidegree $(p,q)$ which is a solution of the equation $\bar\partial u=f$ in $\Omega$. In other words, we prove that the Dolbeault complex of temperate currents on $\Omega$ (i.e. currents on $\Omega$ which extend to currents on $X$) is concentrated in degree $0$. Moreover if $f$ is a current on $X= C^n$ of order $k$, then we can find a solution $u$ which is a current on $C^n$ of order $k+2n+1$. ","math"
"1903.05601","The different faces of branes in Double Field Theory","  We show how the Wess-Zumino terms of the different branes in string theory can be embedded within double field theory. Crucial ingredients in our construction are the identification of the correct brane charge tensors and the use of the double field theory potentials that arise from dualizing the standard double field theory fields. This leads to a picture where under T-duality the brane does not change its worldvolume directions but where, instead, it shows different faces depending on whether some of the worldvolume and/or transverse directions invade the winding space. As a non-trivial by-product we show how the different Wess-Zumino terms are modified when the brane propagates in a background with a non-zero Romans mass parameter. Furthermore, we show that for non-zero mass parameter the brane creation process, when one brane passes through another brane, gets generalized to brane configurations that involve exotic branes as well. ","hep-th"
"2007.10713","Mahler's and Koksma's classifications in fields of power series","  Let $q$ a prime power and ${\mathbb F}_q$ the finite field of $q$ elements. We study the analogues of Mahler's and Koksma's classifications of complex numbers for power series in ${\mathbb F}_q((T^{-1}))$. Among other results, we establish that both classifications coincide, thereby answering a question of Ooto. ","math"
"1805.08304","Anchored Bayesian Gaussian Mixture Models","  Finite mixtures are a flexible modeling tool for irregularly shaped densities and samples from heterogeneous populations. When modeling with mixtures using an exchangeable prior on the component features, the component labels are arbitrary and are indistinguishable in posterior analysis. This makes it impossible to attribute any meaningful interpretation to the marginal posterior distributions of the component features. We propose a model in which a small number of observations are assumed to arise from some of the labeled component densities. The resulting model is not exchangeable, allowing inference on the component features without post-processing. Our method assigns meaning to the component labels at the modeling stage and can be justified as a data-dependent informative prior on the labelings. We show that our method produces interpretable results, often (but not always) similar to those resulting from relabeling algorithms, with the added benefit that the marginal inferences originate directly from a well specified probability model rather than a post hoc manipulation. We provide asymptotic results leading to practical guidelines for model selection that are motivated by maximizing prior information about the class labels and demonstrate our method on real and simulated data. ","stat"
"1906.09002","$B_{s1}(5778)$ as a $B^*\bar{K}$ molecule in the Bethe-Salpeter equation   approach","  We interpret the $B_{s1}(5778)$ as an $S$-wave $B^\ast\bar{K}$ molecular state in the Bethe-Salpeter equation approach. In the ladder and instantaneous approximations, and with the kernel containing one-particle-exchange diagrams and introducing three different form factors (monopole, dipole, and exponential form factors) in the vertex, we find the bound state exists. We also study the decay widths of the decay $B_{s1}(5778)\rightarrow B_s^\ast\pi$ and the radiative decays $B_{s1}(5778)\rightarrow B_s\gamma$ and $B_{s1}(5778)\rightarrow B_s^{\ast}\gamma$, which will be instructive for the forthcoming experiments. ","hep-ph"
"1909.05762","On the Sn/n-Problem","  The Chow-Robbins game is a classical still partly unsolved stopping problem introduced by Chow and Robbins in 1965. You repeatedly toss a fair coin. After each toss, you decide if you take the fraction of heads up to now as a payoff, otherwise you continue.   As a more general stopping problem this reads   \[V(n,x) = \sup_{\tau }\operatorname{E} \left [ \frac{x + S_\tau}{n+\tau}\right]\]   where $S$ is a random walk.   We give a tight upper bound for $V$ when $S$ has subgassian increments. We do this by usinf the analogous time continuous problem with a standard Brownian motion as the driving process. From this we derive an easy proof for the existence of optimal stopping times in the discrete case.   For the Chow-Robbins game we as well give a tight lower bound and use these to calculate, on the integers, the complete continuation and the stopping set of the problem for $n\leq 10^{5}$. ","math"
"1912.11698","Probing vacuum polarization effects with high-intensity lasers","  These notes provide a pedagogical introduction to the theoretical study of vacuum polarization effects in strong electromagnetic fields as provided by state-of-the-art high-intensity lasers. Quantum vacuum fluctuations give rise to effective couplings between electromagnetic fields, thereby supplementing Maxwell's linear theory of classical electrodynamics with nonlinearities. Resorting to a simplified laser pulse model allowing for explicit analytical insights, we demonstrate how to efficiently analyze all-optical signatures of these effective interactions in high-intensity laser experiments. Moreover, we highlight several key features relevant for the accurate planning and quantitative theoretical analysis of quantum vacuum nonlinearities in the collision of high-intensity laser pulses. ","hep-ph"
"1903.04087","Uniting the wave and the particle in quantum mechanics","  We present a unified field theory of wave and particle in quantum mechanics. This emerges from an investigation of three weaknesses in the de Broglie-Bohm (deBB) theory: its reliance on the quantum probability formula to justify the particle law; its insouciance regarding the absence of reciprocal action of the particle on the guiding wave; and its lack of a unified model to represent its inseparable components. These problems are resolved within an analytical framework by requiring that the wave-particle composite exhibits no observable differences with a quantum system. This scheme is implemented by appealing to symmetries (global gauge and spacetime translations) and imposing equality of the corresponding conserved Noether densities (matter, momentum and energy) with their Schrodinger counterparts. In conjunction with the condition of time reversal covariance this implies the deBB law for the particle where the quantum potential mediates the wave-particle interaction (we also show how the time reversal assumption may be replaced by a statistical condition). The method clarifies the nature of the mass of the composite, and its energy-momentum conservation laws. Our principal result is the unification of the Schrodinger equation and the deBB law in an inhomogeneous equation whose solution amalgamates the wavefunction and a singular soliton model of the particle in a unified spacetime field. The wavefunction suffers no reaction from the particle since it is the homogeneous part of the unified field to whose source the particle contributes. The theory applies to many-body systems. We review the objections of de Broglie to the pilot-wave theory and suggest that our field-theoretic model provides a realization of his hitherto unfulfilled double-solution programme. A revised set of postulates for the deBB theory is given in which the unified field is taken as the basic descriptive element. ","quant-ph"
"1807.01642","Violation of vacuum stability by inverse square electric fields","  In the framework of QED with a strong background, we study particle creation (the Schwinger effect) by a time-dependent inverse square electric field. To this end corresponding exact in- and out-solutions of the Dirac and Klein-Gordon equations are found. We calculate the vacuum-to-vacuum probability and differential and total mean numbers of pairs created from the vacuum. For electric fields varying slowly in time, we present detailed calculations of the Schwinger effect and discuss possible asymptotic regimes. The obtained results are consistent with universal estimates of the particle creation effect by electric fields in the locally constant field approximation. Differential and total quantities corresponding to asymmetrical configurations are also discussed in detail. Finally, the inverse square electric field is used to imitate switching on and off processes. Then the case under consideration is compared with the one where an exponential electric field is used to imitate switching on and off processes. ","hep-th"
"1903.05784","Learning Parallax Attention for Stereo Image Super-Resolution","  Stereo image pairs can be used to improve the performance of super-resolution (SR) since additional information is provided from a second viewpoint. However, it is challenging to incorporate this information for SR since disparities between stereo images vary significantly. In this paper, we propose a parallax-attention stereo superresolution network (PASSRnet) to integrate the information from a stereo image pair for SR. Specifically, we introduce a parallax-attention mechanism with a global receptive field along the epipolar line to handle different stereo images with large disparity variations. We also propose a new and the largest dataset for stereo image SR (namely, Flickr1024). Extensive experiments demonstrate that the parallax-attention mechanism can capture correspondence between stereo images to improve SR performance with a small computational and memory cost. Comparative results show that our PASSRnet achieves the state-of-the-art performance on the Middlebury, KITTI 2012 and KITTI 2015 datasets. ","cs"
"2006.09405","Non-adiabatic molecular quantum dynamics with quantum computers","  The theoretical investigation of non-adiabatic processes is hampered by the complexity of the coupled electron-nuclear dynamics beyond the Born-Oppenheimer approximation. Classically, the simulation of such reactions is limited by the unfavourable scaling of the computational resources as a function of the system size. While quantum computing exhibits proven quantum advantage for the simulation of real-time dynamics, the study of quantum algorithms for the description of non-adiabatic phenomena is still unexplored. In this work, we propose a quantum algorithm for the simulation of fast non-adiabatic chemical processes together with an initialization scheme for quantum hardware calculations. In particular, we introduce a first-quantization method for the time evolution of a wavepacket on two coupled harmonic potential energy surfaces (Marcus model). In our approach, the computational resources scale polynomially in the system dimensions, opening up new avenues for the study of photophysical processes that are classically intractable. ","quant-ph"
"2004.10335","How to track your dragon: A Multi-Attentional Framework for real-time   RGB-D 6-DOF Object Pose Tracking","  We present a novel multi-attentional convolutional architecture to tackle the problem of real-time RGB-D 6D object pose tracking of single, known objects. Such a problem poses multiple challenges originating both from the objects' nature and their interaction with their environment, which previous approaches have failed to fully address. The proposed framework encapsulates methods for background clutter and occlusion handling by integrating multiple parallel soft spatial attention modules into a multitask Convolutional Neural Network (CNN) architecture. Moreover, we consider the special geometrical properties of both the object's 3D model and the pose space, and we use a more sophisticated approach for data augmentation for training. The provided experimental results confirm the effectiveness of the proposed multi-attentional architecture, as it improves the State-of-the-Art (SoA) tracking performance by an average score of 40.5% for translation and 57.5% for rotation, when testing on the dataset presented in [1], the most complete dataset designed, up to date, for the problem of RGB-D object tracking. ","cs"
"1911.03830","Path independence of the additive functionals for McKean-Vlasov   stochastic differential equations with jumps","  In this article, the path independent property of additive functionals of McKean-Vlasov stochastic differential equations with jumps is characterised by nonlinear partial integro-differential equations involving $L$-derivatives with respect to probability measures introduced by P.-L. Lions. Our result extends the recent work [16] by Ren and Wang where their concerned McKean-Vlasov stochastic differential equations are driven by Brownian motions. ","math"
"1903.05252","Zero-Shot Autonomous Vehicle Policy Transfer: From Simulation to   Real-World via Adversarial Learning","  In this article, we demonstrate a zero-shot transfer of an autonomous driving policy from simulation to University of Delaware's scaled smart city with adversarial multi-agent reinforcement learning, in which an adversary attempts to decrease the net reward by perturbing both the inputs and outputs of the autonomous vehicles during training. We train the autonomous vehicles to coordinate with each other while crossing a roundabout in the presence of an adversary in simulation. The adversarial policy successfully reproduces the simulated behavior and incidentally outperforms, in terms of travel time, both a human-driving baseline and adversary-free trained policies. Finally, we demonstrate that the addition of adversarial training considerably improves the performance \eat{stability and robustness} of the policies after transfer to the real world compared to Gaussian noise injection. ","cs"
"1907.00860","Energy Efficient Transmission Based on Grouped Spatial Modulation for   upstream DSL Systems","  The digital Subscriber Line (DSL) remains an important component of heterogeneous networking, especially in historic city-centers, where using optical fibre is less realistic. Recently, the power consumption has become an important performance metric in telecommunication due to the associated environmental issues. In the recent bonding model, customer sites have been equipped with two/four copper pairs, which may be exploited for designing grouped spatial modulation (SM) aiming for reducing the power consumption and mitigating the stubborn crosstalk in DSL communications. Explicitly, we view the two pair copper pairs equipped for each user as a group and propose an energy efficient transmission scheme based on grouped SM strategy for the upstream DSL systems, which is capable of reducing the power consumption of the upstream transmitters by activating a single copper line of each user. More especially, in order to compensate for the potential bit-rate reduction imposed by reducing the number of activated lines, the proposed scheme implicitly delivers ``virtual bits"" via activating/deactivating the lines in addition to the classic modulation scheme. This is particularly beneficial in the DSL context, because the cross-talk imposed by activating several lines may swamp the desired signal. Furthermore, a pair of near-optimal soft turbo detection schemes are proposed for exploiting the unique properties of the DSL channel in order to eliminate the error propagation problem of SM detection routinely encountered in wireless channels. Both the attainable energy-efficiency and the achievable Bit Error Ratio (BER) are investigated. Our simulation results demonstrate that the proposed group-based SM is capable of outperforming the vectoring scheme both in terms of its energy efficiency for all the examined loop lengths and transmit powers. ","eess"
"2005.11010","QCD Corrections to $e^+e^- \rightarrow H^{\pm}W^{\mp}$ in Type-I THDM at   Electron Positron Colliders","  We investigate in detail the charged Higgs production associated with a $W$ boson at electron-positron colliders within the framework of the Type-I two-Higgs-doublet model (THDM). We calculate the integrated cross section at the LO and analyze the dependence of the cross section on the THDM parameters and the colliding energy in a benchmark scenario of the input parameters of Higgs sector. The numerical results show that the integrated cross section is sensitive to the charged Higgs mass, especially in the vicinity of $m_{H^{\pm}} \simeq 184~ {\rm GeV}$ at a $500~ {\rm GeV}$ $e^+e^-$ collider, and decreases consistently as the increment of $\tan\beta$ in the low $\tan\beta$ region. The peak in the colliding energy distribution of the cross section arises from the resonance of loop integrals and its position moves towards low colliding energy as the increment of $m_{H^{\pm}}$. We also study the two-loop NLO QCD corrections to both the integrated cross section and the angular distribution of the charged Higgs boson, and find that the QCD relative correction is also sensitive to the charged Higgs mass and strongly depends on the final-state phase space. For $\tan\beta = 2$, the QCD relative correction at a $500~ {\rm GeV}$ $e^+e^-$ collider varies in the range of $[-10\%,\, 11\%]$ as $m_{H^{\pm}}$ increases from $150$ to $400~ {\rm GeV}$. ","hep-ph"
"2002.08813","Comment on ""Criticality Between Cortical States""","  Fontenele and collaborators reported extensive analyses of power-law scalings of neuronal avalanches in experimental recordings and in a critical theoretical model. One of their main conclusions is that the brain operates at criticality in specific regimes. To prove this point, they developed a test (hereafter, ""Fontenele test"") for criticality, which they indicate to rely on our own theoretical result. However, the results we established do not provide necessary and sufficient conditions for criticality, and cannot be extrapolated to derive a test for criticality. Moreover, the authors did not include any control applying the Fontenele test to non-critical systems, to assess possible differences with the experimental data. We propose here two such controls, and show that the Fontenele test can misclassify as critical these non-critical systems. This implies that the analyses of Fontenele et al. do not support their conclusions, and the question of whether the brain operates at criticality remains open. ","q-bio"
"1906.00201","On the enlargement of habitable zones around binary stars in hostile   environments","  We investigate the hypothesis that the size of the habitable zone around hardened binaries in dense star-forming regions increases. Our results indicate that this hypothesis is essentially incorrect. Although certain binary star configurations permit extended habitable zones, such setups typically require all orbits in a system to be near circular. In all other cases planets can only remain habitable if they display an extraordinarily high climate inertia. ","astro-ph"
"1807.10557","On the definition and characterisation of multipartite causal   (non)separability","  The concept of causal nonseparability has been recently introduced, in opposition to that of causal separability, to qualify physical processes that locally abide by the laws of quantum theory, but cannot be embedded in a well-defined global causal structure. While the definition is unambiguous in the bipartite case, its generalisation to the multipartite case is not so straightforward. Two seemingly different generalisations have been proposed, one for a restricted tripartite scenario and one for the general multipartite case. Here we compare the two, showing that they are in fact inequivalent. We propose our own definition of causal (non)separability for the general case, which---although a priori subtly different---turns out to be equivalent to the concept of ""extensible causal (non)separability"" introduced before, and which we argue is a more natural definition for general multipartite scenarios. We then derive necessary, as well as sufficient conditions to characterise causally (non)separable processes in practice. These allow one to devise practical tests, by generalising the tool of witnesses of causal nonseparability. ","quant-ph"
"1902.05676","Structural analysis of nuclear spin clusters via two-dimensional   nanoscale nuclear magnetic resonance spectroscopy","  Two-dimensional Nuclear Magnetic Resonance (NMR) is essential in molecular structure determination. The Nitrogen-Vacancy (NV) center in diamond has been proposed and developed as an outstanding quantum sensor to realize NMR in nanoscale. In this work, we develop a scheme for two-dimensional nanoscale NMR spectroscopy based on quantum controls on an NV center. We carry out a proof of principle experiment on a target of two coupled $^{13}$C nuclear spins in diamond. A COSY-like sequences is used to acquire the data on time domain, which is then converted to frequency domain with the fast Fourier transform (FFT). With the two-dimensional NMR spectrum, the structure and location of the set of nuclear spin are resolved. This work marks a fundamental step towards resolving the structure of a single molecule. ","quant-ph"
"1912.08445","Magritte, a modern software library for 3D radiative transfer: I.   Non-LTE atomic and molecular line modelling","  Radiative transfer is a key component in almost all astrophysical and cosmological simulations. We present Magritte: a modern open-source software library for 3D radiative transfer. It uses a deterministic ray-tracer and formal solver, i.e. it computes the radiation field by tracing rays through the model and solving the radiative transfer equation in its second-order form along a fixed set of rays originating from each point. Magritte can handle structured and unstructured input meshes, as well as smoothed-particle hydrodynamics (SPH) particle data. In this first paper, we describe the numerical implementation, semi-analytic tests and cross-code benchmarks for the non-LTE line radiative transfer module of Magritte. This module uses the radiative transfer solver to self-consistently determine the populations of the quantised energy levels of atoms and molecules using an accelerated Lambda iteration (ALI) scheme. We compare Magritte with the established radiative transfer solvers Ratran (1D) and Lime (3D) on the van Zadelhoff benchmark and present a first application to a simple Keplerian disc model. Comparing with Lime, we conclude that Magritte produces more accurate and more precise results, especially at high optical depth, and that it is faster. ","astro-ph"
"1901.10249","Fast and high-fidelity generation of steady-state entanglement using   pulse modulation and parametric amplification","  We explore an intriguing alternative for a fast and high-fidelity generation of steady-state entanglement. By exponentially enhancing the atom-cavity interaction, we obtain an exponentially-enhanced effective cooperativity of the system, which results in a high fidelity of the state generation. Meanwhile, we modulate the amplitudes of the driving fields to accelerate the population transfer to a target state, e.g., a Bell state. An exponentially-shortened stabilization time is thus predicted. Specifically, when the cooperativity of the system is $C=30$, the fidelity of the acceleration scheme reaches $98.5\%$, and the stabilization time is about 10 times shorter than that without acceleration. Moreover, we find from the numerical simulation that the acceleration scheme is robust against systematic and stochastic (amplitude-noise) errors. ","quant-ph"
"1904.06639","Robustness against additional noise in cellular information transmission","  Fluctuations in intracellular reactions (intrinsic noise) reduce the information transmitted from an extracellular input to a cellular response. However, recent studies have demonstrated that the decrease in the transmitted information with respect to extracellular input fluctuations (extrinsic noise) is smaller when the intrinsic noise is larger. Therefore, it has been suggested that robustness against extrinsic noise increases with the level of the intrinsic noise. We call this phenomenon intrinsic noise-induced robustness (INIR). As previous studies on this phenomenon have focused on complex biochemical reactions, the relation between INIR and the input--output of a system is unclear. Moreover, the mechanism of INIR remains elusive. In this paper, we address these questions by analyzing simple models. We first analyze a model in which the input--output relation is linear. We show that the robustness against extrinsic noise increases with the intrinsic noise, confirming the INIR phenomenon. Moreover, the robustness against the extrinsic noise is more strongly dependent on the intrinsic noise when the variance of the intrinsic noise is larger than that of the input distribution. Next, we analyze a threshold model in which the output depends on whether the input exceeds the threshold. When the threshold is equal to the mean of the input, INIR is realized, but when the threshold is much larger than the mean, the threshold model exhibits stochastic resonance, and INIR is not always apparent. The robustness against extrinsic noise and the transmitted information can be traded off against one another in the linear model and the threshold model without stochastic resonance, whereas they can be simultaneously increased in the threshold model with stochastic resonance. ","q-bio"
"2007.08782","Distinguishing level-1 phylogenetic networks on the basis of data   generated by Markov processes","  Phylogenetic networks can represent evolutionary events that cannot be described by phylogenetic trees. These networks are able to incorporate reticulate evolutionary events such as hybridization, introgression, and lateral gene transfer. Recently, network-based Markov models of DNA sequence evolution have been introduced along with model-based methods for reconstructing phylogenetic networks. For these methods to be consistent, the network parameter needs to be identifiable from data generated under the model. Here, we show that the semi-directed network parameter of a triangle-free, level-1 network model with any fixed number of reticulation vertices is generically identifiable under the Jukes-Cantor, Kimura 2-parameter, or Kimura 3-parameter constraints. ","q-bio"
"1611.09415","$\tau$-invariants for knots in rational homology spheres","  Ozsv\'ath and Szab\'o used the knot filtration on $\widehat{CF}(S^3)$ to define the $\tau$-invariant for knots in the 3-sphere. In this article, we generalize their construction and define a collection of $\tau$-invariants associated to a knot $K$ in a rational homology sphere $Y$. We then show that some of these invariants provide lower bounds for the genus of a surface with boundary $K$ properly embedded in a negative definite 4-manifold with boundary $Y$.. ","math"
"1904.09141","Conserved currents and $\text{T}\bar{\text{T}}_s$ irrelevant   deformations of 2D integrable field theories","  It has been recently discovered that the $\text{T}\bar{\text{T}}$ deformation is closely-related to Jackiw-Teitelboim gravity. At classical level, the introduction of this perturbation induces an interaction between the stress-energy tensor and space-time and the deformed EoMs can be mapped, through a field-dependent change of coordinates, onto the corresponding undeformed ones. The effect of this perturbation on the quantum spectrum is non-perturbatively described by an inhomogeneous Burgers equation. In this paper, we point out that there exist infinite families of models where the geometry couples instead to generic combinations of local conserved currents labelled by the Lorentz spin. In spirit, these generalisations are similar to the $\text{J}\bar{\text{T}}$ model as the resulting theories and the corresponding scattering phase factors are not Lorentz invariant. The link with the $\text{J}\bar{\text{T}}$ model is discussed in detail. While the classical setup described here is very general, we shall use the sine-Gordon model and its CFT limit as explanatory quantum examples. Most of the final equations and considerations are, however, of broader validity or easily generalisable to more complicated systems. ","hep-th"
"1809.05667","On stability of a class of filters for non-linear stochastic systems","  This article develops a comprehensive framework for stability analysis of a broad class of commonly used continuous and discrete time-filters for stochastic dynamic systems with non-linear state dynamics and linear measurements under certain strong assumptions. The class of filters encompasses the extended and unscented Kalman filters and most other Gaussian assumed density filters and their numerical integration approximations. The stability results are in the form of time-uniform mean square bounds and exponential concentration inequalities for the filtering error. In contrast to existing results, it is not always necessary for the model to be exponentially stable or fully observed. We review three classes of models that can be rigorously shown to satisfy the stringent assumptions of the stability theorems. Numerical experiments using synthetic data validate the derived error bounds. ","stat"
"1812.07089","Newton's second law with a semiconvex potential","  We make the elementary observation that the differential equation associated with Newton's second law $m\ddot\gamma(t)=-D V(\gamma(t))$ always has a solution for given initial conditions provided that the potential energy $V$ is semiconvex. That is, if $-D V$ satisfies a one-sided Lipschitz condition. We will then build upon this idea to verify the existence of solutions for the Jeans-Vlasov equation, the pressureless Euler equations in one spatial dimension and the equations of elastodynamics under appropriate semiconvexity assumptions. ","math"
"1911.00999","Echo Planar Time-Resolved Imaging (EPTI) with Subspace Reconstruction   and Optimized Spatiotemporal Encoding","  Purpose: To develop new encoding and reconstruction techniques for fast multi-contrast quantitative imaging. Methods: The recently proposed Echo Planar Time-resolved Imaging (EPTI) technique can achieve fast distortion- and blurring-free multi-contrast quantitative imaging. In this work, a subspace reconstruction framework is developed to improve the reconstruction accuracy of EPTI at high encoding accelerations. The number of unknowns in the reconstruction is significantly reduced by modeling the temporal signal evolutions using low-rank subspace. As part of the proposed reconstruction approach, a B0-update algorithm and a shot-to-shot B0 variation correction method are developed to enable the reconstruction of high-resolution tissue phase images and to mitigate artifacts from shot-to-shot phase variations. Moreover, the EPTI concept is extended to 3D k-space for 3D GE-EPTI, where a new temporal-variant of CAIPI encoding is proposed to further improve performance. Results: The effectiveness of the proposed subspace reconstruction was demonstrated first in 2D GESE EPTI, where the reconstruction achieved higher accuracy when compared to conventional B0-informed GRAPPA. For 3D GE-EPTI, a retrospective undersampling experiment demonstrates that the new temporal-variant CAIPI encoding can achieve up to 72x acceleration with close to 2x reduction in reconstruction error when compared to conventional spatiotemporal-CAIPI encoding. In a prospective undersampling experiment, high-quality whole-brain T2* and QSM maps at 1 mm isotropic resolution was acquired in 52 seconds at 3T using 3D GE-EPTI with temporal-variant CAIPI encoding. Conclusion: The proposed subspace reconstruction and optimized temporal-variant CAIPI encoding can further improve the performance of EPTI for fast quantitative mapping. ","eess"
"1901.01236","Phase diagram of the Kondo model on the zigzag ladder","  The effect of next-nearest-neighbor hopping $t_{2}$ on the ground-state phase diagram of the one-dimensional Kondo lattice is studied with density-matrix renormalization-group techniques and by comparing with the phase diagram of the classical-spin variant of the same model. For a finite $t_{2}$, i.e., for a zigzag-ladder geometry, indirect antiferromagnetic interactions between the localized spins are geometrically frustrated. We demonstrate that $t_{2}$ at the same time triggers several magnetic phases which are absent in the model with nearest-neighbor hopping only. For strong $J$, we find a transition from antiferromagnetic to incommensurate magnetic short-range order, which can be understood entirely in the classical-spin picture. For weaker $J$, a spin-dimerized phase emerges, which spontaneously breaks the discrete translation symmetry. The phase is not accessible to perturbative means but is explained, on a qualitative level, by the classical-spin model as well. Spin dimerization alleviates magnetic frustration and is interpreted as a key to understand the emergence of quasi-long-range spiral magnetic order which is found at weaker couplings. The phase diagram at weak $J$, with gapless quasi-long-range order on top of the two-fold degenerate spin-dimerized ground state, competing with a nondegenerate phase with gapped spin (and charge) excitations, is unconventional and eludes an effective low-energy spin-only theory. ","cond-mat"
"1905.04777","AFSCR: Annotation of Functional Satisfaction Conditions and their   Reconciliation within i* models","  Context: Researchers, both in industry and academia, are facing the challenge of leveraging the benefits of goal oriented requirements engineering (GORE) techniques to business compliance management. This requires analyzing goal models along with their semantics. However, most prominent goal modeling frameworks have no means of capturing the semantics of goals (except what is trivially conveyed by their nomenclature).   Objective: In this paper, we propose the Annotation of Functional Satisfaction Conditions and their Reconciliation (AFSCR) framework for doing the same. The entire framework is presented with respect to i* modeling constructs.   Method: This is a semi-automated framework that requires analysts to annotate individual goals with their immediate goal satisfaction conditions. The AFSCR framework can then reconcile these satisfaction conditions for every goal and verify whether the derived set of cumulative satisfaction conditions is in harmony with the intended set of goal satisfaction conditions.   Result: If the derived and intended sets of satisfaction conditions are in conflict, the framework raises entailment and/or consistency flags. Whenever a conflict is flagged, the framework also provides alternate solutions and possible workaround strategies to the analysts by refactoring the given i* model.   Conclusion: In this paper we present a new framework that uses satisfaction conditions for going beyond the nomenclature and capturing the functional semantics of the goals within i* models. The analysis performed during the reconciliation process is generic enough and can be adapted to any goal modeling framework if required. ","cs"
"1910.03001","Trading off Complexity for Expressiveness in Programming Languages:   Visions and Preliminary Experiences","  When programming resource-scarce embedded smart devices, the designer often requires both the low-level system programming features of a language such as C and higher level capability typical of a language like Java. The choice of a particular language typically implies trade offs between conflicting design goals such as performance, costs, and overheads. The large variety of languages, virtual machines, and translators provides the designer with a dense trade off space, ranging from minimalistic to rich full-fledged approaches, but once a choice is made it is often difficult for the designer to revise it. In this work we propose a system of light-weighted and modular extensions as a method to flexibly reshape the target programming language as needed, adding only those application layer features that match the current design goals. In so doing complexity is made transparent, but not hidden: While the programmer can benefit of higher level constructs, the designer can deal with modular building blocks each characterized by a certain algorithmic complexity and therefore each accountable for a given share of the overhead. As a result the designer is given a finer control on the amount of resources that are consumed by the run-time executive of the chosen programming language. ","cs"
"2006.15507","2nd Place Solution for Waymo Open Dataset Challenge -- 2D Object   Detection","  A practical autonomous driving system urges the need to reliably and accurately detect vehicles and persons. In this report, we introduce a state-of-the-art 2D object detection system for autonomous driving scenarios. Specifically, we integrate both popular two-stage detector and one-stage detector with anchor free fashion to yield a robust detection. Furthermore, we train multiple expert models and design a greedy version of the auto ensemble scheme that automatically merges detections from different models. Notably, our overall detection system achieves 70.28 L2 mAP on the Waymo Open Dataset v1.2, ranking the 2nd place in the 2D detection track of the Waymo Open Dataset Challenges. ","cs"
"1909.10344","The recent advances in the mathematical modelling of human pluripotent   stem cells","  Human pluripotent stem cells hold great promise for developments in regenerative medicine and drug design. The mathematical modelling of stem cells and their properties is necessary to understand and quantify key behaviours and develop non-invasive prognostic modelling tools to assist in the optimisation of laboratory experiments. Here, the recent advances in the mathematical modelling of hPSCs are discussed, including cell kinematics, cell proliferation and colony formation, and pluripotency and differentiation. ","q-bio"
"2008.07323","New CAP Reduction Mechanisms for IEEE 802.15.4 DSME to Support   Fluctuating Traffic in IoT Systems","  In 2015, the IEEE 802.15.4 standard was expanded by the Deterministic and Synchronous Multi-Channel Extension (DSME) to increase reliability, scalability and energy-efficiency in industrial applications. The extension offers a TDMA/FDMA-based channel access, where time is divided into two alternating phases, a contention access period (CAP) and a contention free period (CFP). During the CAP, transmission slots can be allocated offering an exclusive access to the shared medium during the CFP. The fraction $\tau$ of CFP's time slots in a dataframe is a critical value, because it directly influences agility and throughput. A high throughput demands that the CFP is much longer than the CAP, i.e., a high value of the fraction $\tau$, because application data is only sent during the CFP. High agility is given if the expected waiting time to send a CAP message is short and that the length of the CAPs are sufficiently long to accommodate necessary (de)allocations of GTSs, i.e., a low value of the fraction $\tau$. Once DSME is configured according to the needs of an application, the fraction $\tau$ can only assume one of two values and cannot be changed at run-time. In this paper, we propose two extensions of DSME that allow to adopt $\tau$ to the current traffic pattern. We show theoretically and through simulations that the proposed extensions provide a high degree of responsiveness to traffic fluctuations while keeping the throughput high. ","cs"
"1905.10902","Engineering Kernelization for Maximum Cut","  Kernelization is a general theoretical framework for preprocessing instances of NP-hard problems into (generally smaller) instances with bounded size, via the repeated application of data reduction rules. For the fundamental Max Cut problem, kernelization algorithms are theoretically highly efficient for various parameterizations. However, the efficacy of these reduction rules in practice---to aid solving highly challenging benchmark instances to optimality---remains entirely unexplored.   We engineer a new suite of efficient data reduction rules that subsume most of the previously published rules, and demonstrate their significant impact on benchmark data sets, including synthetic instances, and data sets from the VLSI and image segmentation application domains. Our experiments reveal that current state-of-the-art solvers can be sped up by up to multiple orders of magnitude when combined with our data reduction rules. On social and biological networks in particular, kernelization enables us to solve four instances that were previously unsolved in a ten-hour time limit with state-of-the-art solvers; three of these instances are now solved in less than two seconds. ","cs"
"2003.10369","Low Latency End-to-End Streaming Speech Recognition with a Scout Network","  The attention-based Transformer model has achieved promising results for speech recognition (SR) in the offline mode. However, in the streaming mode, the Transformer model usually incurs significant latency to maintain its recognition accuracy when applying a fixed-length look-ahead window in each encoder layer. In this paper, we propose a novel low-latency streaming approach for Transformer models, which consists of a scout network and a recognition network. The scout network detects the whole word boundary without seeing any future frames, while the recognition network predicts the next subword by utilizing the information from all the frames before the predicted boundary. Our model achieves the best performance (2.7/6.4 WER) with only 639 ms latency on the test-clean and test-other data sets of Librispeech. ","eess"
"1802.00317","Polynomial-Time Algorithms for Phylogenetic Inference Problems involving   duplication and reticulation","  A common problem in phylogenetics is to try to infer a species phylogeny from gene trees. We consider different variants of this problem. The first variant, called Unrestricted Minimal Episodes Inference, aims at inferring a species tree based on a model with speciation and duplication where duplications are clustered in duplication episodes. The goal is to minimize the number of such episodes. The second variant, Parental Hybridization, aims at inferring a species \emph{network} based on a model with speciation and reticulation. The goal is to minimize the number of reticulation events. It is a variant of the well-studied Hybridization Number problem with a more generous view on which gene trees are consistent with a given species network. We show that these seemingly different problems are in fact closely related and can, surprisingly, both be solved in polynomial time, using a structure we call ""beaded trees"". However, we also show that methods based on these problems have to be used with care because the optimal species phylogenies always have a restricted form. To mitigate this problem, we introduce a new variant of Unrestricted Minimal Episodes Inference that minimizes the duplication episode depth. We prove that this new variant of the problem can also be solved in polynomial time ","q-bio"
"1912.06662","Properties of simulated galaxies and supermassive black holes in cosmic   voids","  Cosmic voids, the under-dense regions of the cosmic web, are widely used to constrain cosmology. Voids contain few, isolated galaxies, presumably expected to be less evolved and preserving memory of the pristine Universe. We use the cosmological hydrodynamical simulation Horizon-AGN coupled to the void finder {\sc \texttt{VIDE}} to investigate properties of galaxies in voids at z=0. We find that, closer to void centers, low-mass galaxies are more common than their massive counterparts. At fixed dark matter halo mass, they have smaller stellar masses than in denser regions. The star formation rate of void galaxies diminishes when approaching void centers, but their sSFR slightly increases, suggesting that void galaxies form stars more efficiently with respect to their stellar mass. We find that this can not only be attributed to the prevalence of low-mass galaxies. The inner region of voids also predominantly host low-mass BHs. However, the BH mass to galaxy mass ratios resemble those of the whole simulation at z=0. Our results suggest that even if the growth channels in cosmic voids are different than in denser environments, voids grow their galaxies and BHs in a similar way. While a large fraction of the BHs have low Eddington ratios, we find that 20\% could be observed as AGN with log10 L=41.5-42.5 erg/s in hard X-ray (2-10 keV). These results pave the way to future work with larger next-generation hydro simulations, aiming to confirm our findings and prepare the application on data from upcoming large surveys such as PFS, Euclid and WFIRST. ","astro-ph"
"1910.13759","Production of Z'-Boson Resonances with Large Width at the LHC","  Di-lepton searches for Beyond the Standard Model (BSM) Z' bosons that rely on the analysis of the Breit-Wigner (BW) line shape are appropriate in the case of narrow resonances, but likely not sufficient in scenarios featuring Z' states with large widths. Conversely, alternative experimental strategies applicable to wide Z' resonances are much more dependent than the default bump search analyses on the modelling of QCD higher-order corrections to the production processes, for both signal and background. For heavy Z' boson searches in the di-lepton channel at the CERN Large Hadron Collider (LHC), the transverse momentum q_T of the di-lepton system peaks at q_T \ltap 10^{-2} M_{ll}, where M_{ll} is the di-lepton invariant mass. We exploit this to treat the QCD corrections by using the logarithmic resummation methods in M_{ll} / q_T to all orders in the strong coupling constant \alpha_s. We carry out studies of Z' states with large width at the LHC by employing the program {\tt reSolve}, which performs QCD transverse momentum resummation up to Next-to-Next-to-Leading Logarithmic (NNLL) accuracy. We consider two benchmark BSM scenarios, based on the Sequential Standard Model (SSM) and dubbed `SSM wide' and `SSM enhanced'. We present results for the shape and size of Z' boson signals at the differential level, mapped in both cross section (\sigma) and Forward-Backward Asymmetry (A_{\rm FB}), and perform numerical investigations of the experimental sensitivity at the LHC Run 3 and High-Luminosity LHC (HL-LHC). ","hep-ph"
"1908.08797","Dynamical slave-boson mean-field study of the Mott transition in the   Hubbard model in the large-$z$ limit","  The Mott metal-insulator transition in the Hubbard model is studied by constructing a dynamical slave-boson mean-field theory in the limit of large lattice coordination number $z$ that incorporates the binding between doubly occupied (doublon) and empty (holon) sites. On the Mott insulating side where all doublons and holons bond in real space into excitonic pairs leading to the charge gap, the theory simplifies considerably to leading order in $1/\sqrt{z}$, and becomes exact on the infinite-$z$ Bethe lattice. An asymptotic solution is obtained for a continuous Mott transition associated with the closing of the charge gap at a critical value of the Hubbard $U_c$ and the corresponding doublon density $n_d^c$, hopping $\chi_d^c$ and doublon-holon pairing $\Delta_d^c$ amplitudes. We find $U_c=U_{\rm BR} [1 -2n_d^c -\sqrt{z} (\chi_d^c +\Delta_d^c))] \simeq0.8U_{\rm BR}$, where $U_{\rm BR}$ is the critical value for the Brinkman-Rice transition in the Gutzwiller approximation captured in the static mean-field solution of the slave-boson formulation of Kotliar and Ruckenstein. Thus, the Mott transition can be viewed as the quantum correction to the Brinkman-Rice transition due to doublon-holon binding. Quantitative comparisons are made to the results of the dynamical mean-field theory, showing good agreement. In the absence of magnetic order, the Mott insulator is a $U(1)$ quantum spin liquid with nonzero intersite spinon hopping that survives the large-$z$ limit and lifts the $2^N$-fold degeneracy of the local moments. We show that the spinons are coupled to the doublons/holons by a dissipative compact $U(1)$ gauge field in the deconfined phase, realizing the spin-charge separated gapless spin liquid Mott insulator. ","cond-mat"
"1910.05621","Decoding Working Memory Load from EEG with LSTM Networks","  Working memory (WM) is a mechanism that temporarily stores and manipulates information in service of behavioral goals and is a highly dynamic process. Previous studies have considered decoding WM load using EEG but have not investigated the contribution of sequential information contained in the temporal patterns of the EEG data that can differentiate different WM loads. In our study, we develop a novel method of investigating the role of sequential information in the manipulation and storage of verbal information at various time scales and localize topographically the sources of the sequential information based decodability. High density EEG (128-channel) were recorded from twenty subjects performing a Sternberg verbal WM task with varying memory loads. Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) were trained to decode memory load during encoding, retention, activity-silent, and retrieval periods. Decoding accuracy was compared between ordered data and a temporally shuffled version that retains pattern based information of the data but not temporal relation to assess the contribution of sequential information to decoding memory load. The results show that (1) decoding accuracy increases with increase in the length of the EEG time series given to the LSTM for both ordered and temporally shuffled cases, with the increase being faster for ordered than temporally shuffled time series, and (2) according to the decoding weight maps, the frontal, temporal and some parietal areas are an important source of sequential information based decodability. This study, to our knowledge, is the first study applying a LSTM-RNN approach to investigate temporal dynamics in human EEG data in encoding WM load information. ","q-bio"
"1912.07183","MTRNet++: One-stage Mask-based Scene Text Eraser","  A precise, controllable, interpretable and easily trainable text removal approach is necessary for both user-specific and large-scale text removal applications. To achieve this, we propose a one-stage mask-based text inpainting network, MTRNet++. It has a novel architecture that includes mask-refine, coarse-inpainting and fine-inpainting branches, and attention blocks. With this architecture, MTRNet++ can remove text either with or without an external mask. It achieves state-of-the-art results on both the Oxford and SCUT datasets without using external ground-truth masks. The results of ablation studies demonstrate that the proposed multi-branch architecture with attention blocks is effective and essential. It also demonstrates controllability and interpretability. ","cs"
"1901.01154","Mass Spectrum of Exotic X(5568) State via Artificial Neural Network","  In this paper, we assume $X(5568)$ exist and study mass spectrum of $X(5568)$ resonance and its hypothetical charmed partner, $X_c$, by Artificial Neural Network method. The obtained predictions are compared with the experimental data and results of other theoretical works. ","hep-ph"
"1804.07818","Measurement-induced nonlocal entanglement in a hot, strongly-interacting   atomic system","  Quantum technologies use entanglement to outperform classical technologies, and often employ strong cooling and isolation to protect entangled entities from decoherence by random interactions. Here we show that the opposite strategy - promoting random interactions - can help generate and preserve entanglement. We use optical quantum non-demolition measurement to produce entanglement in a hot alkali vapor, in a regime dominated by random spin-exchange collisions. We use Bayesian statistics and spin-squeezing inequalities to show that at least $1.52(4)\times 10^{13}$ of the $5.32(12) \times 10^{13}$ participating atoms enter into singlet-type entangled states, which persist for tens of spin-thermalization times and span thousands of times the nearest-neighbor distance. The results show that high temperatures and strong random interactions need not destroy many-body quantum coherence, that collective measurement can produce very complex entangled states, and that the hot, strongly-interacting media now in use for extreme atomic sensing are well suited for sensing beyond the standard quantum limit. ","quant-ph"
"1908.03529","Sharp energy regularity and typicality results for H\""older solutions of   incompressible Euler equations","  This paper is devoted to show a couple of typicality results for weak solutions $v\in C^\theta$ of the Euler equations, in the case $\theta<1/3$. It is known that convex integration schemes produce wild weak solutions that exhibit anomalous dissipation of the kinetic energy $e_v$. We show that those solutions are typical in the Baire category sense. From \cite{Is15}, it is know that the kinetic energy $e_v$ of $\theta$-H\""older continuous weak solution $v$ of the Euler equations satisfy $ e_v\in C^{\frac{2\theta}{1-\theta}}$. As a first result we prove that solutions with that behavior are a residual set in suitable complete metric space $X_\theta$, that is contained in the space of all $C^\theta$ weak solutions, whose choice is discussed at the end of the paper. More precisely we show that the set of solutions $v\in X_\theta$ with $e_v \in C^{\frac{2\theta}{1-\theta}}$ but not to $\bigcup_{p\ge 1,\varepsilon>0}W^{\frac{2\theta}{1-\theta} + \varepsilon,p}(I)$ for any open $I \subset [0,T]$, are a residual set in $X_\theta$. This, in particular, partially solves [9, Conjecture 1]. We also show that smooth solutions form a nowhere dense set in the space of all the $C^\theta$ weak solutions. The technique is the same and what really distinguishes the two cases is that in the latter there is no need to introduce a different complete metric space with respect to the natural one. ","math"
"1901.10226","First-passage properties of mortal random walks: ballistic behavior,   effective reduction of dimensionality, and scaling functions for hierarchical   graphs","  We consider a mortal random walker on a family of hierarchical graphs in the presence of some trap sites. The configuration comprising the graph, the starting point of the walk, and the locations of the trap sites is taken to be exactly self-similar as one goes from one generation of the family to the next. Under these circumstances, the total probability that the walker hits a trap is determined exactly as a function of the single-step survival probability $q$ of the mortal walker. On the $n^{\rm th}$ generation graph of the family, this probability is shown to be given by the $n^{\rm th}$ iterate of a certain scaling function or map $q \rightarrow f(q)$. The properties of the map then determine, in each case, the behavior of the trapping probability, the mean time to trapping, the temporal scaling factor governing the random walk dimension on the graph, and other related properties. The formalism is illustrated for the cases of a linear hierarchical lattice and the Sierpinski graphs in $2$ and $3$ Euclidean dimensions. We find an effective reduction of the random walk dimensionality due to the ballistic behavior of the surviving particles induced by the mortality constraint. The relevance of this finding for experiments involving travel times of particles in diffusion-decay systems is discussed. ","cond-mat"
"1902.04705","Self-adaptive Single and Multi-illuminant Estimation Framework based on   Deep Learning","  Illuminant estimation plays a key role in digital camera pipeline system, it aims at reducing color casting effect due to the influence of non-white illuminant. Recent researches handle this task by using Convolution Neural Network (CNN) as a mapping function from input image to a single illumination vector. However, global mapping approaches are difficult to deal with scenes under multi-light-sources. In this paper, we proposed a self-adaptive single and multi-illuminant estimation framework, which includes the following novelties: (1) Learning local self-adaptive kernels from the entire image for illuminant estimation with encoder-decoder CNN structure; (2) Providing confidence measurement for the prediction; (3) Clustering-based iterative fitting for computing single and multi-illumination vectors. The proposed global-to-local aggregation is able to predict multi-illuminant regionally by utilizing global information instead of training in patches, as well as brings significant improvement for single illuminant estimation. We outperform the state-of-the-art methods on standard benchmarks with the largest relative improvement of 16%. In addition, we collect a dataset contains over 13k images for illuminant estimation and evaluation. The code and dataset is available on https://github.com/LiamLYJ/KPF_WB ","cs"
"1907.07978","The Cherenkov Telescope Array Performance in Divergent Mode","  Two of the Key Science Projects of the Cherenkov Telescope Array (CTA) consist in performing a deep survey of the Galactic and Extragalactic sky, providing an unbiased view of the Universe at energies above tens of GeV. To optimize the time spent to perform the Extragalactic survey, a so-called ""divergent mode"" of the CTA was proposed as an alternative observation strategy to the traditional parallel pointing in order to increase its instantaneous field of view. The search for transient VHE sources would also benefit from an extended field of view. In the divergent mode, each telescope points to a position in the sky that is slightly offset, in the outward direction, from the center of the field of view. In this contribution, we present the first performance estimation from full Monte Carlo simulation of possible CTA divergent mode setups. ","astro-ph"
"2005.05305","Speckle interferometry at SOAR in 2019","  The results of speckle interferometric observations at the 4.1 m Southern Astrophysical Research Telescope (SOAR) in 2019 are given, totaling 2555 measurements of 1972 resolved pairs with separations from 15 mas (median 0.21"") and magnitude difference up to 6 mag, and non-resolutions of 684 targets. We resolved for the first time 90 new pairs or subsystems in known binaries. This work continues our long-term speckle program. Its main goal is to monitor orbital motion of close binaries, including members of high-order hierarchies and Hipparcos pairs in the solar neighborhood. We give a list of 127 orbits computed using our latest measurements. Their quality varies from excellent (25 orbits of grades 1 and 2) to provisional (47 orbits of grades 4 and 5). ","astro-ph"
"2005.03100","Mobile Edge Computing and Artificial Intelligence: A Mutually-Beneficial   Relationship","  This article provides an overview of mobile edge computing (MEC) and artificial intelligence (AI) and discusses the mutually-beneficial relationship between them. AI provides revolutionary solutions in nearly every important aspect of the MEC offloading process, such as resource management and scheduling. On the other hand, MEC servers are utilized to avail a distributed and parallelized learning framework, namely mobile edge learning. ","eess"
"1904.12128","Achieve Higher Efficiency at Maximum Power with Finite-time Quantum Otto   Cycle","  The optimization of finite-time thermodynamic heat engines was intensively explored recently, yet limited to few cycles, e.g. finite-time Carnot-like cycle. In this paper, we supplement a new type of finite-time engine with quantum Otto cycle and show the better performance. The current model can be widely utilized benefited from the general \mathcal{C}/\tau^{2} scaling of extra work for finite-time adiabatic process with long control time \tau. Such scaling allows analytical optimization of the generic finite-time quantum Otto cycle to surpass the efficiency at maximum power for the Carnot-like engine. We apply the current perturbation method to the quantum piston model and calculate the efficiency at maximum power, which is validated with exact solution. ","quant-ph"
"1909.01509","Group pre-processing versus cluster ram-pressure stripping: the case of   ESO156-G029","  We report on observations of ESO156-G029, member of a galaxy group which is positioned at the virial radius of cluster Abell 3193. ESO156-G029 is located ~ 1.4 Mpc in projected distance from the brightest cluster galaxy NGC1500. We show that ESO156-G029 has disturbed gas kinematics and a highly asymmetric neutral hydrogen (HI) distribution, which are consequences of group pre-processing, and possibly of ram-pressure. Based on the current data we propose a scenario in which ESO156-G029 had a minor gas-rich merger in the past and now starts to experience ram-pressure. We infer that the galaxy will undergo rapid evolution once it gets closer to the cluster centre (less than 0.5 Mpc) where ram-pressure is strong enough to begin stripping the HI from the galaxy. ","astro-ph"
"1905.00901","Infinite Distances and the Axion Weak Gravity Conjecture","  The axion Weak Gravity Conjecture implies that when parametrically increasing the axion decay constants, instanton corrections become increasingly important. We provide strong evidence for the validity of this conjecture by studying the couplings of R-R axions arising in Calabi-Yau compactifications of Type IIA string theory. Specifically, we consider all possible infinite distance limits in complex structure moduli space and identify the axion decay constants that grow parametrically in a certain path-independent way. We then argue that for each of these limits a tower of D2-brane instantons with decreasing actions can be identified. These instantons ensure that the convex hull condition relevant for the multi-axion Weak Gravity Conjecture cannot be violated parametrically. To argue for the existence of such instantons we employ and generalize recent insights about the Swampland Distance Conjecture. Our results are general and not restricted to specific examples, since we use general results about the growth of the Hodge metric and the sl(2)-splittings of the three-form cohomology associated to each limit. ","hep-th"
"1903.02939","ViTOR: Learning to Rank Webpages Based on Visual Features","  The visual appearance of a webpage carries valuable information about its quality and can be used to improve the performance of learning to rank (LTR). We introduce the Visual learning TO Rank (ViTOR) model that integrates state-of-the-art visual features extraction methods by (i) transfer learning from a pre-trained image classification model, and (ii) synthetic saliency heat maps generated from webpage snapshots. Since there is currently no public dataset for the task of LTR with visual features, we also introduce and release the ViTOR dataset, containing visually rich and diverse webpages. The ViTOR dataset consists of visual snapshots, non-visual features and relevance judgments for ClueWeb12 webpages and TREC Web Track queries. We experiment with the proposed ViTOR model on the ViTOR dataset and show that it significantly improves the performance of LTR with visual features ","cs"
"1909.01336","Universal limitations on implementing resourceful unitary evolutions","  We derive a trade-off relation between the accuracy of implementing a desired unitary evolution using a restricted set of free unitaries and the size of the assisting system, in terms of the resource generating/losing capacity of the target unitary. In particular, this relation implies that, for any theory equipped with a resource measure satisfying lenient conditions, any resource changing unitary cannot be perfectly implemented by a free unitary applied to a system and an environment if the environment has finite dimensions. Our results are applicable to a wide class of resources including energy, asymmetry, coherence, entanglement, and magic, imposing ultimate limitations inherent in such important physical settings, as well as providing insights into operational restrictions in general resource theories. ","quant-ph"
"1901.01887","Non-adiabatic transformation of a spin-chain geometry via local control","  We consider transformation from a closed to an open spin chain and vice versa produced by changing single link strength in a pair of neighboring spins. We show that in the non-adiabatic time domain fidelity of such a process can be increased by proper choosing of the control function for spin-spin exchange coupling. We obtain this function for an antiferromagnetic quantum Ising chain and present heuristic reasons restricting possible time-dependences of Hamiltonians applied for a high-fidelity control. ","quant-ph"
"1904.12370","Compact Fenwick trees for dynamic ranking and selection","  The Fenwick tree is a classical implicit data structure that stores an array in such a way that modifying an element, accessing an element, computing a prefix sum and performing a predecessor search on prefix sums all take logarithmic time. We introduce a number of variants which improve the classical implementation of the tree: in particular, we can reduce its size when an upper bound on the array element is known, and we can perform much faster predecessor searches. Our aim is to use our variants to implement an efficient dynamic bit vector: our structure is able to perform updates, ranking and selection in logarithmic time, with a space overhead in the order of a few percents, outperforming existing data structures with the same purpose. Along the way, we highlight the pernicious interplay between the arithmetic behind the Fenwick tree and the structure of current CPU caches, suggesting simple solutions that improve performance significantly. ","cs"
"1910.03048","Waveform Design using Multi-Tone Feedback Frequency Modulation","  This paper introduces a waveform design method using Multi-Tone Feedback Frequency Modulation (MT-FFM), a generalization of the single oscillator feedback FM method developed by [Tomisawa, 1981]. The MT-FFM utilizes a collection of $K$ harmonically related oscillators each governed by a design parameter $z_k$ which are utilized as a discrete set of parameters that may be modified to generate a richer set of modulation functions than in the single oscillator case. The resulting modulation function is represented using a form of Kapteyn series composed of Generalized Bessel Functions. This paper describes the structure of the MT-FFM waveform, derives the Kapteyn series representation of the waveform's modulation function, and demonstrates the design method with a waveform design example. ","eess"
"2003.02360","The binary mass ratio in the black hole transient MAXI J1820+070","  We present intermediate resolution spectroscopy of the optical counterpart to the black hole X-ray transient MAXI J1820+070 (=ASASSN-18ey) obtained with the OSIRIS spectrograph on the 10.4-m Gran Telescopio Canarias. The observations were performed with the source close to the quiescent state and before the onset of renewed activity in August 2019. We make use of these data and K-type dwarf templates taken with the same instrumental configuration to measure the projected rotational velocity of the donor star. We find $v_{rot} \sin i = 84 \pm 5$ km s$^{-1}$ ($1\!-\!\sigma$), which implies a donor to black-hole mass ratio $q = {M_2}/{M_1} = 0.072 \pm 0.012$ for the case of a tidally locked and Roche-lobe filling donor star. The derived dynamical masses for the stellar components are $M_1 = (5.95 \pm 0.22)\sin ^{-3}i$ $M_\odot$ and $M_2 = (0.43 \pm 0.08) \sin^{-3}i$ $M_\odot$. The use of $q$, combined with estimates of the accretion disk size at the time of the optical spectroscopy, allows us to revise our previous orbital inclination constraints to $66^{\circ} < i < 81^{\circ}$. These values lead to 95% confidence level limits on the masses of $5.73 <M_1(M_\odot) < 8.34$ and $0.28 < M_2(M_\odot) < 0.77$. Adopting instead the $63 \pm 3^{\circ}$ orientation angle of the radio jet as the binary inclination leads to $M_1 = 8.48^{+0.79}_{-0.72} M_\odot$ and $M_2 = 0.61^{+0.13}_{-0.12} M_\odot$ ($1\!-\!\sigma$). ","astro-ph"
"1910.03443","Origin of Giant Stellar Clumps in High-Redshift Galaxies","  We examine the nature of kpc-scale clumps seen in high-redshift galaxies using a suite of cosmological simulations of galaxy formation. We identify rest-frame UV clumps in mock HST images smoothed to 500 pc resolution, and compare them with the intrinsic 3D clumps of young stars identified in the simulations with 100 pc resolution. According to this comparison, we expect that the stellar masses of the observed clumps are overestimated by as much as an order of magnitude, and that the sizes of these clumps are also overestimated by factor of several, due to a combination of spatial resolution and projection. The masses of young stars contributing most of the UV emission can also be overestimated by factor of a few. We find that most clumps of young stars present in a simulation at one time dissolve on a timescale shorter than $\sim$150 Myr. Some clumps with dense cores can last longer but eventually disperse. Most of the clumps are not bound structures, with virial parameter $\alpha_{\rm vir}$ > 1. We find similar results for clumps identified in mock maps of H$\alpha$ emission measure. We examine the predictions for effective clump sizes from the linear theory of gravitational perturbations and conclude that they are inconsistent with being formed by global disc instabilities. Instead, the observed clumps represent random projections of multiple smaller star-forming regions. ","astro-ph"
"1908.09529","CT Field of View Extension Using Combined Channels Extension and Deep   Learning Methods","  This paper proposes a method to extend the field of view of computed tomography images. In a first step, the field of view is increased by extrapolating linearly the outer channels in the sinogram space. The modified sinogram is then used to reconstruct extended field of view (EFoV) images containing artifacts due to the channels extension. In a second step, those artifacts are reduced by a deep learning network in image space. The proposed method has been evaluated on a collection of clinical scans. The resulting volumes have been checked for consistency and plausibility and compared to an existing state of the art EFoV method. ","eess"
"1904.00125","Identifying Solar Flare Precursors Using Time Series of SDO/HMI Images   and SHARP Parameters","  We present several methods towards construction of precursors, which show great promise towards early predictions, of solar flare events in this paper. A data pre-processing pipeline is built to extract useful data from multiple sources, Geostationary Operational Environmental Satellites (GOES) and Solar Dynamics Observatory (SDO)/Helioseismic and Magnetic Imager (HMI), to prepare inputs for machine learning algorithms. Two classification models are presented: classification of flares from quiet times for active regions and classification of strong versus weak flare events. We adopt deep learning algorithms to capture both the spatial and temporal information from HMI magnetogram data. Effective feature extraction and feature selection with raw magnetogram data using deep learning and statistical algorithms enable us to train classification models to achieve almost as good performance as using active region parameters provided in HMI/Space-Weather HMI-Active Region Patch (SHARP) data files. Case studies show a significant increase in the prediction score around 20 hours before strong solar flare events. ","astro-ph"
"1805.11258","Iterative Statistical Linear Regression for Gaussian Smoothing in   Continuous-Time Non-linear Stochastic Dynamic Systems","  This paper considers approximate smoothing for discretely observed non-linear stochastic differential equations. The problem is tackled by developing methods for linearising stochastic differential equations with respect to an arbitrary Gaussian process. Two methods are developed based on 1) taking the limit of statistical linear regression of the discretised process and 2) minimising an upper bound to a cost functional. Their difference is manifested in the diffusion of the approximate processes. This in turn gives novel derivations of pre-existing Gaussian smoothers when Method 1 is used and a new class of Gaussian smoothers when Method 2 is used. Furthermore, based on the aforementioned development the iterative Gaussian smoothers in discrete-time are generalised to the continuous-time setting by iteratively re-linearising the stochastic differential equation with respect to the current Gaussian process approximation to the smoothed process. The method is verified in two challenging tracking problems, a reentry problem and a radar tracked coordinated turn model with state dependent diffusion. The results show that the method has better estimation accuracy than state-of-the-art smoothers. ","stat"
"1901.05474","Detecting Dark Matter with Neutron Star Spectroscopy","  The presence of dark matter has been ascertained through a wealth of astrophysical and cosmological phenomena and its nature is a central puzzle in modern science. Elementary particles stand as the most compelling explanation. They have been intensively searched for at underground laboratories looking for an energy recoil signal and at telescopes sifting for excess events in gamma-ray or cosmic-ray observations. In this work, we investigate a detection method based on spectroscopy measurements of neutron stars. We outline the luminosity and age of neutrons stars whose dark matter scattering off neutrons can heat neutron stars up to a measurable level. We show that in this case neutron star spectroscopy could constitute the best probe for dark matter particles over a wide masses and interactions strength. ","hep-ph"
"1904.05303","Calculation of routing value in MPLS network according to traffic   fractal properties","  Method for calculating routing cost of MPLS network is presented in the work. This method allows to minimize routing cost, taking into account traffic fractal properties, choice of traffic transmission path and quality of service requirements. The method uses values of the Hurst parameter and value of normalized spread of traffic values, which makes it possible to apply it to self-similar and multifractal data streams. ","cs"
"1903.10355","A quantitative study on the role of TKI combined with   Wnt/$\beta$-catenin signaling and IFN-$\alpha$ in the treatment of CML   through deterministic and stochastic approaches","  We propose deterministic and stochastic models for studying the pharmacokinetics of chronic myeloid leukemia (CML), upon administration of IFN-$\alpha$ (the traditional treatment for CML), TKI (the current frontline medication for CML) and Wnt/$\beta$-catenin signaling (the state-of-the art therapeutic breakthrough for CML). To the best of our knowledge, no mathematical model incorporating all these three therapeutic protocols are available in literature. Further, this work introduces a stochastic approach in the study of CML dynamics. The key contributions of this work are: (1) Determination of the patient condition, contingent upon the patient specific model parameters, which leads to prediction of the appropriate patient specific therapeutic dosage. (2) Addressing the question of how the dual therapy of TKI and Wnt/$\beta$-catenin signaling or triple combination of all three, offers potentially improved therapeutic responses, particularly in terms of reduced side effects of TKI or IFN-$\alpha$. (3) Prediction of the likelihood of CML extinction/remission based on the level of CML stem cells at detection. ","q-bio"
"2002.02027","Does Nature use neutral beams for interstellar plasma heating around   compact objects?","  A neutral beam injection technique is employed in all major TOKAMAK facilities for heating of magnetically confined plasma. The question then arises, whether a similar mechanism might work in astrophysical objects? For instance, a hyper-Eddington galactic binary SS433 possesses baryonic jets, moving at a quarter of the speed of light, and observations revealed signs of gas cooling and recombination on sub-pc scales and equally strong signs of powerful energy deposition on much larger scales $\sim$100 pc. Here we consider a model where neutral atoms transport this energy. A sub-relativistic beam of neutral atoms penetrates the interstellar medium, these atoms gradually get ionised and deposit their energy over a region, whose longitudinal dimension is set by the ""ionisation length"". The channel, where the energy is deposited, expands sideways and drives a shock in the lateral direction. Once the density in the channel drops, the heating rate by the beam drops accordingly, and the region of the energy release moves along the direction of the beam. We discuss distinct features associated with this scenario and speculate that such configuration might also boost shock acceleration of the ""pick-up"" protons that arise due to ionisation of neutral atoms both upstream and downstream of the shock. ","astro-ph"
"1812.03001","Spin rotation effects in diffractive electroproduction of heavy   quarkonia","  In this work we present for the first time the comprehensive study of the Melosh spin rotation effects in diffractive electroproduction of S-wave heavy quarkonia off a nucleon target. Such a study has been performed within the color dipole approach using, as an example and a reference point, two popular parametrizations of the dipole cross section and two potentials describing the interaction between Q and bar{Q} and entering in the Schroedinger equation based formalism for determination of the quarkonia wave functions. We find a strong onset of spin rotation effects in 1S charmonium photoproduction which is obviously neglected in present calculations of corresponding cross sections. For photoproduction of radially excited Psi'(2S) these effects are even stronger leading to an increase of the photoproduction cross section by a factor of 2-3 depending on the photon energy. Even in production of radially excited Y'(2S) and Y""(3S) they can not be neglected and cause the 20-30% enhancement of the photoproduction cross section. Finally, we predict that the spin effects vanish gradually with photon virtuality Q^2 following universality properties in production of different heavy quarkonia as a function of Q^2 + M_V^2. ","hep-ph"
"1903.02492","A fast, low-leakage, high-fidelity two-qubit gate for a programmable   superconducting quantum computer","  A common approach to realize conditional-phase (CZ) gates in transmon qubits relies on flux control of the qubit frequency to make computational states interact with non-computational ones using a fast-adiabatic trajectory to minimize leakage. We develop a bipolar flux-pulsing method with two key advantages over the traditional unipolar variant. First, the action of the bipolar pulse is robust to long-timescale linear-dynamical distortions in the flux-control line, facilitating tuneup and ensuring atomic repeatability. Second, the flux symmetry of the transmon Hamiltonian makes the conditional phase and the single-qubit phase of the pulsed qubit first-order insensitive to low-frequency flux noise, increasing fidelity. By harnessing destructive interference to minimize leakage, the bipolar pulse can approach the speed limit set by the exchange coupling. We demonstrate a repeatable, high-fidelity ($99.1\%$), low-leakage ($0.1\%$), and fast ($40~\mathrm{ns}$) CZ gate in a circuit QED quantum processor. Detailed numerical simulations with excellent match to experiment show that leakage is dominated by remaining short-timescale distortions and fidelity is limited by high-frequency flux noise. ","quant-ph"
"1901.02273","Long Short-Term Memory Spatial Transformer Network","  Spatial transformer network has been used in a layered form in conjunction with a convolutional network to enable the model to transform data spatially. In this paper, we propose a combined spatial transformer network (STN) and a Long Short-Term Memory network (LSTM) to classify digits in sequences formed by MINST elements. This LSTM-STN model has a top-down attention mechanism profit from LSTM layer, so that the STN layer can perform short-term independent elements for the statement in the process of spatial transformation, thus avoiding the distortion that may be caused when the entire sequence is spatially transformed. It also avoids the influence of this distortion on the subsequent classification process using convolutional neural networks and achieves a single digit error of 1.6\% compared with 2.2\% of Convolutional Neural Network with STN layer. ","eess"
"1701.04068","The Abraham-Lorentz force and electrodynamics at the classical electron   radius","  The Abraham-Lorentz force is a finite remnant of the UV singular structure of the self interaction of a point charge with its own field. The satisfactory description of such interaction needs a relativistic regulator. This turns out to be a problematic point because the energy of regulated relativistic cutoff theories is unbounded from below. However one can construct point splitting regulators which keep the Abraham-Lorentz force stable. The classical language can be reconciled with QED by pointing out that the effective quantum theory for the electric charge supports a saddle point producing the classical radiation reaction forces. ","hep-th"
